<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8"/>
<title>L++ Utils - Combined Function Dependencies</title>
<script src="https://d3js.org/d3.v7.min.js"></script>
<style>
body { font-family: 'Segoe UI', Arial, sans-serif; margin: 0; padding: 20px; background: #0f0f23; color: #eee; }
h1 { color: #00d4ff; margin-bottom: 5px; font-size: 24px; }
.subtitle { color: #888; margin-bottom: 15px; font-size: 14px; }
#container { display: flex; gap: 20px; height: calc(100vh - 120px); }
#graph { flex: 1; position: relative; }
#sidebar { width: 350px; background: #1a1a2e; padding: 15px; border-radius: 8px; overflow-y: auto; }
svg { background: #16213e; border-radius: 8px; width: 100%; height: 100%; }

/* Node styles */
.node { cursor: pointer; }
.node-module { fill: #2a2a4a; stroke-width: 3; }
.node-function { fill: #3a3a5a; stroke-width: 2; }
.node-dependency { fill: #1a1a3a; stroke: #666; stroke-width: 1; stroke-dasharray: 4; }
.node-label { font-size: 11px; fill: #fff; pointer-events: none; font-weight: 500; }
.node-sublabel { font-size: 9px; fill: #888; pointer-events: none; }

/* Edge styles */
.edge { fill: none; stroke-opacity: 0.6; }
.edge-internal { stroke: #4ecdc4; stroke-width: 2; }
.edge-external { stroke: #f39c12; stroke-width: 1.5; stroke-dasharray: 4; }
.edge-local { stroke: #9b59b6; stroke-width: 2; }
.edge-label { font-size: 8px; fill: #666; pointer-events: none; }

/* Highlight styles */
.highlight { stroke-width: 3 !important; stroke-opacity: 1 !important; }
.dim { opacity: 0.2; }

/* Controls */
.controls { display: flex; gap: 8px; margin-bottom: 10px; flex-wrap: wrap; }
.controls button { background: #3a3a5a; color: #fff; border: 1px solid #555; padding: 6px 12px; border-radius: 4px; cursor: pointer; font-size: 12px; }
.controls button:hover { background: #4a4a6a; }
.controls button.active { background: #00d4ff; color: #000; border-color: #00d4ff; }

/* Module legend */
.module-legend { margin-top: 15px; }
.module-item { display: flex; align-items: center; gap: 8px; padding: 5px 0; cursor: pointer; }
.module-item:hover { background: #2a2a4a; }
.module-dot { width: 12px; height: 12px; border-radius: 3px; }
.module-name { font-size: 12px; }

/* Info panel */
h3 { color: #00d4ff; margin: 15px 0 8px 0; font-size: 14px; border-bottom: 1px solid #333; padding-bottom: 5px; }
.info-section { font-size: 12px; line-height: 1.6; }
.info-label { color: #888; }
.info-value { color: #fff; }

/* Source code panel */
.source-panel { margin-top: 10px; }
.source-code { background: #0d0d1a; border: 1px solid #333; border-radius: 4px; padding: 10px; font-family: 'Consolas', 'Monaco', monospace; font-size: 11px; line-height: 1.4; overflow-x: auto; max-height: 300px; overflow-y: auto; white-space: pre; color: #b8b8b8; }
.source-header { display: flex; justify-content: space-between; align-items: center; margin-bottom: 5px; }
.source-toggle { background: #3a3a5a; color: #fff; border: none; padding: 4px 8px; border-radius: 3px; cursor: pointer; font-size: 10px; }
.source-toggle:hover { background: #4a4a6a; }
.docstring { color: #6a9955; font-style: italic; }
.metric { display: flex; justify-content: space-between; padding: 3px 0; }
.metric-bar { height: 4px; background: #333; border-radius: 2px; margin-top: 2px; }
.metric-fill { height: 100%; border-radius: 2px; }

/* Edge list */
.edge-list { max-height: 200px; overflow-y: auto; }
.edge-item { padding: 4px 0; border-bottom: 1px solid #333; font-size: 11px; }
.edge-item .from { color: #4ecdc4; }
.edge-item .to { color: #f39c12; }
.edge-item .type { color: #666; font-size: 10px; }

/* Tooltip */
#tooltip { position: absolute; background: #1a1a2e; border: 1px solid #00d4ff; padding: 10px; border-radius: 4px; pointer-events: none; display: none; max-width: 300px; z-index: 100; font-size: 11px; }
</style>
</head>
<body>
<h1>L++ Utils - Combined Function Dependencies</h1>
<div class="subtitle">Stackable function dependency visualization • Drag nodes to rearrange • Click to inspect</div>

<div class="controls">
  <button onclick="resetView()">Reset View</button>
  <button onclick="fitToView()">Fit</button>
  <button onclick="toggleLayout('force')" id="btn-force" class="active">Force</button>
  <button onclick="toggleLayout('horizontal')" id="btn-horizontal">Horizontal</button>
  <button onclick="toggleLayout('vertical')" id="btn-vertical">Vertical</button>
  <span style="margin-left: 10px; color: #666">|</span>
  <button onclick="toggleEdgeType('internal')" id="btn-internal" class="active">Internal</button>
  <button onclick="toggleEdgeType('external')" id="btn-external" class="active">External</button>
  <button onclick="toggleEdgeType('local')" id="btn-local" class="active">Local</button>
</div>

<div id="container">
  <div id="graph"><svg></svg></div>
  <div id="sidebar">
    <h3>Modules</h3>
    <div class="module-legend" id="module-legend"></div>

    <h3>Selected Node</h3>
    <div class="info-section" id="node-info">Click a node to see details</div>

    <h3>Source Code</h3>
    <div class="source-panel" id="source-panel">
      <div id="source-content" style="color:#666;font-size:11px">Click a function to view source</div>
    </div>

    <h3>Connections</h3>
    <div class="edge-list" id="edge-list"></div>
  </div>
</div>
<div id="tooltip"></div>

<script>
const nodes = [{"id": "composer_compute", "type": "module", "label": "composer_compute", "metrics": {"fanIn": 16, "fanOut": 4, "instability": 0.2, "internalEdges": 2, "externalCallCount": 24, "localCallCount": 0, "callsByCategory": {"stdlib": 24}, "localDependencies": []}, "moduleColor": "#00d4ff", "moduleName": "composer_compute"}, {"id": "composer_compute.load_parent", "type": "function", "label": "load_parent", "direction": "inbound", "parent": "composer_compute", "line": 25, "endLine": 46, "signature": "(params) -> Dict[]", "docstring": "Load the parent blueprint from a JSON file.", "source": "def load_parent(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Load the parent blueprint from a JSON file.\"\"\"\n    path = params.get(\"path\")\n    if not path:\n        return {\"blueprint\": None, \"path\": None, \"error\": \"No path provided\"}\n\n    try:\n        p = Path(path)\n        if not p.exists():\n            return {\"blueprint\": None, \"path\": None,\n                    \"error\": f\"File not found: {path}\"}\n\n        with open(p) as f:\n            raw = json.load(f)\n\n        bp = _normalize_blueprint(raw)\n        return {\"blueprint\": bp, \"path\": str(p), \"error\": None}\n    except json.JSONDecodeError as e:\n        return {\"blueprint\": None, \"path\": None,\n                \"error\": f\"Invalid JSON: {e}\"}\n    except Exception as e:\n        return {\"blueprint\": None, \"path\": None, \"error\": str(e)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "composer_compute"}, {"id": "composer_compute.load_child", "type": "function", "label": "load_child", "direction": "inbound", "parent": "composer_compute", "line": 49, "endLine": 70, "signature": "(params) -> Dict[]", "docstring": "Load a child blueprint to be embedded.", "source": "def load_child(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Load a child blueprint to be embedded.\"\"\"\n    path = params.get(\"path\")\n    if not path:\n        return {\"blueprint\": None, \"path\": None, \"error\": \"No path provided\"}\n\n    try:\n        p = Path(path)\n        if not p.exists():\n            return {\"blueprint\": None, \"path\": None,\n                    \"error\": f\"File not found: {path}\"}\n\n        with open(p) as f:\n            raw = json.load(f)\n\n        bp = _normalize_blueprint(raw)\n        return {\"blueprint\": bp, \"path\": str(p), \"error\": None}\n    except json.JSONDecodeError as e:\n        return {\"blueprint\": None, \"path\": None,\n                \"error\": f\"Invalid JSON: {e}\"}\n    except Exception as e:\n        return {\"blueprint\": None, \"path\": None, \"error\": str(e)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "composer_compute"}, {"id": "composer_compute.init_embedding", "type": "function", "label": "init_embedding", "direction": "inbound", "parent": "composer_compute", "line": 96, "endLine": 119, "signature": "(params) -> Dict[]", "docstring": "Initialize a new embedding definition.", "source": "def init_embedding(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Initialize a new embedding definition.\"\"\"\n    targetState = params.get(\"target_state\")\n    nsPrefix = params.get(\"namespace_prefix\")\n\n    if not targetState:\n        targetState = \"embedded\"\n\n    if not nsPrefix:\n        nsPrefix = targetState\n\n    embedding = {\n        \"target_state\": targetState,\n        \"namespace_prefix\": nsPrefix,\n        \"child\": None,\n        \"child_path\": None,\n        \"contract\": {\n            \"input_map\": {},\n            \"output_map\": {}\n        },\n        \"event_map\": {}\n    }\n\n    return {\"embedding\": embedding, \"namespace_prefix\": nsPrefix}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "composer_compute"}, {"id": "composer_compute.set_input_contract", "type": "function", "label": "set_input_contract", "direction": "inbound", "parent": "composer_compute", "line": 122, "endLine": 131, "signature": "(params) -> Dict[]", "docstring": "Set the input contract mapping for an embedding.", "source": "def set_input_contract(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Set the input contract mapping for an embedding.\"\"\"\n    embedding = copy.deepcopy(params.get(\"embedding\", {}))\n    inputMap = params.get(\"input_map\", {})\n\n    if not embedding:\n        return {\"embedding\": None}\n\n    embedding[\"contract\"][\"input_map\"] = inputMap\n    return {\"embedding\": embedding}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "composer_compute"}, {"id": "composer_compute.set_output_contract", "type": "function", "label": "set_output_contract", "direction": "inbound", "parent": "composer_compute", "line": 134, "endLine": 143, "signature": "(params) -> Dict[]", "docstring": "Set the output contract mapping for an embedding.", "source": "def set_output_contract(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Set the output contract mapping for an embedding.\"\"\"\n    embedding = copy.deepcopy(params.get(\"embedding\", {}))\n    outputMap = params.get(\"output_map\", {})\n\n    if not embedding:\n        return {\"embedding\": None}\n\n    embedding[\"contract\"][\"output_map\"] = outputMap\n    return {\"embedding\": embedding}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "composer_compute"}, {"id": "composer_compute.set_event_map", "type": "function", "label": "set_event_map", "direction": "inbound", "parent": "composer_compute", "line": 146, "endLine": 155, "signature": "(params) -> Dict[]", "docstring": "Set the event mapping for an embedding.", "source": "def set_event_map(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Set the event mapping for an embedding.\"\"\"\n    embedding = copy.deepcopy(params.get(\"embedding\", {}))\n    eventMap = params.get(\"event_map\", {})\n\n    if not embedding:\n        return {\"embedding\": None}\n\n    embedding[\"event_map\"] = eventMap\n    return {\"embedding\": embedding}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "composer_compute"}, {"id": "composer_compute.finalize_embedding", "type": "function", "label": "finalize_embedding", "direction": "inbound", "parent": "composer_compute", "line": 158, "endLine": 174, "signature": "(params) -> Dict[]", "docstring": "Finalize the current embedding and add to list.", "source": "def finalize_embedding(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Finalize the current embedding and add to list.\"\"\"\n    embedding = copy.deepcopy(params.get(\"embedding\", {}))\n    embeddings = list(params.get(\"embeddings\") or [])\n    childBp = params.get(\"child_blueprint\")\n    childPath = params.get(\"child_path\")\n\n    if not embedding:\n        return {\"embeddings\": embeddings, \"current_embedding\": None}\n\n    # Attach child blueprint to embedding\n    embedding[\"child\"] = childBp\n    embedding[\"child_path\"] = childPath\n\n    embeddings.append(embedding)\n\n    return {\"embeddings\": embeddings, \"current_embedding\": None}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "composer_compute"}, {"id": "composer_compute.compose", "type": "function", "label": "compose", "direction": "inbound", "parent": "composer_compute", "line": 181, "endLine": 209, "signature": "(params) -> Dict[]", "docstring": "Execute the composition - embed child blueprints into parent.", "source": "def compose(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Execute the composition - embed child blueprints into parent.\"\"\"\n    parent = params.get(\"parent\")\n    embeddings = params.get(\"embeddings\", [])\n\n    if not parent:\n        return {\"composed\": None, \"error\": \"No parent blueprint\"}\n\n    if not embeddings:\n        return {\"composed\": None, \"error\": \"No embeddings defined\"}\n\n    try:\n        composed = copy.deepcopy(parent)\n\n        for emb in embeddings:\n            composed = _apply_embedding(composed, emb)\n\n        # Update metadata\n        composed[\"id\"] = f\"{parent.get('id', 'unknown')}_composed\"\n        composed[\"name\"] = f\"{parent.get('name', 'Unknown')} (Composed)\"\n        composed[\"version\"] = _bumpVersion(parent.get(\"version\", \"0.0.0\"))\n        composed[\"description\"] = (\n            f\"Composed blueprint from {parent.get('name')} with \"\n            f\"{len(embeddings)} embedding(s)\"\n        )\n\n        return {\"composed\": composed, \"error\": None}\n    except Exception as e:\n        return {\"composed\": None, \"error\": str(e)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "composer_compute"}, {"id": "composer_compute.validate_composition", "type": "function", "label": "validate_composition", "direction": "inbound", "parent": "composer_compute", "line": 480, "endLine": 522, "signature": "(params) -> Dict[]", "docstring": "Validate the composed blueprint.", "source": "def validate_composition(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Validate the composed blueprint.\"\"\"\n    composed = params.get(\"composed\")\n    parent = params.get(\"parent\")\n    embeddings = params.get(\"embeddings\", [])\n\n    errors = []\n    warnings = []\n\n    if not composed:\n        return {\"result\": {\"errors\": [\"No composed blueprint\"], \"warnings\": []}}\n\n    # 1. Check for circular references\n    circularErrors = _check_circular_references(embeddings)\n    errors.extend(circularErrors)\n\n    # 2. Validate all contracts are satisfied\n    contractErrors = _validate_contracts(composed, embeddings)\n    errors.extend(contractErrors)\n\n    # 3. Check for ID collisions\n    collisionErrors = _check_id_collisions(composed)\n    errors.extend(collisionErrors)\n\n    # 4. Validate all state references\n    stateErrors = _validate_state_references(composed)\n    errors.extend(stateErrors)\n\n    # 5. Check for orphaned elements\n    orphanWarnings = _check_orphaned_elements(composed)\n    warnings.extend(orphanWarnings)\n\n    # 6. Validate entry/terminal states\n    entryErrors = _validate_entry_terminal(composed)\n    errors.extend(entryErrors)\n\n    return {\n        \"result\": {\n            \"errors\": errors,\n            \"warnings\": warnings,\n            \"valid\": len(errors) == 0\n        }\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "composer_compute"}, {"id": "composer_compute.flatten", "type": "function", "label": "flatten", "direction": "inbound", "parent": "composer_compute", "line": 683, "endLine": 694, "signature": "(params) -> Dict[]", "docstring": "Flatten nested compositions (resolve all namespace prefixes).", "source": "def flatten(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Flatten nested compositions (resolve all namespace prefixes).\"\"\"\n    composed = params.get(\"composed\")\n\n    if not composed:\n        return {\"flattened\": None}\n\n    # For now, just return as-is. True flattening would involve\n    # resolving nested compositions recursively.\n    flattened = copy.deepcopy(composed)\n\n    return {\"flattened\": flattened}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "composer_compute"}, {"id": "composer_compute.export_composed", "type": "function", "label": "export_composed", "direction": "inbound", "parent": "composer_compute", "line": 701, "endLine": 721, "signature": "(params) -> Dict[]", "docstring": "Export composed blueprint to file.", "source": "def export_composed(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Export composed blueprint to file.\"\"\"\n    blueprint = params.get(\"blueprint\")\n    path = params.get(\"path\")\n\n    if not blueprint:\n        return {\"path\": None, \"error\": \"No composed blueprint to export\"}\n\n    if not path:\n        return {\"path\": None, \"error\": \"No export path specified\"}\n\n    try:\n        p = Path(path)\n        p.parent.mkdir(parents=True, exist_ok=True)\n\n        with open(p, \"w\") as f:\n            json.dump(blueprint, f, indent=2)\n\n        return {\"path\": str(p), \"error\": None}\n    except Exception as e:\n        return {\"path\": None, \"error\": str(e)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "composer_compute"}, {"id": "composer_compute.load_manifest", "type": "function", "label": "load_manifest", "direction": "inbound", "parent": "composer_compute", "line": 728, "endLine": 836, "signature": "(params) -> Dict[]", "docstring": "Load a composition manifest file.", "source": "def load_manifest(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Load a composition manifest file.\"\"\"\n    path = params.get(\"path\")\n\n    if not path:\n        return {\n            \"manifest\": None,\n            \"parent\": None,\n            \"parent_path\": None,\n            \"embeddings\": None,\n            \"error\": \"No path provided\"\n        }\n\n    try:\n        p = Path(path)\n        if not p.exists():\n            return {\n                \"manifest\": None,\n                \"parent\": None,\n                \"parent_path\": None,\n                \"embeddings\": None,\n                \"error\": f\"File not found: {path}\"\n            }\n\n        with open(p) as f:\n            manifest = json.load(f)\n\n        # Load parent blueprint\n        parentPath = manifest.get(\"parent\")\n        if not parentPath:\n            return {\n                \"manifest\": manifest,\n                \"parent\": None,\n                \"parent_path\": None,\n                \"embeddings\": None,\n                \"error\": \"Manifest missing parent path\"\n            }\n\n        # Resolve relative paths from manifest location\n        manifestDir = p.parent\n        parentFullPath = (manifestDir / parentPath).resolve()\n\n        parentResult = load_parent({\"path\": str(parentFullPath)})\n        if parentResult.get(\"error\"):\n            return {\n                \"manifest\": manifest,\n                \"parent\": None,\n                \"parent_path\": None,\n                \"embeddings\": None,\n                \"error\": parentResult[\"error\"]\n            }\n\n        # Load all child blueprints and build embeddings\n        embeddings = []\n        for embDef in manifest.get(\"embeddings\", []):\n            childPath = embDef.get(\"child\")\n            if not childPath:\n                continue\n\n            childFullPath = (manifestDir / childPath).resolve()\n            childResult = load_child({\"path\": str(childFullPath)})\n            if childResult.get(\"error\"):\n                return {\n                    \"manifest\": manifest,\n                    \"parent\": parentResult[\"blueprint\"],\n                    \"parent_path\": str(parentFullPath),\n                    \"embeddings\": None,\n                    \"error\": f\"Failed to load child: {childResult['error']}\"\n                }\n\n            embedding = {\n                \"target_state\": embDef.get(\"target_state\"),\n                \"namespace_prefix\": embDef.get(\n                    \"namespace_prefix\", embDef.get(\"target_state\")\n                ),\n                \"child\": childResult[\"blueprint\"],\n                \"child_path\": str(childFullPath),\n                \"contract\": embDef.get(\"contract\", {\n                    \"input_map\": {},\n                    \"output_map\": {}\n                }),\n                \"event_map\": embDef.get(\"event_map\", {})\n            }\n            embeddings.append(embedding)\n\n        return {\n            \"manifest\": manifest,\n            \"parent\": parentResult[\"blueprint\"],\n            \"parent_path\": str(parentFullPath),\n            \"embeddings\": embeddings,\n            \"error\": None\n        }\n\n    except json.JSONDecodeError as e:\n        return {\n            \"manifest\": None,\n            \"parent\": None,\n            \"parent_path\": None,\n            \"embeddings\": None,\n            \"error\": f\"Invalid JSON: {e}\"\n        }\n    except Exception as e:\n        return {\n            \"manifest\": None,\n            \"parent\": None,\n            \"parent_path\": None,\n            \"embeddings\": None,\n            \"error\": str(e)\n        }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "composer_compute"}, {"id": "composer_compute.compose_from_manifest", "type": "function", "label": "compose_from_manifest", "direction": "inbound", "parent": "composer_compute", "line": 839, "endLine": 858, "signature": "(params) -> Dict[]", "docstring": "Compose blueprints based on a loaded manifest.", "source": "def compose_from_manifest(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Compose blueprints based on a loaded manifest.\"\"\"\n    manifest = params.get(\"manifest\")\n\n    if not manifest:\n        return {\"composed\": None, \"error\": \"No manifest loaded\"}\n\n    # The manifest should have already triggered loading parent and embeddings\n    # This function is called after load_manifest populates the context\n    # We need to access these from context, but since we're in a compute unit,\n    # we need them passed in\n\n    # Actually, since the blueprint drives the flow, the context will have\n    # parent_blueprint and embeddings populated by load_manifest\n    # But this compute unit is called separately, so we use compose()\n\n    # For manifest-based compose, we should receive parent and embeddings\n    # from the context via the action's input_map\n\n    return {\"composed\": None, \"error\": \"Use compose action after load_manifest\"}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "composer_compute"}, {"id": "composer_compute.generate_manifest", "type": "function", "label": "generate_manifest", "direction": "inbound", "parent": "composer_compute", "line": 861, "endLine": 885, "signature": "(params) -> Dict[]", "docstring": "Generate a composition manifest from current state.", "source": "def generate_manifest(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Generate a composition manifest from current state.\"\"\"\n    parentPath = params.get(\"parent_path\")\n    embeddings = params.get(\"embeddings\", [])\n\n    if not parentPath:\n        return {\"manifest\": None}\n\n    manifest = {\n        \"parent\": parentPath,\n        \"embeddings\": []\n    }\n\n    for emb in embeddings:\n        embDef = {\n            \"target_state\": emb.get(\"target_state\"),\n            \"child\": emb.get(\"child_path\"),\n            \"contract\": emb.get(\"contract\", {}),\n            \"event_map\": emb.get(\"event_map\", {})\n        }\n        if emb.get(\"namespace_prefix\") != emb.get(\"target_state\"):\n            embDef[\"namespace_prefix\"] = emb.get(\"namespace_prefix\")\n        manifest[\"embeddings\"].append(embDef)\n\n    return {\"manifest\": manifest}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "composer_compute"}, {"id": "composer_compute.export_manifest", "type": "function", "label": "export_manifest", "direction": "inbound", "parent": "composer_compute", "line": 888, "endLine": 908, "signature": "(params) -> Dict[]", "docstring": "Export composition manifest to file.", "source": "def export_manifest(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Export composition manifest to file.\"\"\"\n    manifest = params.get(\"manifest\")\n    path = params.get(\"path\")\n\n    if not manifest:\n        return {\"path\": None, \"error\": \"No manifest to export\"}\n\n    if not path:\n        return {\"path\": None, \"error\": \"No export path specified\"}\n\n    try:\n        p = Path(path)\n        p.parent.mkdir(parents=True, exist_ok=True)\n\n        with open(p, \"w\") as f:\n            json.dump(manifest, f, indent=2)\n\n        return {\"path\": str(p), \"error\": None}\n    except Exception as e:\n        return {\"path\": None, \"error\": str(e)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "composer_compute"}, {"id": "composer_compute.clear_all", "type": "function", "label": "clear_all", "direction": "inbound", "parent": "composer_compute", "line": 911, "endLine": 921, "signature": "(params) -> Dict[]", "docstring": "Clear all state.", "source": "def clear_all(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Clear all state.\"\"\"\n    return {\n        \"parent_blueprint\": None,\n        \"child_blueprint\": None,\n        \"embeddings\": None,\n        \"current_embedding\": None,\n        \"composed_blueprint\": None,\n        \"validation_result\": None,\n        \"manifest\": None\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "composer_compute"}, {"id": "json", "type": "dependency", "label": "json", "direction": "outbound", "category": "stdlib", "moduleColor": "#00d4ff", "moduleName": "composer_compute"}, {"id": "copy", "type": "dependency", "label": "copy", "direction": "outbound", "category": "stdlib", "moduleColor": "#00d4ff", "moduleName": "composer_compute"}, {"id": "pathlib", "type": "dependency", "label": "pathlib", "direction": "outbound", "category": "stdlib", "moduleColor": "#00d4ff", "moduleName": "composer_compute"}, {"id": "typing", "type": "dependency", "label": "typing", "direction": "outbound", "category": "stdlib", "moduleColor": "#00d4ff", "moduleName": "composer_compute"}, {"id": "debugger_compute", "type": "module", "label": "debugger_compute", "metrics": {"fanIn": 21, "fanOut": 8, "instability": 0.276, "internalEdges": 5, "externalCallCount": 25, "localCallCount": 0, "callsByCategory": {"stdlib": 19, "pip": 6}, "localDependencies": []}, "moduleColor": "#ff6b6b", "moduleName": "debugger_compute"}, {"id": "debugger_compute.load_blueprint", "type": "function", "label": "load_blueprint", "direction": "inbound", "parent": "debugger_compute", "line": 23, "endLine": 98, "signature": "(params) -> Dict[]", "docstring": "Load an L++ blueprint from a JSON file for debugging.", "source": "def load_blueprint(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Load an L++ blueprint from a JSON file for debugging.\"\"\"\n    path = params.get(\"path\")\n    if not path:\n        return {\"blueprint\": None, \"error\": \"No path provided\"}\n\n    try:\n        path = Path(path)\n        if not path.exists():\n            return {\"blueprint\": None, \"error\": f\"File not found: {path}\"}\n\n        with open(path) as f:\n            raw = json.load(f)\n\n        loader = BlueprintLoader(raw)\n        blueprint, load_error = loader.load()\n\n        if load_error:\n            return {\"blueprint\": None, \"error\": load_error}\n\n        # Convert to dict structure for debugging\n        bp_data = {\n            \"id\": blueprint.id,\n            \"name\": blueprint.name,\n            \"version\": blueprint.version,\n            \"description\": blueprint.description,\n            \"entry_state\": blueprint.entry_state,\n            \"terminal_states\": list(blueprint.terminal_states),\n            \"states\": {\n                sid: {\n                    \"description\": s.description,\n                    \"on_enter\": list(s.on_enter),\n                    \"on_exit\": list(s.on_exit)\n                } for sid, s in blueprint.states.items()\n            },\n            \"transitions\": [\n                {\n                    \"id\": t.id,\n                    \"from\": t.from_state,\n                    \"to\": t.to_state,\n                    \"on_event\": t.on_event,\n                    \"gates\": list(t.gates),\n                    \"actions\": list(t.actions)\n                }\n                for t in blueprint.transitions\n            ],\n            \"gates\": {\n                gid: {\n                    \"type\": g.type.value,\n                    \"expression\": g.expression,\n                    \"compute_unit\": g.compute_unit\n                } for gid, g in blueprint.gates.items()\n            },\n            \"actions\": {\n                aid: {\n                    \"type\": a.type.value,\n                    \"target\": a.target,\n                    \"value\": a.value,\n                    \"value_from\": a.value_from,\n                    \"compute_unit\": a.compute_unit,\n                    \"input_map\": a.input_map,\n                    \"output_map\": a.output_map\n                } for aid, a in blueprint.actions.items()\n            },\n            \"context_schema\": raw.get(\"context_schema\", {})\n        }\n\n        return {\n            \"blueprint\": bp_data,\n            \"blueprint_path\": str(path),\n            \"blueprint_name\": blueprint.name,\n            \"blueprint_id\": blueprint.id,\n            \"error\": None\n        }\n    except Exception as e:\n        return {\"blueprint\": None, \"error\": str(e)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#ff6b6b", "moduleName": "debugger_compute"}, {"id": "debugger_compute.init_debug_session", "type": "function", "label": "init_debug_session", "direction": "inbound", "parent": "debugger_compute", "line": 105, "endLine": 144, "signature": "(params) -> Dict[]", "docstring": "Initialize a debug session from blueprint.", "source": "def init_debug_session(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Initialize a debug session from blueprint.\"\"\"\n    bp = params.get(\"blueprint\")\n    if not bp:\n        return {\"error\": \"No blueprint provided\"}\n\n    # Initialize context from schema\n    ctx = {\"_state\": bp[\"entry_state\"]}\n    schema = bp.get(\"context_schema\", {})\n    for prop in schema.get(\"properties\", {}).keys():\n        ctx[prop] = None\n\n    # Get available transitions\n    avail = _get_available_transitions(bp, bp[\"entry_state\"], ctx)\n\n    # Create initial history entry\n    history = [{\n        \"step\": 0,\n        \"timestamp\": datetime.now().isoformat(),\n        \"state\": bp[\"entry_state\"],\n        \"context\": copy.deepcopy(ctx),\n        \"event\": None,\n        \"transition_id\": None,\n        \"gate_results\": {},\n        \"action_results\": []\n    }]\n\n    return {\n        \"debug_state\": bp[\"entry_state\"],\n        \"debug_context\": ctx,\n        \"history\": history,\n        \"history_index\": 0,\n        \"breakpoints\": [],\n        \"watches\": [],\n        \"watch_values\": {},\n        \"available_events\": [t[\"event\"] for t in avail],\n        \"available_transitions\": avail,\n        \"is_paused\": False,\n        \"output\": f\"Debug session started at state: {bp['entry_state']}\"\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#ff6b6b", "moduleName": "debugger_compute"}, {"id": "debugger_compute.reset_session", "type": "function", "label": "reset_session", "direction": "inbound", "parent": "debugger_compute", "line": 147, "endLine": 160, "signature": "(params) -> Dict[]", "docstring": "Reset debug session to initial state, preserving breakpoints.", "source": "def reset_session(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Reset debug session to initial state, preserving breakpoints.\"\"\"\n    bp = params.get(\"blueprint\")\n    breakpoints = params.get(\"breakpoints\", [])\n    watches = params.get(\"watches\", [])\n\n    if not bp:\n        return {\"error\": \"No blueprint provided\"}\n\n    result = init_debug_session({\"blueprint\": bp})\n    result[\"breakpoints\"] = breakpoints\n    result[\"watches\"] = watches\n    result[\"output\"] = f\"Session reset to initial state: {bp['entry_state']}\"\n    return result", "args": ["params"], "returns": "Dict[]", "moduleColor": "#ff6b6b", "moduleName": "debugger_compute"}, {"id": "debugger_compute.set_breakpoint", "type": "function", "label": "set_breakpoint", "direction": "inbound", "parent": "debugger_compute", "line": 167, "endLine": 202, "signature": "(params) -> Dict[]", "docstring": "Add a breakpoint.", "source": "def set_breakpoint(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Add a breakpoint.\"\"\"\n    breakpoints = params.get(\"breakpoints\", [])\n    bp_type = params.get(\"bp_type\", \"state\")\n    target = params.get(\"target\")\n    condition = params.get(\"condition\")\n\n    if not target:\n        return {\n            \"breakpoints\": breakpoints,\n            \"output\": \"Error: breakpoint target required\"\n        }\n\n    # Validate breakpoint type\n    valid_types = [\"state\", \"transition\", \"gate\", \"event\", \"conditional\"]\n    if bp_type not in valid_types:\n        return {\n            \"breakpoints\": breakpoints,\n            \"output\": f\"Error: invalid type. Use: {valid_types}\"\n        }\n\n    bp_id = f\"bp_{len(breakpoints) + 1}_{uuid.uuid4().hex[:6]}\"\n    new_bp = {\n        \"id\": bp_id,\n        \"type\": bp_type,\n        \"target\": target,\n        \"condition\": condition,\n        \"enabled\": True,\n        \"hit_count\": 0\n    }\n\n    new_breakpoints = breakpoints + [new_bp]\n    return {\n        \"breakpoints\": new_breakpoints,\n        \"output\": f\"Breakpoint {bp_id} set: {bp_type} on '{target}'\"\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#ff6b6b", "moduleName": "debugger_compute"}, {"id": "debugger_compute.remove_breakpoint", "type": "function", "label": "remove_breakpoint", "direction": "inbound", "parent": "debugger_compute", "line": 205, "endLine": 231, "signature": "(params) -> Dict[]", "docstring": "Remove a breakpoint by ID or index.", "source": "def remove_breakpoint(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Remove a breakpoint by ID or index.\"\"\"\n    breakpoints = params.get(\"breakpoints\", [])\n    bp_id = params.get(\"bp_id\")\n\n    if not bp_id:\n        return {\"breakpoints\": breakpoints, \"output\": \"Error: bp_id required\"}\n\n    # Try by ID first, then by index\n    new_breakpoints = []\n    removed = False\n    for i, bp in enumerate(breakpoints):\n        if bp[\"id\"] == bp_id or str(i) == str(bp_id):\n            removed = True\n        else:\n            new_breakpoints.append(bp)\n\n    if removed:\n        return {\n            \"breakpoints\": new_breakpoints,\n            \"output\": f\"Breakpoint {bp_id} removed\"\n        }\n    else:\n        return {\n            \"breakpoints\": breakpoints,\n            \"output\": f\"Breakpoint {bp_id} not found\"\n        }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#ff6b6b", "moduleName": "debugger_compute"}, {"id": "debugger_compute.list_breakpoints", "type": "function", "label": "list_breakpoints", "direction": "inbound", "parent": "debugger_compute", "line": 234, "endLine": 252, "signature": "(params) -> Dict[]", "docstring": "List all breakpoints.", "source": "def list_breakpoints(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"List all breakpoints.\"\"\"\n    breakpoints = params.get(\"breakpoints\", [])\n\n    if not breakpoints:\n        return {\"output\": \"No breakpoints set\"}\n\n    lines = [\"Breakpoints:\", \"=\" * 50]\n    for i, bp in enumerate(breakpoints):\n        status = \"ON\" if bp.get(\"enabled\", True) else \"OFF\"\n        cond = f\" when: {bp['condition']}\" if bp.get(\"condition\") else \"\"\n        hits = bp.get(\"hit_count\", 0)\n        lines.append(\n            f\"  [{i}] {bp['id']} [{status}] \"\n            f\"{bp['type']}:{bp['target']}{cond} (hits: {hits})\"\n        )\n    lines.append(\"=\" * 50)\n\n    return {\"output\": \"\\n\".join(lines)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#ff6b6b", "moduleName": "debugger_compute"}, {"id": "debugger_compute.step", "type": "function", "label": "step", "direction": "inbound", "parent": "debugger_compute", "line": 440, "endLine": 582, "signature": "(params) -> Dict[]", "docstring": "Execute one step (event/transition) with full details.", "source": "def step(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Execute one step (event/transition) with full details.\"\"\"\n    bp = params.get(\"blueprint\")\n    state = params.get(\"debug_state\")\n    ctx = params.get(\"debug_context\", {})\n    history = params.get(\"history\", [])\n    history_index = params.get(\"history_index\", 0)\n    breakpoints = params.get(\"breakpoints\", [])\n    watches = params.get(\"watches\", [])\n    event_name = params.get(\"event_name\")\n    event_payload = params.get(\"event_payload\", {})\n\n    if not bp or not state:\n        return {\"error\": \"No blueprint or state\"}\n\n    if not event_name:\n        # Get first available event\n        avail = _get_available_transitions(bp, state, ctx)\n        if not avail:\n            return {\n                \"debug_state\": state,\n                \"debug_context\": ctx,\n                \"history\": history,\n                \"history_index\": history_index,\n                \"output\": \"No available transitions from current state\",\n                \"error\": \"No transitions available\"\n            }\n        event_name = avail[0][\"event\"]\n\n    # Find matching transition\n    eval_ctx = copy.deepcopy(ctx)\n    eval_ctx[\"_state\"] = state\n\n    matched = None\n    gate_results = {}\n\n    for t in bp[\"transitions\"]:\n        if t[\"on_event\"] != event_name:\n            continue\n        if t[\"from\"] != \"*\" and t[\"from\"] != state:\n            continue\n\n        # Evaluate gates\n        gates_pass = True\n        for gate_id in t.get(\"gates\", []):\n            result, details = _evaluate_gate(bp, gate_id, eval_ctx)\n            gate_results[gate_id] = details\n            if not result:\n                gates_pass = False\n                break\n\n        if gates_pass:\n            matched = t\n            break\n\n    if not matched:\n        return {\n            \"debug_state\": state,\n            \"debug_context\": ctx,\n            \"history\": history,\n            \"history_index\": history_index,\n            \"last_gate_results\": gate_results,\n            \"available_events\": [],\n            \"available_transitions\": [],\n            \"output\": f\"No matching transition for event '{event_name}'\",\n            \"error\": f\"No transition for {event_name} from {state}\"\n        }\n\n    # Execute actions\n    new_ctx = copy.deepcopy(ctx)\n    action_results = []\n    for action_id in matched.get(\"actions\", []):\n        new_ctx, details = _execute_action(bp, action_id, new_ctx, event_payload)\n        action_results.append(details)\n\n    # Transition to new state\n    new_state = matched[\"to\"]\n    new_ctx[\"_state\"] = new_state\n\n    # Create history entry\n    new_history = history[:history_index + 1]  # Truncate if we stepped back\n    step_num = len(new_history)\n    new_history.append({\n        \"step\": step_num,\n        \"timestamp\": datetime.now().isoformat(),\n        \"state\": new_state,\n        \"prev_state\": state,\n        \"context\": copy.deepcopy(new_ctx),\n        \"event\": event_name,\n        \"event_payload\": event_payload,\n        \"transition_id\": matched[\"id\"],\n        \"gate_results\": gate_results,\n        \"action_results\": action_results\n    })\n    new_index = step_num\n\n    # Check breakpoints\n    hit_bp = None\n    is_paused = False\n    for bp_item in breakpoints:\n        if _check_breakpoint(bp_item, new_state, matched, event_name, new_ctx):\n            bp_item[\"hit_count\"] = bp_item.get(\"hit_count\", 0) + 1\n            hit_bp = bp_item\n            is_paused = True\n            break\n\n    # Get new available transitions\n    avail = _get_available_transitions(bp, new_state, new_ctx)\n\n    # Update watches\n    watch_values = _update_watches(watches, new_ctx)\n\n    # Build output\n    lines = [\n        f\"Step {step_num}: {state} --[{event_name}]--> {new_state}\"\n    ]\n    if action_results:\n        lines.append(f\"  Actions: {[a['action_id'] for a in action_results]}\")\n    if hit_bp:\n        lines.append(f\"  ** BREAKPOINT HIT: {hit_bp['id']} **\")\n\n    return {\n        \"debug_state\": new_state,\n        \"debug_context\": new_ctx,\n        \"history\": new_history,\n        \"history_index\": new_index,\n        \"available_events\": [t[\"event\"] for t in avail],\n        \"available_transitions\": avail,\n        \"last_transition\": {\n            \"id\": matched[\"id\"],\n            \"from\": state,\n            \"to\": new_state,\n            \"event\": event_name,\n            \"actions\": matched.get(\"actions\", [])\n        },\n        \"last_gate_results\": gate_results,\n        \"last_action_results\": action_results,\n        \"watch_values\": watch_values,\n        \"is_paused\": is_paused,\n        \"hit_breakpoint\": hit_bp,\n        \"output\": \"\\n\".join(lines),\n        \"error\": None\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#ff6b6b", "moduleName": "debugger_compute"}, {"id": "debugger_compute.step_over", "type": "function", "label": "step_over", "direction": "inbound", "parent": "debugger_compute", "line": 585, "endLine": 591, "signature": "(params) -> Dict[]", "docstring": "Step over (execute without action details).", "source": "def step_over(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Step over (execute without action details).\"\"\"\n    result = step(params)\n    # Clear detailed action results for step_over\n    result[\"last_gate_results\"] = {}\n    result[\"last_action_results\"] = []\n    return result", "args": ["params"], "returns": "Dict[]", "moduleColor": "#ff6b6b", "moduleName": "debugger_compute"}, {"id": "debugger_compute.step_back", "type": "function", "label": "step_back", "direction": "inbound", "parent": "debugger_compute", "line": 594, "endLine": 621, "signature": "(params) -> Dict[]", "docstring": "Step back to previous history entry.", "source": "def step_back(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Step back to previous history entry.\"\"\"\n    history = params.get(\"history\", [])\n    history_index = params.get(\"history_index\", 0)\n    bp = params.get(\"blueprint\")\n    watches = params.get(\"watches\", [])\n\n    if history_index <= 0:\n        return {\"output\": \"Cannot step back - at initial state\"}\n\n    new_index = history_index - 1\n    prev_entry = history[new_index]\n\n    state = prev_entry[\"state\"]\n    ctx = copy.deepcopy(prev_entry[\"context\"])\n\n    avail = _get_available_transitions(bp, state, ctx) if bp else []\n    watch_values = _update_watches(watches, ctx)\n\n    return {\n        \"debug_state\": state,\n        \"debug_context\": ctx,\n        \"history_index\": new_index,\n        \"available_events\": [t[\"event\"] for t in avail],\n        \"available_transitions\": avail,\n        \"watch_values\": watch_values,\n        \"output\": f\"Stepped back to step {new_index}: state '{state}'\"\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#ff6b6b", "moduleName": "debugger_compute"}, {"id": "debugger_compute.run_to_breakpoint", "type": "function", "label": "run_to_breakpoint", "direction": "inbound", "parent": "debugger_compute", "line": 628, "endLine": 711, "signature": "(params) -> Dict[]", "docstring": "Run until a breakpoint is hit or terminal state reached.", "source": "def run_to_breakpoint(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Run until a breakpoint is hit or terminal state reached.\"\"\"\n    bp = params.get(\"blueprint\")\n    state = params.get(\"debug_state\")\n    ctx = params.get(\"debug_context\", {})\n    history = params.get(\"history\", [])\n    history_index = params.get(\"history_index\", 0)\n    breakpoints = params.get(\"breakpoints\", [])\n    watches = params.get(\"watches\", [])\n    max_steps = params.get(\"max_steps\", 1000)\n\n    if not bp:\n        return {\"error\": \"No blueprint\"}\n\n    current_state = state\n    current_ctx = copy.deepcopy(ctx)\n    current_history = copy.deepcopy(history)\n    current_index = history_index\n    steps_taken = 0\n    hit_bp = None\n\n    while steps_taken < max_steps:\n        # Check if at terminal state\n        if current_state in bp.get(\"terminal_states\", []):\n            break\n\n        # Get available transitions\n        avail = _get_available_transitions(bp, current_state, current_ctx)\n        if not avail:\n            break\n\n        # Take first available transition\n        event_name = avail[0][\"event\"]\n\n        result = step({\n            \"blueprint\": bp,\n            \"debug_state\": current_state,\n            \"debug_context\": current_ctx,\n            \"history\": current_history,\n            \"history_index\": current_index,\n            \"breakpoints\": breakpoints,\n            \"watches\": watches,\n            \"event_name\": event_name,\n            \"event_payload\": {}\n        })\n\n        if result.get(\"error\"):\n            break\n\n        current_state = result[\"debug_state\"]\n        current_ctx = result[\"debug_context\"]\n        current_history = result[\"history\"]\n        current_index = result[\"history_index\"]\n        steps_taken += 1\n\n        if result.get(\"hit_breakpoint\"):\n            hit_bp = result[\"hit_breakpoint\"]\n            break\n\n    avail = _get_available_transitions(bp, current_state, current_ctx)\n    watch_values = _update_watches(watches, current_ctx)\n\n    lines = [f\"Ran {steps_taken} steps\"]\n    if hit_bp:\n        lines.append(f\"Stopped at breakpoint: {hit_bp['id']}\")\n    elif current_state in bp.get(\"terminal_states\", []):\n        lines.append(f\"Reached terminal state: {current_state}\")\n    elif not avail:\n        lines.append(f\"No available transitions at: {current_state}\")\n    lines.append(f\"Current state: {current_state}\")\n\n    return {\n        \"debug_state\": current_state,\n        \"debug_context\": current_ctx,\n        \"history\": current_history,\n        \"history_index\": current_index,\n        \"available_events\": [t[\"event\"] for t in avail],\n        \"available_transitions\": avail,\n        \"watch_values\": watch_values,\n        \"is_paused\": hit_bp is not None,\n        \"hit_breakpoint\": hit_bp,\n        \"output\": \"\\n\".join(lines),\n        \"error\": None\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#ff6b6b", "moduleName": "debugger_compute"}, {"id": "debugger_compute.continue_execution", "type": "function", "label": "continue_execution", "direction": "inbound", "parent": "debugger_compute", "line": 714, "endLine": 764, "signature": "(params) -> Dict[]", "docstring": "Continue execution after a breakpoint.", "source": "def continue_execution(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Continue execution after a breakpoint.\"\"\"\n    # First step past current position, then run to next breakpoint\n    bp = params.get(\"blueprint\")\n    state = params.get(\"debug_state\")\n    ctx = params.get(\"debug_context\", {})\n    history = params.get(\"history\", [])\n    history_index = params.get(\"history_index\", 0)\n    breakpoints = params.get(\"breakpoints\", [])\n    watches = params.get(\"watches\", [])\n\n    # Get available transitions\n    avail = _get_available_transitions(bp, state, ctx)\n    if not avail:\n        return {\n            \"debug_state\": state,\n            \"debug_context\": ctx,\n            \"history\": history,\n            \"history_index\": history_index,\n            \"output\": \"No transitions available to continue\",\n            \"error\": \"Cannot continue - no available transitions\"\n        }\n\n    # Take one step without checking breakpoints\n    event_name = avail[0][\"event\"]\n    step_result = step({\n        \"blueprint\": bp,\n        \"debug_state\": state,\n        \"debug_context\": ctx,\n        \"history\": history,\n        \"history_index\": history_index,\n        \"breakpoints\": [],  # Skip breakpoint check for first step\n        \"watches\": watches,\n        \"event_name\": event_name,\n        \"event_payload\": {}\n    })\n\n    if step_result.get(\"error\"):\n        return step_result\n\n    # Now run to next breakpoint\n    return run_to_breakpoint({\n        \"blueprint\": bp,\n        \"debug_state\": step_result[\"debug_state\"],\n        \"debug_context\": step_result[\"debug_context\"],\n        \"history\": step_result[\"history\"],\n        \"history_index\": step_result[\"history_index\"],\n        \"breakpoints\": breakpoints,\n        \"watches\": watches,\n        \"max_steps\": 1000\n    })", "args": ["params"], "returns": "Dict[]", "moduleColor": "#ff6b6b", "moduleName": "debugger_compute"}, {"id": "debugger_compute.inspect_state", "type": "function", "label": "inspect_state", "direction": "inbound", "parent": "debugger_compute", "line": 771, "endLine": 804, "signature": "(params) -> Dict[]", "docstring": "Inspect current state details.", "source": "def inspect_state(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Inspect current state details.\"\"\"\n    bp = params.get(\"blueprint\")\n    state = params.get(\"debug_state\")\n    avail_trans = params.get(\"available_transitions\", [])\n\n    if not bp or not state:\n        return {\"output\": \"No state to inspect\"}\n\n    state_info = bp[\"states\"].get(state, {})\n\n    lines = [\n        \"State Inspection:\",\n        \"=\" * 50,\n        f\"  State: {state}\",\n        f\"  Description: {state_info.get('description', 'N/A')}\",\n    ]\n\n    if state in bp.get(\"terminal_states\", []):\n        lines.append(\"  [TERMINAL STATE]\")\n\n    if state == bp.get(\"entry_state\"):\n        lines.append(\"  [ENTRY STATE]\")\n\n    lines.append(\"\")\n    lines.append(f\"  Available Transitions ({len(avail_trans)}):\")\n    for t in avail_trans:\n        gates = t.get(\"gates\", [])\n        gate_str = f\" [gates: {gates}]\" if gates else \"\"\n        lines.append(f\"    {t['event']}: -> {t['to']}{gate_str}\")\n\n    lines.append(\"=\" * 50)\n\n    return {\"output\": \"\\n\".join(lines)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#ff6b6b", "moduleName": "debugger_compute"}, {"id": "debugger_compute.inspect_context", "type": "function", "label": "inspect_context", "direction": "inbound", "parent": "debugger_compute", "line": 807, "endLine": 825, "signature": "(params) -> Dict[]", "docstring": "Inspect context values.", "source": "def inspect_context(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Inspect context values.\"\"\"\n    ctx = params.get(\"debug_context\", {})\n    key = params.get(\"key\")\n\n    if key:\n        value = ctx.get(key, \"<not found>\")\n        return {\"output\": f\"{key} = {json.dumps(value, default=str)}\"}\n\n    lines = [\"Context:\", \"=\" * 50]\n    for k, v in ctx.items():\n        if k != \"_state\":\n            val_str = json.dumps(v, default=str)\n            if len(val_str) > 60:\n                val_str = val_str[:57] + \"...\"\n            lines.append(f\"  {k}: {val_str}\")\n    lines.append(\"=\" * 50)\n\n    return {\"output\": \"\\n\".join(lines)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#ff6b6b", "moduleName": "debugger_compute"}, {"id": "debugger_compute.evaluate_expression", "type": "function", "label": "evaluate_expression", "direction": "inbound", "parent": "debugger_compute", "line": 828, "endLine": 847, "signature": "(params) -> Dict[]", "docstring": "Evaluate an expression in current context.", "source": "def evaluate_expression(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Evaluate an expression in current context.\"\"\"\n    ctx = params.get(\"debug_context\", {})\n    expression = params.get(\"expression\")\n\n    if not expression:\n        return {\"output\": \"No expression provided\"}\n\n    try:\n        # Try as boolean expression first\n        result, error = safe_eval_bool(expression, ctx)\n        if error:\n            # Try as value expression\n            try:\n                result = eval(expression, {\"__builtins__\": {}}, ctx)\n            except Exception as e:\n                return {\"output\": f\"Error: {e}\"}\n        return {\"output\": f\"{expression} = {result}\"}\n    except Exception as e:\n        return {\"output\": f\"Error evaluating: {e}\"}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#ff6b6b", "moduleName": "debugger_compute"}, {"id": "debugger_compute.add_watch", "type": "function", "label": "add_watch", "direction": "inbound", "parent": "debugger_compute", "line": 854, "endLine": 874, "signature": "(params) -> Dict[]", "docstring": "Add a watch expression.", "source": "def add_watch(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Add a watch expression.\"\"\"\n    watches = params.get(\"watches\", [])\n    expression = params.get(\"expression\")\n    name = params.get(\"name\")\n\n    if not expression:\n        return {\"watches\": watches, \"output\": \"Error: expression required\"}\n\n    watch_id = name or f\"watch_{len(watches) + 1}\"\n    new_watch = {\n        \"id\": watch_id,\n        \"name\": name or expression[:20],\n        \"expression\": expression\n    }\n\n    new_watches = watches + [new_watch]\n    return {\n        \"watches\": new_watches,\n        \"output\": f\"Watch added: {watch_id} = {expression}\"\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#ff6b6b", "moduleName": "debugger_compute"}, {"id": "debugger_compute.remove_watch", "type": "function", "label": "remove_watch", "direction": "inbound", "parent": "debugger_compute", "line": 877, "endLine": 889, "signature": "(params) -> Dict[]", "docstring": "Remove a watch expression.", "source": "def remove_watch(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Remove a watch expression.\"\"\"\n    watches = params.get(\"watches\", [])\n    watch_id = params.get(\"watch_id\")\n\n    if not watch_id:\n        return {\"watches\": watches, \"output\": \"Error: watch_id required\"}\n\n    new_watches = [w for w in watches if w[\"id\"] != watch_id]\n    if len(new_watches) == len(watches):\n        return {\"watches\": watches, \"output\": f\"Watch {watch_id} not found\"}\n\n    return {\"watches\": new_watches, \"output\": f\"Watch {watch_id} removed\"}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#ff6b6b", "moduleName": "debugger_compute"}, {"id": "debugger_compute.get_watches", "type": "function", "label": "get_watches", "direction": "inbound", "parent": "debugger_compute", "line": 892, "endLine": 909, "signature": "(params) -> Dict[]", "docstring": "Get current watch values.", "source": "def get_watches(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Get current watch values.\"\"\"\n    watches = params.get(\"watches\", [])\n    ctx = params.get(\"debug_context\", {})\n\n    if not watches:\n        return {\"watch_values\": {}, \"output\": \"No watches set\"}\n\n    watch_values = _update_watches(watches, ctx)\n\n    lines = [\"Watches:\", \"=\" * 50]\n    for watch in watches:\n        wid = watch[\"id\"]\n        val = watch_values.get(wid, \"<unknown>\")\n        lines.append(f\"  {wid}: {watch['expression']} = {val}\")\n    lines.append(\"=\" * 50)\n\n    return {\"watch_values\": watch_values, \"output\": \"\\n\".join(lines)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#ff6b6b", "moduleName": "debugger_compute"}, {"id": "debugger_compute.get_history", "type": "function", "label": "get_history", "direction": "inbound", "parent": "debugger_compute", "line": 916, "endLine": 941, "signature": "(params) -> Dict[]", "docstring": "Get execution history.", "source": "def get_history(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Get execution history.\"\"\"\n    history = params.get(\"history\", [])\n    history_index = params.get(\"history_index\", 0)\n\n    if not history:\n        return {\"output\": \"No history recorded\"}\n\n    lines = [\"Execution History:\", \"=\" * 50]\n    for entry in history:\n        step_num = entry.get(\"step\", 0)\n        state = entry.get(\"state\", \"?\")\n        event = entry.get(\"event\")\n        prev = entry.get(\"prev_state\")\n\n        marker = \" <--\" if step_num == history_index else \"\"\n\n        if event:\n            lines.append(f\"  [{step_num}] {prev} --[{event}]--> {state}{marker}\")\n        else:\n            lines.append(f\"  [{step_num}] Initial: {state}{marker}\")\n\n    lines.append(\"=\" * 50)\n    lines.append(f\"Current position: step {history_index}\")\n\n    return {\"output\": \"\\n\".join(lines)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#ff6b6b", "moduleName": "debugger_compute"}, {"id": "debugger_compute.goto_step", "type": "function", "label": "goto_step", "direction": "inbound", "parent": "debugger_compute", "line": 944, "endLine": 973, "signature": "(params) -> Dict[]", "docstring": "Jump to a specific step in history.", "source": "def goto_step(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Jump to a specific step in history.\"\"\"\n    history = params.get(\"history\", [])\n    target_step = params.get(\"target_step\")\n    bp = params.get(\"blueprint\")\n    watches = params.get(\"watches\", [])\n\n    if target_step is None:\n        return {\"output\": \"Error: step number required\"}\n\n    target_step = int(target_step)\n    if target_step < 0 or target_step >= len(history):\n        return {\"output\": f\"Error: step {target_step} out of range (0-{len(history)-1})\"}\n\n    entry = history[target_step]\n    state = entry[\"state\"]\n    ctx = copy.deepcopy(entry[\"context\"])\n\n    avail = _get_available_transitions(bp, state, ctx) if bp else []\n    watch_values = _update_watches(watches, ctx)\n\n    return {\n        \"debug_state\": state,\n        \"debug_context\": ctx,\n        \"history_index\": target_step,\n        \"available_events\": [t[\"event\"] for t in avail],\n        \"available_transitions\": avail,\n        \"watch_values\": watch_values,\n        \"output\": f\"Jumped to step {target_step}: state '{state}'\"\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#ff6b6b", "moduleName": "debugger_compute"}, {"id": "debugger_compute.compare_states", "type": "function", "label": "compare_states", "direction": "inbound", "parent": "debugger_compute", "line": 976, "endLine": 1022, "signature": "(params) -> Dict[]", "docstring": "Compare context at two different history points.", "source": "def compare_states(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Compare context at two different history points.\"\"\"\n    history = params.get(\"history\", [])\n    step1 = params.get(\"step1\", 0)\n    step2 = params.get(\"step2\")\n\n    if step2 is None:\n        step2 = len(history) - 1\n\n    step1 = int(step1)\n    step2 = int(step2)\n\n    if step1 < 0 or step1 >= len(history):\n        return {\"output\": f\"Error: step1 {step1} out of range\"}\n    if step2 < 0 or step2 >= len(history):\n        return {\"output\": f\"Error: step2 {step2} out of range\"}\n\n    ctx1 = history[step1].get(\"context\", {})\n    ctx2 = history[step2].get(\"context\", {})\n\n    lines = [\n        f\"Comparing step {step1} vs step {step2}:\",\n        \"=\" * 50\n    ]\n\n    all_keys = set(ctx1.keys()) | set(ctx2.keys())\n    all_keys.discard(\"_state\")\n\n    for key in sorted(all_keys):\n        v1 = ctx1.get(key)\n        v2 = ctx2.get(key)\n        if v1 != v2:\n            lines.append(f\"  {key}:\")\n            lines.append(f\"    step {step1}: {json.dumps(v1, default=str)}\")\n            lines.append(f\"    step {step2}: {json.dumps(v2, default=str)}\")\n\n    state1 = history[step1].get(\"state\", \"?\")\n    state2 = history[step2].get(\"state\", \"?\")\n    if state1 != state2:\n        lines.append(f\"  State: {state1} -> {state2}\")\n\n    if len(lines) == 2:\n        lines.append(\"  No differences found\")\n\n    lines.append(\"=\" * 50)\n\n    return {\"output\": \"\\n\".join(lines)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#ff6b6b", "moduleName": "debugger_compute"}, {"id": "debugger_compute.render_status", "type": "function", "label": "render_status", "direction": "inbound", "parent": "debugger_compute", "line": 1029, "endLine": 1073, "signature": "(params) -> Dict[]", "docstring": "Render current debug status.", "source": "def render_status(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Render current debug status.\"\"\"\n    bp_name = params.get(\"blueprint_name\", \"Unknown\")\n    state = params.get(\"debug_state\", \"?\")\n    ctx = params.get(\"debug_context\", {})\n    history_index = params.get(\"history_index\", 0)\n    avail_events = params.get(\"available_events\", [])\n    breakpoints = params.get(\"breakpoints\", [])\n    is_paused = params.get(\"is_paused\", False)\n    hit_bp = params.get(\"hit_breakpoint\")\n\n    lines = [\n        \"=\" * 60,\n        f\"  L++ Debugger: {bp_name}\",\n        \"=\" * 60,\n    ]\n\n    if is_paused and hit_bp:\n        lines.append(f\"  ** PAUSED at breakpoint: {hit_bp['id']} **\")\n\n    lines.extend([\n        f\"  State: {state}\",\n        f\"  Step: {history_index}\",\n        f\"  Breakpoints: {len(breakpoints)}\",\n        \"\",\n        \"  Context (non-null):\"\n    ])\n\n    for k, v in ctx.items():\n        if k != \"_state\" and v is not None:\n            val_str = str(v)\n            if len(val_str) > 40:\n                val_str = val_str[:37] + \"...\"\n            lines.append(f\"    {k}: {val_str}\")\n\n    lines.append(\"\")\n    lines.append(f\"  Available Events ({len(avail_events)}):\")\n    for e in avail_events[:8]:\n        lines.append(f\"    - {e}\")\n    if len(avail_events) > 8:\n        lines.append(f\"    ... and {len(avail_events) - 8} more\")\n\n    lines.append(\"=\" * 60)\n\n    return {\"output\": \"\\n\".join(lines)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#ff6b6b", "moduleName": "debugger_compute"}, {"id": "uuid", "type": "dependency", "label": "uuid", "direction": "outbound", "category": "stdlib", "moduleColor": "#ff6b6b", "moduleName": "debugger_compute"}, {"id": "datetime", "type": "dependency", "label": "datetime", "direction": "outbound", "category": "stdlib", "moduleColor": "#ff6b6b", "moduleName": "debugger_compute"}, {"id": "frame_py.loader", "type": "dependency", "label": "loader", "direction": "outbound", "category": "pip", "moduleColor": "#ff6b6b", "moduleName": "debugger_compute"}, {"id": "frame_py.safe_eval", "type": "dependency", "label": "safe_eval", "direction": "outbound", "category": "pip", "moduleColor": "#ff6b6b", "moduleName": "debugger_compute"}, {"id": "differ_compute", "type": "module", "label": "differ_compute", "metrics": {"fanIn": 11, "fanOut": 4, "instability": 0.267, "internalEdges": 12, "externalCallCount": 18, "localCallCount": 0, "callsByCategory": {"stdlib": 18}, "localDependencies": []}, "moduleColor": "#4ecdc4", "moduleName": "differ_compute"}, {"id": "differ_compute.ChangeType", "type": "class", "label": "ChangeType", "direction": "inbound", "parent": "differ_compute", "line": 18, "endLine": 22, "signature": null, "docstring": null, "source": "class ChangeType:\n    ADDED = \"added\"\n    REMOVED = \"removed\"\n    MODIFIED = \"modified\"\n    UNCHANGED = \"unchanged\"", "args": null, "returns": null, "moduleColor": "#4ecdc4", "moduleName": "differ_compute"}, {"id": "differ_compute.ElementType", "type": "class", "label": "ElementType", "direction": "inbound", "parent": "differ_compute", "line": 25, "endLine": 33, "signature": null, "docstring": null, "source": "class ElementType:\n    STATE = \"state\"\n    TRANSITION = \"transition\"\n    GATE = \"gate\"\n    ACTION = \"action\"\n    CONTEXT_PROPERTY = \"context_property\"\n    ENTRY_STATE = \"entry_state\"\n    TERMINAL_STATE = \"terminal_state\"\n    METADATA = \"metadata\"", "args": null, "returns": null, "moduleColor": "#4ecdc4", "moduleName": "differ_compute"}, {"id": "differ_compute.make_change", "type": "function", "label": "make_change", "direction": "inbound", "parent": "differ_compute", "line": 36, "endLine": 56, "signature": "(element_type, change_type, key, left_value, right_value, details) -> Dict[]", "docstring": "Create a standardized change record.", "source": "def make_change(\n    element_type: str,\n    change_type: str,\n    key: str,\n    left_value: Any = None,\n    right_value: Any = None,\n    details: str = None\n) -> Dict[str, Any]:\n    \"\"\"Create a standardized change record.\"\"\"\n    change = {\n        \"element_type\": element_type,\n        \"change_type\": change_type,\n        \"key\": key\n    }\n    if left_value is not None:\n        change[\"left\"] = left_value\n    if right_value is not None:\n        change[\"right\"] = right_value\n    if details:\n        change[\"details\"] = details\n    return change", "args": ["element_type", "change_type", "key", "left_value", "right_value", "details"], "returns": "Dict[]", "moduleColor": "#4ecdc4", "moduleName": "differ_compute"}, {"id": "differ_compute.load_blueprint", "type": "function", "label": "load_blueprint", "direction": "inbound", "parent": "differ_compute", "line": 63, "endLine": 102, "signature": "(params) -> Dict[]", "docstring": "Load an L++ blueprint from a JSON file.", "source": "def load_blueprint(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Load an L++ blueprint from a JSON file.\"\"\"\n    path = params.get(\"path\")\n    side = params.get(\"side\", \"unknown\")\n\n    if not path:\n        return {\"blueprint\": None, \"path\": None,\n                \"error\": f\"No path provided for {side}\"}\n\n    try:\n        p = Path(path)\n        if not p.exists():\n            return {\"blueprint\": None, \"path\": None,\n                    \"error\": f\"File not found: {path}\"}\n\n        with open(p) as f:\n            raw = json.load(f)\n\n        bp = {\n            \"id\": raw.get(\"id\", \"unknown\"),\n            \"name\": raw.get(\"name\", \"Unknown\"),\n            \"version\": raw.get(\"version\", \"0.0.0\"),\n            \"description\": raw.get(\"description\", \"\"),\n            \"$schema\": raw.get(\"$schema\", \"\"),\n            \"states\": raw.get(\"states\", {}),\n            \"transitions\": raw.get(\"transitions\", []),\n            \"gates\": raw.get(\"gates\", {}),\n            \"actions\": raw.get(\"actions\", {}),\n            \"context_schema\": raw.get(\"context_schema\", {}),\n            \"entry_state\": raw.get(\"entry_state\"),\n            \"terminal_states\": raw.get(\"terminal_states\", []),\n            \"display\": raw.get(\"display\", {})\n        }\n\n        return {\"blueprint\": bp, \"path\": str(p), \"error\": None}\n    except json.JSONDecodeError as e:\n        return {\"blueprint\": None, \"path\": None,\n                \"error\": f\"Invalid JSON in {side}: {e}\"}\n    except Exception as e:\n        return {\"blueprint\": None, \"path\": None, \"error\": str(e)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#4ecdc4", "moduleName": "differ_compute"}, {"id": "differ_compute.clear_all", "type": "function", "label": "clear_all", "direction": "inbound", "parent": "differ_compute", "line": 105, "endLine": 116, "signature": "(params) -> Dict[]", "docstring": "Clear all loaded blueprints and diff results.", "source": "def clear_all(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Clear all loaded blueprints and diff results.\"\"\"\n    return {\n        \"blueprint_left\": None,\n        \"blueprint_right\": None,\n        \"blueprint_base\": None,\n        \"diff_result\": None,\n        \"conflicts\": None,\n        \"merged_blueprint\": None,\n        \"formatted_diff\": None,\n        \"json_patch\": None\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#4ecdc4", "moduleName": "differ_compute"}, {"id": "differ_compute.compute_diff", "type": "function", "label": "compute_diff", "direction": "inbound", "parent": "differ_compute", "line": 241, "endLine": 331, "signature": "(params) -> Dict[]", "docstring": "Compute semantic diff between two blueprints.", "source": "def compute_diff(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Compute semantic diff between two blueprints.\"\"\"\n    left = params.get(\"left\", {})\n    right = params.get(\"right\", {})\n\n    if not left or not right:\n        return {\"diff\": {\"changes\": [], \"summary\": {}, \"identical\": True}}\n\n    changes = []\n\n    # Metadata changes\n    for field in [\"id\", \"name\", \"version\", \"description\", \"$schema\"]:\n        lv = left.get(field)\n        rv = right.get(field)\n        if lv != rv:\n            changes.append(make_change(\n                ElementType.METADATA, ChangeType.MODIFIED, field,\n                left_value=lv, right_value=rv\n            ))\n\n    # Entry state\n    if left.get(\"entry_state\") != right.get(\"entry_state\"):\n        changes.append(make_change(\n            ElementType.ENTRY_STATE, ChangeType.MODIFIED, \"entry_state\",\n            left_value=left.get(\"entry_state\"),\n            right_value=right.get(\"entry_state\")\n        ))\n\n    # States\n    changes.extend(_diff_dict(\n        left.get(\"states\", {}),\n        right.get(\"states\", {}),\n        ElementType.STATE\n    ))\n\n    # Transitions\n    changes.extend(_diff_transitions(\n        left.get(\"transitions\", []),\n        right.get(\"transitions\", [])\n    ))\n\n    # Gates\n    changes.extend(_diff_dict(\n        left.get(\"gates\", {}),\n        right.get(\"gates\", {}),\n        ElementType.GATE\n    ))\n\n    # Actions\n    changes.extend(_diff_dict(\n        left.get(\"actions\", {}),\n        right.get(\"actions\", {}),\n        ElementType.ACTION\n    ))\n\n    # Context schema\n    changes.extend(_diff_context_schema(\n        left.get(\"context_schema\", {}),\n        right.get(\"context_schema\", {})\n    ))\n\n    # Terminal states\n    changes.extend(_diff_terminal_states(\n        left.get(\"terminal_states\", []),\n        right.get(\"terminal_states\", [])\n    ))\n\n    # Summary\n    summary = {\n        \"total\": len(changes),\n        \"added\": sum(1 for c in changes if c[\"change_type\"] == ChangeType.ADDED),\n        \"removed\": sum(1 for c in changes\n                       if c[\"change_type\"] == ChangeType.REMOVED),\n        \"modified\": sum(1 for c in changes\n                        if c[\"change_type\"] == ChangeType.MODIFIED),\n        \"by_type\": {}\n    }\n\n    for c in changes:\n        et = c[\"element_type\"]\n        if et not in summary[\"by_type\"]:\n            summary[\"by_type\"][et] = {\"added\": 0, \"removed\": 0, \"modified\": 0}\n        summary[\"by_type\"][et][c[\"change_type\"]] += 1\n\n    return {\n        \"diff\": {\n            \"changes\": changes,\n            \"summary\": summary,\n            \"identical\": len(changes) == 0\n        }\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#4ecdc4", "moduleName": "differ_compute"}, {"id": "differ_compute.format_diff", "type": "function", "label": "format_diff", "direction": "inbound", "parent": "differ_compute", "line": 338, "endLine": 447, "signature": "(params) -> Dict[]", "docstring": "Format diff for display.", "source": "def format_diff(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Format diff for display.\"\"\"\n    diff = params.get(\"diff\", {})\n    fmt = params.get(\"format\", \"unified\")\n    pathLeft = params.get(\"path_left\", \"left\")\n    pathRight = params.get(\"path_right\", \"right\")\n\n    if not diff:\n        return {\"output\": \"No diff available\", \"format\": fmt}\n\n    changes = diff.get(\"changes\", [])\n    summary = diff.get(\"summary\", {})\n\n    if diff.get(\"identical\"):\n        return {\"output\": \"Blueprints are identical.\", \"format\": fmt}\n\n    lines = []\n\n    if fmt == \"summary\":\n        lines.append(\"=\" * 70)\n        lines.append(\"  L++ Blueprint Diff Summary\")\n        lines.append(\"=\" * 70)\n        lines.append(\"\")\n        lines.append(f\"  Left:  {pathLeft}\")\n        lines.append(f\"  Right: {pathRight}\")\n        lines.append(\"\")\n        lines.append(\"-\" * 70)\n        lines.append(f\"  Total Changes: {summary.get('total', 0)}\")\n        lines.append(f\"    Added:    {summary.get('added', 0)}\")\n        lines.append(f\"    Removed:  {summary.get('removed', 0)}\")\n        lines.append(f\"    Modified: {summary.get('modified', 0)}\")\n        lines.append(\"\")\n\n        byType = summary.get(\"by_type\", {})\n        if byType:\n            lines.append(\"-\" * 70)\n            lines.append(\"  Changes by Element Type:\")\n            for et, counts in sorted(byType.items()):\n                total = sum(counts.values())\n                lines.append(f\"    {et}: {total} \"\n                             f\"(+{counts['added']} -{counts['removed']} \"\n                             f\"~{counts['modified']})\")\n\n        lines.append(\"=\" * 70)\n\n    else:  # unified\n        lines.append(\"=\" * 70)\n        lines.append(\"  L++ Blueprint Diff (Unified)\")\n        lines.append(\"=\" * 70)\n        lines.append(f\"  --- {pathLeft}\")\n        lines.append(f\"  +++ {pathRight}\")\n        lines.append(\"\")\n\n        # Group by element type\n        byType: Dict[str, List] = {}\n        for c in changes:\n            et = c[\"element_type\"]\n            if et not in byType:\n                byType[et] = []\n            byType[et].append(c)\n\n        typeOrder = [\n            ElementType.METADATA,\n            ElementType.ENTRY_STATE,\n            ElementType.STATE,\n            ElementType.TRANSITION,\n            ElementType.GATE,\n            ElementType.ACTION,\n            ElementType.CONTEXT_PROPERTY,\n            ElementType.TERMINAL_STATE\n        ]\n\n        for et in typeOrder:\n            if et not in byType:\n                continue\n            lines.append(\"-\" * 70)\n            lines.append(f\"  [{et.upper()}]\")\n\n            for c in byType[et]:\n                ct = c[\"change_type\"]\n                key = c[\"key\"]\n\n                if ct == ChangeType.ADDED:\n                    lines.append(f\"    + {key}\")\n                    if \"right\" in c:\n                        val = _format_value(c[\"right\"])\n                        for line in val.split(\"\\n\"):\n                            lines.append(f\"      {line}\")\n                elif ct == ChangeType.REMOVED:\n                    lines.append(f\"    - {key}\")\n                    if \"left\" in c:\n                        val = _format_value(c[\"left\"])\n                        for line in val.split(\"\\n\"):\n                            lines.append(f\"      {line}\")\n                elif ct == ChangeType.MODIFIED:\n                    lines.append(f\"    ~ {key}\")\n                    if c.get(\"details\"):\n                        lines.append(f\"      {c['details']}\")\n                    elif \"left\" in c and \"right\" in c:\n                        lines.append(f\"      left:  {_format_value_inline(c['left'])}\")\n                        lines.append(f\"      right: {_format_value_inline(c['right'])}\")\n            lines.append(\"\")\n\n        lines.append(\"=\" * 70)\n        lines.append(f\"  Summary: +{summary.get('added', 0)} \"\n                     f\"-{summary.get('removed', 0)} \"\n                     f\"~{summary.get('modified', 0)}\")\n        lines.append(\"=\" * 70)\n\n    return {\"output\": \"\\n\".join(lines), \"format\": fmt}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#4ecdc4", "moduleName": "differ_compute"}, {"id": "differ_compute.generate_json_patch", "type": "function", "label": "generate_json_patch", "direction": "inbound", "parent": "differ_compute", "line": 474, "endLine": 528, "signature": "(params) -> Dict[]", "docstring": "Generate RFC 6902 JSON patch from diff.", "source": "def generate_json_patch(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Generate RFC 6902 JSON patch from diff.\"\"\"\n    diff = params.get(\"diff\", {})\n    changes = diff.get(\"changes\", [])\n\n    if not changes:\n        return {\"patch\": [], \"formatted\": \"No changes - empty patch\"}\n\n    patch = []\n\n    for c in changes:\n        et = c[\"element_type\"]\n        ct = c[\"change_type\"]\n        key = c[\"key\"]\n\n        # Compute JSON path\n        if et == ElementType.STATE:\n            path = f\"/states/{key}\"\n        elif et == ElementType.GATE:\n            path = f\"/gates/{key}\"\n        elif et == ElementType.ACTION:\n            path = f\"/actions/{key}\"\n        elif et == ElementType.CONTEXT_PROPERTY:\n            path = f\"/context_schema/properties/{key}\"\n        elif et == ElementType.TRANSITION:\n            path = f\"/transitions/{key}\"  # By ID reference\n        elif et == ElementType.ENTRY_STATE:\n            path = \"/entry_state\"\n        elif et == ElementType.TERMINAL_STATE:\n            path = f\"/terminal_states/{key}\"\n        elif et == ElementType.METADATA:\n            path = f\"/{key}\"\n        else:\n            path = f\"/{et}/{key}\"\n\n        if ct == ChangeType.ADDED:\n            patch.append({\n                \"op\": \"add\",\n                \"path\": path,\n                \"value\": c.get(\"right\")\n            })\n        elif ct == ChangeType.REMOVED:\n            patch.append({\n                \"op\": \"remove\",\n                \"path\": path\n            })\n        elif ct == ChangeType.MODIFIED:\n            patch.append({\n                \"op\": \"replace\",\n                \"path\": path,\n                \"value\": c.get(\"right\")\n            })\n\n    formatted = json.dumps(patch, indent=2)\n    return {\"patch\": patch, \"formatted\": formatted}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#4ecdc4", "moduleName": "differ_compute"}, {"id": "differ_compute.detect_conflicts", "type": "function", "label": "detect_conflicts", "direction": "inbound", "parent": "differ_compute", "line": 535, "endLine": 589, "signature": "(params) -> Dict[]", "docstring": "Detect merge conflicts between blueprints.", "source": "def detect_conflicts(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Detect merge conflicts between blueprints.\"\"\"\n    left = params.get(\"left\", {})\n    right = params.get(\"right\", {})\n    base = params.get(\"base\")  # Optional for 3-way merge\n    diff = params.get(\"diff\", {})\n\n    conflicts = []\n    changes = diff.get(\"changes\", [])\n\n    if not base:\n        # Two-way merge: conflicts are elements modified on both sides\n        # Since we only have left->right diff, conflicts are modifications\n        # to elements where both sides differ from a \"theoretical\" base\n        # For 2-way, we flag any modification as potential conflict\n        for c in changes:\n            if c[\"change_type\"] == ChangeType.MODIFIED:\n                conflicts.append({\n                    \"element_type\": c[\"element_type\"],\n                    \"key\": c[\"key\"],\n                    \"left_value\": c.get(\"left\"),\n                    \"right_value\": c.get(\"right\"),\n                    \"reason\": \"Element modified (2-way diff)\"\n                })\n    else:\n        # Three-way merge: conflict when both left and right changed same\n        # element differently from base\n        leftDiff = compute_diff({\"left\": base, \"right\": left})[\"diff\"]\n        rightDiff = compute_diff({\"left\": base, \"right\": right})[\"diff\"]\n\n        leftChanges = {(c[\"element_type\"], c[\"key\"]): c\n                       for c in leftDiff.get(\"changes\", [])}\n        rightChanges = {(c[\"element_type\"], c[\"key\"]): c\n                        for c in rightDiff.get(\"changes\", [])}\n\n        # Conflict: both modified same element differently\n        for key in set(leftChanges.keys()) & set(rightChanges.keys()):\n            lc = leftChanges[key]\n            rc = rightChanges[key]\n\n            # Same change = no conflict\n            if lc.get(\"right\") == rc.get(\"right\"):\n                continue\n\n            # Different changes = conflict\n            conflicts.append({\n                \"element_type\": key[0],\n                \"key\": key[1],\n                \"base_value\": lc.get(\"left\"),\n                \"left_value\": lc.get(\"right\"),\n                \"right_value\": rc.get(\"right\"),\n                \"reason\": \"Both sides modified differently from base\"\n            })\n\n    return {\"conflicts\": conflicts}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#4ecdc4", "moduleName": "differ_compute"}, {"id": "differ_compute.merge_blueprints", "type": "function", "label": "merge_blueprints", "direction": "inbound", "parent": "differ_compute", "line": 596, "endLine": 664, "signature": "(params) -> Dict[]", "docstring": "Merge two blueprints with specified strategy.", "source": "def merge_blueprints(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Merge two blueprints with specified strategy.\"\"\"\n    left = params.get(\"left\", {})\n    right = params.get(\"right\", {})\n    base = params.get(\"base\")\n    strategy = params.get(\"strategy\", \"auto\")\n    conflicts = params.get(\"conflicts\", [])\n\n    # Start with left as base\n    merged = copy.deepcopy(left)\n\n    # Merge metadata (prefer right for auto/take_right)\n    if strategy in (\"auto\", \"take_right\"):\n        for field in [\"id\", \"name\", \"version\", \"description\"]:\n            if right.get(field):\n                merged[field] = right[field]\n        merged[\"version\"] = _bump_version(left.get(\"version\", \"0.0.0\"))\n\n    # Merge states\n    merged[\"states\"] = _merge_dict(\n        left.get(\"states\", {}),\n        right.get(\"states\", {}),\n        strategy, conflicts, ElementType.STATE\n    )\n\n    # Merge gates\n    merged[\"gates\"] = _merge_dict(\n        left.get(\"gates\", {}),\n        right.get(\"gates\", {}),\n        strategy, conflicts, ElementType.GATE\n    )\n\n    # Merge actions\n    merged[\"actions\"] = _merge_dict(\n        left.get(\"actions\", {}),\n        right.get(\"actions\", {}),\n        strategy, conflicts, ElementType.ACTION\n    )\n\n    # Merge transitions\n    merged[\"transitions\"] = _merge_transitions(\n        left.get(\"transitions\", []),\n        right.get(\"transitions\", []),\n        strategy, conflicts\n    )\n\n    # Merge context schema\n    leftProps = left.get(\"context_schema\", {}).get(\"properties\", {})\n    rightProps = right.get(\"context_schema\", {}).get(\"properties\", {})\n    mergedProps = _merge_dict(\n        leftProps, rightProps, strategy, conflicts, ElementType.CONTEXT_PROPERTY\n    )\n    merged[\"context_schema\"] = {\"properties\": mergedProps}\n\n    # Merge terminal states (union for auto)\n    leftTerms = set(left.get(\"terminal_states\", []))\n    rightTerms = set(right.get(\"terminal_states\", []))\n    if strategy == \"take_left\":\n        merged[\"terminal_states\"] = list(leftTerms)\n    elif strategy == \"take_right\":\n        merged[\"terminal_states\"] = list(rightTerms)\n    else:\n        merged[\"terminal_states\"] = sorted(leftTerms | rightTerms)\n\n    # Entry state\n    if strategy == \"take_right\" and right.get(\"entry_state\"):\n        merged[\"entry_state\"] = right[\"entry_state\"]\n\n    return {\"merged\": merged, \"strategy\": strategy}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#4ecdc4", "moduleName": "differ_compute"}, {"id": "differ_compute.export_merged", "type": "function", "label": "export_merged", "direction": "inbound", "parent": "differ_compute", "line": 751, "endLine": 771, "signature": "(params) -> Dict[]", "docstring": "Export merged blueprint to file.", "source": "def export_merged(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Export merged blueprint to file.\"\"\"\n    blueprint = params.get(\"blueprint\")\n    path = params.get(\"path\")\n\n    if not blueprint:\n        return {\"path\": None, \"error\": \"No merged blueprint to export\"}\n\n    if not path:\n        return {\"path\": None, \"error\": \"No export path specified\"}\n\n    try:\n        p = Path(path)\n        p.parent.mkdir(parents=True, exist_ok=True)\n\n        with open(p, \"w\") as f:\n            json.dump(blueprint, f, indent=2)\n\n        return {\"path\": str(p)}\n    except Exception as e:\n        return {\"path\": None, \"error\": str(e)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#4ecdc4", "moduleName": "differ_compute"}, {"id": "linter_compute", "type": "module", "label": "linter_compute", "metrics": {"fanIn": 18, "fanOut": 4, "instability": 0.182, "internalEdges": 16, "externalCallCount": 4, "localCallCount": 0, "callsByCategory": {"stdlib": 4}, "localDependencies": []}, "moduleColor": "#f39c12", "moduleName": "linter_compute"}, {"id": "linter_compute.Severity", "type": "class", "label": "Severity", "direction": "inbound", "parent": "linter_compute", "line": 18, "endLine": 21, "signature": null, "docstring": null, "source": "class Severity:\n    ERROR = \"error\"\n    WARNING = \"warning\"\n    INFO = \"info\"", "args": null, "returns": null, "moduleColor": "#f39c12", "moduleName": "linter_compute"}, {"id": "linter_compute.RuleCode", "type": "class", "label": "RuleCode", "direction": "inbound", "parent": "linter_compute", "line": 24, "endLine": 34, "signature": null, "docstring": null, "source": "class RuleCode:\n    UNREACHABLE_STATE = \"L001\"\n    DEAD_END_STATE = \"L002\"\n    UNUSED_GATE = \"L003\"\n    UNUSED_ACTION = \"L004\"\n    UNUSED_CONTEXT = \"L005\"\n    ORPHANED_TRANSITION = \"L006\"\n    MISSING_GATE_REF = \"L007\"\n    MISSING_ACTION_REF = \"L008\"\n    DUPLICATE_TRANSITION_ID = \"L009\"\n    NAMING_CONVENTION = \"L010\"", "args": null, "returns": null, "moduleColor": "#f39c12", "moduleName": "linter_compute"}, {"id": "linter_compute.make_finding", "type": "function", "label": "make_finding", "direction": "inbound", "parent": "linter_compute", "line": 37, "endLine": 54, "signature": "(code, severity, message, location, suggestion) -> Dict[]", "docstring": "Create a standardized finding dict.", "source": "def make_finding(\n    code: str,\n    severity: str,\n    message: str,\n    location: str = None,\n    suggestion: str = None\n) -> Dict[str, Any]:\n    \"\"\"Create a standardized finding dict.\"\"\"\n    finding = {\n        \"code\": code,\n        \"severity\": severity,\n        \"message\": message\n    }\n    if location:\n        finding[\"location\"] = location\n    if suggestion:\n        finding[\"suggestion\"] = suggestion\n    return finding", "args": ["code", "severity", "message", "location", "suggestion"], "returns": "Dict[]", "moduleColor": "#f39c12", "moduleName": "linter_compute"}, {"id": "linter_compute.load_blueprint", "type": "function", "label": "load_blueprint", "direction": "inbound", "parent": "linter_compute", "line": 61, "endLine": 97, "signature": "(params) -> Dict[]", "docstring": "Load an L++ blueprint from a JSON file for linting.", "source": "def load_blueprint(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Load an L++ blueprint from a JSON file for linting.\"\"\"\n    path = params.get(\"path\")\n    if not path:\n        return {\"blueprint\": None, \"path\": None, \"error\": \"No path provided\"}\n\n    try:\n        path = Path(path)\n        if not path.exists():\n            return {\"blueprint\": None, \"path\": None,\n                    \"error\": f\"File not found: {path}\"}\n\n        with open(path) as f:\n            raw = json.load(f)\n\n        # Store raw dict for linting (we need access to all fields)\n        bp = {\n            \"id\": raw.get(\"id\", \"unknown\"),\n            \"name\": raw.get(\"name\", \"Unknown\"),\n            \"version\": raw.get(\"version\", \"0.0.0\"),\n            \"description\": raw.get(\"description\", \"\"),\n            \"states\": raw.get(\"states\", {}),\n            \"transitions\": raw.get(\"transitions\", []),\n            \"gates\": raw.get(\"gates\", {}),\n            \"actions\": raw.get(\"actions\", {}),\n            \"context_schema\": raw.get(\"context_schema\", {}),\n            \"entry_state\": raw.get(\"entry_state\"),\n            \"terminal_states\": raw.get(\"terminal_states\", []),\n            \"display\": raw.get(\"display\", {})\n        }\n\n        return {\"blueprint\": bp, \"path\": str(path), \"error\": None}\n    except json.JSONDecodeError as e:\n        return {\"blueprint\": None, \"path\": None,\n                \"error\": f\"Invalid JSON: {e}\"}\n    except Exception as e:\n        return {\"blueprint\": None, \"path\": None, \"error\": str(e)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#f39c12", "moduleName": "linter_compute"}, {"id": "linter_compute.init_lint", "type": "function", "label": "init_lint", "direction": "inbound", "parent": "linter_compute", "line": 100, "endLine": 106, "signature": "(params) -> Dict[]", "docstring": "Initialize linting state with empty findings.", "source": "def init_lint(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Initialize linting state with empty findings.\"\"\"\n    return {\n        \"findings\": [],\n        \"summary\": {\"error\": 0, \"warning\": 0, \"info\": 0},\n        \"metrics\": {}\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#f39c12", "moduleName": "linter_compute"}, {"id": "linter_compute.check_unreachable_states", "type": "function", "label": "check_unreachable_states", "direction": "inbound", "parent": "linter_compute", "line": 113, "endLine": 147, "signature": "(params) -> Dict[]", "docstring": "Rule L001: Detect states that have no incoming transitions.\nEntry state is exempt from this check.", "source": "def check_unreachable_states(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Rule L001: Detect states that have no incoming transitions.\n    Entry state is exempt from this check.\n    \"\"\"\n    bp = params.get(\"blueprint\", {})\n    findings = list(params.get(\"findings\", []))\n\n    states = set(bp.get(\"states\", {}).keys())\n    entryState = bp.get(\"entry_state\")\n    transitions = bp.get(\"transitions\", [])\n\n    # Collect all states that are targets of transitions\n    reachable = set()\n    for t in transitions:\n        toState = t.get(\"to\")\n        if toState and toState != \"*\":\n            reachable.add(toState)\n\n    # Entry state is always reachable (it's the start)\n    if entryState:\n        reachable.add(entryState)\n\n    # Find unreachable states\n    unreachable = states - reachable\n    for state in sorted(unreachable):\n        findings.append(make_finding(\n            code=RuleCode.UNREACHABLE_STATE,\n            severity=Severity.WARNING,\n            message=f\"State '{state}' has no incoming transitions\",\n            location=f\"states.{state}\",\n            suggestion=f\"Add a transition to '{state}' or remove it\"\n        ))\n\n    return {\"findings\": findings}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#f39c12", "moduleName": "linter_compute"}, {"id": "linter_compute.check_dead_end_states", "type": "function", "label": "check_dead_end_states", "direction": "inbound", "parent": "linter_compute", "line": 150, "endLine": 190, "signature": "(params) -> Dict[]", "docstring": "Rule L002: Detect non-terminal states with no outgoing transitions.\nTerminal states and wildcard transitions are handled specially.", "source": "def check_dead_end_states(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Rule L002: Detect non-terminal states with no outgoing transitions.\n    Terminal states and wildcard transitions are handled specially.\n    \"\"\"\n    bp = params.get(\"blueprint\", {})\n    findings = list(params.get(\"findings\", []))\n\n    states = set(bp.get(\"states\", {}).keys())\n    terminalStates = set(bp.get(\"terminal_states\", []))\n    transitions = bp.get(\"transitions\", [])\n\n    # Collect states with outgoing transitions\n    hasOutgoing = set()\n    hasWildcard = False\n    for t in transitions:\n        fromState = t.get(\"from\")\n        if fromState == \"*\":\n            hasWildcard = True\n        elif fromState:\n            hasOutgoing.add(fromState)\n\n    # If there's a wildcard, all states have \"outgoing\" via wildcard\n    if hasWildcard:\n        hasOutgoing = states\n\n    # Non-terminal states without outgoing are dead-ends\n    nonTerminal = states - terminalStates\n    deadEnds = nonTerminal - hasOutgoing\n\n    for state in sorted(deadEnds):\n        findings.append(make_finding(\n            code=RuleCode.DEAD_END_STATE,\n            severity=Severity.WARNING,\n            message=f\"Non-terminal state '{state}' has no outgoing transitions\",\n            location=f\"states.{state}\",\n            suggestion=(f\"Add transitions from '{state}', mark as terminal, \"\n                        \"or use wildcard transition\")\n        ))\n\n    return {\"findings\": findings}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#f39c12", "moduleName": "linter_compute"}, {"id": "linter_compute.check_unused_gates", "type": "function", "label": "check_unused_gates", "direction": "inbound", "parent": "linter_compute", "line": 193, "endLine": 231, "signature": "(params) -> Dict[]", "docstring": "Rule L003: Detect gates defined but never referenced in transitions.", "source": "def check_unused_gates(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Rule L003: Detect gates defined but never referenced in transitions.\n    \"\"\"\n    bp = params.get(\"blueprint\", {})\n    findings = list(params.get(\"findings\", []))\n\n    definedGates = set(bp.get(\"gates\", {}).keys())\n    transitions = bp.get(\"transitions\", [])\n\n    # Collect all gate references from transitions\n    usedGates = set()\n    for t in transitions:\n        # Handle both 'gate' (singular) and 'gates' (array) fields\n        gate = t.get(\"gate\")\n        if gate:\n            usedGates.add(gate)\n        gates = t.get(\"gates\", [])\n        for g in gates:\n            usedGates.add(g)\n\n    # Also check display rules for gate usage\n    display = bp.get(\"display\", {})\n    for rule in display.get(\"rules\", []):\n        gate = rule.get(\"gate\")\n        if gate:\n            usedGates.add(gate)\n\n    unused = definedGates - usedGates\n    for gate in sorted(unused):\n        findings.append(make_finding(\n            code=RuleCode.UNUSED_GATE,\n            severity=Severity.INFO,\n            message=f\"Gate '{gate}' is defined but never used\",\n            location=f\"gates.{gate}\",\n            suggestion=f\"Use gate '{gate}' in a transition or remove it\"\n        ))\n\n    return {\"findings\": findings}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#f39c12", "moduleName": "linter_compute"}, {"id": "linter_compute.check_unused_actions", "type": "function", "label": "check_unused_actions", "direction": "inbound", "parent": "linter_compute", "line": 234, "endLine": 261, "signature": "(params) -> Dict[]", "docstring": "Rule L004: Detect actions defined but never referenced in transitions.", "source": "def check_unused_actions(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Rule L004: Detect actions defined but never referenced in transitions.\n    \"\"\"\n    bp = params.get(\"blueprint\", {})\n    findings = list(params.get(\"findings\", []))\n\n    definedActions = set(bp.get(\"actions\", {}).keys())\n    transitions = bp.get(\"transitions\", [])\n\n    # Collect all action references from transitions\n    usedActions = set()\n    for t in transitions:\n        actions = t.get(\"actions\", [])\n        for a in actions:\n            usedActions.add(a)\n\n    unused = definedActions - usedActions\n    for action in sorted(unused):\n        findings.append(make_finding(\n            code=RuleCode.UNUSED_ACTION,\n            severity=Severity.INFO,\n            message=f\"Action '{action}' is defined but never used\",\n            location=f\"actions.{action}\",\n            suggestion=f\"Use action '{action}' in a transition or remove it\"\n        ))\n\n    return {\"findings\": findings}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#f39c12", "moduleName": "linter_compute"}, {"id": "linter_compute.check_unused_context", "type": "function", "label": "check_unused_context", "direction": "inbound", "parent": "linter_compute", "line": 264, "endLine": 332, "signature": "(params) -> Dict[]", "docstring": "Rule L005: Detect context properties never used in gates/actions.", "source": "def check_unused_context(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Rule L005: Detect context properties never used in gates/actions.\n    \"\"\"\n    bp = params.get(\"blueprint\", {})\n    findings = list(params.get(\"findings\", []))\n\n    ctxSchema = bp.get(\"context_schema\", {})\n    props = set(ctxSchema.get(\"properties\", {}).keys())\n\n    if not props:\n        return {\"findings\": findings}\n\n    # Collect all property references from gates and actions\n    usedProps = set()\n\n    # Check gate expressions\n    for gateId, gate in bp.get(\"gates\", {}).items():\n        expr = gate.get(\"expression\", \"\")\n        for prop in props:\n            if prop in expr:\n                usedProps.add(prop)\n\n    # Check action input_map, output_map, target, value_from\n    for actId, action in bp.get(\"actions\", {}).items():\n        # Check target\n        target = action.get(\"target\")\n        if target in props:\n            usedProps.add(target)\n\n        # Check value_from\n        valueFrom = action.get(\"value_from\", \"\")\n        for prop in props:\n            if prop in valueFrom:\n                usedProps.add(prop)\n\n        # Check input_map values\n        inputMap = action.get(\"input_map\", {})\n        for v in inputMap.values():\n            if isinstance(v, str):\n                for prop in props:\n                    if prop in v:\n                        usedProps.add(prop)\n\n        # Check output_map keys\n        outputMap = action.get(\"output_map\", {})\n        for k in outputMap.keys():\n            if k in props:\n                usedProps.add(k)\n\n    # Check display rules\n    display = bp.get(\"display\", {})\n    for rule in display.get(\"rules\", []):\n        template = rule.get(\"template\", \"\")\n        for prop in props:\n            if \"{\" + prop + \"}\" in template or \"{\" + prop + \".\" in template:\n                usedProps.add(prop)\n\n    unused = props - usedProps\n    for prop in sorted(unused):\n        findings.append(make_finding(\n            code=RuleCode.UNUSED_CONTEXT,\n            severity=Severity.INFO,\n            message=f\"Context property '{prop}' is defined but never used\",\n            location=f\"context_schema.properties.{prop}\",\n            suggestion=f\"Use property '{prop}' in gates/actions or remove it\"\n        ))\n\n    return {\"findings\": findings}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#f39c12", "moduleName": "linter_compute"}, {"id": "linter_compute.check_orphaned_transitions", "type": "function", "label": "check_orphaned_transitions", "direction": "inbound", "parent": "linter_compute", "line": 335, "endLine": 372, "signature": "(params) -> Dict[]", "docstring": "Rule L006: Detect transitions referencing non-existent states.", "source": "def check_orphaned_transitions(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Rule L006: Detect transitions referencing non-existent states.\n    \"\"\"\n    bp = params.get(\"blueprint\", {})\n    findings = list(params.get(\"findings\", []))\n\n    states = set(bp.get(\"states\", {}).keys())\n    transitions = bp.get(\"transitions\", [])\n\n    for i, t in enumerate(transitions):\n        tid = t.get(\"id\", f\"transitions[{i}]\")\n        fromState = t.get(\"from\")\n        toState = t.get(\"to\")\n\n        # Check from state (skip wildcard)\n        if fromState and fromState != \"*\" and fromState not in states:\n            findings.append(make_finding(\n                code=RuleCode.ORPHANED_TRANSITION,\n                severity=Severity.ERROR,\n                message=f\"Transition '{tid}' references non-existent \"\n                        f\"from state '{fromState}'\",\n                location=f\"transitions.{tid}.from\",\n                suggestion=f\"Create state '{fromState}' or fix the reference\"\n            ))\n\n        # Check to state (skip wildcard)\n        if toState and toState != \"*\" and toState not in states:\n            findings.append(make_finding(\n                code=RuleCode.ORPHANED_TRANSITION,\n                severity=Severity.ERROR,\n                message=f\"Transition '{tid}' references non-existent \"\n                        f\"to state '{toState}'\",\n                location=f\"transitions.{tid}.to\",\n                suggestion=f\"Create state '{toState}' or fix the reference\"\n            ))\n\n    return {\"findings\": findings}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#f39c12", "moduleName": "linter_compute"}, {"id": "linter_compute.check_missing_gate_refs", "type": "function", "label": "check_missing_gate_refs", "direction": "inbound", "parent": "linter_compute", "line": 375, "endLine": 412, "signature": "(params) -> Dict[]", "docstring": "Rule L007: Detect transitions referencing non-existent gates.", "source": "def check_missing_gate_refs(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Rule L007: Detect transitions referencing non-existent gates.\n    \"\"\"\n    bp = params.get(\"blueprint\", {})\n    findings = list(params.get(\"findings\", []))\n\n    definedGates = set(bp.get(\"gates\", {}).keys())\n    transitions = bp.get(\"transitions\", [])\n\n    for i, t in enumerate(transitions):\n        tid = t.get(\"id\", f\"transitions[{i}]\")\n\n        # Handle both 'gate' and 'gates'\n        gate = t.get(\"gate\")\n        if gate and gate not in definedGates:\n            findings.append(make_finding(\n                code=RuleCode.MISSING_GATE_REF,\n                severity=Severity.ERROR,\n                message=f\"Transition '{tid}' references non-existent \"\n                        f\"gate '{gate}'\",\n                location=f\"transitions.{tid}.gate\",\n                suggestion=f\"Create gate '{gate}' or fix the reference\"\n            ))\n\n        gates = t.get(\"gates\", [])\n        for g in gates:\n            if g not in definedGates:\n                findings.append(make_finding(\n                    code=RuleCode.MISSING_GATE_REF,\n                    severity=Severity.ERROR,\n                    message=f\"Transition '{tid}' references non-existent \"\n                            f\"gate '{g}'\",\n                    location=f\"transitions.{tid}.gates\",\n                    suggestion=f\"Create gate '{g}' or fix the reference\"\n                ))\n\n    return {\"findings\": findings}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#f39c12", "moduleName": "linter_compute"}, {"id": "linter_compute.check_missing_action_refs", "type": "function", "label": "check_missing_action_refs", "direction": "inbound", "parent": "linter_compute", "line": 415, "endLine": 440, "signature": "(params) -> Dict[]", "docstring": "Rule L008: Detect transitions referencing non-existent actions.", "source": "def check_missing_action_refs(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Rule L008: Detect transitions referencing non-existent actions.\n    \"\"\"\n    bp = params.get(\"blueprint\", {})\n    findings = list(params.get(\"findings\", []))\n\n    definedActions = set(bp.get(\"actions\", {}).keys())\n    transitions = bp.get(\"transitions\", [])\n\n    for i, t in enumerate(transitions):\n        tid = t.get(\"id\", f\"transitions[{i}]\")\n        actions = t.get(\"actions\", [])\n\n        for a in actions:\n            if a not in definedActions:\n                findings.append(make_finding(\n                    code=RuleCode.MISSING_ACTION_REF,\n                    severity=Severity.ERROR,\n                    message=f\"Transition '{tid}' references non-existent \"\n                            f\"action '{a}'\",\n                    location=f\"transitions.{tid}.actions\",\n                    suggestion=f\"Create action '{a}' or fix the reference\"\n                ))\n\n    return {\"findings\": findings}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#f39c12", "moduleName": "linter_compute"}, {"id": "linter_compute.check_duplicate_ids", "type": "function", "label": "check_duplicate_ids", "direction": "inbound", "parent": "linter_compute", "line": 443, "endLine": 468, "signature": "(params) -> Dict[]", "docstring": "Rule L009: Detect duplicate transition IDs.", "source": "def check_duplicate_ids(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Rule L009: Detect duplicate transition IDs.\n    \"\"\"\n    bp = params.get(\"blueprint\", {})\n    findings = list(params.get(\"findings\", []))\n\n    transitions = bp.get(\"transitions\", [])\n    seenIds: Dict[str, int] = {}\n\n    for i, t in enumerate(transitions):\n        tid = t.get(\"id\")\n        if tid:\n            if tid in seenIds:\n                findings.append(make_finding(\n                    code=RuleCode.DUPLICATE_TRANSITION_ID,\n                    severity=Severity.ERROR,\n                    message=f\"Duplicate transition ID '{tid}' \"\n                            f\"(first at index {seenIds[tid]}, again at {i})\",\n                    location=f\"transitions[{i}]\",\n                    suggestion=f\"Rename one of the transitions with ID '{tid}'\"\n                ))\n            else:\n                seenIds[tid] = i\n\n    return {\"findings\": findings}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#f39c12", "moduleName": "linter_compute"}, {"id": "linter_compute.check_naming_conventions", "type": "function", "label": "check_naming_conventions", "direction": "inbound", "parent": "linter_compute", "line": 471, "endLine": 543, "signature": "(params) -> Dict[]", "docstring": "Rule L010: Check naming conventions.\n- IDs should be snake_case\n- Events should be UPPER_CASE", "source": "def check_naming_conventions(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Rule L010: Check naming conventions.\n    - IDs should be snake_case\n    - Events should be UPPER_CASE\n    \"\"\"\n    bp = params.get(\"blueprint\", {})\n    findings = list(params.get(\"findings\", []))\n\n    snakeCasePattern = re.compile(r'^[a-z][a-z0-9_]*$')\n    upperCasePattern = re.compile(r'^[A-Z][A-Z0-9_]*$')\n\n    # Check state IDs\n    for stateId in bp.get(\"states\", {}).keys():\n        if not snakeCasePattern.match(stateId):\n            findings.append(make_finding(\n                code=RuleCode.NAMING_CONVENTION,\n                severity=Severity.INFO,\n                message=f\"State ID '{stateId}' should be snake_case\",\n                location=f\"states.{stateId}\",\n                suggestion=f\"Rename to '{stateId.lower().replace('-', '_')}'\"\n            ))\n\n    # Check gate IDs\n    for gateId in bp.get(\"gates\", {}).keys():\n        if not snakeCasePattern.match(gateId):\n            findings.append(make_finding(\n                code=RuleCode.NAMING_CONVENTION,\n                severity=Severity.INFO,\n                message=f\"Gate ID '{gateId}' should be snake_case\",\n                location=f\"gates.{gateId}\",\n                suggestion=f\"Rename to '{gateId.lower().replace('-', '_')}'\"\n            ))\n\n    # Check action IDs\n    for actionId in bp.get(\"actions\", {}).keys():\n        if not snakeCasePattern.match(actionId):\n            findings.append(make_finding(\n                code=RuleCode.NAMING_CONVENTION,\n                severity=Severity.INFO,\n                message=f\"Action ID '{actionId}' should be snake_case\",\n                location=f\"actions.{actionId}\",\n                suggestion=f\"Rename to '{actionId.lower().replace('-', '_')}'\"\n            ))\n\n    # Check transition IDs\n    for i, t in enumerate(bp.get(\"transitions\", [])):\n        tid = t.get(\"id\")\n        if tid and not snakeCasePattern.match(tid):\n            findings.append(make_finding(\n                code=RuleCode.NAMING_CONVENTION,\n                severity=Severity.INFO,\n                message=f\"Transition ID '{tid}' should be snake_case\",\n                location=f\"transitions.{tid}\",\n                suggestion=f\"Rename to '{tid.lower().replace('-', '_')}'\"\n            ))\n\n    # Check event names\n    seenEvents = set()\n    for t in bp.get(\"transitions\", []):\n        event = t.get(\"on_event\")\n        if event and event not in seenEvents:\n            seenEvents.add(event)\n            if not upperCasePattern.match(event):\n                findings.append(make_finding(\n                    code=RuleCode.NAMING_CONVENTION,\n                    severity=Severity.INFO,\n                    message=f\"Event '{event}' should be UPPER_CASE\",\n                    location=f\"on_event: {event}\",\n                    suggestion=f\"Rename to '{event.upper().replace('-', '_')}'\"\n                ))\n\n    return {\"findings\": findings}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#f39c12", "moduleName": "linter_compute"}, {"id": "linter_compute.compute_metrics", "type": "function", "label": "compute_metrics", "direction": "inbound", "parent": "linter_compute", "line": 550, "endLine": 584, "signature": "(params) -> Dict[]", "docstring": "Compute complexity metrics for the blueprint.", "source": "def compute_metrics(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Compute complexity metrics for the blueprint.\"\"\"\n    bp = params.get(\"blueprint\", {})\n\n    states = bp.get(\"states\", {})\n    transitions = bp.get(\"transitions\", [])\n    gates = bp.get(\"gates\", {})\n    actions = bp.get(\"actions\", {})\n    ctxSchema = bp.get(\"context_schema\", {})\n    props = ctxSchema.get(\"properties\", {})\n\n    # Count unique events\n    events = set()\n    for t in transitions:\n        event = t.get(\"on_event\")\n        if event:\n            events.add(event)\n\n    # Cyclomatic complexity: E - N + 2P\n    # E = edges (transitions), N = nodes (states), P = connected components (1)\n    numStates = len(states)\n    numTransitions = len(transitions)\n    cyclomaticComplexity = numTransitions - numStates + 2\n\n    metrics = {\n        \"state_count\": numStates,\n        \"transition_count\": numTransitions,\n        \"gate_count\": len(gates),\n        \"action_count\": len(actions),\n        \"event_count\": len(events),\n        \"context_property_count\": len(props),\n        \"cyclomatic_complexity\": max(1, cyclomaticComplexity)\n    }\n\n    return {\"metrics\": metrics}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#f39c12", "moduleName": "linter_compute"}, {"id": "linter_compute.compute_summary", "type": "function", "label": "compute_summary", "direction": "inbound", "parent": "linter_compute", "line": 587, "endLine": 597, "signature": "(params) -> Dict[]", "docstring": "Compute summary counts by severity.", "source": "def compute_summary(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Compute summary counts by severity.\"\"\"\n    findings = params.get(\"findings\", [])\n\n    summary = {\"error\": 0, \"warning\": 0, \"info\": 0}\n    for f in findings:\n        sev = f.get(\"severity\", \"info\")\n        if sev in summary:\n            summary[sev] += 1\n\n    return {\"summary\": summary}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#f39c12", "moduleName": "linter_compute"}, {"id": "linter_compute.generate_report", "type": "function", "label": "generate_report", "direction": "inbound", "parent": "linter_compute", "line": 604, "endLine": 680, "signature": "(params) -> Dict[]", "docstring": "Generate a formatted lint report.", "source": "def generate_report(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Generate a formatted lint report.\"\"\"\n    bp = params.get(\"blueprint\", {})\n    bpPath = params.get(\"blueprint_path\", \"unknown\")\n    findings = params.get(\"findings\", [])\n    summary = params.get(\"summary\", {})\n    metrics = params.get(\"metrics\", {})\n\n    lines = []\n    lines.append(\"=\" * 70)\n    lines.append(f\"  L++ Blueprint Linter Report\")\n    lines.append(\"=\" * 70)\n    lines.append(\"\")\n    lines.append(f\"  Blueprint: {bp.get('name', 'Unknown')} (v{bp.get('version', '?')})\")\n    lines.append(f\"  ID: {bp.get('id', 'unknown')}\")\n    lines.append(f\"  Path: {bpPath}\")\n    lines.append(\"\")\n\n    # Summary\n    lines.append(\"-\" * 70)\n    lines.append(\"  SUMMARY\")\n    lines.append(\"-\" * 70)\n    errCount = summary.get(\"error\", 0)\n    warnCount = summary.get(\"warning\", 0)\n    infoCount = summary.get(\"info\", 0)\n    total = errCount + warnCount + infoCount\n\n    if total == 0:\n        lines.append(\"  No issues found. Blueprint is clean!\")\n    else:\n        lines.append(f\"  Errors:   {errCount}\")\n        lines.append(f\"  Warnings: {warnCount}\")\n        lines.append(f\"  Info:     {infoCount}\")\n        lines.append(f\"  Total:    {total}\")\n    lines.append(\"\")\n\n    # Metrics\n    lines.append(\"-\" * 70)\n    lines.append(\"  METRICS\")\n    lines.append(\"-\" * 70)\n    lines.append(f\"  States:      {metrics.get('state_count', 0)}\")\n    lines.append(f\"  Transitions: {metrics.get('transition_count', 0)}\")\n    lines.append(f\"  Gates:       {metrics.get('gate_count', 0)}\")\n    lines.append(f\"  Actions:     {metrics.get('action_count', 0)}\")\n    lines.append(f\"  Events:      {metrics.get('event_count', 0)}\")\n    lines.append(f\"  Context Props: {metrics.get('context_property_count', 0)}\")\n    lines.append(f\"  Cyclomatic Complexity: {metrics.get('cyclomatic_complexity', 1)}\")\n    lines.append(\"\")\n\n    # Findings\n    if findings:\n        lines.append(\"-\" * 70)\n        lines.append(\"  FINDINGS\")\n        lines.append(\"-\" * 70)\n\n        # Group by severity\n        for severity in [Severity.ERROR, Severity.WARNING, Severity.INFO]:\n            sevFindings = [f for f in findings if f.get(\"severity\") == severity]\n            if sevFindings:\n                icon = {\"error\": \"[E]\", \"warning\": \"[W]\", \"info\": \"[I]\"}\n                lines.append(\"\")\n                lines.append(f\"  {severity.upper()}S ({len(sevFindings)})\")\n                for f in sevFindings:\n                    code = f.get(\"code\", \"?\")\n                    msg = f.get(\"message\", \"\")\n                    loc = f.get(\"location\", \"\")\n                    sug = f.get(\"suggestion\", \"\")\n                    lines.append(f\"    {icon[severity]} {code}: {msg}\")\n                    if loc:\n                        lines.append(f\"       Location: {loc}\")\n                    if sug:\n                        lines.append(f\"       Suggestion: {sug}\")\n                    lines.append(\"\")\n\n    lines.append(\"=\" * 70)\n\n    return {\"report\": \"\\n\".join(lines)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#f39c12", "moduleName": "linter_compute"}, {"id": "re", "type": "dependency", "label": "re", "direction": "outbound", "category": "stdlib", "moduleColor": "#f39c12", "moduleName": "linter_compute"}, {"id": "playground_compute", "type": "module", "label": "playground_compute", "metrics": {"fanIn": 11, "fanOut": 9, "instability": 0.45, "internalEdges": 0, "externalCallCount": 25, "localCallCount": 0, "callsByCategory": {"stdlib": 24, "pip": 1}, "localDependencies": []}, "moduleColor": "#9b59b6", "moduleName": "playground_compute"}, {"id": "playground_compute.load_blueprint", "type": "function", "label": "load_blueprint", "direction": "inbound", "parent": "playground_compute", "line": 29, "endLine": 82, "signature": "(params) -> Dict[]", "docstring": "Load blueprint from JSON string or file path.", "source": "def load_blueprint(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Load blueprint from JSON string or file path.\"\"\"\n    json_string = params.get(\"json_string\")\n    file_path = params.get(\"file_path\")\n\n    if file_path:\n        try:\n            path = Path(file_path)\n            if not path.exists():\n                return {\n                    \"blueprint_json\": None,\n                    \"blueprint\": None,\n                    \"blueprint_name\": None,\n                    \"is_valid_json\": False,\n                    \"error\": f\"File not found: {file_path}\"\n                }\n            with open(path) as f:\n                json_string = f.read()\n        except Exception as e:\n            return {\n                \"blueprint_json\": None,\n                \"blueprint\": None,\n                \"blueprint_name\": None,\n                \"is_valid_json\": False,\n                \"error\": str(e)\n            }\n\n    if not json_string:\n        return {\n            \"blueprint_json\": None,\n            \"blueprint\": None,\n            \"blueprint_name\": None,\n            \"is_valid_json\": False,\n            \"error\": \"No JSON string or file path provided\"\n        }\n\n    # Try to parse JSON\n    try:\n        bp_data = json.loads(json_string)\n        return {\n            \"blueprint_json\": json_string,\n            \"blueprint\": bp_data,\n            \"blueprint_name\": bp_data.get(\"name\", bp_data.get(\"id\", \"Untitled\")),\n            \"is_valid_json\": True,\n            \"error\": None\n        }\n    except json.JSONDecodeError as e:\n        return {\n            \"blueprint_json\": json_string,\n            \"blueprint\": None,\n            \"blueprint_name\": None,\n            \"is_valid_json\": False,\n            \"error\": f\"JSON parse error at line {e.lineno}: {e.msg}\"\n        }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#9b59b6", "moduleName": "playground_compute"}, {"id": "playground_compute.validate_json", "type": "function", "label": "validate_json", "direction": "inbound", "parent": "playground_compute", "line": 89, "endLine": 116, "signature": "(params) -> Dict[]", "docstring": "Validate JSON syntax.", "source": "def validate_json(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Validate JSON syntax.\"\"\"\n    json_string = params.get(\"json_string\", \"\")\n\n    if not json_string:\n        return {\n            \"is_valid\": False,\n            \"result\": {\"errors\": [\"Empty JSON string\"]},\n            \"error\": \"Empty JSON string\"\n        }\n\n    try:\n        json.loads(json_string)\n        return {\n            \"is_valid\": True,\n            \"result\": {\"errors\": [], \"message\": \"Valid JSON syntax\"},\n            \"error\": None\n        }\n    except json.JSONDecodeError as e:\n        return {\n            \"is_valid\": False,\n            \"result\": {\n                \"errors\": [f\"Line {e.lineno}, Column {e.colno}: {e.msg}\"],\n                \"line\": e.lineno,\n                \"column\": e.colno\n            },\n            \"error\": f\"JSON parse error at line {e.lineno}: {e.msg}\"\n        }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#9b59b6", "moduleName": "playground_compute"}, {"id": "playground_compute.validate_blueprint", "type": "function", "label": "validate_blueprint", "direction": "inbound", "parent": "playground_compute", "line": 119, "endLine": 257, "signature": "(params) -> Dict[]", "docstring": "Validate blueprint structure against L++ schema.", "source": "def validate_blueprint(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Validate blueprint structure against L++ schema.\"\"\"\n    json_string = params.get(\"blueprint_json\", \"\")\n\n    if not json_string:\n        return {\n            \"is_valid\": False,\n            \"result\": {\"errors\": [\"No blueprint JSON provided\"]},\n            \"error\": \"No blueprint JSON provided\"\n        }\n\n    try:\n        bp = json.loads(json_string)\n    except json.JSONDecodeError as e:\n        return {\n            \"is_valid\": False,\n            \"result\": {\"errors\": [f\"Invalid JSON: {e.msg}\"]},\n            \"error\": f\"Invalid JSON: {e.msg}\"\n        }\n\n    errors = []\n    warnings = []\n\n    # Check required fields\n    required = [\"id\", \"states\", \"transitions\", \"entry_state\"]\n    for field in required:\n        if field not in bp:\n            errors.append(f\"Missing required field: {field}\")\n\n    # Check schema version\n    schema = bp.get(\"$schema\", \"\")\n    if not schema:\n        warnings.append(\"Missing $schema field (recommended: lpp/v0.1.2)\")\n    elif \"lpp\" not in schema:\n        warnings.append(f\"Unrecognized schema: {schema}\")\n\n    # Check states\n    states = bp.get(\"states\", {})\n    if not isinstance(states, dict):\n        errors.append(\"'states' must be an object\")\n    elif len(states) == 0:\n        errors.append(\"At least one state is required\")\n\n    # Check entry_state exists\n    entry = bp.get(\"entry_state\")\n    if entry and entry not in states:\n        errors.append(f\"entry_state '{entry}' not found in states\")\n\n    # Check terminal_states exist\n    terminals = bp.get(\"terminal_states\", [])\n    for t in terminals:\n        if t not in states:\n            errors.append(f\"terminal_state '{t}' not found in states\")\n\n    # Check transitions\n    transitions = bp.get(\"transitions\", [])\n    if not isinstance(transitions, list):\n        errors.append(\"'transitions' must be an array\")\n    else:\n        trans_ids = set()\n        for i, t in enumerate(transitions):\n            if not isinstance(t, dict):\n                errors.append(f\"Transition {i} must be an object\")\n                continue\n\n            # Check required transition fields\n            if \"id\" not in t:\n                errors.append(f\"Transition {i} missing 'id'\")\n            else:\n                if t[\"id\"] in trans_ids:\n                    errors.append(f\"Duplicate transition id: {t['id']}\")\n                trans_ids.add(t[\"id\"])\n\n            if \"from\" not in t:\n                errors.append(f\"Transition {i} missing 'from'\")\n            elif t[\"from\"] != \"*\" and t[\"from\"] not in states:\n                errors.append(f\"Transition {t.get('id', i)}: \"\n                              f\"from state '{t['from']}' not found\")\n\n            if \"to\" not in t:\n                errors.append(f\"Transition {i} missing 'to'\")\n            elif t[\"to\"] != \"*\" and t[\"to\"] not in states:\n                errors.append(f\"Transition {t.get('id', i)}: \"\n                              f\"to state '{t['to']}' not found\")\n\n            if \"on_event\" not in t:\n                errors.append(f\"Transition {t.get('id', i)} missing 'on_event'\")\n\n            # Check gates reference\n            for gate_id in t.get(\"gates\", []):\n                if gate_id not in bp.get(\"gates\", {}):\n                    errors.append(f\"Transition {t.get('id', i)}: \"\n                                  f\"gate '{gate_id}' not found\")\n\n            # Check actions reference\n            for action_id in t.get(\"actions\", []):\n                if action_id not in bp.get(\"actions\", {}):\n                    errors.append(f\"Transition {t.get('id', i)}: \"\n                                  f\"action '{action_id}' not found\")\n\n    # Check gates\n    gates = bp.get(\"gates\", {})\n    for gate_id, gate in gates.items():\n        if not isinstance(gate, dict):\n            errors.append(f\"Gate '{gate_id}' must be an object\")\n            continue\n        gate_type = gate.get(\"type\")\n        if gate_type not in [\"expression\", \"compute\"]:\n            errors.append(f\"Gate '{gate_id}': invalid type '{gate_type}'\")\n        if gate_type == \"expression\" and \"expression\" not in gate:\n            errors.append(f\"Gate '{gate_id}': missing 'expression'\")\n        if gate_type == \"compute\" and \"compute_unit\" not in gate:\n            errors.append(f\"Gate '{gate_id}': missing 'compute_unit'\")\n\n    # Check actions\n    actions = bp.get(\"actions\", {})\n    for action_id, action in actions.items():\n        if not isinstance(action, dict):\n            errors.append(f\"Action '{action_id}' must be an object\")\n            continue\n        action_type = action.get(\"type\")\n        if action_type not in [\"set\", \"compute\", \"emit\"]:\n            errors.append(f\"Action '{action_id}': invalid type '{action_type}'\")\n        if action_type == \"set\" and \"target\" not in action:\n            errors.append(f\"Action '{action_id}': missing 'target'\")\n        if action_type == \"compute\" and \"compute_unit\" not in action:\n            errors.append(f\"Action '{action_id}': missing 'compute_unit'\")\n\n    is_valid = len(errors) == 0\n\n    return {\n        \"is_valid\": is_valid,\n        \"result\": {\n            \"errors\": errors,\n            \"warnings\": warnings,\n            \"message\": \"Valid blueprint\" if is_valid else f\"{len(errors)} error(s)\"\n        },\n        \"error\": errors[0] if errors else None\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#9b59b6", "moduleName": "playground_compute"}, {"id": "playground_compute.format_blueprint", "type": "function", "label": "format_blueprint", "direction": "inbound", "parent": "playground_compute", "line": 264, "endLine": 285, "signature": "(params) -> Dict[]", "docstring": "Format/prettify JSON with consistent style.", "source": "def format_blueprint(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Format/prettify JSON with consistent style.\"\"\"\n    json_string = params.get(\"json_string\", \"\")\n\n    if not json_string:\n        return {\n            \"formatted\": \"\",\n            \"output\": \"No JSON to format\"\n        }\n\n    try:\n        bp = json.loads(json_string)\n        formatted = json.dumps(bp, indent=2, ensure_ascii=False)\n        return {\n            \"formatted\": formatted,\n            \"output\": \"Blueprint formatted successfully\"\n        }\n    except json.JSONDecodeError as e:\n        return {\n            \"formatted\": json_string,\n            \"output\": f\"Cannot format invalid JSON: {e.msg}\"\n        }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#9b59b6", "moduleName": "playground_compute"}, {"id": "playground_compute.generate_diagram", "type": "function", "label": "generate_diagram", "direction": "inbound", "parent": "playground_compute", "line": 292, "endLine": 333, "signature": "(params) -> Dict[]", "docstring": "Generate Mermaid stateDiagram from blueprint.", "source": "def generate_diagram(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Generate Mermaid stateDiagram from blueprint.\"\"\"\n    bp = params.get(\"blueprint\")\n\n    if not bp:\n        return {\"mermaid\": \"\"}\n\n    lines = [\"stateDiagram-v2\"]\n\n    # Entry state\n    entry = bp.get(\"entry_state\")\n    if entry:\n        lines.append(f\"    [*] --> {entry}\")\n\n    # State descriptions as notes\n    states = bp.get(\"states\", {})\n    for sid, state in states.items():\n        if isinstance(state, dict) and state.get(\"description\"):\n            desc = state[\"description\"][:50].replace('\"', \"'\")\n            lines.append(f\"    {sid}: {desc}\")\n\n    # Transitions\n    transitions = bp.get(\"transitions\", [])\n    for t in transitions:\n        from_state = t.get(\"from\", \"?\")\n        to_state = t.get(\"to\", \"?\")\n        event = t.get(\"on_event\", \"?\")\n\n        if from_state == \"*\":\n            # Wildcard: show from all non-target states\n            for sid in states:\n                if sid != to_state:\n                    lines.append(f\"    {sid} --> {to_state}: {event}\")\n        else:\n            lines.append(f\"    {from_state} --> {to_state}: {event}\")\n\n    # Terminal states\n    terminals = bp.get(\"terminal_states\", [])\n    for term in terminals:\n        lines.append(f\"    {term} --> [*]\")\n\n    return {\"mermaid\": \"\\n\".join(lines)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#9b59b6", "moduleName": "playground_compute"}, {"id": "playground_compute.init_simulation", "type": "function", "label": "init_simulation", "direction": "inbound", "parent": "playground_compute", "line": 340, "endLine": 387, "signature": "(params) -> Dict[]", "docstring": "Initialize simulation state from blueprint.", "source": "def init_simulation(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Initialize simulation state from blueprint.\"\"\"\n    bp = params.get(\"blueprint\")\n\n    if not bp:\n        return {\n            \"sim_state\": None,\n            \"sim_context\": {},\n            \"available_events\": [],\n            \"trace\": [],\n            \"output\": \"No blueprint provided\"\n        }\n\n    entry = bp.get(\"entry_state\")\n    if not entry:\n        return {\n            \"sim_state\": None,\n            \"sim_context\": {},\n            \"available_events\": [],\n            \"trace\": [],\n            \"output\": \"Blueprint has no entry_state\"\n        }\n\n    # Initialize context from schema\n    ctx = {\"_state\": entry}\n    schema = bp.get(\"context_schema\", {})\n    for prop in schema.get(\"properties\", {}).keys():\n        ctx[prop] = None\n\n    # Get available events\n    events = _get_available_events(bp, entry, ctx)\n\n    # Create initial trace\n    trace = [{\n        \"step\": 0,\n        \"timestamp\": datetime.now().isoformat(),\n        \"state\": entry,\n        \"context\": copy.deepcopy(ctx),\n        \"event\": None\n    }]\n\n    return {\n        \"sim_state\": entry,\n        \"sim_context\": ctx,\n        \"available_events\": events,\n        \"trace\": trace,\n        \"output\": f\"Simulation initialized at state: {entry}\"\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#9b59b6", "moduleName": "playground_compute"}, {"id": "playground_compute.get_available_events", "type": "function", "label": "get_available_events", "direction": "inbound", "parent": "playground_compute", "line": 440, "endLine": 450, "signature": "(params) -> Dict[]", "docstring": "Get list of valid events in current simulation state.", "source": "def get_available_events(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Get list of valid events in current simulation state.\"\"\"\n    bp = params.get(\"blueprint\")\n    state = params.get(\"sim_state\")\n    ctx = params.get(\"sim_context\", {})\n\n    if not bp or not state:\n        return {\"events\": []}\n\n    events = _get_available_events(bp, state, ctx)\n    return {\"events\": events}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#9b59b6", "moduleName": "playground_compute"}, {"id": "playground_compute.dispatch_event", "type": "function", "label": "dispatch_event", "direction": "inbound", "parent": "playground_compute", "line": 496, "endLine": 582, "signature": "(params) -> Dict[]", "docstring": "Dispatch an event and process state transition.", "source": "def dispatch_event(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Dispatch an event and process state transition.\"\"\"\n    bp = params.get(\"blueprint\")\n    state = params.get(\"sim_state\")\n    ctx = params.get(\"sim_context\", {})\n    trace = params.get(\"sim_trace\", [])\n    event_name = params.get(\"event_name\")\n    event_payload = params.get(\"event_payload\", {})\n\n    if not bp or not state or not event_name:\n        return {\n            \"sim_state\": state,\n            \"sim_context\": ctx,\n            \"available_events\": [],\n            \"trace\": trace,\n            \"output\": \"Missing required parameters\",\n            \"error\": \"Missing blueprint, state, or event_name\"\n        }\n\n    # Find matching transition\n    eval_ctx = copy.deepcopy(ctx)\n    eval_ctx[\"_state\"] = state\n\n    matched = None\n    for t in bp.get(\"transitions\", []):\n        if t.get(\"on_event\") != event_name:\n            continue\n        from_state = t.get(\"from\")\n        if from_state != \"*\" and from_state != state:\n            continue\n\n        # Check gates\n        gates_pass = True\n        for gate_id in t.get(\"gates\", []):\n            if not _evaluate_gate(bp, gate_id, eval_ctx):\n                gates_pass = False\n                break\n\n        if gates_pass:\n            matched = t\n            break\n\n    if not matched:\n        return {\n            \"sim_state\": state,\n            \"sim_context\": ctx,\n            \"available_events\": _get_available_events(bp, state, ctx),\n            \"trace\": trace,\n            \"output\": f\"No matching transition for '{event_name}'\",\n            \"error\": f\"No transition for {event_name} from {state}\"\n        }\n\n    # Execute actions\n    new_ctx = copy.deepcopy(ctx)\n    for action_id in matched.get(\"actions\", []):\n        new_ctx = _execute_action(bp, action_id, new_ctx, event_payload)\n\n    # Perform transition\n    new_state = matched.get(\"to\")\n    new_ctx[\"_state\"] = new_state\n\n    # Update trace\n    new_trace = copy.deepcopy(trace)\n    new_trace.append({\n        \"step\": len(trace),\n        \"timestamp\": datetime.now().isoformat(),\n        \"state\": new_state,\n        \"prev_state\": state,\n        \"event\": event_name,\n        \"event_payload\": event_payload,\n        \"transition_id\": matched.get(\"id\"),\n        \"context\": copy.deepcopy(new_ctx)\n    })\n\n    # Get new available events\n    events = _get_available_events(bp, new_state, new_ctx)\n\n    output = f\"{state} --[{event_name}]--> {new_state}\"\n\n    return {\n        \"sim_state\": new_state,\n        \"sim_context\": new_ctx,\n        \"available_events\": events,\n        \"trace\": new_trace,\n        \"output\": output,\n        \"error\": None\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#9b59b6", "moduleName": "playground_compute"}, {"id": "playground_compute.encode_share_url", "type": "function", "label": "encode_share_url", "direction": "inbound", "parent": "playground_compute", "line": 589, "endLine": 613, "signature": "(params) -> Dict[]", "docstring": "Encode blueprint as base64 URL parameter.", "source": "def encode_share_url(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Encode blueprint as base64 URL parameter.\"\"\"\n    json_string = params.get(\"blueprint_json\", \"\")\n    base_url = params.get(\"base_url\", \"http://localhost:8765\")\n\n    if not json_string:\n        return {\n            \"url\": \"\",\n            \"output\": \"No blueprint to share\"\n        }\n\n    try:\n        # Compress and encode\n        compressed = zlib.compress(json_string.encode(\"utf-8\"))\n        encoded = base64.urlsafe_b64encode(compressed).decode(\"ascii\")\n        url = f\"{base_url}?bp={encoded}\"\n        return {\n            \"url\": url,\n            \"output\": f\"Share URL generated ({len(encoded)} chars)\"\n        }\n    except Exception as e:\n        return {\n            \"url\": \"\",\n            \"output\": f\"Failed to encode: {e}\"\n        }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#9b59b6", "moduleName": "playground_compute"}, {"id": "playground_compute.decode_share_url", "type": "function", "label": "decode_share_url", "direction": "inbound", "parent": "playground_compute", "line": 616, "endLine": 662, "signature": "(params) -> Dict[]", "docstring": "Decode blueprint from base64 URL parameter.", "source": "def decode_share_url(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Decode blueprint from base64 URL parameter.\"\"\"\n    url = params.get(\"url\", \"\")\n\n    if not url:\n        return {\n            \"blueprint_json\": None,\n            \"blueprint\": None,\n            \"blueprint_name\": None,\n            \"is_valid_json\": False,\n            \"output\": \"No URL provided\",\n            \"error\": \"No URL provided\"\n        }\n\n    try:\n        # Extract bp parameter\n        if \"?bp=\" in url:\n            encoded = url.split(\"?bp=\")[1].split(\"&\")[0]\n        elif \"bp=\" in url:\n            encoded = url.split(\"bp=\")[1].split(\"&\")[0]\n        else:\n            encoded = url\n\n        # Decode and decompress\n        compressed = base64.urlsafe_b64decode(encoded)\n        json_string = zlib.decompress(compressed).decode(\"utf-8\")\n\n        # Parse\n        bp = json.loads(json_string)\n\n        return {\n            \"blueprint_json\": json_string,\n            \"blueprint\": bp,\n            \"blueprint_name\": bp.get(\"name\", bp.get(\"id\", \"Imported\")),\n            \"is_valid_json\": True,\n            \"output\": \"Blueprint imported from URL\",\n            \"error\": None\n        }\n    except Exception as e:\n        return {\n            \"blueprint_json\": None,\n            \"blueprint\": None,\n            \"blueprint_name\": None,\n            \"is_valid_json\": False,\n            \"output\": f\"Failed to decode URL: {e}\",\n            \"error\": str(e)\n        }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#9b59b6", "moduleName": "playground_compute"}, {"id": "playground_compute.export_blueprint", "type": "function", "label": "export_blueprint", "direction": "inbound", "parent": "playground_compute", "line": 669, "endLine": 708, "signature": "(params) -> Dict[]", "docstring": "Export blueprint to file.", "source": "def export_blueprint(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Export blueprint to file.\"\"\"\n    json_string = params.get(\"blueprint_json\", \"\")\n    file_path = params.get(\"file_path\")\n\n    if not json_string:\n        return {\n            \"output\": \"No blueprint to export\",\n            \"error\": \"No blueprint\"\n        }\n\n    if not file_path:\n        # Generate default filename\n        try:\n            bp = json.loads(json_string)\n            name = bp.get(\"id\", \"blueprint\")\n            file_path = f\"./{name}.json\"\n        except:\n            file_path = \"./blueprint.json\"\n\n    try:\n        # Format before writing\n        bp = json.loads(json_string)\n        formatted = json.dumps(bp, indent=2, ensure_ascii=False)\n\n        path = Path(file_path)\n        path.parent.mkdir(parents=True, exist_ok=True)\n\n        with open(path, \"w\", encoding=\"utf-8\") as f:\n            f.write(formatted)\n\n        return {\n            \"output\": f\"Exported to: {file_path}\",\n            \"error\": None\n        }\n    except Exception as e:\n        return {\n            \"output\": f\"Export failed: {e}\",\n            \"error\": str(e)\n        }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#9b59b6", "moduleName": "playground_compute"}, {"id": "base64", "type": "dependency", "label": "base64", "direction": "outbound", "category": "stdlib", "moduleColor": "#9b59b6", "moduleName": "playground_compute"}, {"id": "zlib", "type": "dependency", "label": "zlib", "direction": "outbound", "category": "stdlib", "moduleColor": "#9b59b6", "moduleName": "playground_compute"}, {"id": "registry_compute", "type": "module", "label": "registry_compute", "metrics": {"fanIn": 18, "fanOut": 5, "instability": 0.217, "internalEdges": 2, "externalCallCount": 33, "localCallCount": 0, "callsByCategory": {"stdlib": 33}, "localDependencies": []}, "moduleColor": "#1abc9c", "moduleName": "registry_compute"}, {"id": "registry_compute.init_registry", "type": "function", "label": "init_registry", "direction": "inbound", "parent": "registry_compute", "line": 19, "endLine": 51, "signature": "(params) -> Dict[]", "docstring": "Initialize a new empty registry at the specified path.", "source": "def init_registry(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Initialize a new empty registry at the specified path.\"\"\"\n    registry_path = params.get(\"registry_path\")\n    if not registry_path:\n        return {\"error\": \"No registry path provided\"}\n\n    try:\n        path = Path(registry_path)\n        path.mkdir(parents=True, exist_ok=True)\n\n        index = {\n            \"version\": \"1.0.0\",\n            \"created_at\": datetime.utcnow().isoformat() + \"Z\",\n            \"updated_at\": datetime.utcnow().isoformat() + \"Z\",\n            \"blueprints\": {}\n        }\n\n        index_path = path / \"index.json\"\n        with open(index_path, \"w\") as f:\n            json.dump(index, f, indent=2)\n\n        # Create versions directory\n        (path / \"versions\").mkdir(exist_ok=True)\n\n        return {\n            \"path\": str(path),\n            \"index\": index,\n            \"blueprints\": {},\n            \"message\": f\"Registry initialized at {path}\",\n            \"error\": None\n        }\n    except Exception as e:\n        return {\"error\": str(e)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#1abc9c", "moduleName": "registry_compute"}, {"id": "registry_compute.load_registry", "type": "function", "label": "load_registry", "direction": "inbound", "parent": "registry_compute", "line": 54, "endLine": 81, "signature": "(params) -> Dict[]", "docstring": "Load an existing registry from disk.", "source": "def load_registry(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Load an existing registry from disk.\"\"\"\n    registry_path = params.get(\"registry_path\")\n    if not registry_path:\n        return {\"error\": \"No registry path provided\"}\n\n    try:\n        path = Path(registry_path)\n        index_path = path / \"index.json\"\n\n        if not index_path.exists():\n            return {\"error\": f\"Registry not found at {path}\"}\n\n        with open(index_path) as f:\n            index = json.load(f)\n\n        blueprints = index.get(\"blueprints\", {})\n        stats = _compute_stats(blueprints)\n\n        return {\n            \"path\": str(path),\n            \"index\": index,\n            \"blueprints\": blueprints,\n            \"stats\": stats,\n            \"error\": None\n        }\n    except Exception as e:\n        return {\"error\": str(e)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#1abc9c", "moduleName": "registry_compute"}, {"id": "registry_compute.save_registry", "type": "function", "label": "save_registry", "direction": "inbound", "parent": "registry_compute", "line": 84, "endLine": 102, "signature": "(params) -> Dict[]", "docstring": "Save registry index to disk.", "source": "def save_registry(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Save registry index to disk.\"\"\"\n    registry_path = params.get(\"registry_path\")\n    index = params.get(\"index\")\n\n    if not registry_path or not index:\n        return {\"error\": \"Missing registry path or index\"}\n\n    try:\n        path = Path(registry_path)\n        index[\"updated_at\"] = datetime.utcnow().isoformat() + \"Z\"\n\n        index_path = path / \"index.json\"\n        with open(index_path, \"w\") as f:\n            json.dump(index, f, indent=2)\n\n        return {\"message\": \"Registry saved\", \"error\": None}\n    except Exception as e:\n        return {\"error\": str(e)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#1abc9c", "moduleName": "registry_compute"}, {"id": "registry_compute.register_blueprint", "type": "function", "label": "register_blueprint", "direction": "inbound", "parent": "registry_compute", "line": 109, "endLine": 174, "signature": "(params) -> Dict[]", "docstring": "Register a new blueprint in the registry.", "source": "def register_blueprint(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Register a new blueprint in the registry.\"\"\"\n    registry_path = params.get(\"registry_path\")\n    index = params.get(\"index\")\n    blueprint_path = params.get(\"blueprint_path\")\n    tags = params.get(\"tags\", [])\n    owner = params.get(\"owner\", \"unknown\")\n\n    if not blueprint_path:\n        return {\"error\": \"No blueprint path provided\"}\n\n    try:\n        bp_path = Path(blueprint_path)\n        if not bp_path.exists():\n            return {\"error\": f\"Blueprint not found: {blueprint_path}\"}\n\n        with open(bp_path) as f:\n            blueprint = json.load(f)\n\n        bp_id = blueprint.get(\"id\")\n        if not bp_id:\n            return {\"error\": \"Blueprint has no 'id' field\"}\n\n        blueprints = index.get(\"blueprints\", {})\n        if bp_id in blueprints:\n            return {\"error\": f\"Blueprint '{bp_id}' already registered. Use UPDATE.\"}\n\n        version = blueprint.get(\"version\", \"1.0.0\")\n        now = datetime.utcnow().isoformat() + \"Z\"\n\n        # Extract dependencies from actions\n        deps = _extract_dependencies(blueprint)\n\n        # Create metadata entry\n        entry = {\n            \"current_version\": version,\n            \"versions\": [version],\n            \"description\": blueprint.get(\"description\", \"\"),\n            \"name\": blueprint.get(\"name\", bp_id),\n            \"tags\": tags if isinstance(tags, list) else [tags] if tags else [],\n            \"dependencies\": deps,\n            \"deprecated\": False,\n            \"deprecated_reason\": None,\n            \"created_at\": now,\n            \"updated_at\": now,\n            \"owner\": owner,\n            \"source_path\": str(bp_path.absolute())\n        }\n\n        blueprints[bp_id] = entry\n        index[\"blueprints\"] = blueprints\n\n        # Copy blueprint to versions directory\n        reg_path = Path(registry_path)\n        version_dir = reg_path / \"versions\" / bp_id\n        version_dir.mkdir(parents=True, exist_ok=True)\n        shutil.copy(bp_path, version_dir / f\"{version}.json\")\n\n        return {\n            \"index\": index,\n            \"blueprints\": blueprints,\n            \"message\": f\"Registered {bp_id} v{version}\",\n            \"error\": None\n        }\n    except Exception as e:\n        return {\"error\": str(e)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#1abc9c", "moduleName": "registry_compute"}, {"id": "registry_compute.update_blueprint", "type": "function", "label": "update_blueprint", "direction": "inbound", "parent": "registry_compute", "line": 177, "endLine": 235, "signature": "(params) -> Dict[]", "docstring": "Update an existing blueprint with version bump.", "source": "def update_blueprint(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Update an existing blueprint with version bump.\"\"\"\n    registry_path = params.get(\"registry_path\")\n    index = params.get(\"index\")\n    blueprint_id = params.get(\"blueprint_id\")\n    blueprint_path = params.get(\"blueprint_path\")\n    bump = params.get(\"bump\", \"patch\")  # major, minor, patch\n\n    blueprints = index.get(\"blueprints\", {})\n\n    if blueprint_id and blueprint_id not in blueprints:\n        return {\"error\": f\"Blueprint '{blueprint_id}' not found in registry\"}\n\n    try:\n        bp_path = Path(blueprint_path)\n        if not bp_path.exists():\n            return {\"error\": f\"Blueprint file not found: {blueprint_path}\"}\n\n        with open(bp_path) as f:\n            blueprint = json.load(f)\n\n        bp_id = blueprint_id or blueprint.get(\"id\")\n        if not bp_id:\n            return {\"error\": \"No blueprint ID provided or found in file\"}\n\n        if bp_id not in blueprints:\n            return {\"error\": f\"Blueprint '{bp_id}' not registered. Use REGISTER.\"}\n\n        entry = blueprints[bp_id]\n        old_version = entry[\"current_version\"]\n        new_version = _bump_version(old_version, bump)\n\n        # Update entry\n        entry[\"current_version\"] = new_version\n        entry[\"versions\"].append(new_version)\n        entry[\"updated_at\"] = datetime.utcnow().isoformat() + \"Z\"\n        entry[\"description\"] = blueprint.get(\"description\", entry[\"description\"])\n        entry[\"name\"] = blueprint.get(\"name\", entry[\"name\"])\n        entry[\"dependencies\"] = _extract_dependencies(blueprint)\n        entry[\"source_path\"] = str(bp_path.absolute())\n\n        blueprints[bp_id] = entry\n        index[\"blueprints\"] = blueprints\n\n        # Copy to versions directory\n        reg_path = Path(registry_path)\n        version_dir = reg_path / \"versions\" / bp_id\n        version_dir.mkdir(parents=True, exist_ok=True)\n        shutil.copy(bp_path, version_dir / f\"{new_version}.json\")\n\n        return {\n            \"index\": index,\n            \"blueprints\": blueprints,\n            \"updated\": entry,\n            \"message\": f\"Updated {bp_id}: {old_version} -> {new_version}\",\n            \"error\": None\n        }\n    except Exception as e:\n        return {\"error\": str(e)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#1abc9c", "moduleName": "registry_compute"}, {"id": "registry_compute.get_blueprint", "type": "function", "label": "get_blueprint", "direction": "inbound", "parent": "registry_compute", "line": 242, "endLine": 293, "signature": "(params) -> Dict[]", "docstring": "Get a blueprint by ID and optionally version.", "source": "def get_blueprint(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Get a blueprint by ID and optionally version.\"\"\"\n    registry_path = params.get(\"registry_path\")\n    index = params.get(\"index\")\n    blueprint_id = params.get(\"blueprint_id\")\n    version = params.get(\"version\")\n\n    if not blueprint_id:\n        return {\"error\": \"No blueprint ID provided\"}\n\n    blueprints = index.get(\"blueprints\", {})\n    if blueprint_id not in blueprints:\n        return {\"error\": f\"Blueprint '{blueprint_id}' not found\"}\n\n    entry = blueprints[blueprint_id]\n    target_version = version or entry[\"current_version\"]\n\n    if target_version not in entry[\"versions\"]:\n        return {\"error\": f\"Version {target_version} not found for {blueprint_id}\"}\n\n    try:\n        reg_path = Path(registry_path)\n        bp_file = reg_path / \"versions\" / blueprint_id / f\"{target_version}.json\"\n\n        if bp_file.exists():\n            with open(bp_file) as f:\n                blueprint_data = json.load(f)\n        else:\n            # Fall back to source path for current version\n            if target_version == entry[\"current_version\"]:\n                source = entry.get(\"source_path\")\n                if source and Path(source).exists():\n                    with open(source) as f:\n                        blueprint_data = json.load(f)\n                else:\n                    blueprint_data = None\n            else:\n                blueprint_data = None\n\n        result = {\n            \"metadata\": entry,\n            \"data\": blueprint_data\n        }\n\n        return {\n            \"blueprint\": result,\n            \"blueprint_id\": blueprint_id,\n            \"version\": target_version,\n            \"error\": None\n        }\n    except Exception as e:\n        return {\"error\": str(e)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#1abc9c", "moduleName": "registry_compute"}, {"id": "registry_compute.list_blueprints", "type": "function", "label": "list_blueprints", "direction": "inbound", "parent": "registry_compute", "line": 296, "endLine": 331, "signature": "(params) -> Dict[]", "docstring": "List all blueprints with optional filtering.", "source": "def list_blueprints(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"List all blueprints with optional filtering.\"\"\"\n    index = params.get(\"index\")\n    filter_tag = params.get(\"filter_tag\")\n    show_deprecated = params.get(\"filter_deprecated\", False)\n\n    if not index:\n        return {\"results\": [], \"stats\": {}}\n\n    blueprints = index.get(\"blueprints\", {})\n    results = []\n\n    for bp_id, entry in blueprints.items():\n        # Filter deprecated\n        if not show_deprecated and entry.get(\"deprecated\", False):\n            continue\n\n        # Filter by tag\n        if filter_tag and filter_tag not in entry.get(\"tags\", []):\n            continue\n\n        results.append({\n            \"id\": bp_id,\n            \"name\": entry.get(\"name\", bp_id),\n            \"version\": entry[\"current_version\"],\n            \"description\": entry.get(\"description\", \"\")[:80],\n            \"tags\": entry.get(\"tags\", []),\n            \"deprecated\": entry.get(\"deprecated\", False),\n            \"updated_at\": entry.get(\"updated_at\", \"\")\n        })\n\n    # Sort by name\n    results.sort(key=lambda x: x[\"name\"].lower())\n    stats = _compute_stats(blueprints)\n\n    return {\"results\": results, \"stats\": stats}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#1abc9c", "moduleName": "registry_compute"}, {"id": "registry_compute.search_blueprints", "type": "function", "label": "search_blueprints", "direction": "inbound", "parent": "registry_compute", "line": 334, "endLine": 382, "signature": "(params) -> Dict[]", "docstring": "Search blueprints by query string.", "source": "def search_blueprints(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Search blueprints by query string.\"\"\"\n    index = params.get(\"index\")\n    query = params.get(\"query\", \"\").lower()\n    search_tags = params.get(\"search_tags\", True)\n    search_description = params.get(\"search_description\", True)\n\n    if not index or not query:\n        return {\"results\": [], \"query\": query}\n\n    blueprints = index.get(\"blueprints\", {})\n    results = []\n\n    for bp_id, entry in blueprints.items():\n        score = 0\n\n        # Match ID\n        if query in bp_id.lower():\n            score += 10\n\n        # Match name\n        if query in entry.get(\"name\", \"\").lower():\n            score += 8\n\n        # Match description\n        if search_description and query in entry.get(\"description\", \"\").lower():\n            score += 5\n\n        # Match tags\n        if search_tags:\n            for tag in entry.get(\"tags\", []):\n                if query in tag.lower():\n                    score += 3\n\n        if score > 0:\n            results.append({\n                \"id\": bp_id,\n                \"name\": entry.get(\"name\", bp_id),\n                \"version\": entry[\"current_version\"],\n                \"description\": entry.get(\"description\", \"\")[:80],\n                \"tags\": entry.get(\"tags\", []),\n                \"score\": score,\n                \"deprecated\": entry.get(\"deprecated\", False)\n            })\n\n    # Sort by score descending\n    results.sort(key=lambda x: -x[\"score\"])\n\n    return {\"results\": results, \"query\": query}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#1abc9c", "moduleName": "registry_compute"}, {"id": "registry_compute.get_versions", "type": "function", "label": "get_versions", "direction": "inbound", "parent": "registry_compute", "line": 389, "endLine": 417, "signature": "(params) -> Dict[]", "docstring": "Get version history for a blueprint.", "source": "def get_versions(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Get version history for a blueprint.\"\"\"\n    index = params.get(\"index\")\n    blueprint_id = params.get(\"blueprint_id\")\n\n    if not blueprint_id:\n        return {\"error\": \"No blueprint ID provided\"}\n\n    blueprints = index.get(\"blueprints\", {})\n    if blueprint_id not in blueprints:\n        return {\"error\": f\"Blueprint '{blueprint_id}' not found\"}\n\n    entry = blueprints[blueprint_id]\n    versions = entry.get(\"versions\", [])\n\n    # Build version info\n    version_info = []\n    for v in reversed(versions):  # Most recent first\n        info = {\n            \"version\": v,\n            \"is_current\": v == entry[\"current_version\"]\n        }\n        version_info.append(info)\n\n    return {\n        \"versions\": version_info,\n        \"blueprint_id\": blueprint_id,\n        \"error\": None\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#1abc9c", "moduleName": "registry_compute"}, {"id": "registry_compute.compare_versions", "type": "function", "label": "compare_versions", "direction": "inbound", "parent": "registry_compute", "line": 420, "endLine": 449, "signature": "(params) -> Dict[]", "docstring": "Compare two versions of a blueprint.", "source": "def compare_versions(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Compare two versions of a blueprint.\"\"\"\n    registry_path = params.get(\"registry_path\")\n    blueprint_id = params.get(\"blueprint_id\")\n    version_a = params.get(\"version_a\")\n    version_b = params.get(\"version_b\")\n\n    if not all([blueprint_id, version_a, version_b]):\n        return {\"error\": \"Missing blueprint_id, version_a, or version_b\"}\n\n    try:\n        reg_path = Path(registry_path)\n        file_a = reg_path / \"versions\" / blueprint_id / f\"{version_a}.json\"\n        file_b = reg_path / \"versions\" / blueprint_id / f\"{version_b}.json\"\n\n        if not file_a.exists():\n            return {\"error\": f\"Version {version_a} not found\"}\n        if not file_b.exists():\n            return {\"error\": f\"Version {version_b} not found\"}\n\n        with open(file_a) as f:\n            bp_a = json.load(f)\n        with open(file_b) as f:\n            bp_b = json.load(f)\n\n        diff = _diff_blueprints(bp_a, bp_b, version_a, version_b)\n\n        return {\"diff\": diff, \"error\": None}\n    except Exception as e:\n        return {\"error\": str(e)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#1abc9c", "moduleName": "registry_compute"}, {"id": "registry_compute.rollback_version", "type": "function", "label": "rollback_version", "direction": "inbound", "parent": "registry_compute", "line": 452, "endLine": 497, "signature": "(params) -> Dict[]", "docstring": "Rollback to a previous version.", "source": "def rollback_version(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Rollback to a previous version.\"\"\"\n    registry_path = params.get(\"registry_path\")\n    index = params.get(\"index\")\n    blueprint_id = params.get(\"blueprint_id\")\n    target_version = params.get(\"target_version\")\n\n    if not all([blueprint_id, target_version]):\n        return {\"error\": \"Missing blueprint_id or target_version\"}\n\n    blueprints = index.get(\"blueprints\", {})\n    if blueprint_id not in blueprints:\n        return {\"error\": f\"Blueprint '{blueprint_id}' not found\"}\n\n    entry = blueprints[blueprint_id]\n    if target_version not in entry[\"versions\"]:\n        return {\"error\": f\"Version {target_version} not found\"}\n\n    # Create a new version entry that points to the rollback\n    old_current = entry[\"current_version\"]\n    new_version = _bump_version(old_current, \"patch\")\n\n    try:\n        reg_path = Path(registry_path)\n        source_file = reg_path / \"versions\" / blueprint_id / f\"{target_version}.json\"\n        target_file = reg_path / \"versions\" / blueprint_id / f\"{new_version}.json\"\n\n        if source_file.exists():\n            shutil.copy(source_file, target_file)\n\n        entry[\"current_version\"] = new_version\n        entry[\"versions\"].append(new_version)\n        entry[\"updated_at\"] = datetime.utcnow().isoformat() + \"Z\"\n\n        blueprints[blueprint_id] = entry\n        index[\"blueprints\"] = blueprints\n\n        return {\n            \"index\": index,\n            \"blueprints\": blueprints,\n            \"blueprint\": entry,\n            \"message\": f\"Rolled back {blueprint_id} to {target_version} as {new_version}\",\n            \"error\": None\n        }\n    except Exception as e:\n        return {\"error\": str(e)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#1abc9c", "moduleName": "registry_compute"}, {"id": "registry_compute.get_dependencies", "type": "function", "label": "get_dependencies", "direction": "inbound", "parent": "registry_compute", "line": 504, "endLine": 539, "signature": "(params) -> Dict[]", "docstring": "Get dependency graph for a blueprint.", "source": "def get_dependencies(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Get dependency graph for a blueprint.\"\"\"\n    registry_path = params.get(\"registry_path\")\n    index = params.get(\"index\")\n    blueprint_id = params.get(\"blueprint_id\")\n\n    if not blueprint_id:\n        return {\"error\": \"No blueprint ID provided\"}\n\n    blueprints = index.get(\"blueprints\", {})\n    if blueprint_id not in blueprints:\n        return {\"error\": f\"Blueprint '{blueprint_id}' not found\"}\n\n    entry = blueprints[blueprint_id]\n    direct_deps = entry.get(\"dependencies\", [])\n\n    # Build dependency tree\n    graph = {\n        \"root\": blueprint_id,\n        \"nodes\": {},\n        \"edges\": []\n    }\n\n    visited = set()\n    _build_dep_tree(blueprint_id, blueprints, graph, visited)\n\n    # Also find reverse dependencies (who depends on this)\n    dependents = []\n    for bp_id, bp_entry in blueprints.items():\n        if bp_id != blueprint_id:\n            if blueprint_id in bp_entry.get(\"dependencies\", []):\n                dependents.append(bp_id)\n\n    graph[\"dependents\"] = dependents\n\n    return {\"graph\": graph, \"error\": None}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#1abc9c", "moduleName": "registry_compute"}, {"id": "registry_compute.check_circular_deps", "type": "function", "label": "check_circular_deps", "direction": "inbound", "parent": "registry_compute", "line": 542, "endLine": 591, "signature": "(params) -> Dict[]", "docstring": "Check for circular dependencies.", "source": "def check_circular_deps(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Check for circular dependencies.\"\"\"\n    index = params.get(\"index\")\n    blueprint_id = params.get(\"blueprint_id\")\n\n    blueprints = index.get(\"blueprints\", {})\n\n    if blueprint_id:\n        # Check specific blueprint\n        cycle = _detect_cycle(blueprint_id, blueprints)\n        if cycle:\n            return {\n                \"result\": {\n                    \"has_cycle\": True,\n                    \"cycle\": cycle,\n                    \"message\": f\"Circular dependency detected: {' -> '.join(cycle)}\"\n                },\n                \"error\": None\n            }\n        return {\n            \"result\": {\n                \"has_cycle\": False,\n                \"message\": f\"No circular dependencies for {blueprint_id}\"\n            },\n            \"error\": None\n        }\n    else:\n        # Check all blueprints\n        all_cycles = []\n        for bp_id in blueprints:\n            cycle = _detect_cycle(bp_id, blueprints)\n            if cycle and cycle not in all_cycles:\n                all_cycles.append(cycle)\n\n        if all_cycles:\n            return {\n                \"result\": {\n                    \"has_cycles\": True,\n                    \"cycles\": all_cycles,\n                    \"message\": f\"Found {len(all_cycles)} circular dependencies\"\n                },\n                \"error\": None\n            }\n        return {\n            \"result\": {\n                \"has_cycles\": False,\n                \"message\": \"No circular dependencies found\"\n            },\n            \"error\": None\n        }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#1abc9c", "moduleName": "registry_compute"}, {"id": "registry_compute.deprecate_blueprint", "type": "function", "label": "deprecate_blueprint", "direction": "inbound", "parent": "registry_compute", "line": 598, "endLine": 624, "signature": "(params) -> Dict[]", "docstring": "Mark a blueprint as deprecated.", "source": "def deprecate_blueprint(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Mark a blueprint as deprecated.\"\"\"\n    index = params.get(\"index\")\n    blueprint_id = params.get(\"blueprint_id\")\n    reason = params.get(\"reason\", \"No reason provided\")\n\n    if not blueprint_id:\n        return {\"error\": \"No blueprint ID provided\"}\n\n    blueprints = index.get(\"blueprints\", {})\n    if blueprint_id not in blueprints:\n        return {\"error\": f\"Blueprint '{blueprint_id}' not found\"}\n\n    entry = blueprints[blueprint_id]\n    entry[\"deprecated\"] = True\n    entry[\"deprecated_reason\"] = reason\n    entry[\"updated_at\"] = datetime.utcnow().isoformat() + \"Z\"\n\n    blueprints[blueprint_id] = entry\n    index[\"blueprints\"] = blueprints\n\n    return {\n        \"index\": index,\n        \"blueprints\": blueprints,\n        \"message\": f\"Deprecated {blueprint_id}: {reason}\",\n        \"error\": None\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#1abc9c", "moduleName": "registry_compute"}, {"id": "registry_compute.delete_blueprint", "type": "function", "label": "delete_blueprint", "direction": "inbound", "parent": "registry_compute", "line": 627, "endLine": 671, "signature": "(params) -> Dict[]", "docstring": "Delete a blueprint from the registry.", "source": "def delete_blueprint(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Delete a blueprint from the registry.\"\"\"\n    registry_path = params.get(\"registry_path\")\n    index = params.get(\"index\")\n    blueprint_id = params.get(\"blueprint_id\")\n    delete_files = params.get(\"delete_files\", False)\n\n    if not blueprint_id:\n        return {\"error\": \"No blueprint ID provided\"}\n\n    blueprints = index.get(\"blueprints\", {})\n    if blueprint_id not in blueprints:\n        return {\"error\": f\"Blueprint '{blueprint_id}' not found\"}\n\n    # Check for dependents\n    dependents = []\n    for bp_id, entry in blueprints.items():\n        if bp_id != blueprint_id:\n            if blueprint_id in entry.get(\"dependencies\", []):\n                dependents.append(bp_id)\n\n    if dependents:\n        return {\n            \"error\": f\"Cannot delete: {blueprint_id} is depended on by: \"\n                     f\"{', '.join(dependents)}\"\n        }\n\n    del blueprints[blueprint_id]\n    index[\"blueprints\"] = blueprints\n\n    # Optionally delete version files\n    if delete_files and registry_path:\n        try:\n            version_dir = Path(registry_path) / \"versions\" / blueprint_id\n            if version_dir.exists():\n                shutil.rmtree(version_dir)\n        except Exception:\n            pass  # Non-critical\n\n    return {\n        \"index\": index,\n        \"blueprints\": blueprints,\n        \"message\": f\"Deleted {blueprint_id}\",\n        \"error\": None\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#1abc9c", "moduleName": "registry_compute"}, {"id": "registry_compute.export_registry", "type": "function", "label": "export_registry", "direction": "inbound", "parent": "registry_compute", "line": 678, "endLine": 720, "signature": "(params) -> Dict[]", "docstring": "Export registry metadata.", "source": "def export_registry(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Export registry metadata.\"\"\"\n    index = params.get(\"index\")\n    fmt = params.get(\"format\", \"json\")\n\n    if not index:\n        return {\"error\": \"No index loaded\"}\n\n    blueprints = index.get(\"blueprints\", {})\n    stats = _compute_stats(blueprints)\n\n    export_data = {\n        \"registry_version\": index.get(\"version\", \"1.0.0\"),\n        \"exported_at\": datetime.utcnow().isoformat() + \"Z\",\n        \"statistics\": stats,\n        \"blueprints\": {}\n    }\n\n    for bp_id, entry in blueprints.items():\n        export_data[\"blueprints\"][bp_id] = {\n            \"name\": entry.get(\"name\", bp_id),\n            \"current_version\": entry[\"current_version\"],\n            \"description\": entry.get(\"description\", \"\"),\n            \"tags\": entry.get(\"tags\", []),\n            \"dependencies\": entry.get(\"dependencies\", []),\n            \"deprecated\": entry.get(\"deprecated\", False),\n            \"owner\": entry.get(\"owner\", \"unknown\")\n        }\n\n    if fmt == \"markdown\":\n        md_lines = [\"# L++ Blueprint Registry Export\", \"\"]\n        md_lines.append(f\"Exported: {export_data['exported_at']}\")\n        md_lines.append(f\"Total: {stats['total']} blueprints\")\n        md_lines.append(\"\")\n        md_lines.append(\"| ID | Name | Version | Tags |\")\n        md_lines.append(\"|---|---|---|---|\")\n        for bp_id, bp in export_data[\"blueprints\"].items():\n            tags = \", \".join(bp[\"tags\"][:3])\n            md_lines.append(f\"| {bp_id} | {bp['name']} | {bp['current_version']} | {tags} |\")\n\n        return {\"data\": {\"format\": \"markdown\", \"content\": \"\\n\".join(md_lines)}, \"error\": None}\n\n    return {\"data\": export_data, \"error\": None}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#1abc9c", "moduleName": "registry_compute"}, {"id": "registry_compute.get_stats", "type": "function", "label": "get_stats", "direction": "inbound", "parent": "registry_compute", "line": 723, "endLine": 730, "signature": "(params) -> Dict[]", "docstring": "Get registry statistics.", "source": "def get_stats(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Get registry statistics.\"\"\"\n    index = params.get(\"index\")\n    if not index:\n        return {\"stats\": {}}\n\n    blueprints = index.get(\"blueprints\", {})\n    return {\"stats\": _compute_stats(blueprints)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#1abc9c", "moduleName": "registry_compute"}, {"id": "registry_compute.dfs", "type": "function", "label": "dfs", "direction": "inbound", "parent": "registry_compute", "line": 913, "endLine": 932, "signature": "(node)", "docstring": null, "source": "    def dfs(node):\n        if node in path:\n            cycle_start = path.index(node)\n            return path[cycle_start:] + [node]\n\n        if node in visited:\n            return None\n\n        visited.add(node)\n        path.append(node)\n\n        entry = blueprints.get(node)\n        if entry:\n            for dep in entry.get(\"dependencies\", []):\n                cycle = dfs(dep)\n                if cycle:\n                    return cycle\n\n        path.pop()\n        return None", "args": ["node"], "returns": null, "moduleColor": "#1abc9c", "moduleName": "registry_compute"}, {"id": "shutil", "type": "dependency", "label": "shutil", "direction": "outbound", "category": "stdlib", "moduleColor": "#1abc9c", "moduleName": "registry_compute"}, {"id": "compliance_compute", "type": "module", "label": "compliance_compute", "metrics": {"fanIn": 9, "fanOut": 5, "instability": 0.357, "internalEdges": 3, "externalCallCount": 16, "localCallCount": 0, "callsByCategory": {"stdlib": 16}, "localDependencies": []}, "moduleColor": "#e74c3c", "moduleName": "compliance_compute"}, {"id": "compliance_compute.load_blueprint", "type": "function", "label": "load_blueprint", "direction": "inbound", "parent": "compliance_compute", "line": 15, "endLine": 36, "signature": "(params) -> Dict[]", "docstring": "Load an L++ blueprint from a JSON file for compliance checking.", "source": "def load_blueprint(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Load an L++ blueprint from a JSON file for compliance checking.\"\"\"\n    path = params.get(\"path\")\n    if not path:\n        return {\"blueprint\": None, \"error\": \"No path provided\"}\n\n    try:\n        path = Path(path)\n        if not path.exists():\n            return {\"blueprint\": None, \"error\": f\"File not found: {path}\"}\n\n        with open(path) as f:\n            blueprint = json.load(f)\n\n        return {\n            \"blueprint\": blueprint,\n            \"blueprint_path\": str(path),\n            \"blueprint_name\": blueprint.get(\"name\", path.stem),\n            \"error\": None\n        }\n    except Exception as e:\n        return {\"blueprint\": None, \"error\": str(e)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#e74c3c", "moduleName": "compliance_compute"}, {"id": "compliance_compute.load_policy", "type": "function", "label": "load_policy", "direction": "inbound", "parent": "compliance_compute", "line": 39, "endLine": 65, "signature": "(params) -> Dict[]", "docstring": "Load a single compliance policy and add to existing policies.", "source": "def load_policy(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Load a single compliance policy and add to existing policies.\"\"\"\n    path = params.get(\"path\")\n    existing = params.get(\"policies\", []) or []\n\n    if not path:\n        return {\"policies\": existing, \"error\": \"No path provided\"}\n\n    try:\n        path = Path(path)\n        if not path.exists():\n            return {\"policies\": existing, \"error\": f\"File not found: {path}\"}\n\n        with open(path) as f:\n            policy = json.load(f)\n\n        # Validate policy structure\n        if not policy.get(\"policy_id\"):\n            return {\"policies\": existing, \"error\": \"Invalid policy: missing policy_id\"}\n\n        # Add to existing policies (avoid duplicates)\n        policies = [p for p in existing if p.get(\"policy_id\") != policy.get(\"policy_id\")]\n        policies.append(policy)\n\n        return {\"policies\": policies, \"error\": None}\n    except Exception as e:\n        return {\"policies\": existing, \"error\": str(e)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#e74c3c", "moduleName": "compliance_compute"}, {"id": "compliance_compute.load_policies", "type": "function", "label": "load_policies", "direction": "inbound", "parent": "compliance_compute", "line": 68, "endLine": 98, "signature": "(params) -> Dict[]", "docstring": "Load all compliance policies from a directory.", "source": "def load_policies(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Load all compliance policies from a directory.\"\"\"\n    dirPath = params.get(\"dir_path\")\n\n    if not dirPath:\n        # Default to built-in policies\n        dirPath = Path(__file__).parent.parent / \"policies\"\n    else:\n        dirPath = Path(dirPath)\n\n    if not dirPath.exists():\n        return {\"policies\": [], \"error\": f\"Directory not found: {dirPath}\"}\n\n    policies = []\n    errors = []\n\n    for pf in sorted(dirPath.glob(\"*.json\")):\n        try:\n            with open(pf) as f:\n                policy = json.load(f)\n            if policy.get(\"policy_id\"):\n                policies.append(policy)\n        except Exception as e:\n            errors.append(f\"{pf.name}: {e}\")\n\n    error = \"; \".join(errors) if errors else None\n    return {\n        \"policies\": policies,\n        \"policies_dir\": str(dirPath),\n        \"error\": error\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#e74c3c", "moduleName": "compliance_compute"}, {"id": "compliance_compute.evaluate_rule", "type": "function", "label": "evaluate_rule", "direction": "inbound", "parent": "compliance_compute", "line": 101, "endLine": 134, "signature": "(params) -> Dict[]", "docstring": "Evaluate a single rule against a blueprint.", "source": "def evaluate_rule(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Evaluate a single rule against a blueprint.\"\"\"\n    blueprint = params.get(\"blueprint\", {})\n    rule = params.get(\"rule\", {})\n    policy = params.get(\"policy\", {})\n\n    ruleType = rule.get(\"type\")\n    findings = []\n\n    if ruleType == \"state_exists\":\n        findings = _check_state_exists(blueprint, rule, policy)\n    elif ruleType == \"transition_requires_gate\":\n        findings = _check_transition_requires_gate(blueprint, rule, policy)\n    elif ruleType == \"transition_requires_action\":\n        findings = _check_transition_requires_action(blueprint, rule, policy)\n    elif ruleType == \"gate_expression_check\":\n        findings = _check_gate_expression(blueprint, rule, policy)\n    elif ruleType == \"action_type_required\":\n        findings = _check_action_type_required(blueprint, rule, policy)\n    elif ruleType == \"context_property_required\":\n        findings = _check_context_property(blueprint, rule, policy)\n    elif ruleType == \"no_direct_transition\":\n        findings = _check_no_direct_transition(blueprint, rule, policy)\n    else:\n        findings = [{\n            \"policy_id\": policy.get(\"policy_id\"),\n            \"rule_type\": ruleType,\n            \"severity\": \"warning\",\n            \"message\": f\"Unknown rule type: {ruleType}\",\n            \"element\": None,\n            \"passed\": False\n        }]\n\n    return {\"findings\": findings}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#e74c3c", "moduleName": "compliance_compute"}, {"id": "compliance_compute.check_policy", "type": "function", "label": "check_policy", "direction": "inbound", "parent": "compliance_compute", "line": 416, "endLine": 431, "signature": "(params) -> Dict[]", "docstring": "Check blueprint against a single policy.", "source": "def check_policy(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Check blueprint against a single policy.\"\"\"\n    blueprint = params.get(\"blueprint\", {})\n    policy = params.get(\"policy\", {})\n\n    allFindings = []\n\n    for rule in policy.get(\"rules\", []):\n        result = evaluate_rule({\n            \"blueprint\": blueprint,\n            \"rule\": rule,\n            \"policy\": policy\n        })\n        allFindings.extend(result.get(\"findings\", []))\n\n    return {\"findings\": allFindings, \"error\": None}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#e74c3c", "moduleName": "compliance_compute"}, {"id": "compliance_compute.check_all_policies", "type": "function", "label": "check_all_policies", "direction": "inbound", "parent": "compliance_compute", "line": 434, "endLine": 456, "signature": "(params) -> Dict[]", "docstring": "Check blueprint against all loaded policies.", "source": "def check_all_policies(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Check blueprint against all loaded policies.\"\"\"\n    blueprint = params.get(\"blueprint\", {})\n    policies = params.get(\"policies\", [])\n\n    allFindings = []\n    summary = {\"error\": 0, \"warning\": 0, \"info\": 0, \"passed\": 0, \"failed\": 0}\n\n    for policy in policies:\n        result = check_policy({\"blueprint\": blueprint, \"policy\": policy})\n        pFindings = result.get(\"findings\", [])\n        allFindings.extend(pFindings)\n\n        for f in pFindings:\n            sev = f.get(\"severity\", \"info\")\n            if sev in summary:\n                summary[sev] += 1\n            if f.get(\"passed\"):\n                summary[\"passed\"] += 1\n            else:\n                summary[\"failed\"] += 1\n\n    return {\"findings\": allFindings, \"summary\": summary, \"error\": None}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#e74c3c", "moduleName": "compliance_compute"}, {"id": "compliance_compute.calculate_score", "type": "function", "label": "calculate_score", "direction": "inbound", "parent": "compliance_compute", "line": 459, "endLine": 475, "signature": "(params) -> Dict[]", "docstring": "Calculate compliance score as percentage.", "source": "def calculate_score(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Calculate compliance score as percentage.\"\"\"\n    findings = params.get(\"findings\", [])\n\n    if not findings:\n        return {\"score\": 100}\n\n    # Filter out info-only findings\n    checkFindings = [f for f in findings if f.get(\"severity\") != \"info\"]\n    if not checkFindings:\n        return {\"score\": 100}\n\n    passed = sum(1 for f in checkFindings if f.get(\"passed\"))\n    total = len(checkFindings)\n\n    score = round((passed / total) * 100) if total > 0 else 100\n    return {\"score\": score}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#e74c3c", "moduleName": "compliance_compute"}, {"id": "compliance_compute.generate_report", "type": "function", "label": "generate_report", "direction": "inbound", "parent": "compliance_compute", "line": 478, "endLine": 540, "signature": "(params) -> Dict[]", "docstring": "Generate a comprehensive compliance report.", "source": "def generate_report(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Generate a comprehensive compliance report.\"\"\"\n    blueprint = params.get(\"blueprint\", {})\n    bpName = params.get(\"blueprint_name\", blueprint.get(\"name\", \"Unknown\"))\n    policies = params.get(\"policies\", [])\n    findings = params.get(\"findings\", [])\n    summary = params.get(\"summary\", {})\n\n    # Calculate score\n    scoreResult = calculate_score({\"findings\": findings})\n    score = scoreResult[\"score\"]\n\n    # Group findings by severity\n    byS = {\"error\": [], \"warning\": [], \"info\": []}\n    for f in findings:\n        sev = f.get(\"severity\", \"info\")\n        if sev in byS:\n            byS[sev].append(f)\n\n    # Group findings by policy\n    byP = {}\n    for f in findings:\n        pid = f.get(\"policy_id\", \"unknown\")\n        if pid not in byP:\n            byP[pid] = []\n        byP[pid].append(f)\n\n    report = {\n        \"title\": f\"Compliance Report: {bpName}\",\n        \"generated_at\": datetime.now().isoformat(),\n        \"blueprint\": {\n            \"name\": bpName,\n            \"id\": blueprint.get(\"id\"),\n            \"version\": blueprint.get(\"version\")\n        },\n        \"policies_checked\": [p.get(\"policy_id\") for p in policies],\n        \"score\": score,\n        \"summary\": {\n            \"total_checks\": len(findings),\n            \"passed\": summary.get(\"passed\", 0),\n            \"failed\": summary.get(\"failed\", 0),\n            \"by_severity\": {\n                \"errors\": len(byS[\"error\"]),\n                \"warnings\": len(byS[\"warning\"]),\n                \"info\": len(byS[\"info\"])\n            }\n        },\n        \"status\": \"PASS\" if score >= 80 else \"WARNING\" if score >= 50 else \"FAIL\",\n        \"findings_by_severity\": byS,\n        \"findings_by_policy\": byP,\n        \"remediations\": [\n            {\n                \"policy_id\": f.get(\"policy_id\"),\n                \"element\": f.get(\"element\"),\n                \"issue\": f.get(\"message\"),\n                \"fix\": f.get(\"remediation\")\n            }\n            for f in findings\n            if not f.get(\"passed\") and f.get(\"remediation\")\n        ]\n    }\n\n    return {\"report\": report, \"score\": score}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#e74c3c", "moduleName": "compliance_compute"}, {"id": "compliance_compute.export_report", "type": "function", "label": "export_report", "direction": "inbound", "parent": "compliance_compute", "line": 543, "endLine": 570, "signature": "(params) -> Dict[]", "docstring": "Export compliance report to a file.", "source": "def export_report(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Export compliance report to a file.\"\"\"\n    report = params.get(\"report\", {})\n    outPath = params.get(\"output_path\", \"./compliance_report.json\")\n    fmt = params.get(\"format\", \"json\")\n\n    try:\n        outPath = Path(outPath)\n\n        if fmt == \"json\":\n            with open(outPath, \"w\") as f:\n                json.dump(report, f, indent=2)\n        elif fmt == \"md\" or fmt == \"markdown\":\n            content = _format_report_markdown(report)\n            outPath = outPath.with_suffix(\".md\")\n            with open(outPath, \"w\") as f:\n                f.write(content)\n        elif fmt == \"txt\" or fmt == \"text\":\n            content = _format_report_text(report)\n            outPath = outPath.with_suffix(\".txt\")\n            with open(outPath, \"w\") as f:\n                f.write(content)\n        else:\n            return {\"export_path\": None, \"error\": f\"Unknown format: {fmt}\"}\n\n        return {\"export_path\": str(outPath), \"error\": None}\n    except Exception as e:\n        return {\"export_path\": None, \"error\": str(e)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#e74c3c", "moduleName": "compliance_compute"}, {"id": "coverage_compute", "type": "module", "label": "coverage_compute", "metrics": {"fanIn": 18, "fanOut": 5, "instability": 0.217, "internalEdges": 6, "externalCallCount": 11, "localCallCount": 0, "callsByCategory": {"stdlib": 10, "pip": 1}, "localDependencies": []}, "moduleColor": "#3498db", "moduleName": "coverage_compute"}, {"id": "coverage_compute.load_blueprint", "type": "function", "label": "load_blueprint", "direction": "inbound", "parent": "coverage_compute", "line": 21, "endLine": 78, "signature": "(params) -> Dict[]", "docstring": "Load an L++ blueprint from a JSON file.", "source": "def load_blueprint(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Load an L++ blueprint from a JSON file.\"\"\"\n    path = params.get(\"path\")\n    if not path:\n        return {\"blueprint\": None, \"path\": None, \"error\": \"No path provided\"}\n\n    try:\n        path = Path(path)\n        if not path.exists():\n            return {\"blueprint\": None, \"path\": None,\n                    \"error\": f\"File not found: {path}\"}\n\n        with open(path) as f:\n            raw = json.load(f)\n\n        loader = BlueprintLoader(raw)\n        blueprint, loadError = loader.load()\n\n        if loadError:\n            return {\"blueprint\": None, \"path\": None, \"error\": loadError}\n\n        # Convert to dict structure for processing\n        bpData = {\n            \"id\": blueprint.id,\n            \"name\": blueprint.name,\n            \"version\": blueprint.version,\n            \"description\": blueprint.description,\n            \"states\": {\n                sid: {\"description\": s.description}\n                for sid, s in blueprint.states.items()\n            },\n            \"transitions\": [\n                {\n                    \"id\": t.id,\n                    \"from\": t.from_state,\n                    \"to\": t.to_state,\n                    \"on_event\": t.on_event,\n                    \"gates\": list(t.gates),\n                    \"actions\": list(t.actions)\n                }\n                for t in blueprint.transitions\n            ],\n            \"gates\": {\n                gid: {\"type\": \"expression\", \"expression\": g.expression}\n                for gid, g in blueprint.gates.items()\n            },\n            \"actions\": {\n                aid: {\"type\": a.type.value}\n                for aid, a in blueprint.actions.items()\n            },\n            \"entry_state\": blueprint.entry_state,\n            \"terminal_states\": list(blueprint.terminal_states)\n        }\n\n        return {\"blueprint\": bpData, \"path\": str(path), \"error\": None}\n\n    except Exception as e:\n        return {\"blueprint\": None, \"path\": None, \"error\": str(e)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#3498db", "moduleName": "coverage_compute"}, {"id": "coverage_compute.init_coverage", "type": "function", "label": "init_coverage", "direction": "inbound", "parent": "coverage_compute", "line": 85, "endLine": 132, "signature": "(params) -> Dict[]", "docstring": "Initialize coverage tracking for a blueprint.", "source": "def init_coverage(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Initialize coverage tracking for a blueprint.\"\"\"\n    bp = params.get(\"blueprint\")\n    if not bp:\n        return {\n            \"coverage_data\": None,\n            \"state_hits\": {},\n            \"transition_hits\": {},\n            \"gate_hits\": {},\n            \"action_hits\": {},\n            \"event_hits\": {}\n        }\n\n    # Initialize state hits (all states start at 0)\n    stateHits = {sid: 0 for sid in bp[\"states\"]}\n\n    # Initialize transition hits\n    transHits = {t[\"id\"]: 0 for t in bp[\"transitions\"]}\n\n    # Initialize gate hits with true/false breakdown\n    gateHits = {\n        gid: {\"total\": 0, \"true\": 0, \"false\": 0}\n        for gid in bp.get(\"gates\", {})\n    }\n\n    # Initialize action hits\n    actionHits = {aid: 0 for aid in bp.get(\"actions\", {})}\n\n    # Initialize event hits (from transitions)\n    events = set()\n    for t in bp[\"transitions\"]:\n        events.add(t[\"on_event\"])\n    eventHits = {evt: 0 for evt in events}\n\n    coverageData = {\n        \"initialized_at\": datetime.now().isoformat(),\n        \"blueprint_id\": bp[\"id\"],\n        \"blueprint_version\": bp[\"version\"]\n    }\n\n    return {\n        \"coverage_data\": coverageData,\n        \"state_hits\": stateHits,\n        \"transition_hits\": transHits,\n        \"gate_hits\": gateHits,\n        \"action_hits\": actionHits,\n        \"event_hits\": eventHits\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#3498db", "moduleName": "coverage_compute"}, {"id": "coverage_compute.record_state", "type": "function", "label": "record_state", "direction": "inbound", "parent": "coverage_compute", "line": 139, "endLine": 149, "signature": "(params) -> Dict[]", "docstring": "Record a state visit.", "source": "def record_state(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Record a state visit.\"\"\"\n    stateHits = params.get(\"state_hits\", {}).copy()\n    stateId = params.get(\"state_id\")\n\n    if stateId and stateId in stateHits:\n        stateHits[stateId] = stateHits.get(stateId, 0) + 1\n    elif stateId:\n        stateHits[stateId] = 1\n\n    return {\"state_hits\": stateHits}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#3498db", "moduleName": "coverage_compute"}, {"id": "coverage_compute.record_transition", "type": "function", "label": "record_transition", "direction": "inbound", "parent": "coverage_compute", "line": 152, "endLine": 162, "signature": "(params) -> Dict[]", "docstring": "Record a transition being taken.", "source": "def record_transition(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Record a transition being taken.\"\"\"\n    transHits = params.get(\"transition_hits\", {}).copy()\n    transId = params.get(\"transition_id\")\n\n    if transId and transId in transHits:\n        transHits[transId] = transHits.get(transId, 0) + 1\n    elif transId:\n        transHits[transId] = 1\n\n    return {\"transition_hits\": transHits}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#3498db", "moduleName": "coverage_compute"}, {"id": "coverage_compute.record_gate", "type": "function", "label": "record_gate", "direction": "inbound", "parent": "coverage_compute", "line": 165, "endLine": 181, "signature": "(params) -> Dict[]", "docstring": "Record a gate evaluation with its result.", "source": "def record_gate(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Record a gate evaluation with its result.\"\"\"\n    gateHits = params.get(\"gate_hits\", {}).copy()\n    gateId = params.get(\"gate_id\")\n    result = params.get(\"result\", True)\n\n    if gateId:\n        if gateId not in gateHits:\n            gateHits[gateId] = {\"total\": 0, \"true\": 0, \"false\": 0}\n\n        gateHits[gateId][\"total\"] += 1\n        if result:\n            gateHits[gateId][\"true\"] += 1\n        else:\n            gateHits[gateId][\"false\"] += 1\n\n    return {\"gate_hits\": gateHits}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#3498db", "moduleName": "coverage_compute"}, {"id": "coverage_compute.record_action", "type": "function", "label": "record_action", "direction": "inbound", "parent": "coverage_compute", "line": 184, "endLine": 194, "signature": "(params) -> Dict[]", "docstring": "Record an action execution.", "source": "def record_action(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Record an action execution.\"\"\"\n    actionHits = params.get(\"action_hits\", {}).copy()\n    actionId = params.get(\"action_id\")\n\n    if actionId and actionId in actionHits:\n        actionHits[actionId] = actionHits.get(actionId, 0) + 1\n    elif actionId:\n        actionHits[actionId] = 1\n\n    return {\"action_hits\": actionHits}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#3498db", "moduleName": "coverage_compute"}, {"id": "coverage_compute.record_event", "type": "function", "label": "record_event", "direction": "inbound", "parent": "coverage_compute", "line": 197, "endLine": 207, "signature": "(params) -> Dict[]", "docstring": "Record an event being dispatched.", "source": "def record_event(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Record an event being dispatched.\"\"\"\n    eventHits = params.get(\"event_hits\", {}).copy()\n    eventName = params.get(\"event_name\")\n\n    if eventName and eventName in eventHits:\n        eventHits[eventName] = eventHits.get(eventName, 0) + 1\n    elif eventName:\n        eventHits[eventName] = 1\n\n    return {\"event_hits\": eventHits}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#3498db", "moduleName": "coverage_compute"}, {"id": "coverage_compute.import_trace", "type": "function", "label": "import_trace", "direction": "inbound", "parent": "coverage_compute", "line": 214, "endLine": 308, "signature": "(params) -> Dict[]", "docstring": "Import trace data from a file and update coverage.", "source": "def import_trace(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Import trace data from a file and update coverage.\"\"\"\n    path = params.get(\"path\")\n    stateHits = params.get(\"state_hits\", {}).copy()\n    transHits = params.get(\"transition_hits\", {}).copy()\n    gateHits = params.get(\"gate_hits\", {}).copy()\n    actionHits = params.get(\"action_hits\", {}).copy()\n    eventHits = params.get(\"event_hits\", {}).copy()\n\n    if not path:\n        return {\n            \"trace_data\": None,\n            \"state_hits\": stateHits,\n            \"transition_hits\": transHits,\n            \"gate_hits\": gateHits,\n            \"action_hits\": actionHits,\n            \"event_hits\": eventHits,\n            \"error\": \"No path provided\"\n        }\n\n    try:\n        tracePath = Path(path)\n        if not tracePath.exists():\n            return {\n                \"trace_data\": None,\n                \"state_hits\": stateHits,\n                \"transition_hits\": transHits,\n                \"gate_hits\": gateHits,\n                \"action_hits\": actionHits,\n                \"event_hits\": eventHits,\n                \"error\": f\"Trace file not found: {path}\"\n            }\n\n        with open(tracePath) as f:\n            traceData = json.load(f)\n\n        # Process trace entries\n        entries = traceData if isinstance(traceData, list) else traceData.get(\n            \"entries\", traceData.get(\"trace\", []))\n\n        for entry in entries:\n            entryType = entry.get(\"type\", \"\")\n\n            if entryType == \"state\" or \"state\" in entry:\n                sid = entry.get(\"state_id\", entry.get(\"state\"))\n                if sid:\n                    stateHits[sid] = stateHits.get(sid, 0) + 1\n\n            if entryType == \"transition\" or \"transition_id\" in entry:\n                tid = entry.get(\"transition_id\", entry.get(\"transition\"))\n                if tid:\n                    transHits[tid] = transHits.get(tid, 0) + 1\n\n            if entryType == \"gate\" or \"gate_id\" in entry:\n                gid = entry.get(\"gate_id\", entry.get(\"gate\"))\n                result = entry.get(\"result\", True)\n                if gid:\n                    if gid not in gateHits:\n                        gateHits[gid] = {\"total\": 0, \"true\": 0, \"false\": 0}\n                    gateHits[gid][\"total\"] += 1\n                    if result:\n                        gateHits[gid][\"true\"] += 1\n                    else:\n                        gateHits[gid][\"false\"] += 1\n\n            if entryType == \"action\" or \"action_id\" in entry:\n                aid = entry.get(\"action_id\", entry.get(\"action\"))\n                if aid:\n                    actionHits[aid] = actionHits.get(aid, 0) + 1\n\n            if entryType == \"event\" or \"event\" in entry:\n                evt = entry.get(\"event_name\", entry.get(\"event\"))\n                if evt:\n                    eventHits[evt] = eventHits.get(evt, 0) + 1\n\n        return {\n            \"trace_data\": entries,\n            \"state_hits\": stateHits,\n            \"transition_hits\": transHits,\n            \"gate_hits\": gateHits,\n            \"action_hits\": actionHits,\n            \"event_hits\": eventHits,\n            \"error\": None\n        }\n\n    except Exception as e:\n        return {\n            \"trace_data\": None,\n            \"state_hits\": stateHits,\n            \"transition_hits\": transHits,\n            \"gate_hits\": gateHits,\n            \"action_hits\": actionHits,\n            \"event_hits\": eventHits,\n            \"error\": str(e)\n        }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#3498db", "moduleName": "coverage_compute"}, {"id": "coverage_compute.compute_metrics", "type": "function", "label": "compute_metrics", "direction": "inbound", "parent": "coverage_compute", "line": 315, "endLine": 425, "signature": "(params) -> Dict[]", "docstring": "Compute coverage metrics from hit data.", "source": "def compute_metrics(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Compute coverage metrics from hit data.\"\"\"\n    bp = params.get(\"blueprint\")\n    stateHits = params.get(\"state_hits\", {})\n    transHits = params.get(\"transition_hits\", {})\n    gateHits = params.get(\"gate_hits\", {})\n    actionHits = params.get(\"action_hits\", {})\n    eventHits = params.get(\"event_hits\", {})\n\n    if not bp:\n        return {\"metrics\": None}\n\n    # State coverage\n    totalStates = len(bp[\"states\"])\n    coveredStates = sum(1 for h in stateHits.values() if h > 0)\n    statePct = (coveredStates / totalStates * 100) if totalStates else 0\n\n    # Transition coverage\n    totalTrans = len(bp[\"transitions\"])\n    coveredTrans = sum(1 for h in transHits.values() if h > 0)\n    transPct = (coveredTrans / totalTrans * 100) if totalTrans else 0\n\n    # Gate coverage (evaluated at least once)\n    totalGates = len(bp.get(\"gates\", {}))\n    coveredGates = sum(1 for g in gateHits.values() if g.get(\"total\", 0) > 0)\n    gatePct = (coveredGates / totalGates * 100) if totalGates else 0\n\n    # Gate branch coverage (both true and false branches)\n    branchTotal = totalGates * 2  # Each gate has 2 branches\n    branchCovered = sum(\n        (1 if g.get(\"true\", 0) > 0 else 0) + (1 if g.get(\"false\", 0) > 0 else 0)\n        for g in gateHits.values()\n    )\n    branchPct = (branchCovered / branchTotal * 100) if branchTotal else 0\n\n    # Action coverage\n    totalActions = len(bp.get(\"actions\", {}))\n    coveredActions = sum(1 for h in actionHits.values() if h > 0)\n    actionPct = (coveredActions / totalActions * 100) if totalActions else 0\n\n    # Event coverage\n    allEvents = set(t[\"on_event\"] for t in bp[\"transitions\"])\n    totalEvents = len(allEvents)\n    coveredEvents = sum(1 for e, h in eventHits.items() if h > 0 and e in allEvents)\n    eventPct = (coveredEvents / totalEvents * 100) if totalEvents else 0\n\n    # Overall coverage (weighted average)\n    weights = {\n        \"state\": 0.25,\n        \"transition\": 0.35,\n        \"gate\": 0.20,\n        \"action\": 0.15,\n        \"event\": 0.05\n    }\n    overallPct = (\n        statePct * weights[\"state\"] +\n        transPct * weights[\"transition\"] +\n        gatePct * weights[\"gate\"] +\n        actionPct * weights[\"action\"] +\n        eventPct * weights[\"event\"]\n    )\n\n    metrics = {\n        \"computed_at\": datetime.now().isoformat(),\n        \"blueprint_id\": bp[\"id\"],\n        \"overall_percentage\": round(overallPct, 1),\n        \"state_coverage\": {\n            \"total\": totalStates,\n            \"covered\": coveredStates,\n            \"percentage\": round(statePct, 1),\n            \"uncovered\": [s for s, h in stateHits.items() if h == 0]\n        },\n        \"state_percentage\": round(statePct, 1),\n        \"transition_coverage\": {\n            \"total\": totalTrans,\n            \"covered\": coveredTrans,\n            \"percentage\": round(transPct, 1),\n            \"uncovered\": [t for t, h in transHits.items() if h == 0]\n        },\n        \"transition_percentage\": round(transPct, 1),\n        \"gate_coverage\": {\n            \"total\": totalGates,\n            \"covered\": coveredGates,\n            \"percentage\": round(gatePct, 1),\n            \"branch_coverage\": round(branchPct, 1),\n            \"uncovered\": [g for g, h in gateHits.items() if h.get(\"total\", 0) == 0],\n            \"missing_true\": [g for g, h in gateHits.items() if h.get(\"true\", 0) == 0],\n            \"missing_false\": [g for g, h in gateHits.items() if h.get(\"false\", 0) == 0]\n        },\n        \"action_coverage\": {\n            \"total\": totalActions,\n            \"covered\": coveredActions,\n            \"percentage\": round(actionPct, 1),\n            \"uncovered\": [a for a, h in actionHits.items() if h == 0]\n        },\n        \"event_coverage\": {\n            \"total\": totalEvents,\n            \"covered\": coveredEvents,\n            \"percentage\": round(eventPct, 1),\n            \"uncovered\": [e for e in allEvents if eventHits.get(e, 0) == 0]\n        },\n        \"hit_counts\": {\n            \"states\": dict(stateHits),\n            \"transitions\": dict(transHits),\n            \"gates\": {g: h.get(\"total\", 0) for g, h in gateHits.items()},\n            \"actions\": dict(actionHits),\n            \"events\": dict(eventHits)\n        }\n    }\n\n    return {\"metrics\": metrics}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#3498db", "moduleName": "coverage_compute"}, {"id": "coverage_compute.generate_summary", "type": "function", "label": "generate_summary", "direction": "inbound", "parent": "coverage_compute", "line": 432, "endLine": 469, "signature": "(params) -> Dict[]", "docstring": "Generate a summary coverage report.", "source": "def generate_summary(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Generate a summary coverage report.\"\"\"\n    bp = params.get(\"blueprint\")\n    metrics = params.get(\"metrics\")\n\n    if not bp or not metrics:\n        return {\"report\": \"No metrics available\"}\n\n    lines = [\n        \"=\" * 60,\n        f\"  COVERAGE SUMMARY: {bp['name']}\",\n        \"=\" * 60,\n        \"\",\n        f\"  Overall Coverage: {metrics['overall_percentage']}%\",\n        \"\",\n        \"  Component Breakdown:\",\n        f\"    States:      {metrics['state_coverage']['covered']:3d}/\"\n        f\"{metrics['state_coverage']['total']:3d}  \"\n        f\"({metrics['state_coverage']['percentage']:5.1f}%)\",\n        f\"    Transitions: {metrics['transition_coverage']['covered']:3d}/\"\n        f\"{metrics['transition_coverage']['total']:3d}  \"\n        f\"({metrics['transition_coverage']['percentage']:5.1f}%)\",\n        f\"    Gates:       {metrics['gate_coverage']['covered']:3d}/\"\n        f\"{metrics['gate_coverage']['total']:3d}  \"\n        f\"({metrics['gate_coverage']['percentage']:5.1f}%)\",\n        f\"    Actions:     {metrics['action_coverage']['covered']:3d}/\"\n        f\"{metrics['action_coverage']['total']:3d}  \"\n        f\"({metrics['action_coverage']['percentage']:5.1f}%)\",\n        f\"    Events:      {metrics['event_coverage']['covered']:3d}/\"\n        f\"{metrics['event_coverage']['total']:3d}  \"\n        f\"({metrics['event_coverage']['percentage']:5.1f}%)\",\n        \"\",\n        f\"  Gate Branch Coverage: {metrics['gate_coverage']['branch_coverage']}%\",\n        \"\",\n        \"=\" * 60\n    ]\n\n    return {\"report\": \"\\n\".join(lines)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#3498db", "moduleName": "coverage_compute"}, {"id": "coverage_compute.generate_detailed", "type": "function", "label": "generate_detailed", "direction": "inbound", "parent": "coverage_compute", "line": 472, "endLine": 541, "signature": "(params) -> Dict[]", "docstring": "Generate a detailed coverage report with hit counts.", "source": "def generate_detailed(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Generate a detailed coverage report with hit counts.\"\"\"\n    bp = params.get(\"blueprint\")\n    metrics = params.get(\"metrics\")\n    stateHits = params.get(\"state_hits\", {})\n    transHits = params.get(\"transition_hits\", {})\n    gateHits = params.get(\"gate_hits\", {})\n    actionHits = params.get(\"action_hits\", {})\n\n    if not bp or not metrics:\n        return {\"report\": \"No metrics available\"}\n\n    lines = [\n        \"=\" * 70,\n        f\"  DETAILED COVERAGE REPORT: {bp['name']}\",\n        \"=\" * 70,\n        \"\",\n        \"  STATES\",\n        \"  \" + \"-\" * 66,\n    ]\n\n    for sid, hits in sorted(stateHits.items()):\n        status = \"[X]\" if hits > 0 else \"[ ]\"\n        desc = bp[\"states\"].get(sid, {}).get(\"description\", \"\")[:40]\n        lines.append(f\"    {status} {sid:25} hits={hits:4d}  {desc}\")\n\n    lines.extend([\n        \"\",\n        \"  TRANSITIONS\",\n        \"  \" + \"-\" * 66,\n    ])\n\n    for trans in bp[\"transitions\"]:\n        tid = trans[\"id\"]\n        hits = transHits.get(tid, 0)\n        status = \"[X]\" if hits > 0 else \"[ ]\"\n        arrow = f\"{trans['from']} --[{trans['on_event']}]--> {trans['to']}\"\n        lines.append(f\"    {status} {tid:20} hits={hits:4d}  {arrow[:35]}\")\n\n    lines.extend([\n        \"\",\n        \"  GATES\",\n        \"  \" + \"-\" * 66,\n    ])\n\n    for gid, data in sorted(gateHits.items()):\n        total = data.get(\"total\", 0)\n        trueHits = data.get(\"true\", 0)\n        falseHits = data.get(\"false\", 0)\n        status = \"[X]\" if total > 0 else \"[ ]\"\n        branchInfo = f\"T={trueHits}, F={falseHits}\"\n        lines.append(f\"    {status} {gid:25} hits={total:4d}  ({branchInfo})\")\n\n    lines.extend([\n        \"\",\n        \"  ACTIONS\",\n        \"  \" + \"-\" * 66,\n    ])\n\n    for aid, hits in sorted(actionHits.items()):\n        status = \"[X]\" if hits > 0 else \"[ ]\"\n        atype = bp.get(\"actions\", {}).get(aid, {}).get(\"type\", \"?\")\n        lines.append(f\"    {status} {aid:30} hits={hits:4d}  type={atype}\")\n\n    lines.extend([\n        \"\",\n        \"=\" * 70\n    ])\n\n    return {\"report\": \"\\n\".join(lines)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#3498db", "moduleName": "coverage_compute"}, {"id": "coverage_compute.generate_gap_report", "type": "function", "label": "generate_gap_report", "direction": "inbound", "parent": "coverage_compute", "line": 544, "endLine": 641, "signature": "(params) -> Dict[]", "docstring": "Generate a gap analysis report with suggestions.", "source": "def generate_gap_report(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Generate a gap analysis report with suggestions.\"\"\"\n    bp = params.get(\"blueprint\")\n    metrics = params.get(\"metrics\")\n    stateHits = params.get(\"state_hits\", {})\n    transHits = params.get(\"transition_hits\", {})\n    gateHits = params.get(\"gate_hits\", {})\n    actionHits = params.get(\"action_hits\", {})\n\n    if not bp or not metrics:\n        return {\"report\": \"No metrics available\"}\n\n    lines = [\n        \"=\" * 70,\n        f\"  COVERAGE GAP ANALYSIS: {bp['name']}\",\n        \"=\" * 70,\n        \"\",\n    ]\n\n    # Uncovered states\n    uncoveredStates = [s for s, h in stateHits.items() if h == 0]\n    if uncoveredStates:\n        lines.append(\"  UNCOVERED STATES\")\n        lines.append(\"  \" + \"-\" * 66)\n        for sid in uncoveredStates:\n            # Find how to reach this state\n            incomingTrans = [t for t in bp[\"transitions\"]\n                            if t[\"to\"] == sid and t[\"from\"] != \"*\"]\n            if incomingTrans:\n                suggestion = (f\"Try: dispatch('{incomingTrans[0]['on_event']}') \"\n                            f\"from state '{incomingTrans[0]['from']}'\")\n            else:\n                suggestion = \"No incoming transitions found\"\n            lines.append(f\"    - {sid}\")\n            lines.append(f\"      Suggestion: {suggestion}\")\n        lines.append(\"\")\n\n    # Uncovered transitions\n    uncoveredTrans = [t for t, h in transHits.items() if h == 0]\n    if uncoveredTrans:\n        lines.append(\"  UNCOVERED TRANSITIONS\")\n        lines.append(\"  \" + \"-\" * 66)\n        for tid in uncoveredTrans:\n            trans = next((t for t in bp[\"transitions\"] if t[\"id\"] == tid), None)\n            if trans:\n                gates = trans.get(\"gates\", [])\n                gateInfo = f\" (gates: {', '.join(gates)})\" if gates else \"\"\n                lines.append(f\"    - {tid}\")\n                lines.append(f\"      Path: {trans['from']} --[{trans['on_event']}]--> \"\n                           f\"{trans['to']}{gateInfo}\")\n                if gates:\n                    lines.append(f\"      Suggestion: Ensure gates pass: {gates}\")\n        lines.append(\"\")\n\n    # Gates missing branch coverage\n    missingTrue = [g for g, h in gateHits.items() if h.get(\"true\", 0) == 0]\n    missingFalse = [g for g, h in gateHits.items() if h.get(\"false\", 0) == 0]\n\n    if missingTrue or missingFalse:\n        lines.append(\"  INCOMPLETE GATE BRANCH COVERAGE\")\n        lines.append(\"  \" + \"-\" * 66)\n        for gid in set(missingTrue + missingFalse):\n            expr = bp.get(\"gates\", {}).get(gid, {}).get(\"expression\", \"?\")\n            branches = []\n            if gid in missingTrue:\n                branches.append(\"true\")\n            if gid in missingFalse:\n                branches.append(\"false\")\n            lines.append(f\"    - {gid}: missing {', '.join(branches)} branch\")\n            lines.append(f\"      Expression: {expr[:50]}\")\n        lines.append(\"\")\n\n    # Uncovered actions\n    uncoveredActions = [a for a, h in actionHits.items() if h == 0]\n    if uncoveredActions:\n        lines.append(\"  UNCOVERED ACTIONS\")\n        lines.append(\"  \" + \"-\" * 66)\n        for aid in uncoveredActions:\n            # Find which transitions use this action\n            usingTrans = [t[\"id\"] for t in bp[\"transitions\"]\n                         if aid in t.get(\"actions\", [])]\n            lines.append(f\"    - {aid}\")\n            if usingTrans:\n                lines.append(f\"      Used by: {', '.join(usingTrans[:3])}\")\n            else:\n                lines.append(\"      Warning: Action not used by any transition\")\n        lines.append(\"\")\n\n    if not any([uncoveredStates, uncoveredTrans, missingTrue, missingFalse,\n                uncoveredActions]):\n        lines.append(\"  No coverage gaps found! 100% coverage achieved.\")\n        lines.append(\"\")\n\n    lines.extend([\n        \"=\" * 70\n    ])\n\n    return {\"report\": \"\\n\".join(lines)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#3498db", "moduleName": "coverage_compute"}, {"id": "coverage_compute.export_html", "type": "function", "label": "export_html", "direction": "inbound", "parent": "coverage_compute", "line": 648, "endLine": 805, "signature": "(params) -> Dict[]", "docstring": "Generate an interactive HTML coverage report.", "source": "def export_html(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Generate an interactive HTML coverage report.\"\"\"\n    bp = params.get(\"blueprint\")\n    metrics = params.get(\"metrics\")\n    stateHits = params.get(\"state_hits\", {})\n    transHits = params.get(\"transition_hits\", {})\n    gateHits = params.get(\"gate_hits\", {})\n    actionHits = params.get(\"action_hits\", {})\n    outPath = params.get(\"path\")\n\n    if not bp or not metrics:\n        return {\"html\": None, \"path\": None}\n\n    # Color coding function\n    def covColor(pct):\n        if pct >= 80:\n            return \"#4caf50\"  # green\n        elif pct >= 50:\n            return \"#ff9800\"  # orange\n        else:\n            return \"#f44336\"  # red\n\n    def hitColor(hits):\n        if hits > 0:\n            return \"#e8f5e9\"  # light green\n        else:\n            return \"#ffebee\"  # light red\n\n    overallColor = covColor(metrics[\"overall_percentage\"])\n\n    html = f\"\"\"<!DOCTYPE html>\n<html>\n<head>\n    <title>Coverage Report: {bp['name']}</title>\n    <style>\n        body {{ font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; margin: 20px; }}\n        h1 {{ color: #333; }}\n        .summary {{ background: #f5f5f5; padding: 20px; border-radius: 8px; margin-bottom: 20px; }}\n        .overall {{ font-size: 48px; font-weight: bold; color: {overallColor}; }}\n        .metrics {{ display: flex; gap: 20px; flex-wrap: wrap; }}\n        .metric {{ background: white; padding: 15px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); min-width: 150px; }}\n        .metric-value {{ font-size: 24px; font-weight: bold; }}\n        .metric-label {{ color: #666; font-size: 12px; text-transform: uppercase; }}\n        table {{ border-collapse: collapse; width: 100%; margin: 20px 0; }}\n        th, td {{ padding: 10px; text-align: left; border-bottom: 1px solid #ddd; }}\n        th {{ background: #f5f5f5; }}\n        .hit {{ background: #e8f5e9; }}\n        .miss {{ background: #ffebee; }}\n        .section {{ margin: 30px 0; }}\n        .bar {{ height: 20px; border-radius: 10px; background: #eee; overflow: hidden; }}\n        .bar-fill {{ height: 100%; transition: width 0.3s; }}\n    </style>\n</head>\n<body>\n    <h1>Coverage Report: {bp['name']}</h1>\n    <p>Generated: {metrics['computed_at']}</p>\n\n    <div class=\"summary\">\n        <div class=\"overall\">{metrics['overall_percentage']}%</div>\n        <div>Overall Coverage</div>\n    </div>\n\n    <div class=\"metrics\">\n        <div class=\"metric\">\n            <div class=\"metric-value\" style=\"color: {covColor(metrics['state_coverage']['percentage'])}\">{metrics['state_coverage']['percentage']}%</div>\n            <div class=\"metric-label\">State Coverage</div>\n            <div>{metrics['state_coverage']['covered']}/{metrics['state_coverage']['total']}</div>\n        </div>\n        <div class=\"metric\">\n            <div class=\"metric-value\" style=\"color: {covColor(metrics['transition_coverage']['percentage'])}\">{metrics['transition_coverage']['percentage']}%</div>\n            <div class=\"metric-label\">Transition Coverage</div>\n            <div>{metrics['transition_coverage']['covered']}/{metrics['transition_coverage']['total']}</div>\n        </div>\n        <div class=\"metric\">\n            <div class=\"metric-value\" style=\"color: {covColor(metrics['gate_coverage']['percentage'])}\">{metrics['gate_coverage']['percentage']}%</div>\n            <div class=\"metric-label\">Gate Coverage</div>\n            <div>{metrics['gate_coverage']['covered']}/{metrics['gate_coverage']['total']}</div>\n        </div>\n        <div class=\"metric\">\n            <div class=\"metric-value\" style=\"color: {covColor(metrics['action_coverage']['percentage'])}\">{metrics['action_coverage']['percentage']}%</div>\n            <div class=\"metric-label\">Action Coverage</div>\n            <div>{metrics['action_coverage']['covered']}/{metrics['action_coverage']['total']}</div>\n        </div>\n    </div>\n\n    <div class=\"section\">\n        <h2>States</h2>\n        <table>\n            <tr><th>State</th><th>Hits</th><th>Description</th></tr>\n\"\"\"\n\n    for sid, hits in sorted(stateHits.items()):\n        cls = \"hit\" if hits > 0 else \"miss\"\n        desc = bp[\"states\"].get(sid, {}).get(\"description\", \"\")\n        html += f'            <tr class=\"{cls}\"><td>{sid}</td><td>{hits}</td><td>{desc}</td></tr>\\n'\n\n    html += \"\"\"        </table>\n    </div>\n\n    <div class=\"section\">\n        <h2>Transitions</h2>\n        <table>\n            <tr><th>ID</th><th>From</th><th>Event</th><th>To</th><th>Hits</th></tr>\n\"\"\"\n\n    for trans in bp[\"transitions\"]:\n        tid = trans[\"id\"]\n        hits = transHits.get(tid, 0)\n        cls = \"hit\" if hits > 0 else \"miss\"\n        html += f'            <tr class=\"{cls}\"><td>{tid}</td><td>{trans[\"from\"]}</td><td>{trans[\"on_event\"]}</td><td>{trans[\"to\"]}</td><td>{hits}</td></tr>\\n'\n\n    html += \"\"\"        </table>\n    </div>\n\n    <div class=\"section\">\n        <h2>Gates</h2>\n        <table>\n            <tr><th>Gate</th><th>Total Hits</th><th>True</th><th>False</th><th>Expression</th></tr>\n\"\"\"\n\n    for gid, data in sorted(gateHits.items()):\n        total = data.get(\"total\", 0)\n        cls = \"hit\" if total > 0 else \"miss\"\n        expr = bp.get(\"gates\", {}).get(gid, {}).get(\"expression\", \"\")[:50]\n        html += f'            <tr class=\"{cls}\"><td>{gid}</td><td>{total}</td><td>{data.get(\"true\", 0)}</td><td>{data.get(\"false\", 0)}</td><td>{expr}</td></tr>\\n'\n\n    html += \"\"\"        </table>\n    </div>\n\n    <div class=\"section\">\n        <h2>Actions</h2>\n        <table>\n            <tr><th>Action</th><th>Hits</th><th>Type</th></tr>\n\"\"\"\n\n    for aid, hits in sorted(actionHits.items()):\n        cls = \"hit\" if hits > 0 else \"miss\"\n        atype = bp.get(\"actions\", {}).get(aid, {}).get(\"type\", \"?\")\n        html += f'            <tr class=\"{cls}\"><td>{aid}</td><td>{hits}</td><td>{atype}</td></tr>\\n'\n\n    html += \"\"\"        </table>\n    </div>\n</body>\n</html>\"\"\"\n\n    # Write to file if path provided\n    if outPath:\n        try:\n            outFile = Path(outPath)\n            if not outFile.suffix:\n                outFile = outFile.with_suffix(\".html\")\n            outFile.parent.mkdir(parents=True, exist_ok=True)\n            outFile.write_text(html)\n            return {\"html\": html, \"path\": str(outFile)}\n        except Exception as e:\n            return {\"html\": html, \"path\": None, \"error\": str(e)}\n\n    return {\"html\": html, \"path\": None}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#3498db", "moduleName": "coverage_compute"}, {"id": "coverage_compute.export_json", "type": "function", "label": "export_json", "direction": "inbound", "parent": "coverage_compute", "line": 808, "endLine": 853, "signature": "(params) -> Dict[]", "docstring": "Export coverage data as JSON.", "source": "def export_json(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Export coverage data as JSON.\"\"\"\n    bp = params.get(\"blueprint\")\n    metrics = params.get(\"metrics\")\n    stateHits = params.get(\"state_hits\", {})\n    transHits = params.get(\"transition_hits\", {})\n    gateHits = params.get(\"gate_hits\", {})\n    actionHits = params.get(\"action_hits\", {})\n    eventHits = params.get(\"event_hits\", {})\n    outPath = params.get(\"path\")\n\n    if not bp or not metrics:\n        return {\"json\": None, \"path\": None}\n\n    data = {\n        \"coverage_report\": {\n            \"blueprint_id\": bp[\"id\"],\n            \"blueprint_name\": bp[\"name\"],\n            \"blueprint_version\": bp[\"version\"],\n            \"generated_at\": datetime.now().isoformat(),\n            \"metrics\": metrics,\n            \"raw_data\": {\n                \"state_hits\": stateHits,\n                \"transition_hits\": transHits,\n                \"gate_hits\": gateHits,\n                \"action_hits\": actionHits,\n                \"event_hits\": eventHits\n            }\n        }\n    }\n\n    jsonStr = json.dumps(data, indent=2)\n\n    # Write to file if path provided\n    if outPath:\n        try:\n            outFile = Path(outPath)\n            if not outFile.suffix:\n                outFile = outFile.with_suffix(\".json\")\n            outFile.parent.mkdir(parents=True, exist_ok=True)\n            outFile.write_text(jsonStr)\n            return {\"json\": jsonStr, \"path\": str(outFile)}\n        except Exception as e:\n            return {\"json\": jsonStr, \"path\": None, \"error\": str(e)}\n\n    return {\"json\": jsonStr, \"path\": None}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#3498db", "moduleName": "coverage_compute"}, {"id": "coverage_compute.reset_coverage", "type": "function", "label": "reset_coverage", "direction": "inbound", "parent": "coverage_compute", "line": 860, "endLine": 872, "signature": "(params) -> Dict[]", "docstring": "Reset coverage data while keeping blueprint loaded.", "source": "def reset_coverage(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Reset coverage data while keeping blueprint loaded.\"\"\"\n    bp = params.get(\"blueprint\")\n    result = init_coverage({\"blueprint\": bp})\n    result.update({\n        \"metrics\": None,\n        \"summary_report\": None,\n        \"detailed_report\": None,\n        \"gap_report\": None,\n        \"html_report\": None,\n        \"json_report\": None\n    })\n    return result", "args": ["params"], "returns": "Dict[]", "moduleColor": "#3498db", "moduleName": "coverage_compute"}, {"id": "coverage_compute.clear_all", "type": "function", "label": "clear_all", "direction": "inbound", "parent": "coverage_compute", "line": 875, "endLine": 894, "signature": "(params) -> Dict[]", "docstring": "Clear all state including blueprint.", "source": "def clear_all(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Clear all state including blueprint.\"\"\"\n    return {\n        \"blueprint\": None,\n        \"blueprint_path\": None,\n        \"coverage_data\": None,\n        \"state_hits\": {},\n        \"transition_hits\": {},\n        \"gate_hits\": {},\n        \"action_hits\": {},\n        \"event_hits\": {},\n        \"metrics\": None,\n        \"summary_report\": None,\n        \"detailed_report\": None,\n        \"gap_report\": None,\n        \"html_report\": None,\n        \"json_report\": None,\n        \"trace_data\": None,\n        \"error\": None\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#3498db", "moduleName": "coverage_compute"}, {"id": "coverage_compute.covColor", "type": "function", "label": "covColor", "direction": "inbound", "parent": "coverage_compute", "line": 662, "endLine": 668, "signature": "(pct)", "docstring": null, "source": "    def covColor(pct):\n        if pct >= 80:\n            return \"#4caf50\"  # green\n        elif pct >= 50:\n            return \"#ff9800\"  # orange\n        else:\n            return \"#f44336\"  # red", "args": ["pct"], "returns": null, "moduleColor": "#3498db", "moduleName": "coverage_compute"}, {"id": "coverage_compute.hitColor", "type": "function", "label": "hitColor", "direction": "inbound", "parent": "coverage_compute", "line": 670, "endLine": 674, "signature": "(hits)", "docstring": null, "source": "    def hitColor(hits):\n        if hits > 0:\n            return \"#e8f5e9\"  # light green\n        else:\n            return \"#ffebee\"  # light red", "args": ["hits"], "returns": null, "moduleColor": "#3498db", "moduleName": "coverage_compute"}, {"id": "dashboard_compute", "type": "module", "label": "dashboard_compute", "metrics": {"fanIn": 4, "fanOut": 4, "instability": 0.5, "internalEdges": 0, "externalCallCount": 23, "localCallCount": 0, "callsByCategory": {"stdlib": 23}, "localDependencies": []}, "moduleColor": "#2ecc71", "moduleName": "dashboard_compute"}, {"id": "dashboard_compute.scanTools", "type": "function", "label": "scanTools", "direction": "inbound", "parent": "dashboard_compute", "line": 27, "endLine": 64, "signature": "(params) -> dict", "docstring": "Scan utils directory for L++ tool blueprints.", "source": "def scanTools(params: dict) -> dict:\n    \"\"\"Scan utils directory for L++ tool blueprints.\"\"\"\n    utilsPath = params.get(\"utilsPath\", \"\")\n    if not utilsPath or not os.path.isdir(utilsPath):\n        return {\"tools\": [], \"hasTools\": False, \"error\": f\"Invalid utils path: {utilsPath}\"}\n\n    tools = []\n    for item in sorted(os.listdir(utilsPath)):\n        toolDir = os.path.join(utilsPath, item)\n        if not os.path.isdir(toolDir):\n            continue\n\n        # Skip non-tool directories\n        if item.startswith(\"__\") or item in [\"results\", \"src\"]:\n            continue\n\n        # Look for blueprint JSON (either {name}.json or blueprint.json)\n        blueprintPath = None\n        for jsonFile in [f\"{item}.json\", \"blueprint.json\"]:\n            candidate = os.path.join(toolDir, jsonFile)\n            if os.path.exists(candidate):\n                blueprintPath = candidate\n                break\n\n        if not blueprintPath:\n            continue\n\n        # Build tool metadata\n        toolMeta = {\n            \"id\": item,\n            \"dir\": toolDir,\n            \"blueprintPath\": blueprintPath,\n            \"visualizations\": _findVisualizations(toolDir, item),\n            \"simpleMmd\": _findSimpleMmd(toolDir, item)\n        }\n        tools.append(toolMeta)\n\n    return {\"tools\": tools, \"hasTools\": len(tools) > 0, \"error\": None}", "args": ["params"], "returns": "dict", "moduleColor": "#2ecc71", "moduleName": "dashboard_compute"}, {"id": "dashboard_compute.analyzeTools", "type": "function", "label": "analyzeTools", "direction": "inbound", "parent": "dashboard_compute", "line": 112, "endLine": 187, "signature": "(params) -> dict", "docstring": "Analyze tool blueprints to extract statistics.", "source": "def analyzeTools(params: dict) -> dict:\n    \"\"\"Analyze tool blueprints to extract statistics.\"\"\"\n    tools = params.get(\"tools\", [])\n    if not tools:\n        return {\"tools\": tools, \"statistics\": {}, \"error\": \"No tools to analyze\"}\n\n    totalStats = {\n        \"toolCount\": len(tools),\n        \"totalStates\": 0,\n        \"totalTransitions\": 0,\n        \"totalGates\": 0,\n        \"totalActions\": 0,\n        \"withVisualizations\": 0\n    }\n\n    analyzedTools = []\n    for tool in tools:\n        try:\n            with open(tool[\"blueprintPath\"], \"r\", encoding=\"utf-8\") as f:\n                blueprint = json.load(f)\n        except Exception as e:\n            tool[\"error\"] = str(e)\n            tool[\"stats\"] = {}\n            tool[\"blueprint\"] = {}\n            analyzedTools.append(tool)\n            continue\n\n        # Extract blueprint metadata\n        tool[\"name\"] = blueprint.get(\"name\", tool[\"id\"])\n        tool[\"description\"] = blueprint.get(\"description\", \"\")\n        tool[\"version\"] = blueprint.get(\"version\", \"\")\n        tool[\"schema\"] = blueprint.get(\"$schema\", \"\")\n\n        # Calculate statistics\n        states = blueprint.get(\"states\", {})\n        transitions = blueprint.get(\"transitions\", [])\n        gates = blueprint.get(\"gates\", {})\n        actions = blueprint.get(\"actions\", {})\n\n        tool[\"stats\"] = {\n            \"statesCount\": len(states),\n            \"transitionsCount\": len(transitions),\n            \"gatesCount\": len(gates),\n            \"actionsCount\": len(actions),\n            \"entryState\": blueprint.get(\"entry_state\", \"\"),\n            \"terminalStates\": blueprint.get(\"terminal_states\", [])\n        }\n\n        # Store states list for display\n        tool[\"states\"] = list(states.keys())\n\n        # Update totals\n        totalStats[\"totalStates\"] += len(states)\n        totalStats[\"totalTransitions\"] += len(transitions)\n        totalStats[\"totalGates\"] += len(gates)\n        totalStats[\"totalActions\"] += len(actions)\n\n        # Check visualizations\n        vizCount = sum(1 for v in tool[\"visualizations\"].values() if v)\n        if vizCount > 0:\n            totalStats[\"withVisualizations\"] += 1\n\n        # Load simple mermaid if available\n        if tool.get(\"simpleMmd\"):\n            try:\n                with open(tool[\"simpleMmd\"], \"r\", encoding=\"utf-8\") as f:\n                    tool[\"mermaidContent\"] = f.read()\n            except:\n                tool[\"mermaidContent\"] = None\n        else:\n            tool[\"mermaidContent\"] = None\n\n        tool[\"blueprint\"] = blueprint\n        analyzedTools.append(tool)\n\n    return {\"tools\": analyzedTools, \"statistics\": totalStats, \"error\": None}", "args": ["params"], "returns": "dict", "moduleColor": "#2ecc71", "moduleName": "dashboard_compute"}, {"id": "dashboard_compute.categorizeTools", "type": "function", "label": "categorizeTools", "direction": "inbound", "parent": "dashboard_compute", "line": 190, "endLine": 227, "signature": "(params) -> dict", "docstring": "Group tools by naming patterns into categories.", "source": "def categorizeTools(params: dict) -> dict:\n    \"\"\"Group tools by naming patterns into categories.\"\"\"\n    tools = params.get(\"tools\", [])\n    if not tools:\n        return {\"categories\": {}, \"error\": \"No tools to categorize\"}\n\n    categories = defaultdict(list)\n    categorized = set()\n\n    # First pass: match against patterns\n    for tool in tools:\n        toolId = tool[\"id\"].lower()\n        matched = False\n\n        for category, patterns in CATEGORY_PATTERNS.items():\n            for pattern in patterns:\n                if pattern in toolId:\n                    categories[category].append(tool)\n                    categorized.add(tool[\"id\"])\n                    matched = True\n                    break\n            if matched:\n                break\n\n    # Second pass: put uncategorized in \"Other Tools\"\n    for tool in tools:\n        if tool[\"id\"] not in categorized:\n            categories[\"Other Tools\"].append(tool)\n\n    # Sort categories by name, but keep \"Other Tools\" last\n    sortedCategories = {}\n    for cat in sorted(categories.keys()):\n        if cat != \"Other Tools\":\n            sortedCategories[cat] = categories[cat]\n    if \"Other Tools\" in categories:\n        sortedCategories[\"Other Tools\"] = categories[\"Other Tools\"]\n\n    return {\"categories\": dict(sortedCategories), \"error\": None}", "args": ["params"], "returns": "dict", "moduleColor": "#2ecc71", "moduleName": "dashboard_compute"}, {"id": "dashboard_compute.generateDashboard", "type": "function", "label": "generateDashboard", "direction": "inbound", "parent": "dashboard_compute", "line": 230, "endLine": 248, "signature": "(params) -> dict", "docstring": "Generate interactive dashboard HTML.", "source": "def generateDashboard(params: dict) -> dict:\n    \"\"\"Generate interactive dashboard HTML.\"\"\"\n    tools = params.get(\"tools\", [])\n    categories = params.get(\"categories\", {})\n    statistics = params.get(\"statistics\", {})\n    utilsPath = params.get(\"utilsPath\", \"\")\n\n    if not tools:\n        return {\"htmlPath\": None, \"hasHtml\": False, \"error\": \"No tools to display\"}\n\n    htmlPath = os.path.join(utilsPath, \"dashboard.html\")\n    html = _buildDashboardHtml(tools, categories, statistics, utilsPath)\n\n    try:\n        with open(htmlPath, \"w\", encoding=\"utf-8\") as f:\n            f.write(html)\n        return {\"htmlPath\": htmlPath, \"hasHtml\": True, \"error\": None}\n    except Exception as e:\n        return {\"htmlPath\": None, \"hasHtml\": False, \"error\": str(e)}", "args": ["params"], "returns": "dict", "moduleColor": "#2ecc71", "moduleName": "dashboard_compute"}, {"id": "os", "type": "dependency", "label": "os", "direction": "outbound", "category": "stdlib", "moduleColor": "#2ecc71", "moduleName": "dashboard_compute"}, {"id": "collections", "type": "dependency", "label": "collections", "direction": "outbound", "category": "stdlib", "moduleColor": "#2ecc71", "moduleName": "dashboard_compute"}, {"id": "doc_compute", "type": "module", "label": "doc_compute", "metrics": {"fanIn": 18, "fanOut": 6, "instability": 0.25, "internalEdges": 1, "externalCallCount": 9, "localCallCount": 0, "callsByCategory": {"stdlib": 8, "pip": 1}, "localDependencies": []}, "moduleColor": "#e67e22", "moduleName": "doc_compute"}, {"id": "doc_compute.load_blueprint", "type": "function", "label": "load_blueprint", "direction": "inbound", "parent": "doc_compute", "line": 20, "endLine": 82, "signature": "(params) -> Dict[]", "docstring": "Load an L++ blueprint from a JSON file.", "source": "def load_blueprint(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Load an L++ blueprint from a JSON file.\"\"\"\n    path = params.get(\"path\")\n    if not path:\n        return {\"blueprint\": None, \"error\": \"No path provided\"}\n\n    try:\n        path = Path(path)\n        if not path.exists():\n            return {\"blueprint\": None, \"error\": f\"File not found: {path}\"}\n\n        with open(path) as f:\n            raw = json.load(f)\n\n        loader = BlueprintLoader(raw)\n        blueprint, error = loader.load()\n\n        if error:\n            return {\"blueprint\": None, \"error\": error}\n\n        # Convert to dict for easy access\n        bp_data = {\n            \"id\": blueprint.id,\n            \"name\": blueprint.name,\n            \"version\": blueprint.version,\n            \"description\": blueprint.description,\n            \"schema\": raw.get(\"$schema\", \"unknown\"),\n            \"states\": {\n                sid: {\"description\": s.description}\n                for sid, s in blueprint.states.items()\n            },\n            \"transitions\": [\n                {\n                    \"id\": t.id,\n                    \"from\": t.from_state,\n                    \"to\": t.to_state,\n                    \"on_event\": t.on_event,\n                    \"gate\": t.gates[0] if t.gates else None,\n                    \"gates\": list(t.gates),\n                    \"actions\": list(t.actions)\n                }\n                for t in blueprint.transitions\n            ],\n            \"gates\": {\n                gid: {\"expression\": g.expression, \"type\": g.type.value}\n                for gid, g in blueprint.gates.items()\n            },\n            \"actions\": raw.get(\"actions\", {}),\n            \"context_schema\": raw.get(\"context_schema\", {}),\n            \"entry_state\": blueprint.entry_state,\n            \"terminal_states\": list(blueprint.terminal_states),\n            \"display\": raw.get(\"display\", {})\n        }\n\n        return {\n            \"blueprint\": bp_data,\n            \"blueprint_path\": str(path),\n            \"blueprint_name\": blueprint.name,\n            \"blueprint_id\": blueprint.id,\n            \"error\": None\n        }\n    except Exception as e:\n        return {\"blueprint\": None, \"error\": str(e)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#e67e22", "moduleName": "doc_compute"}, {"id": "doc_compute.init_defaults", "type": "function", "label": "init_defaults", "direction": "inbound", "parent": "doc_compute", "line": 85, "endLine": 93, "signature": "(params) -> Dict[]", "docstring": "Initialize default documentation settings.", "source": "def init_defaults(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Initialize default documentation settings.\"\"\"\n    return {\n        \"output_format\": \"markdown\",\n        \"include_mermaid\": True,\n        \"include_tables\": True,\n        \"include_quickstart\": True,\n        \"include_context\": True\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#e67e22", "moduleName": "doc_compute"}, {"id": "doc_compute.toggle", "type": "function", "label": "toggle", "direction": "inbound", "parent": "doc_compute", "line": 96, "endLine": 99, "signature": "(params) -> Dict[]", "docstring": "Toggle a boolean value.", "source": "def toggle(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Toggle a boolean value.\"\"\"\n    current = params.get(\"current\", False)\n    return {\"result\": not current}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#e67e22", "moduleName": "doc_compute"}, {"id": "doc_compute.clear_sections", "type": "function", "label": "clear_sections", "direction": "inbound", "parent": "doc_compute", "line": 102, "endLine": 115, "signature": "(params) -> Dict[]", "docstring": "Clear all generated sections.", "source": "def clear_sections(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Clear all generated sections.\"\"\"\n    return {\n        \"overview_section\": None,\n        \"mermaid_section\": None,\n        \"states_section\": None,\n        \"transitions_section\": None,\n        \"gates_section\": None,\n        \"actions_section\": None,\n        \"context_section\": None,\n        \"events_section\": None,\n        \"quickstart_section\": None,\n        \"assembled_doc\": None\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#e67e22", "moduleName": "doc_compute"}, {"id": "doc_compute.extract_metadata", "type": "function", "label": "extract_metadata", "direction": "inbound", "parent": "doc_compute", "line": 122, "endLine": 141, "signature": "(params) -> Dict[]", "docstring": "Extract metadata from blueprint.", "source": "def extract_metadata(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Extract metadata from blueprint.\"\"\"\n    bp = params.get(\"blueprint\", {})\n\n    metadata = {\n        \"name\": bp.get(\"name\", \"Untitled\"),\n        \"id\": bp.get(\"id\", \"unknown\"),\n        \"version\": bp.get(\"version\", \"0.0.0\"),\n        \"description\": bp.get(\"description\", \"\"),\n        \"schema\": bp.get(\"schema\", \"lpp/v0.1.2\"),\n        \"state_count\": len(bp.get(\"states\", {})),\n        \"transition_count\": len(bp.get(\"transitions\", [])),\n        \"gate_count\": len(bp.get(\"gates\", {})),\n        \"action_count\": len(bp.get(\"actions\", {})),\n        \"entry_state\": bp.get(\"entry_state\", \"\"),\n        \"terminal_states\": bp.get(\"terminal_states\", []),\n        \"generated_at\": datetime.now().isoformat()\n    }\n\n    return {\"metadata\": metadata}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#e67e22", "moduleName": "doc_compute"}, {"id": "doc_compute.generate_overview", "type": "function", "label": "generate_overview", "direction": "inbound", "parent": "doc_compute", "line": 148, "endLine": 174, "signature": "(params) -> Dict[]", "docstring": "Generate the overview section.", "source": "def generate_overview(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Generate the overview section.\"\"\"\n    bp = params.get(\"blueprint\", {})\n    metadata = params.get(\"metadata\", {})\n\n    lines = [\n        f\"# {bp.get('name', 'Untitled Blueprint')}\",\n        \"\",\n        bp.get(\"description\", \"\") or \"_No description provided._\",\n        \"\",\n        \"## Overview\",\n        \"\",\n        \"| Property | Value |\",\n        \"|----------|-------|\",\n        f\"| **ID** | `{bp.get('id', 'unknown')}` |\",\n        f\"| **Version** | {bp.get('version', '0.0.0')} |\",\n        f\"| **Schema** | {bp.get('schema', 'lpp/v0.1.2')} |\",\n        f\"| **Entry State** | `{bp.get('entry_state', '-')}` |\",\n        f\"| **Terminal States** | {_format_list(bp.get('terminal_states', []))} |\",\n        f\"| **States** | {metadata.get('state_count', 0)} |\",\n        f\"| **Transitions** | {metadata.get('transition_count', 0)} |\",\n        f\"| **Gates** | {metadata.get('gate_count', 0)} |\",\n        f\"| **Actions** | {metadata.get('action_count', 0)} |\",\n        \"\",\n    ]\n\n    return {\"section\": \"\\n\".join(lines)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#e67e22", "moduleName": "doc_compute"}, {"id": "doc_compute.generate_mermaid", "type": "function", "label": "generate_mermaid", "direction": "inbound", "parent": "doc_compute", "line": 177, "endLine": 224, "signature": "(params) -> Dict[]", "docstring": "Generate mermaid state diagram section.", "source": "def generate_mermaid(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Generate mermaid state diagram section.\"\"\"\n    bp = params.get(\"blueprint\", {})\n\n    lines = [\n        \"## State Machine Diagram\",\n        \"\",\n        \"```mermaid\",\n        \"stateDiagram-v2\",\n        f\"    [*] --> {bp.get('entry_state', 'init')}\",\n        \"\",\n    ]\n\n    # State definitions with descriptions\n    for sid, state in bp.get(\"states\", {}).items():\n        desc = state.get(\"description\", \"\")\n        if desc:\n            safe_desc = desc.replace('\"', \"'\")[:50]\n            lines.append(f'    {sid}: {sid}\\\\n{safe_desc}')\n        else:\n            lines.append(f\"    {sid}: {sid}\")\n    lines.append(\"\")\n\n    # Transitions - expand wildcards\n    all_states = list(bp.get(\"states\", {}).keys())\n    seen = set()\n    for t in bp.get(\"transitions\", []):\n        label = t[\"on_event\"]\n        if t.get(\"gate\"):\n            label = f\"{t['on_event']} [{t['gate']}]\"\n\n        from_states = all_states if t[\"from\"] == \"*\" else [t[\"from\"]]\n        for from_state in from_states:\n            if from_state != t[\"to\"]:  # Skip self-loops for clarity\n                key = (from_state, t[\"to\"], label)\n                if key not in seen:\n                    seen.add(key)\n                    lines.append(f\"    {from_state} --> {t['to']}: {label}\")\n\n    lines.append(\"\")\n\n    # Terminal states\n    for ts in bp.get(\"terminal_states\", []):\n        lines.append(f\"    {ts} --> [*]\")\n\n    lines.extend([\"```\", \"\"])\n\n    return {\"section\": \"\\n\".join(lines)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#e67e22", "moduleName": "doc_compute"}, {"id": "doc_compute.generate_states_table", "type": "function", "label": "generate_states_table", "direction": "inbound", "parent": "doc_compute", "line": 227, "endLine": 247, "signature": "(params) -> Dict[]", "docstring": "Generate states documentation table.", "source": "def generate_states_table(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Generate states documentation table.\"\"\"\n    bp = params.get(\"blueprint\", {})\n    entry = bp.get(\"entry_state\")\n    terminals = bp.get(\"terminal_states\", [])\n\n    lines = [\n        \"## States\",\n        \"\",\n        \"| State | Type | Description |\",\n        \"|-------|------|-------------|\",\n    ]\n\n    for sid, state in bp.get(\"states\", {}).items():\n        stype = \"Entry\" if sid == entry else (\"Terminal\" if sid in terminals\n                                              else \"Normal\")\n        desc = state.get(\"description\", \"-\")\n        lines.append(f\"| `{sid}` | {stype} | {desc} |\")\n\n    lines.append(\"\")\n    return {\"section\": \"\\n\".join(lines)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#e67e22", "moduleName": "doc_compute"}, {"id": "doc_compute.generate_transitions_table", "type": "function", "label": "generate_transitions_table", "direction": "inbound", "parent": "doc_compute", "line": 250, "endLine": 276, "signature": "(params) -> Dict[]", "docstring": "Generate transitions documentation table.", "source": "def generate_transitions_table(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Generate transitions documentation table.\"\"\"\n    bp = params.get(\"blueprint\", {})\n    transitions = bp.get(\"transitions\", [])\n\n    if not transitions:\n        return {\"section\": \"## Transitions\\n\\n_No transitions defined._\\n\"}\n\n    lines = [\n        \"## Transitions\",\n        \"\",\n        \"| ID | From | To | Event | Gate(s) | Action(s) |\",\n        \"|----|------|-----|-------|---------|-----------|\",\n    ]\n\n    for t in transitions:\n        tid = t.get(\"id\", \"-\")\n        frm = t.get(\"from\", \"-\")\n        to = t.get(\"to\", \"-\")\n        event = t.get(\"on_event\", \"-\")\n        gates = \", \".join(t.get(\"gates\", [])) or \"-\"\n        actions = \", \".join(t.get(\"actions\", [])) or \"-\"\n        lines.append(f\"| `{tid}` | `{frm}` | `{to}` | `{event}` | {gates} | \"\n                     f\"{actions} |\")\n\n    lines.append(\"\")\n    return {\"section\": \"\\n\".join(lines)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#e67e22", "moduleName": "doc_compute"}, {"id": "doc_compute.generate_gates_table", "type": "function", "label": "generate_gates_table", "direction": "inbound", "parent": "doc_compute", "line": 279, "endLine": 302, "signature": "(params) -> Dict[]", "docstring": "Generate gates documentation table.", "source": "def generate_gates_table(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Generate gates documentation table.\"\"\"\n    bp = params.get(\"blueprint\", {})\n    gates = bp.get(\"gates\", {})\n\n    if not gates:\n        return {\"section\": \"## Gates\\n\\n_No gates defined._\\n\"}\n\n    lines = [\n        \"## Gates\",\n        \"\",\n        \"Gates are boolean guards that control transition eligibility.\",\n        \"\",\n        \"| Gate | Type | Expression |\",\n        \"|------|------|------------|\",\n    ]\n\n    for gid, gate in gates.items():\n        gtype = gate.get(\"type\", \"expression\")\n        expr = gate.get(\"expression\", \"-\")\n        lines.append(f\"| `{gid}` | {gtype} | `{expr}` |\")\n\n    lines.append(\"\")\n    return {\"section\": \"\\n\".join(lines)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#e67e22", "moduleName": "doc_compute"}, {"id": "doc_compute.generate_actions_table", "type": "function", "label": "generate_actions_table", "direction": "inbound", "parent": "doc_compute", "line": 305, "endLine": 328, "signature": "(params) -> Dict[]", "docstring": "Generate actions documentation table.", "source": "def generate_actions_table(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Generate actions documentation table.\"\"\"\n    bp = params.get(\"blueprint\", {})\n    actions = bp.get(\"actions\", {})\n\n    if not actions:\n        return {\"section\": \"## Actions\\n\\n_No actions defined._\\n\"}\n\n    lines = [\n        \"## Actions\",\n        \"\",\n        \"Actions are side-effects executed during transitions.\",\n        \"\",\n        \"| Action | Type | Details |\",\n        \"|--------|------|---------|\",\n    ]\n\n    for aid, action in actions.items():\n        atype = action.get(\"type\", \"unknown\")\n        details = _format_action_details(action)\n        lines.append(f\"| `{aid}` | `{atype}` | {details} |\")\n\n    lines.append(\"\")\n    return {\"section\": \"\\n\".join(lines)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#e67e22", "moduleName": "doc_compute"}, {"id": "doc_compute.generate_context_docs", "type": "function", "label": "generate_context_docs", "direction": "inbound", "parent": "doc_compute", "line": 354, "endLine": 379, "signature": "(params) -> Dict[]", "docstring": "Generate context schema documentation.", "source": "def generate_context_docs(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Generate context schema documentation.\"\"\"\n    bp = params.get(\"blueprint\", {})\n    schema = bp.get(\"context_schema\", {})\n    props = schema.get(\"properties\", {})\n\n    if not props:\n        return {\"section\": \"## Context Schema\\n\\n_No context properties._\\n\"}\n\n    lines = [\n        \"## Context Schema\",\n        \"\",\n        \"The context schema defines the data interface (\\\"Flange\\\") for this \"\n        \"blueprint.\",\n        \"\",\n        \"| Property | Type | Description |\",\n        \"|----------|------|-------------|\",\n    ]\n\n    for name, prop in props.items():\n        ptype = prop.get(\"type\", \"any\")\n        desc = prop.get(\"description\", \"-\")\n        lines.append(f\"| `{name}` | `{ptype}` | {desc} |\")\n\n    lines.append(\"\")\n    return {\"section\": \"\\n\".join(lines)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#e67e22", "moduleName": "doc_compute"}, {"id": "doc_compute.generate_events_list", "type": "function", "label": "generate_events_list", "direction": "inbound", "parent": "doc_compute", "line": 382, "endLine": 415, "signature": "(params) -> Dict[]", "docstring": "Generate events documentation.", "source": "def generate_events_list(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Generate events documentation.\"\"\"\n    bp = params.get(\"blueprint\", {})\n    transitions = bp.get(\"transitions\", [])\n\n    # Collect unique events\n    events: Dict[str, List[str]] = {}\n    for t in transitions:\n        event = t.get(\"on_event\", \"\")\n        if event:\n            if event not in events:\n                events[event] = []\n            events[event].append(f\"`{t.get('from', '?')}` -> `{t.get('to', '?')}`\")\n\n    if not events:\n        return {\"section\": \"## Events\\n\\n_No events defined._\\n\"}\n\n    lines = [\n        \"## Events\",\n        \"\",\n        \"Events trigger state transitions in the blueprint.\",\n        \"\",\n        \"| Event | Transitions |\",\n        \"|-------|-------------|\",\n    ]\n\n    for event, trans in sorted(events.items()):\n        trans_str = \", \".join(trans[:3])\n        if len(trans) > 3:\n            trans_str += f\" (+{len(trans) - 3} more)\"\n        lines.append(f\"| `{event}` | {trans_str} |\")\n\n    lines.append(\"\")\n    return {\"section\": \"\\n\".join(lines)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#e67e22", "moduleName": "doc_compute"}, {"id": "doc_compute.generate_quickstart", "type": "function", "label": "generate_quickstart", "direction": "inbound", "parent": "doc_compute", "line": 418, "endLine": 469, "signature": "(params) -> Dict[]", "docstring": "Generate quick-start guide with example event sequences.", "source": "def generate_quickstart(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Generate quick-start guide with example event sequences.\"\"\"\n    bp = params.get(\"blueprint\", {})\n\n    entry = bp.get(\"entry_state\", \"init\")\n    transitions = bp.get(\"transitions\", [])\n    terminals = bp.get(\"terminal_states\", [])\n\n    # Find paths from entry to terminals or interesting states\n    paths = _find_example_paths(entry, transitions, terminals, max_depth=5)\n\n    lines = [\n        \"## Quick Start Guide\",\n        \"\",\n        \"### Basic Usage\",\n        \"\",\n        \"```python\",\n        \"# Load and compile the blueprint\",\n        \"from frame_py.compiler import compile_blueprint\",\n        \"\",\n        f'compile_blueprint(\"{bp.get(\"id\", \"blueprint\")}.json\", \"compiled.py\")',\n        \"\",\n        \"# Create operator instance\",\n        \"from compiled import create_operator\",\n        \"op = create_operator(compute_registry)\",\n        \"\",\n        \"# Dispatch events\",\n    ]\n\n    # Add example event dispatches\n    if paths:\n        for event in paths[0][:3]:\n            lines.append(f'op.dispatch(\"{event}\")')\n    else:\n        lines.append('op.dispatch(\"YOUR_EVENT_HERE\")')\n\n    lines.extend([\n        \"```\",\n        \"\",\n        \"### Example Event Sequences\",\n        \"\",\n    ])\n\n    if paths:\n        for i, path in enumerate(paths[:3], 1):\n            seq = \" -> \".join([f\"`{e}`\" for e in path])\n            lines.append(f\"{i}. {seq}\")\n    else:\n        lines.append(\"_No example paths found._\")\n\n    lines.append(\"\")\n    return {\"section\": \"\\n\".join(lines)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#e67e22", "moduleName": "doc_compute"}, {"id": "doc_compute.assemble_markdown", "type": "function", "label": "assemble_markdown", "direction": "inbound", "parent": "doc_compute", "line": 516, "endLine": 545, "signature": "(params) -> Dict[]", "docstring": "Assemble all sections into final markdown document.", "source": "def assemble_markdown(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Assemble all sections into final markdown document.\"\"\"\n    parts = [params.get(\"overview_section\", \"\")]\n\n    if params.get(\"include_quickstart\"):\n        parts.append(params.get(\"quickstart_section\", \"\"))\n\n    if params.get(\"include_mermaid\"):\n        parts.append(params.get(\"mermaid_section\", \"\"))\n\n    if params.get(\"include_tables\"):\n        parts.append(params.get(\"states_section\", \"\"))\n        parts.append(params.get(\"transitions_section\", \"\"))\n        parts.append(params.get(\"gates_section\", \"\"))\n        parts.append(params.get(\"actions_section\", \"\"))\n\n    if params.get(\"include_context\"):\n        parts.append(params.get(\"context_section\", \"\"))\n\n    parts.append(params.get(\"events_section\", \"\"))\n\n    # Footer\n    parts.extend([\n        \"---\",\n        \"\",\n        \"_Generated by L++ Documentation Generator_\",\n        \"\"\n    ])\n\n    return {\"doc\": \"\\n\".join(filter(None, parts))}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#e67e22", "moduleName": "doc_compute"}, {"id": "doc_compute.assemble_html", "type": "function", "label": "assemble_html", "direction": "inbound", "parent": "doc_compute", "line": 548, "endLine": 634, "signature": "(params) -> Dict[]", "docstring": "Assemble all sections into HTML document with styling.", "source": "def assemble_html(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Assemble all sections into HTML document with styling.\"\"\"\n    bp_name = params.get(\"blueprint_name\", \"L++ Blueprint\")\n\n    # Build markdown first\n    md_result = assemble_markdown(params)\n    md_content = md_result.get(\"doc\", \"\")\n\n    # Convert markdown to HTML with styling\n    html_parts = [\n        \"<!DOCTYPE html>\",\n        \"<html lang=\\\"en\\\">\",\n        \"<head>\",\n        \"    <meta charset=\\\"UTF-8\\\">\",\n        \"    <meta name=\\\"viewport\\\" content=\\\"width=device-width, \"\n        \"initial-scale=1.0\\\">\",\n        f\"    <title>{bp_name} - Documentation</title>\",\n        \"    <style>\",\n        \"        :root {\",\n        \"            --primary: #2563eb;\",\n        \"            --bg: #f8fafc;\",\n        \"            --text: #1e293b;\",\n        \"            --border: #e2e8f0;\",\n        \"            --code-bg: #f1f5f9;\",\n        \"        }\",\n        \"        body {\",\n        \"            font-family: -apple-system, BlinkMacSystemFont, \"\n        \"'Segoe UI', Roboto, sans-serif;\",\n        \"            line-height: 1.6;\",\n        \"            max-width: 900px;\",\n        \"            margin: 0 auto;\",\n        \"            padding: 2rem;\",\n        \"            background: var(--bg);\",\n        \"            color: var(--text);\",\n        \"        }\",\n        \"        h1, h2, h3 { color: var(--primary); }\",\n        \"        h1 { border-bottom: 2px solid var(--primary); \"\n        \"padding-bottom: 0.5rem; }\",\n        \"        h2 { margin-top: 2rem; }\",\n        \"        table {\",\n        \"            width: 100%;\",\n        \"            border-collapse: collapse;\",\n        \"            margin: 1rem 0;\",\n        \"            background: white;\",\n        \"            box-shadow: 0 1px 3px rgba(0,0,0,0.1);\",\n        \"        }\",\n        \"        th, td {\",\n        \"            padding: 0.75rem;\",\n        \"            text-align: left;\",\n        \"            border: 1px solid var(--border);\",\n        \"        }\",\n        \"        th { background: var(--primary); color: white; }\",\n        \"        tr:nth-child(even) { background: var(--bg); }\",\n        \"        code {\",\n        \"            background: var(--code-bg);\",\n        \"            padding: 0.2rem 0.4rem;\",\n        \"            border-radius: 3px;\",\n        \"            font-size: 0.9em;\",\n        \"        }\",\n        \"        pre {\",\n        \"            background: #1e293b;\",\n        \"            color: #e2e8f0;\",\n        \"            padding: 1rem;\",\n        \"            border-radius: 8px;\",\n        \"            overflow-x: auto;\",\n        \"        }\",\n        \"        pre code { background: none; color: inherit; }\",\n        \"        .mermaid { background: white; padding: 1rem; \"\n        \"border-radius: 8px; }\",\n        \"    </style>\",\n        \"    <script src=\\\"https://cdn.jsdelivr.net/npm/mermaid/dist/\"\n        \"mermaid.min.js\\\"></script>\",\n        \"</head>\",\n        \"<body>\",\n    ]\n\n    # Convert markdown to HTML (simple conversion)\n    html_content = _markdown_to_html(md_content)\n    html_parts.append(html_content)\n\n    html_parts.extend([\n        \"    <script>mermaid.initialize({startOnLoad:true});</script>\",\n        \"</body>\",\n        \"</html>\"\n    ])\n\n    return {\"doc\": \"\\n\".join(html_parts)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#e67e22", "moduleName": "doc_compute"}, {"id": "doc_compute.assemble_json", "type": "function", "label": "assemble_json", "direction": "inbound", "parent": "doc_compute", "line": 760, "endLine": 784, "signature": "(params) -> Dict[]", "docstring": "Assemble documentation as JSON structure.", "source": "def assemble_json(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Assemble documentation as JSON structure.\"\"\"\n    bp = params.get(\"blueprint\", {})\n    metadata = params.get(\"metadata\", {})\n\n    doc = {\n        \"metadata\": metadata,\n        \"blueprint\": {\n            \"id\": bp.get(\"id\"),\n            \"name\": bp.get(\"name\"),\n            \"version\": bp.get(\"version\"),\n            \"description\": bp.get(\"description\"),\n            \"schema\": bp.get(\"schema\"),\n            \"entry_state\": bp.get(\"entry_state\"),\n            \"terminal_states\": bp.get(\"terminal_states\", [])\n        },\n        \"states\": bp.get(\"states\", {}),\n        \"transitions\": bp.get(\"transitions\", []),\n        \"gates\": bp.get(\"gates\", {}),\n        \"actions\": bp.get(\"actions\", {}),\n        \"context_schema\": bp.get(\"context_schema\", {}),\n        \"generated_at\": metadata.get(\"generated_at\", \"\")\n    }\n\n    return {\"doc\": json.dumps(doc, indent=2)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#e67e22", "moduleName": "doc_compute"}, {"id": "doc_compute.export_docs", "type": "function", "label": "export_docs", "direction": "inbound", "parent": "doc_compute", "line": 791, "endLine": 807, "signature": "(params) -> Dict[]", "docstring": "Export documentation to file.", "source": "def export_docs(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Export documentation to file.\"\"\"\n    content = params.get(\"content\", \"\")\n    path = params.get(\"path\", \"\")\n    fmt = params.get(\"format\", \"markdown\")\n\n    if not path:\n        # Generate default path\n        path = f\"./docs_output.{_get_extension(fmt)}\"\n\n    try:\n        p = Path(path)\n        p.parent.mkdir(parents=True, exist_ok=True)\n        p.write_text(content)\n        return {\"path\": str(p.absolute()), \"error\": None}\n    except Exception as e:\n        return {\"path\": None, \"error\": str(e)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#e67e22", "moduleName": "doc_compute"}, {"id": "simulator_compute", "type": "module", "label": "simulator_compute", "metrics": {"fanIn": 20, "fanOut": 9, "instability": 0.31, "internalEdges": 3, "externalCallCount": 40, "localCallCount": 0, "callsByCategory": {"stdlib": 37, "pip": 3}, "localDependencies": []}, "moduleColor": "#00d4ff", "moduleName": "simulator_compute"}, {"id": "simulator_compute.load_blueprint", "type": "function", "label": "load_blueprint", "direction": "inbound", "parent": "simulator_compute", "line": 25, "endLine": 100, "signature": "(params) -> Dict[]", "docstring": "Load an L++ blueprint from a JSON file for simulation.", "source": "def load_blueprint(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Load an L++ blueprint from a JSON file for simulation.\"\"\"\n    path = params.get(\"path\")\n    if not path:\n        return {\"blueprint\": None, \"error\": \"No path provided\"}\n\n    try:\n        path = Path(path)\n        if not path.exists():\n            return {\"blueprint\": None, \"error\": f\"File not found: {path}\"}\n\n        with open(path) as f:\n            raw = json.load(f)\n\n        loader = BlueprintLoader(raw)\n        blueprint, load_error = loader.load()\n\n        if load_error:\n            return {\"blueprint\": None, \"error\": load_error}\n\n        # Convert to a dict-like structure for simulation\n        bp_data = {\n            \"id\": blueprint.id,\n            \"name\": blueprint.name,\n            \"version\": blueprint.version,\n            \"description\": blueprint.description,\n            \"entry_state\": blueprint.entry_state,\n            \"terminal_states\": list(blueprint.terminal_states),\n            \"states\": {\n                sid: {\n                    \"description\": s.description,\n                    \"on_enter\": list(s.on_enter),\n                    \"on_exit\": list(s.on_exit)\n                } for sid, s in blueprint.states.items()\n            },\n            \"transitions\": [\n                {\n                    \"id\": t.id,\n                    \"from\": t.from_state,\n                    \"to\": t.to_state,\n                    \"on_event\": t.on_event,\n                    \"gates\": list(t.gates),\n                    \"actions\": list(t.actions)\n                }\n                for t in blueprint.transitions\n            ],\n            \"gates\": {\n                gid: {\n                    \"type\": g.type.value,\n                    \"expression\": g.expression,\n                    \"compute_unit\": g.compute_unit\n                } for gid, g in blueprint.gates.items()\n            },\n            \"actions\": {\n                aid: {\n                    \"type\": a.type.value,\n                    \"target\": a.target,\n                    \"value\": a.value,\n                    \"value_from\": a.value_from,\n                    \"compute_unit\": a.compute_unit,\n                    \"input_map\": a.input_map,\n                    \"output_map\": a.output_map\n                } for aid, a in blueprint.actions.items()\n            },\n            \"context_schema\": raw.get(\"context_schema\", {})\n        }\n\n        return {\n            \"blueprint\": bp_data,\n            \"blueprint_path\": str(path),\n            \"blueprint_name\": blueprint.name,\n            \"blueprint_id\": blueprint.id,\n            \"error\": None\n        }\n    except Exception as e:\n        return {\"blueprint\": None, \"error\": str(e)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "simulator_compute"}, {"id": "simulator_compute.init_simulation", "type": "function", "label": "init_simulation", "direction": "inbound", "parent": "simulator_compute", "line": 107, "endLine": 141, "signature": "(params) -> Dict[]", "docstring": "Initialize simulation state from blueprint.", "source": "def init_simulation(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Initialize simulation state from blueprint.\"\"\"\n    bp = params.get(\"blueprint\")\n    if not bp:\n        return {\"error\": \"No blueprint provided\"}\n\n    # Initialize context from schema defaults\n    ctx = {\"_state\": bp[\"entry_state\"]}\n    schema = bp.get(\"context_schema\", {})\n    for prop in schema.get(\"properties\", {}).keys():\n        ctx[prop] = None\n\n    # Get available events in entry state\n    avail = _get_available_transitions(bp, bp[\"entry_state\"], ctx)\n\n    # Create initial trace entry\n    trace = [{\n        \"step\": 0,\n        \"timestamp\": datetime.now().isoformat(),\n        \"state\": bp[\"entry_state\"],\n        \"context\": copy.deepcopy(ctx),\n        \"event\": None,\n        \"transition_id\": None\n    }]\n\n    return {\n        \"sim_state\": bp[\"entry_state\"],\n        \"sim_context\": ctx,\n        \"available_events\": [t[\"event\"] for t in avail],\n        \"available_transitions\": avail,\n        \"trace\": trace,\n        \"forks\": {},\n        \"current_fork\": None,\n        \"mode\": \"manual\"\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "simulator_compute"}, {"id": "simulator_compute.reset_simulation", "type": "function", "label": "reset_simulation", "direction": "inbound", "parent": "simulator_compute", "line": 144, "endLine": 152, "signature": "(params) -> Dict[]", "docstring": "Reset simulation to initial state.", "source": "def reset_simulation(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Reset simulation to initial state.\"\"\"\n    bp = params.get(\"blueprint\")\n    if not bp:\n        return {\"error\": \"No blueprint provided\"}\n\n    result = init_simulation({\"blueprint\": bp})\n    result[\"output\"] = f\"Reset to initial state: {bp['entry_state']}\"\n    return result", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "simulator_compute"}, {"id": "simulator_compute.set_context", "type": "function", "label": "set_context", "direction": "inbound", "parent": "simulator_compute", "line": 159, "endLine": 171, "signature": "(params) -> Dict[]", "docstring": "Set a context value for simulation.", "source": "def set_context(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Set a context value for simulation.\"\"\"\n    ctx = params.get(\"sim_context\", {})\n    key = params.get(\"key\")\n    value = params.get(\"value\")\n\n    if not key:\n        return {\"sim_context\": ctx, \"error\": \"No key provided\"}\n\n    new_ctx = copy.deepcopy(ctx)\n    new_ctx[key] = value\n\n    return {\"sim_context\": new_ctx}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "simulator_compute"}, {"id": "simulator_compute.get_available_events", "type": "function", "label": "get_available_events", "direction": "inbound", "parent": "simulator_compute", "line": 228, "endLine": 243, "signature": "(params) -> Dict[]", "docstring": "List valid events in current state.", "source": "def get_available_events(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"List valid events in current state.\"\"\"\n    bp = params.get(\"blueprint\")\n    state = params.get(\"sim_state\")\n    ctx = params.get(\"sim_context\", {})\n\n    if not bp or not state:\n        return {\"available_events\": [], \"available_transitions\": []}\n\n    avail = _get_available_transitions(bp, state, ctx)\n    events = list(set(t[\"event\"] for t in avail))\n\n    return {\n        \"available_events\": events,\n        \"available_transitions\": avail\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "simulator_compute"}, {"id": "simulator_compute.evaluate_gates", "type": "function", "label": "evaluate_gates", "direction": "inbound", "parent": "simulator_compute", "line": 246, "endLine": 263, "signature": "(params) -> Dict[]", "docstring": "Evaluate all gates with current context.", "source": "def evaluate_gates(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Evaluate all gates with current context.\"\"\"\n    bp = params.get(\"blueprint\")\n    ctx = params.get(\"sim_context\", {})\n\n    if not bp:\n        return {\"output\": \"No blueprint\"}\n\n    lines = [\"Gate Evaluation Results:\", \"=\" * 40]\n    for gate_id, gate in bp.get(\"gates\", {}).items():\n        if gate[\"type\"] == \"expression\":\n            result, _ = safe_eval_bool(gate[\"expression\"], ctx)\n            status = \"PASS\" if result else \"FAIL\"\n            lines.append(f\"  [{status}] {gate_id}: {gate['expression']}\")\n        else:\n            lines.append(f\"  [SKIP] {gate_id}: compute gate\")\n\n    return {\"output\": \"\\n\".join(lines)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "simulator_compute"}, {"id": "simulator_compute.dispatch_event", "type": "function", "label": "dispatch_event", "direction": "inbound", "parent": "simulator_compute", "line": 310, "endLine": 392, "signature": "(params) -> Dict[]", "docstring": "Dispatch an event and process state transition.", "source": "def dispatch_event(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Dispatch an event and process state transition.\"\"\"\n    bp = params.get(\"blueprint\")\n    state = params.get(\"sim_state\")\n    ctx = params.get(\"sim_context\", {})\n    trace = params.get(\"trace\", [])\n    event_name = params.get(\"event_name\")\n    event_payload = params.get(\"event_payload\", {})\n\n    if not bp or not state or not event_name:\n        return {\"error\": \"Missing required parameters\"}\n\n    # Find matching transition\n    eval_ctx = copy.deepcopy(ctx)\n    eval_ctx[\"_state\"] = state\n\n    matched = None\n    for t in bp[\"transitions\"]:\n        if t[\"on_event\"] != event_name:\n            continue\n        if t[\"from\"] != \"*\" and t[\"from\"] != state:\n            continue\n\n        # Check gates\n        gates_pass = True\n        for gate_id in t.get(\"gates\", []):\n            if not _evaluate_gate(bp, gate_id, eval_ctx):\n                gates_pass = False\n                break\n\n        if gates_pass:\n            matched = t\n            break\n\n    if not matched:\n        return {\n            \"sim_state\": state,\n            \"sim_context\": ctx,\n            \"trace\": trace,\n            \"available_events\": [],\n            \"available_transitions\": [],\n            \"output\": f\"No matching transition for event '{event_name}'\",\n            \"error\": f\"No transition for {event_name} from {state}\"\n        }\n\n    # Execute actions\n    new_ctx = copy.deepcopy(ctx)\n    for action_id in matched.get(\"actions\", []):\n        new_ctx = _execute_action(bp, action_id, new_ctx, event_payload)\n\n    # Perform transition\n    new_state = matched[\"to\"]\n    new_ctx[\"_state\"] = new_state\n\n    # Record in trace\n    new_trace = copy.deepcopy(trace)\n    new_trace.append({\n        \"step\": len(trace),\n        \"timestamp\": datetime.now().isoformat(),\n        \"state\": new_state,\n        \"prev_state\": state,\n        \"context\": copy.deepcopy(new_ctx),\n        \"event\": event_name,\n        \"event_payload\": event_payload,\n        \"transition_id\": matched[\"id\"]\n    })\n\n    # Get new available transitions\n    avail = _get_available_transitions(bp, new_state, new_ctx)\n\n    output = f\"{state} --[{event_name}]--> {new_state}\"\n    if matched.get(\"actions\"):\n        output += f\" (actions: {', '.join(matched['actions'])})\"\n\n    return {\n        \"sim_state\": new_state,\n        \"sim_context\": new_ctx,\n        \"trace\": new_trace,\n        \"available_events\": [t[\"event\"] for t in avail],\n        \"available_transitions\": avail,\n        \"output\": output,\n        \"error\": None\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "simulator_compute"}, {"id": "simulator_compute.fork_simulation", "type": "function", "label": "fork_simulation", "direction": "inbound", "parent": "simulator_compute", "line": 399, "endLine": 422, "signature": "(params) -> Dict[]", "docstring": "Create a fork of current simulation state for what-if analysis.", "source": "def fork_simulation(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Create a fork of current simulation state for what-if analysis.\"\"\"\n    forks = params.get(\"forks\", {})\n    fork_name = params.get(\"fork_name\")\n    state = params.get(\"sim_state\")\n    ctx = params.get(\"sim_context\", {})\n    trace = params.get(\"trace\", [])\n\n    if not fork_name:\n        fork_name = f\"fork_{len(forks) + 1}\"\n\n    new_forks = copy.deepcopy(forks)\n    new_forks[fork_name] = {\n        \"sim_state\": state,\n        \"sim_context\": copy.deepcopy(ctx),\n        \"trace\": copy.deepcopy(trace),\n        \"created_at\": datetime.now().isoformat()\n    }\n\n    return {\n        \"forks\": new_forks,\n        \"current_fork\": fork_name,\n        \"output\": f\"Created fork '{fork_name}' at state {state}\"\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "simulator_compute"}, {"id": "simulator_compute.switch_fork", "type": "function", "label": "switch_fork", "direction": "inbound", "parent": "simulator_compute", "line": 425, "endLine": 446, "signature": "(params) -> Dict[]", "docstring": "Switch to a different simulation fork.", "source": "def switch_fork(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Switch to a different simulation fork.\"\"\"\n    forks = params.get(\"forks\", {})\n    fork_name = params.get(\"fork_name\")\n\n    if not fork_name or fork_name not in forks:\n        return {\n            \"error\": f\"Fork '{fork_name}' not found\",\n            \"output\": f\"Available forks: {list(forks.keys())}\"\n        }\n\n    fork = forks[fork_name]\n    return {\n        \"sim_state\": fork[\"sim_state\"],\n        \"sim_context\": copy.deepcopy(fork[\"sim_context\"]),\n        \"trace\": copy.deepcopy(fork[\"trace\"]),\n        \"current_fork\": fork_name,\n        \"available_events\": [],\n        \"available_transitions\": [],\n        \"output\": f\"Switched to fork '{fork_name}' at state {fork['sim_state']}\",\n        \"error\": None\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "simulator_compute"}, {"id": "simulator_compute.step_back", "type": "function", "label": "step_back", "direction": "inbound", "parent": "simulator_compute", "line": 453, "endLine": 477, "signature": "(params) -> Dict[]", "docstring": "Step back to previous state from trace.", "source": "def step_back(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Step back to previous state from trace.\"\"\"\n    trace = params.get(\"trace\", [])\n    bp = params.get(\"blueprint\")\n\n    if len(trace) < 2:\n        return {\"output\": \"Cannot step back - at initial state\"}\n\n    # Go to previous step\n    new_trace = trace[:-1]\n    prev_step = new_trace[-1]\n\n    state = prev_step[\"state\"]\n    ctx = copy.deepcopy(prev_step[\"context\"])\n\n    avail = _get_available_transitions(bp, state, ctx) if bp else []\n\n    return {\n        \"sim_state\": state,\n        \"sim_context\": ctx,\n        \"trace\": new_trace,\n        \"available_events\": [t[\"event\"] for t in avail],\n        \"available_transitions\": avail,\n        \"output\": f\"Stepped back to state: {state} (step {len(new_trace) - 1})\"\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "simulator_compute"}, {"id": "simulator_compute.set_sequence", "type": "function", "label": "set_sequence", "direction": "inbound", "parent": "simulator_compute", "line": 484, "endLine": 496, "signature": "(params) -> Dict[]", "docstring": "Set an event sequence for execution.", "source": "def set_sequence(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Set an event sequence for execution.\"\"\"\n    events = params.get(\"events\", [])\n\n    if isinstance(events, str):\n        # Parse comma-separated string\n        events = [e.strip() for e in events.split(\",\") if e.strip()]\n\n    return {\n        \"sequence\": events,\n        \"sequence_index\": 0,\n        \"mode\": \"sequence\"\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "simulator_compute"}, {"id": "simulator_compute.run_sequence", "type": "function", "label": "run_sequence", "direction": "inbound", "parent": "simulator_compute", "line": 499, "endLine": 545, "signature": "(params) -> Dict[]", "docstring": "Execute a pre-defined event sequence.", "source": "def run_sequence(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Execute a pre-defined event sequence.\"\"\"\n    bp = params.get(\"blueprint\")\n    state = params.get(\"sim_state\")\n    ctx = params.get(\"sim_context\", {})\n    trace = params.get(\"trace\", [])\n    sequence = params.get(\"sequence\", [])\n\n    if not sequence:\n        return {\"output\": \"No sequence defined\", \"error\": \"Empty sequence\"}\n\n    results = []\n    current_state = state\n    current_ctx = copy.deepcopy(ctx)\n    current_trace = copy.deepcopy(trace)\n\n    for i, event in enumerate(sequence):\n        result = dispatch_event({\n            \"blueprint\": bp,\n            \"sim_state\": current_state,\n            \"sim_context\": current_ctx,\n            \"trace\": current_trace,\n            \"event_name\": event,\n            \"event_payload\": {}\n        })\n\n        if result.get(\"error\"):\n            results.append(f\"Step {i+1}: FAILED - {event} ({result['error']})\")\n            break\n        else:\n            results.append(f\"Step {i+1}: {result['output']}\")\n            current_state = result[\"sim_state\"]\n            current_ctx = result[\"sim_context\"]\n            current_trace = result[\"trace\"]\n\n    avail = _get_available_transitions(bp, current_state, current_ctx)\n\n    return {\n        \"sim_state\": current_state,\n        \"sim_context\": current_ctx,\n        \"trace\": current_trace,\n        \"sequence_index\": len(sequence),\n        \"available_events\": [t[\"event\"] for t in avail],\n        \"available_transitions\": avail,\n        \"output\": \"\\n\".join([\"Sequence Execution:\", \"-\" * 40] + results),\n        \"error\": None\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "simulator_compute"}, {"id": "simulator_compute.fuzz_run", "type": "function", "label": "fuzz_run", "direction": "inbound", "parent": "simulator_compute", "line": 552, "endLine": 633, "signature": "(params) -> Dict[]", "docstring": "Random event exploration to discover state space.", "source": "def fuzz_run(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Random event exploration to discover state space.\"\"\"\n    bp = params.get(\"blueprint\")\n    state = params.get(\"sim_state\")\n    ctx = params.get(\"sim_context\", {})\n    trace = params.get(\"trace\", [])\n    steps = params.get(\"steps\", 10)\n    seed = params.get(\"seed\")\n\n    if seed is not None:\n        random.seed(seed)\n\n    current_state = state\n    current_ctx = copy.deepcopy(ctx)\n    current_trace = copy.deepcopy(trace)\n    visited_states = {state}\n    transitions_taken = []\n    deadends = 0\n\n    for i in range(steps):\n        avail = _get_available_transitions(bp, current_state, current_ctx)\n        if not avail:\n            deadends += 1\n            transitions_taken.append(f\"Step {i+1}: DEADEND at {current_state}\")\n            break\n\n        # Pick random available transition\n        chosen = random.choice(avail)\n        event = chosen[\"event\"]\n\n        result = dispatch_event({\n            \"blueprint\": bp,\n            \"sim_state\": current_state,\n            \"sim_context\": current_ctx,\n            \"trace\": current_trace,\n            \"event_name\": event,\n            \"event_payload\": {}\n        })\n\n        if not result.get(\"error\"):\n            transitions_taken.append(\n                f\"Step {i+1}: {current_state} --[{event}]--> \"\n                f\"{result['sim_state']}\"\n            )\n            current_state = result[\"sim_state\"]\n            current_ctx = result[\"sim_context\"]\n            current_trace = result[\"trace\"]\n            visited_states.add(current_state)\n        else:\n            transitions_taken.append(\n                f\"Step {i+1}: FAILED {event} - {result['error']}\"\n            )\n\n    avail = _get_available_transitions(bp, current_state, current_ctx)\n\n    fuzz_result = {\n        \"steps_executed\": len(transitions_taken),\n        \"states_visited\": list(visited_states),\n        \"unique_states\": len(visited_states),\n        \"deadends\": deadends,\n        \"final_state\": current_state\n    }\n\n    output_lines = [\n        f\"Fuzz Run ({steps} steps requested):\",\n        \"=\" * 50\n    ] + transitions_taken + [\n        \"=\" * 50,\n        f\"Visited {len(visited_states)} unique states: \"\n        f\"{', '.join(visited_states)}\",\n        f\"Final state: {current_state}\"\n    ]\n\n    return {\n        \"sim_state\": current_state,\n        \"sim_context\": current_ctx,\n        \"trace\": current_trace,\n        \"fuzz_result\": fuzz_result,\n        \"available_events\": [t[\"event\"] for t in avail],\n        \"available_transitions\": avail,\n        \"output\": \"\\n\".join(output_lines)\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "simulator_compute"}, {"id": "simulator_compute.explore_state_space", "type": "function", "label": "explore_state_space", "direction": "inbound", "parent": "simulator_compute", "line": 640, "endLine": 715, "signature": "(params) -> Dict[]", "docstring": "Enumerate all reachable states using BFS.", "source": "def explore_state_space(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Enumerate all reachable states using BFS.\"\"\"\n    bp = params.get(\"blueprint\")\n    start_state = params.get(\"sim_state\")\n    start_ctx = params.get(\"sim_context\", {})\n    max_depth = params.get(\"max_depth\", 10)\n\n    if not bp:\n        return {\"output\": \"No blueprint\", \"state_space\": None}\n\n    # BFS exploration\n    visited = set()\n    edges = []\n    queue = deque([(start_state, copy.deepcopy(start_ctx), 0)])\n    state_info = {}\n\n    while queue:\n        state, ctx, depth = queue.popleft()\n\n        state_key = state\n        if state_key in visited:\n            continue\n        visited.add(state_key)\n\n        if depth >= max_depth:\n            continue\n\n        avail = _get_available_transitions(bp, state, ctx)\n        state_info[state] = {\n            \"available_events\": [t[\"event\"] for t in avail],\n            \"is_terminal\": state in bp.get(\"terminal_states\", [])\n        }\n\n        for trans in avail:\n            target = trans[\"to\"]\n            edges.append({\n                \"from\": state,\n                \"to\": target,\n                \"event\": trans[\"event\"],\n                \"transition_id\": trans[\"id\"]\n            })\n\n            if target not in visited:\n                # Simple context propagation (no action execution)\n                new_ctx = copy.deepcopy(ctx)\n                new_ctx[\"_state\"] = target\n                queue.append((target, new_ctx, depth + 1))\n\n    state_space = {\n        \"states\": list(visited),\n        \"edges\": edges,\n        \"state_info\": state_info,\n        \"start_state\": start_state,\n        \"total_states\": len(visited),\n        \"total_edges\": len(edges)\n    }\n\n    lines = [\n        \"State Space Exploration:\",\n        \"=\" * 50,\n        f\"Reachable states ({len(visited)}):\"\n    ]\n    for s in sorted(visited):\n        info = state_info.get(s, {})\n        terminal = \" [TERMINAL]\" if info.get(\"is_terminal\") else \"\"\n        events = info.get(\"available_events\", [])\n        lines.append(f\"  - {s}{terminal} -> events: {events}\")\n\n    lines.append(f\"\\nEdges ({len(edges)}):\")\n    for e in edges:\n        lines.append(f\"  {e['from']} --[{e['event']}]--> {e['to']}\")\n\n    return {\n        \"state_space\": state_space,\n        \"output\": \"\\n\".join(lines)\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "simulator_compute"}, {"id": "simulator_compute.find_path", "type": "function", "label": "find_path", "direction": "inbound", "parent": "simulator_compute", "line": 722, "endLine": 792, "signature": "(params) -> Dict[]", "docstring": "Find event sequence to reach target state using BFS.", "source": "def find_path(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Find event sequence to reach target state using BFS.\"\"\"\n    bp = params.get(\"blueprint\")\n    start_state = params.get(\"sim_state\")\n    start_ctx = params.get(\"sim_context\", {})\n    target = params.get(\"target_state\")\n\n    if not bp or not target:\n        return {\"output\": \"Missing blueprint or target\", \"path_result\": None}\n\n    if start_state == target:\n        return {\n            \"path_result\": {\"path\": [], \"found\": True},\n            \"output\": f\"Already at target state: {target}\"\n        }\n\n    # BFS for shortest path\n    visited = set()\n    queue = deque([(start_state, copy.deepcopy(start_ctx), [])])\n\n    while queue:\n        state, ctx, path = queue.popleft()\n\n        if state in visited:\n            continue\n        visited.add(state)\n\n        avail = _get_available_transitions(bp, state, ctx)\n\n        for trans in avail:\n            new_path = path + [{\n                \"from\": state,\n                \"event\": trans[\"event\"],\n                \"to\": trans[\"to\"],\n                \"transition_id\": trans[\"id\"]\n            }]\n\n            if trans[\"to\"] == target:\n                # Found path\n                events = [p[\"event\"] for p in new_path]\n                lines = [\n                    f\"Path to '{target}' found!\",\n                    \"=\" * 50,\n                    f\"Steps: {len(new_path)}\",\n                    f\"Events: {' -> '.join(events)}\",\n                    \"\",\n                    \"Detailed path:\"\n                ]\n                for i, p in enumerate(new_path):\n                    lines.append(\n                        f\"  {i+1}. {p['from']} --[{p['event']}]--> {p['to']}\"\n                    )\n\n                return {\n                    \"path_result\": {\n                        \"found\": True,\n                        \"path\": new_path,\n                        \"events\": events\n                    },\n                    \"output\": \"\\n\".join(lines)\n                }\n\n            if trans[\"to\"] not in visited:\n                new_ctx = copy.deepcopy(ctx)\n                new_ctx[\"_state\"] = trans[\"to\"]\n                queue.append((trans[\"to\"], new_ctx, new_path))\n\n    return {\n        \"path_result\": {\"found\": False, \"path\": []},\n        \"output\": f\"No path found from '{start_state}' to '{target}'\"\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "simulator_compute"}, {"id": "simulator_compute.export_trace", "type": "function", "label": "export_trace", "direction": "inbound", "parent": "simulator_compute", "line": 799, "endLine": 835, "signature": "(params) -> Dict[]", "docstring": "Export simulation trace to JSON file.", "source": "def export_trace(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Export simulation trace to JSON file.\"\"\"\n    trace = params.get(\"trace\", [])\n    blueprint_id = params.get(\"blueprint_id\", \"unknown\")\n    path = params.get(\"path\")\n\n    if not trace:\n        return {\"output\": \"No trace to export\"}\n\n    if not path:\n        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n        path = f\"./traces/{blueprint_id}_{timestamp}.json\"\n\n    path = Path(path)\n    path.parent.mkdir(parents=True, exist_ok=True)\n\n    # Extract events for replay\n    events = []\n    for step in trace[1:]:  # Skip initial state\n        if step.get(\"event\"):\n            events.append({\n                \"event\": step[\"event\"],\n                \"payload\": step.get(\"event_payload\", {})\n            })\n\n    export_data = {\n        \"blueprint_id\": blueprint_id,\n        \"exported_at\": datetime.now().isoformat(),\n        \"trace\": trace,\n        \"events\": events,\n        \"final_state\": trace[-1][\"state\"] if trace else None\n    }\n\n    with open(path, \"w\") as f:\n        json.dump(export_data, f, indent=2)\n\n    return {\"output\": f\"Trace exported to: {path}\"}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "simulator_compute"}, {"id": "simulator_compute.import_trace", "type": "function", "label": "import_trace", "direction": "inbound", "parent": "simulator_compute", "line": 838, "endLine": 867, "signature": "(params) -> Dict[]", "docstring": "Import and prepare trace for replay.", "source": "def import_trace(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Import and prepare trace for replay.\"\"\"\n    path = params.get(\"path\")\n\n    if not path:\n        return {\"error\": \"No path provided\"}\n\n    path = Path(path)\n    if not path.exists():\n        return {\"error\": f\"File not found: {path}\"}\n\n    try:\n        with open(path) as f:\n            data = json.load(f)\n\n        events = data.get(\"events\", [])\n        sequence = [e[\"event\"] for e in events]\n\n        return {\n            \"trace\": data.get(\"trace\", []),\n            \"sequence\": sequence,\n            \"mode\": \"replay\",\n            \"output\": (\n                f\"Imported trace with {len(events)} events. \"\n                f\"Use RUN_SEQUENCE to replay.\"\n            ),\n            \"error\": None\n        }\n    except Exception as e:\n        return {\"error\": str(e)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "simulator_compute"}, {"id": "simulator_compute.render_status", "type": "function", "label": "render_status", "direction": "inbound", "parent": "simulator_compute", "line": 874, "endLine": 908, "signature": "(params) -> Dict[]", "docstring": "Render current simulation status.", "source": "def render_status(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Render current simulation status.\"\"\"\n    bp_name = params.get(\"blueprint_name\", \"Unknown\")\n    state = params.get(\"sim_state\", \"?\")\n    ctx = params.get(\"sim_context\", {})\n    avail_events = params.get(\"available_events\", [])\n    trace = params.get(\"trace\", [])\n    mode = params.get(\"mode\", \"manual\")\n    fork = params.get(\"current_fork\")\n\n    lines = [\n        \"=\" * 60,\n        f\"  L++ Simulator: {bp_name}\",\n        \"=\" * 60,\n        f\"  Mode: {mode}\" + (f\" (fork: {fork})\" if fork else \"\"),\n        f\"  State: {state}\",\n        f\"  Steps: {len(trace) - 1}\",\n        \"\",\n        \"  Context:\",\n    ]\n\n    for k, v in ctx.items():\n        if k != \"_state\" and v is not None:\n            lines.append(f\"    {k}: {v}\")\n\n    lines.append(\"\")\n    lines.append(f\"  Available Events ({len(avail_events)}):\")\n    for e in avail_events[:10]:\n        lines.append(f\"    - {e}\")\n    if len(avail_events) > 10:\n        lines.append(f\"    ... and {len(avail_events) - 10} more\")\n\n    lines.append(\"=\" * 60)\n\n    return {\"output\": \"\\n\".join(lines)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "simulator_compute"}, {"id": "simulator_compute.render_trace", "type": "function", "label": "render_trace", "direction": "inbound", "parent": "simulator_compute", "line": 911, "endLine": 937, "signature": "(params) -> Dict[]", "docstring": "Render execution trace.", "source": "def render_trace(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Render execution trace.\"\"\"\n    trace = params.get(\"trace\", [])\n\n    if not trace:\n        return {\"output\": \"No trace recorded\"}\n\n    lines = [\n        \"Execution Trace:\",\n        \"=\" * 50\n    ]\n\n    for step in trace:\n        step_num = step.get(\"step\", 0)\n        state = step.get(\"state\", \"?\")\n        event = step.get(\"event\")\n        prev = step.get(\"prev_state\")\n\n        if event:\n            lines.append(f\"  [{step_num}] {prev} --[{event}]--> {state}\")\n        else:\n            lines.append(f\"  [{step_num}] Initial: {state}\")\n\n    lines.append(\"=\" * 50)\n    lines.append(f\"Total steps: {len(trace) - 1}\")\n\n    return {\"output\": \"\\n\".join(lines)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "simulator_compute"}, {"id": "simulator_compute.render_state_space", "type": "function", "label": "render_state_space", "direction": "inbound", "parent": "simulator_compute", "line": 940, "endLine": 969, "signature": "(params) -> Dict[]", "docstring": "Render explored state space.", "source": "def render_state_space(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Render explored state space.\"\"\"\n    space = params.get(\"state_space\")\n\n    if not space:\n        return {\"output\": \"No state space explored\"}\n\n    lines = [\n        \"State Space Graph:\",\n        \"=\" * 50,\n        f\"States: {space.get('total_states', 0)}\",\n        f\"Edges: {space.get('total_edges', 0)}\",\n        \"\",\n        \"Mermaid Diagram:\",\n        \"```mermaid\",\n        \"stateDiagram-v2\"\n    ]\n\n    start = space.get(\"start_state\")\n    if start:\n        lines.append(f\"    [*] --> {start}\")\n\n    for edge in space.get(\"edges\", []):\n        lines.append(\n            f\"    {edge['from']} --> {edge['to']}: {edge['event']}\"\n        )\n\n    lines.append(\"```\")\n\n    return {\"output\": \"\\n\".join(lines)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "simulator_compute"}, {"id": "random", "type": "dependency", "label": "random", "direction": "outbound", "category": "stdlib", "moduleColor": "#00d4ff", "moduleName": "simulator_compute"}, {"id": "tracer_compute", "type": "module", "label": "tracer_compute", "metrics": {"fanIn": 19, "fanOut": 5, "instability": 0.208, "internalEdges": 4, "externalCallCount": 12, "localCallCount": 0, "callsByCategory": {"stdlib": 12}, "localDependencies": []}, "moduleColor": "#ff6b6b", "moduleName": "tracer_compute"}, {"id": "tracer_compute.init_tracer", "type": "function", "label": "init_tracer", "direction": "inbound", "parent": "tracer_compute", "line": 106, "endLine": 128, "signature": "(params) -> Dict[]", "docstring": "Initialize tracer with configuration.", "source": "def init_tracer(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Initialize tracer with configuration.\"\"\"\n    output_format = params.get(\"output_format\", \"human\")\n    include_context = params.get(\"include_context\", True)\n    include_timing = params.get(\"include_timing\", True)\n    max_spans = params.get(\"max_spans\", 10000)\n\n    if output_format not in OUTPUT_FORMATS:\n        output_format = \"human\"\n\n    config = {\n        \"output_format\": output_format,\n        \"include_context\": include_context,\n        \"include_timing\": include_timing,\n        \"max_spans\": max_spans,\n        \"initialized_at\": _now_iso()\n    }\n\n    return {\n        \"config\": config,\n        \"output_format\": output_format,\n        \"output\": f\"Tracer initialized with format: {output_format}\"\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#ff6b6b", "moduleName": "tracer_compute"}, {"id": "tracer_compute.start_trace", "type": "function", "label": "start_trace", "direction": "inbound", "parent": "tracer_compute", "line": 135, "endLine": 175, "signature": "(params) -> Dict[]", "docstring": "Start a new trace for a blueprint execution.", "source": "def start_trace(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Start a new trace for a blueprint execution.\"\"\"\n    config = params.get(\"config\") or {}\n    blueprint_id = params.get(\"blueprint_id\", \"unknown\")\n    blueprint_name = params.get(\"blueprint_name\", \"Unknown Blueprint\")\n    metadata = params.get(\"metadata\") or {}\n\n    trace_id = _gen_trace_id()\n    root_span_id = _gen_span_id()\n    start_time = _now_iso()\n\n    # Create root span\n    root_span = {\n        \"span_id\": root_span_id,\n        \"trace_id\": trace_id,\n        \"parent_span_id\": None,\n        \"name\": f\"blueprint:{blueprint_name}\",\n        \"span_type\": \"blueprint\",\n        \"start_time\": start_time,\n        \"end_time\": None,\n        \"duration_ms\": None,\n        \"status\": \"OK\",\n        \"attributes\": {\n            \"lpp.blueprint.id\": blueprint_id,\n            \"lpp.blueprint.name\": blueprint_name,\n            \"lpp.blueprint.metadata\": metadata\n        },\n        \"events\": []\n    }\n\n    return {\n        \"trace_id\": trace_id,\n        \"root_span_id\": root_span_id,\n        \"spans\": [root_span],\n        \"active_spans\": {root_span_id: root_span},\n        \"events\": [],\n        \"blueprint_id\": blueprint_id,\n        \"blueprint_name\": blueprint_name,\n        \"start_time\": start_time,\n        \"output\": f\"Trace started: {trace_id} for {blueprint_name}\"\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#ff6b6b", "moduleName": "tracer_compute"}, {"id": "tracer_compute.end_trace", "type": "function", "label": "end_trace", "direction": "inbound", "parent": "tracer_compute", "line": 178, "endLine": 213, "signature": "(params) -> Dict[]", "docstring": "End the current trace.", "source": "def end_trace(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"End the current trace.\"\"\"\n    trace_id = params.get(\"trace_id\")\n    root_span_id = params.get(\"root_span_id\")\n    spans = params.get(\"spans\", [])\n    active_spans = params.get(\"active_spans\", {})\n    start_time = params.get(\"start_time\")\n\n    end_time = _now_iso()\n\n    # Close all active spans\n    new_spans = []\n    for span in spans:\n        if span[\"span_id\"] in active_spans:\n            span = dict(span)\n            span[\"end_time\"] = end_time\n            span[\"duration_ms\"] = _duration_ms(span[\"start_time\"], end_time)\n        new_spans.append(span)\n\n    # Find and update root span\n    for i, span in enumerate(new_spans):\n        if span[\"span_id\"] == root_span_id:\n            new_spans[i] = dict(span)\n            new_spans[i][\"end_time\"] = end_time\n            new_spans[i][\"duration_ms\"] = _duration_ms(start_time, end_time)\n            break\n\n    total_duration = _duration_ms(start_time, end_time)\n\n    return {\n        \"spans\": new_spans,\n        \"active_spans\": {},\n        \"end_time\": end_time,\n        \"output\": f\"Trace ended: {trace_id} ({total_duration:.2f}ms, \"\n                  f\"{len(new_spans)} spans)\"\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#ff6b6b", "moduleName": "tracer_compute"}, {"id": "tracer_compute.clear_trace", "type": "function", "label": "clear_trace", "direction": "inbound", "parent": "tracer_compute", "line": 216, "endLine": 229, "signature": "(params) -> Dict[]", "docstring": "Clear all trace data.", "source": "def clear_trace(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Clear all trace data.\"\"\"\n    return {\n        \"trace_id\": None,\n        \"root_span_id\": None,\n        \"spans\": None,\n        \"active_spans\": None,\n        \"events\": None,\n        \"start_time\": None,\n        \"end_time\": None,\n        \"analysis_result\": None,\n        \"formatted_output\": None,\n        \"output\": \"Trace cleared\"\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#ff6b6b", "moduleName": "tracer_compute"}, {"id": "tracer_compute.record_span", "type": "function", "label": "record_span", "direction": "inbound", "parent": "tracer_compute", "line": 236, "endLine": 272, "signature": "(params) -> Dict[]", "docstring": "Record a complete span (already timed).", "source": "def record_span(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Record a complete span (already timed).\"\"\"\n    trace_id = params.get(\"trace_id\")\n    spans = params.get(\"spans\", [])\n    span_type = params.get(\"span_type\", \"generic\")\n    name = params.get(\"name\", \"unnamed\")\n    parent_span_id = params.get(\"parent_span_id\")\n    attributes = params.get(\"attributes\") or {}\n    start_time = params.get(\"start_time\") or _now_iso()\n    end_time = params.get(\"end_time\") or _now_iso()\n    duration_ms = params.get(\"duration_ms\")\n\n    if duration_ms is None:\n        duration_ms = _duration_ms(start_time, end_time)\n\n    span_id = _gen_span_id()\n\n    span = {\n        \"span_id\": span_id,\n        \"trace_id\": trace_id,\n        \"parent_span_id\": parent_span_id,\n        \"name\": name,\n        \"span_type\": span_type,\n        \"start_time\": start_time,\n        \"end_time\": end_time,\n        \"duration_ms\": duration_ms,\n        \"status\": \"OK\",\n        \"attributes\": attributes,\n        \"events\": []\n    }\n\n    new_spans = spans + [span]\n\n    return {\n        \"spans\": new_spans,\n        \"output\": f\"Recorded span: {name} ({duration_ms:.2f}ms)\"\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#ff6b6b", "moduleName": "tracer_compute"}, {"id": "tracer_compute.start_span", "type": "function", "label": "start_span", "direction": "inbound", "parent": "tracer_compute", "line": 275, "endLine": 314, "signature": "(params) -> Dict[]", "docstring": "Start a new span (for timed events).", "source": "def start_span(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Start a new span (for timed events).\"\"\"\n    trace_id = params.get(\"trace_id\")\n    spans = params.get(\"spans\", [])\n    active_spans = params.get(\"active_spans\", {})\n    span_type = params.get(\"span_type\", \"generic\")\n    name = params.get(\"name\", \"unnamed\")\n    parent_span_id = params.get(\"parent_span_id\")\n    attributes = params.get(\"attributes\") or {}\n\n    # Auto-parent to current active span if not specified\n    if parent_span_id is None:\n        parent_span_id = _get_current_span_id(active_spans)\n\n    span_id = _gen_span_id()\n    start_time = _now_iso()\n\n    span = {\n        \"span_id\": span_id,\n        \"trace_id\": trace_id,\n        \"parent_span_id\": parent_span_id,\n        \"name\": name,\n        \"span_type\": span_type,\n        \"start_time\": start_time,\n        \"end_time\": None,\n        \"duration_ms\": None,\n        \"status\": \"UNSET\",\n        \"attributes\": attributes,\n        \"events\": []\n    }\n\n    new_spans = spans + [span]\n    new_active = dict(active_spans)\n    new_active[span_id] = span\n\n    return {\n        \"spans\": new_spans,\n        \"active_spans\": new_active,\n        \"output\": f\"Started span: {name} [{span_id[:8]}]\"\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#ff6b6b", "moduleName": "tracer_compute"}, {"id": "tracer_compute.end_span", "type": "function", "label": "end_span", "direction": "inbound", "parent": "tracer_compute", "line": 317, "endLine": 361, "signature": "(params) -> Dict[]", "docstring": "End an active span.", "source": "def end_span(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"End an active span.\"\"\"\n    span_id = params.get(\"span_id\")\n    spans = params.get(\"spans\", [])\n    active_spans = params.get(\"active_spans\", {})\n    attributes = params.get(\"attributes\") or {}\n    status = params.get(\"status\", \"OK\")\n\n    if not span_id:\n        # End most recent active span\n        span_id = _get_current_span_id(active_spans)\n\n    if not span_id or span_id not in active_spans:\n        return {\n            \"spans\": spans,\n            \"active_spans\": active_spans,\n            \"output\": f\"No active span to end: {span_id}\"\n        }\n\n    end_time = _now_iso()\n\n    new_spans = []\n    span_name = \"unknown\"\n    duration = 0.0\n\n    for span in spans:\n        if span[\"span_id\"] == span_id:\n            span = dict(span)\n            span[\"end_time\"] = end_time\n            span[\"duration_ms\"] = _duration_ms(span[\"start_time\"], end_time)\n            span[\"status\"] = status\n            span[\"attributes\"].update(attributes)\n            span_name = span[\"name\"]\n            duration = span[\"duration_ms\"]\n        new_spans.append(span)\n\n    new_active = dict(active_spans)\n    if span_id in new_active:\n        del new_active[span_id]\n\n    return {\n        \"spans\": new_spans,\n        \"active_spans\": new_active,\n        \"output\": f\"Ended span: {span_name} ({duration:.2f}ms)\"\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#ff6b6b", "moduleName": "tracer_compute"}, {"id": "tracer_compute.record_state_change", "type": "function", "label": "record_state_change", "direction": "inbound", "parent": "tracer_compute", "line": 368, "endLine": 421, "signature": "(params) -> Dict[]", "docstring": "Record a state transition event.", "source": "def record_state_change(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Record a state transition event.\"\"\"\n    trace_id = params.get(\"trace_id\")\n    spans = params.get(\"spans\", [])\n    events = params.get(\"events\", [])\n    active_spans = params.get(\"active_spans\", {})\n    from_state = params.get(\"from_state\")\n    to_state = params.get(\"to_state\")\n    transition_id = params.get(\"transition_id\")\n    trigger_event = params.get(\"trigger_event\")\n\n    timestamp = _now_iso()\n    parent_span_id = _get_current_span_id(active_spans)\n\n    # Create transition span\n    span_id = _gen_span_id()\n    span = {\n        \"span_id\": span_id,\n        \"trace_id\": trace_id,\n        \"parent_span_id\": parent_span_id,\n        \"name\": f\"transition:{from_state}->{to_state}\",\n        \"span_type\": \"transition\",\n        \"start_time\": timestamp,\n        \"end_time\": timestamp,\n        \"duration_ms\": 0,\n        \"status\": \"OK\",\n        \"attributes\": {\n            \"lpp.transition.id\": transition_id,\n            \"lpp.transition.from\": from_state,\n            \"lpp.transition.to\": to_state,\n            \"lpp.transition.event\": trigger_event\n        },\n        \"events\": []\n    }\n\n    # Create event entry\n    event = {\n        \"timestamp\": timestamp,\n        \"type\": \"state_change\",\n        \"trace_id\": trace_id,\n        \"span_id\": span_id,\n        \"attributes\": {\n            \"from_state\": from_state,\n            \"to_state\": to_state,\n            \"transition_id\": transition_id,\n            \"trigger_event\": trigger_event\n        }\n    }\n\n    return {\n        \"spans\": spans + [span],\n        \"events\": events + [event],\n        \"output\": f\"State: {from_state} -> {to_state} [{trigger_event}]\"\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#ff6b6b", "moduleName": "tracer_compute"}, {"id": "tracer_compute.record_gate_eval", "type": "function", "label": "record_gate_eval", "direction": "inbound", "parent": "tracer_compute", "line": 424, "endLine": 477, "signature": "(params) -> Dict[]", "docstring": "Record a gate evaluation.", "source": "def record_gate_eval(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Record a gate evaluation.\"\"\"\n    trace_id = params.get(\"trace_id\")\n    spans = params.get(\"spans\", [])\n    events = params.get(\"events\", [])\n    active_spans = params.get(\"active_spans\", {})\n    gate_id = params.get(\"gate_id\")\n    expression = params.get(\"expression\")\n    result = params.get(\"result\")\n    input_values = params.get(\"input_values\") or {}\n\n    timestamp = _now_iso()\n    parent_span_id = _get_current_span_id(active_spans)\n\n    span_id = _gen_span_id()\n    span = {\n        \"span_id\": span_id,\n        \"trace_id\": trace_id,\n        \"parent_span_id\": parent_span_id,\n        \"name\": f\"gate:{gate_id}\",\n        \"span_type\": \"gate\",\n        \"start_time\": timestamp,\n        \"end_time\": timestamp,\n        \"duration_ms\": 0,\n        \"status\": \"OK\" if result else \"ERROR\",\n        \"attributes\": {\n            \"lpp.gate.id\": gate_id,\n            \"lpp.gate.expression\": expression,\n            \"lpp.gate.result\": result,\n            \"lpp.gate.inputs\": input_values\n        },\n        \"events\": []\n    }\n\n    event = {\n        \"timestamp\": timestamp,\n        \"type\": \"gate_eval\",\n        \"trace_id\": trace_id,\n        \"span_id\": span_id,\n        \"attributes\": {\n            \"gate_id\": gate_id,\n            \"expression\": expression,\n            \"result\": result,\n            \"input_values\": input_values\n        }\n    }\n\n    result_str = \"PASS\" if result else \"FAIL\"\n\n    return {\n        \"spans\": spans + [span],\n        \"events\": events + [event],\n        \"output\": f\"Gate {gate_id}: {result_str}\"\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#ff6b6b", "moduleName": "tracer_compute"}, {"id": "tracer_compute.record_action", "type": "function", "label": "record_action", "direction": "inbound", "parent": "tracer_compute", "line": 480, "endLine": 531, "signature": "(params) -> Dict[]", "docstring": "Record an action execution.", "source": "def record_action(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Record an action execution.\"\"\"\n    trace_id = params.get(\"trace_id\")\n    spans = params.get(\"spans\", [])\n    events = params.get(\"events\", [])\n    active_spans = params.get(\"active_spans\", {})\n    action_id = params.get(\"action_id\")\n    action_type = params.get(\"action_type\", \"unknown\")\n    input_map = params.get(\"input_map\") or {}\n    output_map = params.get(\"output_map\") or {}\n    duration_ms = params.get(\"duration_ms\", 0)\n\n    timestamp = _now_iso()\n    parent_span_id = _get_current_span_id(active_spans)\n\n    span_id = _gen_span_id()\n    span = {\n        \"span_id\": span_id,\n        \"trace_id\": trace_id,\n        \"parent_span_id\": parent_span_id,\n        \"name\": f\"action:{action_id}\",\n        \"span_type\": \"action\",\n        \"start_time\": timestamp,\n        \"end_time\": timestamp,\n        \"duration_ms\": duration_ms,\n        \"status\": \"OK\",\n        \"attributes\": {\n            \"lpp.action.id\": action_id,\n            \"lpp.action.type\": action_type,\n            \"lpp.action.input_map\": input_map,\n            \"lpp.action.output_map\": output_map\n        },\n        \"events\": []\n    }\n\n    event = {\n        \"timestamp\": timestamp,\n        \"type\": \"action\",\n        \"trace_id\": trace_id,\n        \"span_id\": span_id,\n        \"attributes\": {\n            \"action_id\": action_id,\n            \"action_type\": action_type,\n            \"duration_ms\": duration_ms\n        }\n    }\n\n    return {\n        \"spans\": spans + [span],\n        \"events\": events + [event],\n        \"output\": f\"Action {action_id} ({action_type}) [{duration_ms:.2f}ms]\"\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#ff6b6b", "moduleName": "tracer_compute"}, {"id": "tracer_compute.record_event", "type": "function", "label": "record_event", "direction": "inbound", "parent": "tracer_compute", "line": 534, "endLine": 559, "signature": "(params) -> Dict[]", "docstring": "Record an event dispatch.", "source": "def record_event(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Record an event dispatch.\"\"\"\n    trace_id = params.get(\"trace_id\")\n    events = params.get(\"events\", [])\n    active_spans = params.get(\"active_spans\", {})\n    event_name = params.get(\"event_name\")\n    event_payload = params.get(\"event_payload\") or {}\n\n    timestamp = _now_iso()\n    span_id = _get_current_span_id(active_spans)\n\n    event = {\n        \"timestamp\": timestamp,\n        \"type\": \"event_dispatch\",\n        \"trace_id\": trace_id,\n        \"span_id\": span_id,\n        \"attributes\": {\n            \"event_name\": event_name,\n            \"event_payload\": event_payload\n        }\n    }\n\n    return {\n        \"events\": events + [event],\n        \"output\": f\"Event: {event_name}\"\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#ff6b6b", "moduleName": "tracer_compute"}, {"id": "tracer_compute.record_context_change", "type": "function", "label": "record_context_change", "direction": "inbound", "parent": "tracer_compute", "line": 562, "endLine": 592, "signature": "(params) -> Dict[]", "docstring": "Record a context mutation.", "source": "def record_context_change(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Record a context mutation.\"\"\"\n    trace_id = params.get(\"trace_id\")\n    events = params.get(\"events\", [])\n    active_spans = params.get(\"active_spans\", {})\n    key = params.get(\"key\")\n    old_value = params.get(\"old_value\")\n    new_value = params.get(\"new_value\")\n\n    timestamp = _now_iso()\n    span_id = _get_current_span_id(active_spans)\n\n    event = {\n        \"timestamp\": timestamp,\n        \"type\": \"context_mutation\",\n        \"trace_id\": trace_id,\n        \"span_id\": span_id,\n        \"attributes\": {\n            \"key\": key,\n            \"old_value\": old_value,\n            \"new_value\": new_value\n        }\n    }\n\n    old_str = _truncate(str(old_value), 20)\n    new_str = _truncate(str(new_value), 20)\n\n    return {\n        \"events\": events + [event],\n        \"output\": f\"Context: {key} = {old_str} -> {new_str}\"\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#ff6b6b", "moduleName": "tracer_compute"}, {"id": "tracer_compute.format_otlp", "type": "function", "label": "format_otlp", "direction": "inbound", "parent": "tracer_compute", "line": 606, "endLine": 683, "signature": "(params) -> Dict[]", "docstring": "Format trace as OpenTelemetry Protocol JSON.", "source": "def format_otlp(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Format trace as OpenTelemetry Protocol JSON.\"\"\"\n    trace_id = params.get(\"trace_id\")\n    spans = params.get(\"spans\", [])\n    events = params.get(\"events\", [])\n    blueprint_id = params.get(\"blueprint_id\")\n    blueprint_name = params.get(\"blueprint_name\")\n    start_time = params.get(\"start_time\")\n    end_time = params.get(\"end_time\")\n\n    # Convert to OTLP format\n    otlp_spans = []\n    for span in spans:\n        otlp_span = {\n            \"traceId\": span.get(\"trace_id\", \"\"),\n            \"spanId\": span.get(\"span_id\", \"\"),\n            \"parentSpanId\": span.get(\"parent_span_id\", \"\"),\n            \"name\": span.get(\"name\", \"\"),\n            \"kind\": 1,  # SPAN_KIND_INTERNAL\n            \"startTimeUnixNano\": _iso_to_ns(span.get(\"start_time\")),\n            \"endTimeUnixNano\": _iso_to_ns(span.get(\"end_time\")),\n            \"attributes\": _attrs_to_otlp(span.get(\"attributes\", {})),\n            \"status\": {\n                \"code\": 1 if span.get(\"status\") == \"OK\" else 2,\n                \"message\": span.get(\"status\", \"OK\")\n            },\n            \"events\": [\n                {\n                    \"timeUnixNano\": _iso_to_ns(e.get(\"timestamp\")),\n                    \"name\": e.get(\"type\", \"event\"),\n                    \"attributes\": _attrs_to_otlp(e.get(\"attributes\", {}))\n                }\n                for e in span.get(\"events\", [])\n            ]\n        }\n        otlp_spans.append(otlp_span)\n\n    # Add trace-level events as span events on root\n    for evt in events:\n        otlp_event = {\n            \"timeUnixNano\": _iso_to_ns(evt.get(\"timestamp\")),\n            \"name\": evt.get(\"type\", \"event\"),\n            \"attributes\": _attrs_to_otlp(evt.get(\"attributes\", {}))\n        }\n        # Add to first (root) span\n        if otlp_spans:\n            otlp_spans[0][\"events\"].append(otlp_event)\n\n    otlp_doc = {\n        \"resourceSpans\": [{\n            \"resource\": {\n                \"attributes\": [\n                    {\"key\": \"service.name\",\n                     \"value\": {\"stringValue\": OTLP_SERVICE_NAME}},\n                    {\"key\": \"service.version\",\n                     \"value\": {\"stringValue\": OTLP_SERVICE_VERSION}},\n                    {\"key\": \"lpp.blueprint.id\",\n                     \"value\": {\"stringValue\": blueprint_id or \"\"}},\n                    {\"key\": \"lpp.blueprint.name\",\n                     \"value\": {\"stringValue\": blueprint_name or \"\"}}\n                ]\n            },\n            \"scopeSpans\": [{\n                \"scope\": {\n                    \"name\": \"lpp-tracer\",\n                    \"version\": \"1.0.0\"\n                },\n                \"spans\": otlp_spans\n            }]\n        }]\n    }\n\n    formatted = json.dumps(otlp_doc, indent=2)\n\n    return {\n        \"formatted_output\": formatted,\n        \"output\": f\"Formatted as OTLP JSON ({len(otlp_spans)} spans)\"\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#ff6b6b", "moduleName": "tracer_compute"}, {"id": "tracer_compute.format_jsonl", "type": "function", "label": "format_jsonl", "direction": "inbound", "parent": "tracer_compute", "line": 715, "endLine": 757, "signature": "(params) -> Dict[]", "docstring": "Format trace as JSON Lines (one JSON object per line).", "source": "def format_jsonl(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Format trace as JSON Lines (one JSON object per line).\"\"\"\n    trace_id = params.get(\"trace_id\")\n    spans = params.get(\"spans\", [])\n    events = params.get(\"events\", [])\n\n    lines = []\n\n    # Add spans\n    for span in spans:\n        line = {\n            \"type\": \"span\",\n            \"trace_id\": trace_id,\n            \"span_id\": span.get(\"span_id\"),\n            \"parent_span_id\": span.get(\"parent_span_id\"),\n            \"name\": span.get(\"name\"),\n            \"span_type\": span.get(\"span_type\"),\n            \"start_time\": span.get(\"start_time\"),\n            \"end_time\": span.get(\"end_time\"),\n            \"duration_ms\": span.get(\"duration_ms\"),\n            \"status\": span.get(\"status\"),\n            \"attributes\": span.get(\"attributes\", {})\n        }\n        lines.append(json.dumps(line, default=str))\n\n    # Add events\n    for evt in events:\n        line = {\n            \"type\": \"event\",\n            \"trace_id\": trace_id,\n            \"span_id\": evt.get(\"span_id\"),\n            \"timestamp\": evt.get(\"timestamp\"),\n            \"event_type\": evt.get(\"type\"),\n            \"attributes\": evt.get(\"attributes\", {})\n        }\n        lines.append(json.dumps(line, default=str))\n\n    formatted = \"\\n\".join(lines)\n\n    return {\n        \"formatted_output\": formatted,\n        \"output\": f\"Formatted as JSON Lines ({len(lines)} lines)\"\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#ff6b6b", "moduleName": "tracer_compute"}, {"id": "tracer_compute.format_human", "type": "function", "label": "format_human", "direction": "inbound", "parent": "tracer_compute", "line": 760, "endLine": 846, "signature": "(params) -> Dict[]", "docstring": "Format trace as human-readable text.", "source": "def format_human(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Format trace as human-readable text.\"\"\"\n    trace_id = params.get(\"trace_id\")\n    spans = params.get(\"spans\", [])\n    events = params.get(\"events\", [])\n    blueprint_name = params.get(\"blueprint_name\", \"Unknown\")\n    start_time = params.get(\"start_time\")\n    end_time = params.get(\"end_time\")\n\n    total_duration = _duration_ms(start_time, end_time) if end_time else 0\n\n    lines = [\n        \"=\" * 70,\n        f\"  L++ Execution Trace: {blueprint_name}\",\n        \"=\" * 70,\n        f\"  Trace ID: {trace_id}\",\n        f\"  Started:  {start_time}\",\n        f\"  Ended:    {end_time or 'in progress'}\",\n        f\"  Duration: {total_duration:.2f}ms\",\n        f\"  Spans:    {len(spans)}\",\n        f\"  Events:   {len(events)}\",\n        \"=\" * 70,\n        \"\",\n        \"SPANS:\",\n        \"-\" * 70\n    ]\n\n    # Sort spans by start time\n    sorted_spans = sorted(spans, key=lambda s: s.get(\"start_time\", \"\"))\n\n    for span in sorted_spans:\n        name = span.get(\"name\", \"unknown\")\n        span_type = span.get(\"span_type\", \"generic\")\n        dur = span.get(\"duration_ms\", 0) or 0\n        status = span.get(\"status\", \"?\")\n\n        lines.append(\n            f\"  [{span_type:12}] {name:40} {dur:8.2f}ms [{status}]\"\n        )\n\n        # Show key attributes\n        attrs = span.get(\"attributes\", {})\n        for k, v in attrs.items():\n            if k.startswith(\"lpp.\"):\n                short_key = k.replace(\"lpp.\", \"\")\n                val_str = _truncate(str(v), 40)\n                lines.append(f\"                  {short_key}: {val_str}\")\n\n    lines.extend([\n        \"\",\n        \"EVENTS:\",\n        \"-\" * 70\n    ])\n\n    # Sort events by timestamp\n    sorted_events = sorted(events, key=lambda e: e.get(\"timestamp\", \"\"))\n\n    for evt in sorted_events:\n        ts = evt.get(\"timestamp\", \"\")\n        if ts:\n            ts = ts.split(\"T\")[1][:12]  # Just time portion\n        evt_type = evt.get(\"type\", \"unknown\")\n        attrs = evt.get(\"attributes\", {})\n\n        summary = \"\"\n        if evt_type == \"state_change\":\n            summary = f\"{attrs.get('from_state')} -> {attrs.get('to_state')}\"\n        elif evt_type == \"gate_eval\":\n            result = \"PASS\" if attrs.get(\"result\") else \"FAIL\"\n            summary = f\"{attrs.get('gate_id')}: {result}\"\n        elif evt_type == \"action\":\n            summary = f\"{attrs.get('action_id')} ({attrs.get('action_type')})\"\n        elif evt_type == \"event_dispatch\":\n            summary = attrs.get(\"event_name\", \"\")\n        elif evt_type == \"context_mutation\":\n            summary = f\"{attrs.get('key')} changed\"\n\n        lines.append(f\"  [{ts}] {evt_type:18} {summary}\")\n\n    lines.extend([\"\", \"=\" * 70])\n\n    formatted = \"\\n\".join(lines)\n\n    return {\n        \"formatted_output\": formatted,\n        \"output\": f\"Formatted as human-readable ({len(lines)} lines)\"\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#ff6b6b", "moduleName": "tracer_compute"}, {"id": "tracer_compute.format_timeline", "type": "function", "label": "format_timeline", "direction": "inbound", "parent": "tracer_compute", "line": 849, "endLine": 967, "signature": "(params) -> Dict[]", "docstring": "Format trace as ASCII timeline visualization.", "source": "def format_timeline(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Format trace as ASCII timeline visualization.\"\"\"\n    trace_id = params.get(\"trace_id\")\n    spans = params.get(\"spans\", [])\n    events = params.get(\"events\", [])\n    blueprint_name = params.get(\"blueprint_name\", \"Unknown\")\n    start_time = params.get(\"start_time\")\n    end_time = params.get(\"end_time\")\n\n    if not spans:\n        return {\n            \"formatted_output\": \"No spans to visualize\",\n            \"output\": \"No spans to visualize\"\n        }\n\n    total_duration = _duration_ms(start_time, end_time) if end_time else 1000\n    if total_duration == 0:\n        total_duration = 1  # Avoid division by zero\n\n    width = 60  # Timeline width in characters\n\n    lines = [\n        \"=\" * 70,\n        f\"  Timeline: {blueprint_name}\",\n        f\"  Trace: {trace_id}\",\n        f\"  Total Duration: {total_duration:.2f}ms\",\n        \"=\" * 70,\n        \"\",\n        f\"{'Span':<30} {'Timeline':>{width}} {'ms':>8}\",\n        \"-\" * 100\n    ]\n\n    # Sort spans by start time\n    sorted_spans = sorted(spans, key=lambda s: s.get(\"start_time\", \"\"))\n\n    trace_start = _parse_iso(start_time) if start_time else None\n\n    for span in sorted_spans:\n        name = span.get(\"name\", \"unknown\")[:28]\n        span_start = span.get(\"start_time\")\n        span_end = span.get(\"end_time\") or end_time\n        dur = span.get(\"duration_ms\", 0) or 0\n\n        # Calculate position on timeline\n        if trace_start and span_start:\n            start_offset = _duration_ms(start_time, span_start)\n            end_offset = _duration_ms(start_time, span_end) if span_end else \\\n                start_offset + dur\n        else:\n            start_offset = 0\n            end_offset = dur\n\n        # Convert to character positions\n        start_pos = int((start_offset / total_duration) * width)\n        end_pos = int((end_offset / total_duration) * width)\n\n        start_pos = max(0, min(width - 1, start_pos))\n        end_pos = max(start_pos + 1, min(width, end_pos))\n\n        # Build timeline bar\n        bar = [\".\"] * width\n        bar_char = \"#\"\n\n        # Use different chars for different span types\n        span_type = span.get(\"span_type\", \"\")\n        if span_type == \"transition\":\n            bar_char = \">\"\n        elif span_type == \"gate\":\n            bar_char = \"?\"\n        elif span_type == \"action\":\n            bar_char = \"*\"\n        elif span_type == \"blueprint\":\n            bar_char = \"=\"\n\n        for i in range(start_pos, end_pos):\n            bar[i] = bar_char\n\n        timeline_str = \"\".join(bar)\n        lines.append(f\"{name:<30} |{timeline_str}| {dur:>7.2f}\")\n\n    # Add legend\n    lines.extend([\n        \"\",\n        \"-\" * 100,\n        \"Legend: = blueprint  > transition  ? gate  * action  # other\",\n        \"\",\n        \"Events:\",\n        \"-\" * 100\n    ])\n\n    # Show events on timeline\n    sorted_events = sorted(events, key=lambda e: e.get(\"timestamp\", \"\"))\n\n    for evt in sorted_events[:20]:  # Limit to 20 events\n        ts = evt.get(\"timestamp\")\n        evt_type = evt.get(\"type\", \"unknown\")[:15]\n\n        if trace_start and ts:\n            offset = _duration_ms(start_time, ts)\n            pos = int((offset / total_duration) * width)\n            pos = max(0, min(width - 1, pos))\n        else:\n            pos = 0\n\n        # Build marker line\n        marker = [\" \"] * width\n        marker[pos] = \"v\"\n        marker_str = \"\".join(marker)\n\n        lines.append(f\"{evt_type:<30} |{marker_str}|\")\n\n    lines.append(\"=\" * 70)\n\n    formatted = \"\\n\".join(lines)\n\n    return {\n        \"formatted_output\": formatted,\n        \"output\": f\"Formatted as timeline ({len(sorted_spans)} spans)\"\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#ff6b6b", "moduleName": "tracer_compute"}, {"id": "tracer_compute.export_trace", "type": "function", "label": "export_trace", "direction": "inbound", "parent": "tracer_compute", "line": 974, "endLine": 1035, "signature": "(params) -> Dict[]", "docstring": "Export trace to a file.", "source": "def export_trace(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Export trace to a file.\"\"\"\n    formatted_output = params.get(\"formatted_output\")\n    output_format = params.get(\"output_format\", \"human\")\n    path = params.get(\"path\")\n    trace_id = params.get(\"trace_id\")\n    spans = params.get(\"spans\", [])\n    events = params.get(\"events\", [])\n    blueprint_id = params.get(\"blueprint_id\")\n    blueprint_name = params.get(\"blueprint_name\")\n    start_time = params.get(\"start_time\")\n    end_time = params.get(\"end_time\")\n\n    # Generate default path if not provided\n    if not path:\n        ext_map = {\n            \"otlp\": \"json\",\n            \"jsonl\": \"jsonl\",\n            \"human\": \"txt\",\n            \"timeline\": \"txt\"\n        }\n        ext = ext_map.get(output_format, \"txt\")\n        path = f\"trace_{trace_id[:8]}.{ext}\"\n\n    # Format if not already formatted\n    if not formatted_output:\n        format_params = {\n            \"trace_id\": trace_id,\n            \"spans\": spans,\n            \"events\": events,\n            \"blueprint_id\": blueprint_id,\n            \"blueprint_name\": blueprint_name,\n            \"start_time\": start_time,\n            \"end_time\": end_time\n        }\n\n        if output_format == \"otlp\":\n            result = format_otlp(format_params)\n        elif output_format == \"jsonl\":\n            result = format_jsonl(format_params)\n        elif output_format == \"timeline\":\n            result = format_timeline(format_params)\n        else:\n            result = format_human(format_params)\n\n        formatted_output = result.get(\"formatted_output\", \"\")\n\n    # Write to file\n    try:\n        path_obj = Path(path)\n        path_obj.parent.mkdir(parents=True, exist_ok=True)\n        path_obj.write_text(formatted_output)\n\n        return {\n            \"export_path\": str(path_obj.absolute()),\n            \"output\": f\"Exported trace to: {path_obj.absolute()}\"\n        }\n    except Exception as e:\n        return {\n            \"export_path\": None,\n            \"output\": f\"Export failed: {e}\"\n        }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#ff6b6b", "moduleName": "tracer_compute"}, {"id": "tracer_compute.analyze_trace", "type": "function", "label": "analyze_trace", "direction": "inbound", "parent": "tracer_compute", "line": 1042, "endLine": 1184, "signature": "(params) -> Dict[]", "docstring": "Analyze trace data for insights.", "source": "def analyze_trace(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Analyze trace data for insights.\"\"\"\n    trace_id = params.get(\"trace_id\")\n    spans = params.get(\"spans\", [])\n    events = params.get(\"events\", [])\n    start_time = params.get(\"start_time\")\n    end_time = params.get(\"end_time\")\n\n    total_duration = _duration_ms(start_time, end_time) if end_time else 0\n\n    # Collect statistics\n    span_count = len(spans)\n    event_count = len(events)\n\n    # Analyze by span type\n    by_type = {}\n    for span in spans:\n        span_type = span.get(\"span_type\", \"unknown\")\n        if span_type not in by_type:\n            by_type[span_type] = {\"count\": 0, \"total_ms\": 0, \"spans\": []}\n        by_type[span_type][\"count\"] += 1\n        dur = span.get(\"duration_ms\", 0) or 0\n        by_type[span_type][\"total_ms\"] += dur\n        by_type[span_type][\"spans\"].append(span)\n\n    # Find slowest spans\n    sorted_by_duration = sorted(\n        spans,\n        key=lambda s: s.get(\"duration_ms\", 0) or 0,\n        reverse=True\n    )\n    slowest = sorted_by_duration[:5]\n\n    # Analyze state transitions\n    state_changes = [e for e in events if e.get(\"type\") == \"state_change\"]\n    state_visits = {}\n    for sc in state_changes:\n        attrs = sc.get(\"attributes\", {})\n        to_state = attrs.get(\"to_state\")\n        if to_state:\n            state_visits[to_state] = state_visits.get(to_state, 0) + 1\n\n    # Analyze gate results\n    gate_evals = [e for e in events if e.get(\"type\") == \"gate_eval\"]\n    gate_stats = {\"pass\": 0, \"fail\": 0}\n    for ge in gate_evals:\n        attrs = ge.get(\"attributes\", {})\n        if attrs.get(\"result\"):\n            gate_stats[\"pass\"] += 1\n        else:\n            gate_stats[\"fail\"] += 1\n\n    # Analyze events\n    event_types = {}\n    for evt in events:\n        evt_type = evt.get(\"type\", \"unknown\")\n        event_types[evt_type] = event_types.get(evt_type, 0) + 1\n\n    analysis = {\n        \"trace_id\": trace_id,\n        \"total_duration_ms\": total_duration,\n        \"span_count\": span_count,\n        \"event_count\": event_count,\n        \"spans_by_type\": {\n            k: {\"count\": v[\"count\"], \"total_ms\": v[\"total_ms\"]}\n            for k, v in by_type.items()\n        },\n        \"slowest_spans\": [\n            {\n                \"name\": s.get(\"name\"),\n                \"type\": s.get(\"span_type\"),\n                \"duration_ms\": s.get(\"duration_ms\", 0)\n            }\n            for s in slowest\n        ],\n        \"state_visits\": state_visits,\n        \"gate_stats\": gate_stats,\n        \"event_types\": event_types\n    }\n\n    # Format output\n    lines = [\n        \"=\" * 60,\n        \"  Trace Analysis\",\n        \"=\" * 60,\n        f\"  Trace ID:    {trace_id}\",\n        f\"  Duration:    {total_duration:.2f}ms\",\n        f\"  Spans:       {span_count}\",\n        f\"  Events:      {event_count}\",\n        \"\",\n        \"  SPANS BY TYPE:\",\n        \"  \" + \"-\" * 50\n    ]\n\n    for st, stats in by_type.items():\n        avg = stats[\"total_ms\"] / stats[\"count\"] if stats[\"count\"] else 0\n        lines.append(\n            f\"    {st:15} count: {stats['count']:4}  \"\n            f\"total: {stats['total_ms']:8.2f}ms  avg: {avg:.2f}ms\"\n        )\n\n    lines.extend([\n        \"\",\n        \"  SLOWEST SPANS:\",\n        \"  \" + \"-\" * 50\n    ])\n\n    for s in slowest:\n        lines.append(\n            f\"    {s.get('name', 'unknown')[:35]:35} \"\n            f\"{s.get('duration_ms', 0):8.2f}ms\"\n        )\n\n    lines.extend([\n        \"\",\n        \"  STATE VISITS:\",\n        \"  \" + \"-\" * 50\n    ])\n\n    for state, count in sorted(state_visits.items(),\n                                key=lambda x: x[1], reverse=True):\n        lines.append(f\"    {state:30} {count:4} visits\")\n\n    lines.extend([\n        \"\",\n        \"  GATE EVALUATION:\",\n        \"  \" + \"-\" * 50,\n        f\"    Pass: {gate_stats['pass']}  Fail: {gate_stats['fail']}\",\n        \"\",\n        \"  EVENT TYPES:\",\n        \"  \" + \"-\" * 50\n    ])\n\n    for evt_type, count in sorted(event_types.items(),\n                                   key=lambda x: x[1], reverse=True):\n        lines.append(f\"    {evt_type:30} {count:4}\")\n\n    lines.append(\"=\" * 60)\n\n    return {\n        \"analysis_result\": analysis,\n        \"output\": \"\\n\".join(lines)\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#ff6b6b", "moduleName": "tracer_compute"}, {"id": "tracer_compute.render_status", "type": "function", "label": "render_status", "direction": "inbound", "parent": "tracer_compute", "line": 1191, "endLine": 1224, "signature": "(params) -> Dict[]", "docstring": "Render current tracer status.", "source": "def render_status(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Render current tracer status.\"\"\"\n    trace_id = params.get(\"trace_id\")\n    blueprint_name = params.get(\"blueprint_name\", \"N/A\")\n    spans = params.get(\"spans\") or []\n    events = params.get(\"events\") or []\n    active_spans = params.get(\"active_spans\") or {}\n    start_time = params.get(\"start_time\")\n    output_format = params.get(\"output_format\", \"human\")\n\n    lines = [\n        \"=\" * 50,\n        \"  L++ Execution Tracer Status\",\n        \"=\" * 50,\n        f\"  Trace ID:      {trace_id or 'None'}\",\n        f\"  Blueprint:     {blueprint_name}\",\n        f\"  Format:        {output_format}\",\n        f\"  Started:       {start_time or 'N/A'}\",\n        f\"  Spans:         {len(spans)}\",\n        f\"  Active Spans:  {len(active_spans)}\",\n        f\"  Events:        {len(events)}\",\n    ]\n\n    if active_spans:\n        lines.append(\"\")\n        lines.append(\"  Active Spans:\")\n        for sid, span in list(active_spans.items())[:5]:\n            lines.append(f\"    - {span.get('name', 'unknown')} [{sid[:8]}]\")\n\n    lines.append(\"=\" * 50)\n\n    return {\n        \"output\": \"\\n\".join(lines)\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#ff6b6b", "moduleName": "tracer_compute"}, {"id": "function_decoder_compute", "type": "module", "label": "function_decoder_compute", "metrics": {"fanIn": 18, "fanOut": 5, "instability": 0.217, "internalEdges": 5, "externalCallCount": 14, "localCallCount": 0, "callsByCategory": {"stdlib": 14}, "localDependencies": []}, "moduleColor": "#4ecdc4", "moduleName": "function_decoder_compute"}, {"id": "function_decoder_compute.loadFile", "type": "function", "label": "loadFile", "direction": "inbound", "parent": "function_decoder_compute", "line": 45, "endLine": 54, "signature": "(params) -> dict", "docstring": "Load Python file from disk.", "source": "def loadFile(params: dict) -> dict:\n    \"\"\"Load Python file from disk.\"\"\"\n    filePath = params.get(\"filePath\", \"\")\n    if not filePath:\n        return {\"sourceCode\": None, \"error\": \"No file path provided\"}\n    try:\n        with open(filePath, \"r\", encoding=\"utf-8\") as f:\n            return {\"sourceCode\": f.read(), \"error\": None}\n    except Exception as e:\n        return {\"sourceCode\": None, \"error\": str(e)}", "args": ["params"], "returns": "dict", "moduleColor": "#4ecdc4", "moduleName": "function_decoder_compute"}, {"id": "function_decoder_compute.parseAst", "type": "function", "label": "parseAst", "direction": "inbound", "parent": "function_decoder_compute", "line": 57, "endLine": 66, "signature": "(params) -> dict", "docstring": "Parse source code into AST.", "source": "def parseAst(params: dict) -> dict:\n    \"\"\"Parse source code into AST.\"\"\"\n    sourceCode = params.get(\"sourceCode\")\n    if not sourceCode:\n        return {\"ast\": None, \"error\": \"No source code\"}\n    try:\n        tree = ast.parse(sourceCode)\n        return {\"ast\": tree, \"error\": None}\n    except SyntaxError as e:\n        return {\"ast\": None, \"error\": f\"Syntax error: {e}\"}", "args": ["params"], "returns": "dict", "moduleColor": "#4ecdc4", "moduleName": "function_decoder_compute"}, {"id": "function_decoder_compute.extractExports", "type": "function", "label": "extractExports", "direction": "inbound", "parent": "function_decoder_compute", "line": 69, "endLine": 155, "signature": "(params) -> dict", "docstring": "Extract public functions and classes (inbound interface).", "source": "def extractExports(params: dict) -> dict:\n    \"\"\"Extract public functions and classes (inbound interface).\"\"\"\n    tree = params.get(\"ast\")\n    filePath = params.get(\"filePath\", \"\")\n    sourceCode = params.get(\"sourceCode\", \"\")\n    if not tree:\n        return {\"exports\": []}\n\n    moduleName = Path(filePath).stem if filePath else \"unknown\"\n    exports = []\n    sourceLines = sourceCode.split('\\n') if sourceCode else []\n\n    def get_source(node):\n        \"\"\"Extract source code for a node using line numbers.\"\"\"\n        if not sourceLines or not hasattr(node, 'lineno'):\n            return None\n        start = node.lineno - 1\n        end = getattr(node, 'end_lineno', start + 1)\n        if start < len(sourceLines) and end <= len(sourceLines):\n            return '\\n'.join(sourceLines[start:end])\n        return None\n\n    for node in ast.walk(tree):\n        if isinstance(node, ast.FunctionDef):\n            if not node.name.startswith(\"_\"):\n                exports.append({\n                    \"type\": \"function\",\n                    \"name\": node.name,\n                    \"module\": moduleName,\n                    \"line\": node.lineno,\n                    \"endLine\": getattr(node, 'end_lineno', node.lineno),\n                    \"args\": [a.arg for a in node.args.args],\n                    \"returns\": _get_annotation(node.returns),\n                    \"docstring\": ast.get_docstring(node),\n                    \"decorators\": [_get_decorator_name(d) for d in node.decorator_list],\n                    \"source\": get_source(node)\n                })\n        elif isinstance(node, ast.AsyncFunctionDef):\n            if not node.name.startswith(\"_\"):\n                exports.append({\n                    \"type\": \"async_function\",\n                    \"name\": node.name,\n                    \"module\": moduleName,\n                    \"line\": node.lineno,\n                    \"endLine\": getattr(node, 'end_lineno', node.lineno),\n                    \"args\": [a.arg for a in node.args.args],\n                    \"returns\": _get_annotation(node.returns),\n                    \"docstring\": ast.get_docstring(node),\n                    \"decorators\": [_get_decorator_name(d) for d in node.decorator_list],\n                    \"source\": get_source(node)\n                })\n        elif isinstance(node, ast.ClassDef):\n            if not node.name.startswith(\"_\"):\n                methods = []\n                for item in node.body:\n                    if isinstance(item, (ast.FunctionDef, ast.AsyncFunctionDef)):\n                        if not item.name.startswith(\"_\") or item.name in (\n                            \"__init__\", \"__call__\", \"__enter__\", \"__exit__\"\n                        ):\n                            methods.append(item.name)\n                exports.append({\n                    \"type\": \"class\",\n                    \"name\": node.name,\n                    \"module\": moduleName,\n                    \"line\": node.lineno,\n                    \"endLine\": getattr(node, 'end_lineno', node.lineno),\n                    \"bases\": [_get_name(b) for b in node.bases],\n                    \"methods\": methods,\n                    \"docstring\": ast.get_docstring(node),\n                    \"source\": get_source(node)\n                })\n\n    # Check for module-level __all__\n    for node in ast.iter_child_nodes(tree):\n        if isinstance(node, ast.Assign):\n            for target in node.targets:\n                if isinstance(target, ast.Name) and target.id == \"__all__\":\n                    if isinstance(node.value, (ast.List, ast.Tuple)):\n                        explicit = [\n                            elt.value for elt in node.value.elts\n                            if isinstance(elt, ast.Constant)\n                        ]\n                        # Filter exports to only __all__ members\n                        exports = [e for e in exports if e[\"name\"] in explicit]\n                        break\n\n    return {\"exports\": exports}", "args": ["params"], "returns": "dict", "moduleColor": "#4ecdc4", "moduleName": "function_decoder_compute"}, {"id": "function_decoder_compute.extractImports", "type": "function", "label": "extractImports", "direction": "inbound", "parent": "function_decoder_compute", "line": 158, "endLine": 194, "signature": "(params) -> dict", "docstring": "Extract import statements with aliases and classify them.", "source": "def extractImports(params: dict) -> dict:\n    \"\"\"Extract import statements with aliases and classify them.\"\"\"\n    tree = params.get(\"ast\")\n    if not tree:\n        return {\"imports\": []}\n\n    imports = []\n    for node in ast.walk(tree):\n        if isinstance(node, ast.Import):\n            for alias in node.names:\n                mod = alias.name.split(\".\")[0]\n                imports.append({\n                    \"type\": \"import\",\n                    \"module\": alias.name,\n                    \"alias\": alias.asname or alias.name,\n                    \"line\": node.lineno,\n                    \"category\": _classify_module(mod),\n                    \"names\": []\n                })\n        elif isinstance(node, ast.ImportFrom):\n            mod = node.module or \"\"\n            baseMod = mod.split(\".\")[0] if mod else \"\"\n            isRelative = node.level > 0\n            imports.append({\n                \"type\": \"from_import\",\n                \"module\": mod,\n                \"level\": node.level,\n                \"alias\": None,\n                \"line\": node.lineno,\n                \"category\": \"local\" if isRelative else _classify_module(baseMod),\n                \"names\": [\n                    {\"name\": a.name, \"alias\": a.asname or a.name}\n                    for a in node.names\n                ]\n            })\n\n    return {\"imports\": imports}", "args": ["params"], "returns": "dict", "moduleColor": "#4ecdc4", "moduleName": "function_decoder_compute"}, {"id": "function_decoder_compute.traceInternalCalls", "type": "function", "label": "traceInternalCalls", "direction": "inbound", "parent": "function_decoder_compute", "line": 197, "endLine": 236, "signature": "(params) -> dict", "docstring": "Trace function-to-function calls within the script.", "source": "def traceInternalCalls(params: dict) -> dict:\n    \"\"\"Trace function-to-function calls within the script.\"\"\"\n    tree = params.get(\"ast\")\n    exports = params.get(\"exports\", [])\n    if not tree:\n        return {\"internalCalls\": []}\n\n    exportNames = {e[\"name\"] for e in exports}\n    calls = []\n\n    class CallVisitor(ast.NodeVisitor):\n        def __init__(self):\n            self.currentFunc = None\n\n        def visit_FunctionDef(self, node):\n            prevFunc = self.currentFunc\n            self.currentFunc = node.name\n            self.generic_visit(node)\n            self.currentFunc = prevFunc\n\n        def visit_AsyncFunctionDef(self, node):\n            prevFunc = self.currentFunc\n            self.currentFunc = node.name\n            self.generic_visit(node)\n            self.currentFunc = prevFunc\n\n        def visit_Call(self, node):\n            if self.currentFunc:\n                callee = _get_call_name(node)\n                if callee and callee in exportNames:\n                    calls.append({\n                        \"from\": self.currentFunc,\n                        \"to\": callee,\n                        \"line\": node.lineno,\n                        \"type\": \"internal\"\n                    })\n            self.generic_visit(node)\n\n    CallVisitor().visit(tree)\n    return {\"internalCalls\": calls}", "args": ["params"], "returns": "dict", "moduleColor": "#4ecdc4", "moduleName": "function_decoder_compute"}, {"id": "function_decoder_compute.traceExternalCalls", "type": "function", "label": "traceExternalCalls", "direction": "inbound", "parent": "function_decoder_compute", "line": 239, "endLine": 323, "signature": "(params) -> dict", "docstring": "Trace calls to imported modules, separating external and local.", "source": "def traceExternalCalls(params: dict) -> dict:\n    \"\"\"Trace calls to imported modules, separating external and local.\"\"\"\n    tree = params.get(\"ast\")\n    imports = params.get(\"imports\", [])\n    if not tree:\n        return {\"externalCalls\": [], \"localCalls\": []}\n\n    # Build alias -> (module, category) mapping\n    aliasMap = {}\n    for imp in imports:\n        if imp[\"type\"] == \"import\":\n            aliasMap[imp[\"alias\"]] = (imp[\"module\"], imp[\"category\"])\n        elif imp[\"type\"] == \"from_import\":\n            for n in imp[\"names\"]:\n                aliasMap[n[\"alias\"]] = (\n                    f\"{imp['module']}.{n['name']}\" if imp[\"module\"] else n[\"name\"],\n                    imp[\"category\"]\n                )\n\n    externalCalls = []\n    localCalls = []\n\n    class ExternalCallVisitor(ast.NodeVisitor):\n        def __init__(self):\n            self.currentFunc = None\n\n        def visit_FunctionDef(self, node):\n            prevFunc = self.currentFunc\n            self.currentFunc = node.name\n            self.generic_visit(node)\n            self.currentFunc = prevFunc\n\n        def visit_AsyncFunctionDef(self, node):\n            prevFunc = self.currentFunc\n            self.currentFunc = node.name\n            self.generic_visit(node)\n            self.currentFunc = prevFunc\n\n        def visit_Call(self, node):\n            caller = self.currentFunc or \"<module>\"\n            # Handle attribute calls like requests.get()\n            if isinstance(node.func, ast.Attribute):\n                parts = []\n                n = node.func\n                while isinstance(n, ast.Attribute):\n                    parts.append(n.attr)\n                    n = n.value\n                if isinstance(n, ast.Name):\n                    parts.append(n.id)\n                parts.reverse()\n                root = parts[0] if parts else None\n                if root and root in aliasMap:\n                    mod, cat = aliasMap[root]\n                    fullCall = \".\".join(parts)\n                    entry = {\n                        \"from\": caller,\n                        \"to\": fullCall,\n                        \"module\": mod,\n                        \"line\": node.lineno\n                    }\n                    if cat == \"local\":\n                        localCalls.append(entry)\n                    else:\n                        entry[\"category\"] = cat\n                        externalCalls.append(entry)\n            # Handle direct calls like json_loads()\n            elif isinstance(node.func, ast.Name):\n                name = node.func.id\n                if name in aliasMap:\n                    mod, cat = aliasMap[name]\n                    entry = {\n                        \"from\": caller,\n                        \"to\": name,\n                        \"module\": mod,\n                        \"line\": node.lineno\n                    }\n                    if cat == \"local\":\n                        localCalls.append(entry)\n                    else:\n                        entry[\"category\"] = cat\n                        externalCalls.append(entry)\n            self.generic_visit(node)\n\n    ExternalCallVisitor().visit(tree)\n    return {\"externalCalls\": externalCalls, \"localCalls\": localCalls}", "args": ["params"], "returns": "dict", "moduleColor": "#4ecdc4", "moduleName": "function_decoder_compute"}, {"id": "function_decoder_compute.computeCoupling", "type": "function", "label": "computeCoupling", "direction": "inbound", "parent": "function_decoder_compute", "line": 326, "endLine": 370, "signature": "(params) -> dict", "docstring": "Compute coupling metrics: fan-in, fan-out, afferent/efferent.", "source": "def computeCoupling(params: dict) -> dict:\n    \"\"\"Compute coupling metrics: fan-in, fan-out, afferent/efferent.\"\"\"\n    exports = params.get(\"exports\", [])\n    imports = params.get(\"imports\", [])\n    internalCalls = params.get(\"internalCalls\", [])\n    externalCalls = params.get(\"externalCalls\", [])\n    localCalls = params.get(\"localCalls\", [])\n\n    # Fan-out: number of external dependencies\n    fanOut = len(set(imp[\"module\"] for imp in imports if imp[\"category\"] != \"local\"))\n\n    # Fan-in: number of exports (potential inbound callers)\n    fanIn = len(exports)\n\n    # Internal complexity: number of internal call edges\n    internalEdges = len(internalCalls)\n\n    # External call count by category\n    callsByCategory = defaultdict(int)\n    for call in externalCalls:\n        callsByCategory[call.get(\"category\", \"unknown\")] += 1\n\n    # Local coupling: connections to other local scripts\n    localDeps = set()\n    for call in localCalls:\n        localDeps.add(call[\"module\"].split(\".\")[0])\n    for imp in imports:\n        if imp[\"category\"] == \"local\":\n            localDeps.add(imp[\"module\"].split(\".\")[0] if imp[\"module\"] else \"\")\n\n    # Instability: I = Ce / (Ca + Ce) where Ce = fan-out, Ca = fan-in\n    instability = fanOut / (fanIn + fanOut) if (fanIn + fanOut) > 0 else 0\n\n    return {\n        \"coupling\": {\n            \"fanIn\": fanIn,\n            \"fanOut\": fanOut,\n            \"instability\": round(instability, 3),\n            \"internalEdges\": internalEdges,\n            \"externalCallCount\": len(externalCalls),\n            \"localCallCount\": len(localCalls),\n            \"callsByCategory\": dict(callsByCategory),\n            \"localDependencies\": list(localDeps)\n        }\n    }", "args": ["params"], "returns": "dict", "moduleColor": "#4ecdc4", "moduleName": "function_decoder_compute"}, {"id": "function_decoder_compute.generateModuleGraph", "type": "function", "label": "generateModuleGraph", "direction": "inbound", "parent": "function_decoder_compute", "line": 373, "endLine": 473, "signature": "(params) -> dict", "docstring": "Generate final linkable module graph JSON.", "source": "def generateModuleGraph(params: dict) -> dict:\n    \"\"\"Generate final linkable module graph JSON.\"\"\"\n    filePath = params.get(\"filePath\", \"\")\n    exports = params.get(\"exports\", [])\n    imports = params.get(\"imports\", [])\n    internalCalls = params.get(\"internalCalls\", [])\n    externalCalls = params.get(\"externalCalls\", [])\n    localCalls = params.get(\"localCalls\", [])\n    coupling = params.get(\"coupling\", {})\n\n    moduleName = Path(filePath).stem if filePath else \"unknown\"\n\n    # Build nodes\n    nodes = []\n\n    # Module node (central)\n    nodes.append({\n        \"id\": moduleName,\n        \"type\": \"module\",\n        \"label\": moduleName,\n        \"metrics\": coupling\n    })\n\n    # Export nodes (inbound interface)\n    for exp in exports:\n        nodes.append({\n            \"id\": f\"{moduleName}.{exp['name']}\",\n            \"type\": exp[\"type\"],\n            \"label\": exp[\"name\"],\n            \"direction\": \"inbound\",\n            \"parent\": moduleName,\n            \"line\": exp.get(\"line\"),\n            \"endLine\": exp.get(\"endLine\"),\n            \"signature\": _build_signature(exp),\n            \"docstring\": exp.get(\"docstring\"),\n            \"source\": exp.get(\"source\"),\n            \"args\": exp.get(\"args\"),\n            \"returns\": exp.get(\"returns\")\n        })\n\n    # Import nodes (outbound dependencies)\n    seenMods = set()\n    for imp in imports:\n        mod = imp[\"module\"] or f\"relative.level{imp.get('level', 1)}\"\n        if mod not in seenMods:\n            seenMods.add(mod)\n            nodes.append({\n                \"id\": mod,\n                \"type\": \"dependency\",\n                \"label\": mod.split(\".\")[-1],\n                \"direction\": \"outbound\",\n                \"category\": imp[\"category\"]\n            })\n\n    # Build edges\n    edges = []\n\n    # Internal call edges\n    for call in internalCalls:\n        edges.append({\n            \"from\": f\"{moduleName}.{call['from']}\",\n            \"to\": f\"{moduleName}.{call['to']}\",\n            \"type\": \"internal\",\n            \"line\": call.get(\"line\")\n        })\n\n    # External call edges\n    for call in externalCalls:\n        mod = call[\"module\"].split(\".\")[0]\n        edges.append({\n            \"from\": f\"{moduleName}.{call['from']}\" if call[\"from\"] != \"<module>\" else moduleName,\n            \"to\": mod,\n            \"type\": \"external\",\n            \"category\": call.get(\"category\"),\n            \"line\": call.get(\"line\")\n        })\n\n    # Local call edges (to other scripts)\n    for call in localCalls:\n        mod = call[\"module\"].split(\".\")[0]\n        edges.append({\n            \"from\": f\"{moduleName}.{call['from']}\" if call[\"from\"] != \"<module>\" else moduleName,\n            \"to\": mod,\n            \"type\": \"local\",\n            \"line\": call.get(\"line\")\n        })\n\n    return {\n        \"moduleGraph\": {\n            \"module\": moduleName,\n            \"filePath\": filePath,\n            \"inbound\": [e for e in exports],\n            \"outbound\": [\n                {\"module\": imp[\"module\"], \"category\": imp[\"category\"], \"names\": imp[\"names\"]}\n                for imp in imports\n            ],\n            \"nodes\": nodes,\n            \"edges\": edges,\n            \"coupling\": coupling\n        }\n    }", "args": ["params"], "returns": "dict", "moduleColor": "#4ecdc4", "moduleName": "function_decoder_compute"}, {"id": "function_decoder_compute.visualizeModuleGraph", "type": "function", "label": "visualizeModuleGraph", "direction": "inbound", "parent": "function_decoder_compute", "line": 545, "endLine": 609, "signature": "(params) -> dict", "docstring": "Generate stackable HTML visualization for module graph(s).\n\nArgs:\n    params: dict with 'moduleGraphs' (list of moduleGraph dicts or single),\n            'outputPath' (HTML file path), 'title' (optional)\n\nReturns:\n    dict with 'htmlPath', 'error'", "source": "def visualizeModuleGraph(params: dict) -> dict:\n    \"\"\"Generate stackable HTML visualization for module graph(s).\n    \n    Args:\n        params: dict with 'moduleGraphs' (list of moduleGraph dicts or single),\n                'outputPath' (HTML file path), 'title' (optional)\n    \n    Returns:\n        dict with 'htmlPath', 'error'\n    \"\"\"\n    import json as json_mod\n    \n    graphs = params.get(\"moduleGraphs\", [])\n    if not isinstance(graphs, list):\n        graphs = [graphs]\n    \n    outputPath = params.get(\"outputPath\", \"function_graph.html\")\n    title = params.get(\"title\", \"Function Module Graph\")\n    \n    if not graphs:\n        return {\"htmlPath\": None, \"error\": \"No module graphs provided\"}\n    \n    # Merge all graphs into combined nodes/edges\n    all_nodes = []\n    all_edges = []\n    module_colors = {}\n    color_palette = [\n        \"#00d4ff\", \"#ff6b6b\", \"#4ecdc4\", \"#f39c12\", \"#9b59b6\",\n        \"#1abc9c\", \"#e74c3c\", \"#3498db\", \"#2ecc71\", \"#e67e22\"\n    ]\n    \n    for idx, graph in enumerate(graphs):\n        if not graph:\n            continue\n        mod_name = graph.get(\"module\", f\"module_{idx}\")\n        module_colors[mod_name] = color_palette[idx % len(color_palette)]\n        \n        for node in graph.get(\"nodes\", []):\n            node_copy = dict(node)\n            node_copy[\"moduleColor\"] = module_colors[mod_name]\n            node_copy[\"moduleName\"] = mod_name\n            all_nodes.append(node_copy)\n        \n        for edge in graph.get(\"edges\", []):\n            all_edges.append(edge)\n    \n    # Deduplicate dependency nodes\n    seen_deps = set()\n    deduped_nodes = []\n    for node in all_nodes:\n        if node.get(\"type\") == \"dependency\":\n            if node[\"id\"] not in seen_deps:\n                seen_deps.add(node[\"id\"])\n                deduped_nodes.append(node)\n        else:\n            deduped_nodes.append(node)\n    \n    html = _build_function_html(title, deduped_nodes, all_edges, module_colors)\n    \n    try:\n        with open(outputPath, \"w\", encoding=\"utf-8\") as f:\n            f.write(html)\n        return {\"htmlPath\": outputPath, \"error\": None}\n    except Exception as e:\n        return {\"htmlPath\": None, \"error\": str(e)}", "args": ["params"], "returns": "dict", "moduleColor": "#4ecdc4", "moduleName": "function_decoder_compute"}, {"id": "function_decoder_compute.get_source", "type": "function", "label": "get_source", "direction": "inbound", "parent": "function_decoder_compute", "line": 81, "endLine": 89, "signature": "(node)", "docstring": "Extract source code for a node using line numbers.", "source": "    def get_source(node):\n        \"\"\"Extract source code for a node using line numbers.\"\"\"\n        if not sourceLines or not hasattr(node, 'lineno'):\n            return None\n        start = node.lineno - 1\n        end = getattr(node, 'end_lineno', start + 1)\n        if start < len(sourceLines) and end <= len(sourceLines):\n            return '\\n'.join(sourceLines[start:end])\n        return None", "args": ["node"], "returns": null, "moduleColor": "#4ecdc4", "moduleName": "function_decoder_compute"}, {"id": "function_decoder_compute.CallVisitor", "type": "class", "label": "CallVisitor", "direction": "inbound", "parent": "function_decoder_compute", "line": 207, "endLine": 233, "signature": null, "docstring": null, "source": "    class CallVisitor(ast.NodeVisitor):\n        def __init__(self):\n            self.currentFunc = None\n\n        def visit_FunctionDef(self, node):\n            prevFunc = self.currentFunc\n            self.currentFunc = node.name\n            self.generic_visit(node)\n            self.currentFunc = prevFunc\n\n        def visit_AsyncFunctionDef(self, node):\n            prevFunc = self.currentFunc\n            self.currentFunc = node.name\n            self.generic_visit(node)\n            self.currentFunc = prevFunc\n\n        def visit_Call(self, node):\n            if self.currentFunc:\n                callee = _get_call_name(node)\n                if callee and callee in exportNames:\n                    calls.append({\n                        \"from\": self.currentFunc,\n                        \"to\": callee,\n                        \"line\": node.lineno,\n                        \"type\": \"internal\"\n                    })\n            self.generic_visit(node)", "args": null, "returns": null, "moduleColor": "#4ecdc4", "moduleName": "function_decoder_compute"}, {"id": "function_decoder_compute.ExternalCallVisitor", "type": "class", "label": "ExternalCallVisitor", "direction": "inbound", "parent": "function_decoder_compute", "line": 261, "endLine": 320, "signature": null, "docstring": null, "source": "    class ExternalCallVisitor(ast.NodeVisitor):\n        def __init__(self):\n            self.currentFunc = None\n\n        def visit_FunctionDef(self, node):\n            prevFunc = self.currentFunc\n            self.currentFunc = node.name\n            self.generic_visit(node)\n            self.currentFunc = prevFunc\n\n        def visit_AsyncFunctionDef(self, node):\n            prevFunc = self.currentFunc\n            self.currentFunc = node.name\n            self.generic_visit(node)\n            self.currentFunc = prevFunc\n\n        def visit_Call(self, node):\n            caller = self.currentFunc or \"<module>\"\n            # Handle attribute calls like requests.get()\n            if isinstance(node.func, ast.Attribute):\n                parts = []\n                n = node.func\n                while isinstance(n, ast.Attribute):\n                    parts.append(n.attr)\n                    n = n.value\n                if isinstance(n, ast.Name):\n                    parts.append(n.id)\n                parts.reverse()\n                root = parts[0] if parts else None\n                if root and root in aliasMap:\n                    mod, cat = aliasMap[root]\n                    fullCall = \".\".join(parts)\n                    entry = {\n                        \"from\": caller,\n                        \"to\": fullCall,\n                        \"module\": mod,\n                        \"line\": node.lineno\n                    }\n                    if cat == \"local\":\n                        localCalls.append(entry)\n                    else:\n                        entry[\"category\"] = cat\n                        externalCalls.append(entry)\n            # Handle direct calls like json_loads()\n            elif isinstance(node.func, ast.Name):\n                name = node.func.id\n                if name in aliasMap:\n                    mod, cat = aliasMap[name]\n                    entry = {\n                        \"from\": caller,\n                        \"to\": name,\n                        \"module\": mod,\n                        \"line\": node.lineno\n                    }\n                    if cat == \"local\":\n                        localCalls.append(entry)\n                    else:\n                        entry[\"category\"] = cat\n                        externalCalls.append(entry)\n            self.generic_visit(node)", "args": null, "returns": null, "moduleColor": "#4ecdc4", "moduleName": "function_decoder_compute"}, {"id": "function_decoder_compute.visit_FunctionDef", "type": "function", "label": "visit_FunctionDef", "direction": "inbound", "parent": "function_decoder_compute", "line": 211, "endLine": 215, "signature": "(self, node)", "docstring": null, "source": "        def visit_FunctionDef(self, node):\n            prevFunc = self.currentFunc\n            self.currentFunc = node.name\n            self.generic_visit(node)\n            self.currentFunc = prevFunc", "args": ["self", "node"], "returns": null, "moduleColor": "#4ecdc4", "moduleName": "function_decoder_compute"}, {"id": "function_decoder_compute.visit_AsyncFunctionDef", "type": "function", "label": "visit_AsyncFunctionDef", "direction": "inbound", "parent": "function_decoder_compute", "line": 217, "endLine": 221, "signature": "(self, node)", "docstring": null, "source": "        def visit_AsyncFunctionDef(self, node):\n            prevFunc = self.currentFunc\n            self.currentFunc = node.name\n            self.generic_visit(node)\n            self.currentFunc = prevFunc", "args": ["self", "node"], "returns": null, "moduleColor": "#4ecdc4", "moduleName": "function_decoder_compute"}, {"id": "function_decoder_compute.visit_Call", "type": "function", "label": "visit_Call", "direction": "inbound", "parent": "function_decoder_compute", "line": 223, "endLine": 233, "signature": "(self, node)", "docstring": null, "source": "        def visit_Call(self, node):\n            if self.currentFunc:\n                callee = _get_call_name(node)\n                if callee and callee in exportNames:\n                    calls.append({\n                        \"from\": self.currentFunc,\n                        \"to\": callee,\n                        \"line\": node.lineno,\n                        \"type\": \"internal\"\n                    })\n            self.generic_visit(node)", "args": ["self", "node"], "returns": null, "moduleColor": "#4ecdc4", "moduleName": "function_decoder_compute"}, {"id": "function_decoder_compute.visit_FunctionDef", "type": "function", "label": "visit_FunctionDef", "direction": "inbound", "parent": "function_decoder_compute", "line": 265, "endLine": 269, "signature": "(self, node)", "docstring": null, "source": "        def visit_FunctionDef(self, node):\n            prevFunc = self.currentFunc\n            self.currentFunc = node.name\n            self.generic_visit(node)\n            self.currentFunc = prevFunc", "args": ["self", "node"], "returns": null, "moduleColor": "#4ecdc4", "moduleName": "function_decoder_compute"}, {"id": "function_decoder_compute.visit_AsyncFunctionDef", "type": "function", "label": "visit_AsyncFunctionDef", "direction": "inbound", "parent": "function_decoder_compute", "line": 271, "endLine": 275, "signature": "(self, node)", "docstring": null, "source": "        def visit_AsyncFunctionDef(self, node):\n            prevFunc = self.currentFunc\n            self.currentFunc = node.name\n            self.generic_visit(node)\n            self.currentFunc = prevFunc", "args": ["self", "node"], "returns": null, "moduleColor": "#4ecdc4", "moduleName": "function_decoder_compute"}, {"id": "function_decoder_compute.visit_Call", "type": "function", "label": "visit_Call", "direction": "inbound", "parent": "function_decoder_compute", "line": 277, "endLine": 320, "signature": "(self, node)", "docstring": null, "source": "        def visit_Call(self, node):\n            caller = self.currentFunc or \"<module>\"\n            # Handle attribute calls like requests.get()\n            if isinstance(node.func, ast.Attribute):\n                parts = []\n                n = node.func\n                while isinstance(n, ast.Attribute):\n                    parts.append(n.attr)\n                    n = n.value\n                if isinstance(n, ast.Name):\n                    parts.append(n.id)\n                parts.reverse()\n                root = parts[0] if parts else None\n                if root and root in aliasMap:\n                    mod, cat = aliasMap[root]\n                    fullCall = \".\".join(parts)\n                    entry = {\n                        \"from\": caller,\n                        \"to\": fullCall,\n                        \"module\": mod,\n                        \"line\": node.lineno\n                    }\n                    if cat == \"local\":\n                        localCalls.append(entry)\n                    else:\n                        entry[\"category\"] = cat\n                        externalCalls.append(entry)\n            # Handle direct calls like json_loads()\n            elif isinstance(node.func, ast.Name):\n                name = node.func.id\n                if name in aliasMap:\n                    mod, cat = aliasMap[name]\n                    entry = {\n                        \"from\": caller,\n                        \"to\": name,\n                        \"module\": mod,\n                        \"line\": node.lineno\n                    }\n                    if cat == \"local\":\n                        localCalls.append(entry)\n                    else:\n                        entry[\"category\"] = cat\n                        externalCalls.append(entry)\n            self.generic_visit(node)", "args": ["self", "node"], "returns": null, "moduleColor": "#4ecdc4", "moduleName": "function_decoder_compute"}, {"id": "ast", "type": "dependency", "label": "ast", "direction": "outbound", "category": "stdlib", "moduleColor": "#4ecdc4", "moduleName": "function_decoder_compute"}, {"id": "graph_visualizer_compute", "type": "module", "label": "graph_visualizer_compute", "metrics": {"fanIn": 1, "fanOut": 2, "instability": 0.667, "internalEdges": 0, "externalCallCount": 7, "localCallCount": 0, "callsByCategory": {"stdlib": 7}, "localDependencies": []}, "moduleColor": "#f39c12", "moduleName": "graph_visualizer_compute"}, {"id": "graph_visualizer_compute.process", "type": "function", "label": "process", "direction": "inbound", "parent": "graph_visualizer_compute", "line": 10, "endLine": 105, "signature": "(params) -> dict", "docstring": "Generate an interactive HTML visualization of an L++ blueprint.\n\nArgs:\n    params: dict with 'blueprint' (JSON string) and optional 'html_path'\n    \nReturns:\n    dict with 'has_html', 'html_path', and optional 'error'", "source": "def process(params: dict) -> dict:\n    \"\"\"\n    Generate an interactive HTML visualization of an L++ blueprint.\n    \n    Args:\n        params: dict with 'blueprint' (JSON string) and optional 'html_path'\n        \n    Returns:\n        dict with 'has_html', 'html_path', and optional 'error'\n    \"\"\"\n    blueprint_str = params.get(\"blueprint\", \"\")\n    html_path = params.get(\"html_path\", \"graph_visualizer.html\")\n    \n    try:\n        blueprint = json.loads(blueprint_str)\n    except Exception as e:\n        return {\"has_html\": False, \"error\": f\"Invalid JSON: {e}\"}\n    \n    # L++ schema: states is a dict {name: {description: ...}}\n    states_dict = blueprint.get(\"states\", {})\n    transitions = blueprint.get(\"transitions\", [])\n    gates_dict = blueprint.get(\"gates\", {})\n    entry_state = blueprint.get(\"entry_state\", \"\")\n    terminal_states = blueprint.get(\"terminal_states\", [])\n    skill_name = blueprint.get(\"name\", blueprint.get(\"id\", \"L++ Skill\"))\n    \n    # Collect valid node IDs\n    valid_node_ids = set(states_dict.keys())\n    \n    # Build adjacency for layer calculation\n    adjacency = defaultdict(set)\n    back_adjacency = defaultdict(set)\n    \n    links = []\n    for t in transitions:\n        if isinstance(t, dict):\n            from_state = t.get(\"from\", \"\")\n            to_state = t.get(\"to\", \"\")\n            event = t.get(\"on_event\", \"\")\n            gate_list = t.get(\"gates\", [])\n            gate_str = \", \".join(gate_list) if gate_list else \"\"\n            \n            # Skip invalid to_state\n            if to_state == \"*\" or to_state not in valid_node_ids:\n                continue\n            \n            # Expand wildcard from_state to all valid states\n            if from_state == \"*\":\n                source_states = [s for s in valid_node_ids if s != to_state]\n            elif from_state not in valid_node_ids:\n                continue\n            else:\n                source_states = [from_state]\n            \n            for src in source_states:\n                adjacency[src].add(to_state)\n                back_adjacency[to_state].add(src)\n                links.append({\n                    \"source\": src, \n                    \"target\": to_state, \n                    \"label\": event,\n                    \"gates\": gate_str\n                })\n    \n    # Calculate layers using BFS from entry state\n    layers = _calculate_layers(entry_state, adjacency, valid_node_ids, terminal_states)\n    \n    nodes = []\n    for state_id, state_info in states_dict.items():\n        desc = state_info.get(\"description\", \"\") if isinstance(state_info, dict) else str(state_info)\n        is_entry = state_id == entry_state\n        is_terminal = state_id in terminal_states\n        layer = layers.get(state_id, 5)  # Default middle layer\n        # Include full state definition for click-to-view\n        state_def = state_info if isinstance(state_info, dict) else {\"value\": state_info}\n        nodes.append({\n            \"id\": state_id,\n            \"label\": state_id,\n            \"description\": desc,\n            \"type\": \"state\",\n            \"isEntry\": is_entry,\n            \"isTerminal\": is_terminal,\n            \"layer\": layer,\n            \"definition\": state_def\n        })\n\n    # Build the HTML with gates for click-to-view\n    html_content = _build_html(skill_name, nodes, links, gates_dict)\n    \n    try:\n        with open(html_path, \"w\", encoding=\"utf-8\") as f:\n            f.write(html_content)\n    except Exception as e:\n        return {\"has_html\": False, \"error\": f\"Failed to write HTML: {e}\"}\n    \n    return {\"has_html\": True, \"html_path\": html_path}", "args": ["params"], "returns": "dict", "moduleColor": "#f39c12", "moduleName": "graph_visualizer_compute"}, {"id": "extractor_compute", "type": "module", "label": "extractor_compute", "metrics": {"fanIn": 23, "fanOut": 5, "instability": 0.179, "internalEdges": 31, "externalCallCount": 7, "localCallCount": 0, "callsByCategory": {"stdlib": 7}, "localDependencies": []}, "moduleColor": "#9b59b6", "moduleName": "extractor_compute"}, {"id": "extractor_compute.loadSource", "type": "function", "label": "loadSource", "direction": "inbound", "parent": "extractor_compute", "line": 37, "endLine": 48, "signature": "(params) -> dict", "docstring": "Load Python source file from disk.", "source": "def loadSource(params: dict) -> dict:\n    \"\"\"Load Python source file from disk.\"\"\"\n    filePath = params.get(\"filePath\")\n    if not filePath:\n        return {\"sourceCode\": None, \"error\": \"No file path provided\"}\n    try:\n        with open(filePath, \"r\", encoding=\"utf-8\") as f:\n            return {\"sourceCode\": f.read(), \"error\": None}\n    except FileNotFoundError:\n        return {\"sourceCode\": None, \"error\": f\"File not found: {filePath}\"}\n    except Exception as e:\n        return {\"sourceCode\": None, \"error\": str(e)}", "args": ["params"], "returns": "dict", "moduleColor": "#9b59b6", "moduleName": "extractor_compute"}, {"id": "extractor_compute.parseAst", "type": "function", "label": "parseAst", "direction": "inbound", "parent": "extractor_compute", "line": 51, "endLine": 61, "signature": "(params) -> dict", "docstring": "Parse Python source into AST.", "source": "def parseAst(params: dict) -> dict:\n    \"\"\"Parse Python source into AST.\"\"\"\n    source = params.get(\"sourceCode\")\n    if not source:\n        return {\"ast\": None, \"error\": \"No source code\"}\n    try:\n        tree = ast.parse(source)\n        astDict = _astToDict(tree)\n        return {\"ast\": astDict, \"error\": None}\n    except SyntaxError as e:\n        return {\"ast\": None, \"error\": f\"Syntax error: {e}\"}", "args": ["params"], "returns": "dict", "moduleColor": "#9b59b6", "moduleName": "extractor_compute"}, {"id": "extractor_compute.findStatePatterns", "type": "function", "label": "findStatePatterns", "direction": "inbound", "parent": "extractor_compute", "line": 81, "endLine": 270, "signature": "(params) -> dict", "docstring": "Detect state machine patterns in code.", "source": "def findStatePatterns(params: dict) -> dict:\n    \"\"\"Detect state machine patterns in code.\"\"\"\n    astDict = params.get(\"ast\", {})\n    mode = params.get(\"analysisMode\", \"heuristic\")\n\n    patterns = {\n        \"mode\": mode,\n        \"stateClasses\": [],\n        \"stateVariables\": [],\n        \"ifChains\": [],\n        \"matchStatements\": [],\n        \"eventHandlers\": [],\n        \"enumDefinitions\": [],\n        \"constantDefinitions\": [],\n        \"annotations\": []\n    }\n\n    def walk(node, parent=None, className=None):\n        if not isinstance(node, dict):\n            return\n\n        ntype = node.get(\"_type\")\n\n        # Pattern 1: Class with state attribute OR Enum\n        if ntype == \"ClassDef\":\n            clsName = node.get(\"name\", \"\")\n            bases = [_getName(b) for b in node.get(\"bases\", [])]\n\n            # Check if this is an Enum class (Pattern 6)\n            isEnum = any(\"Enum\" in b for b in bases)\n            if isEnum:\n                members = []\n                for item in node.get(\"body\", []):\n                    if isinstance(item, dict) and item.get(\"_type\") == \"Assign\":\n                        for t in item.get(\"targets\", []):\n                            members.append({\n                                \"name\": _getName(t),\n                                \"line\": item.get(\"lineno\")\n                            })\n                patterns[\"enumDefinitions\"].append({\n                    \"name\": clsName,\n                    \"members\": members,\n                    \"line\": node.get(\"lineno\")\n                })\n                # Don't process enum as state class\n                for item in node.get(\"body\", []):\n                    walk(item, node, clsName)\n                return\n\n            # Regular class - check for state attribute\n            hasStateAttr = False\n            stateAttrName = None\n            methods = []\n\n            for item in node.get(\"body\", []):\n                if isinstance(item, dict):\n                    # Check for state attribute assignments at class level\n                    if item.get(\"_type\") == \"Assign\":\n                        for target in item.get(\"targets\", []):\n                            tname = _getName(target).lower()\n                            if any(kw in tname for kw in STATE_KEYWORDS):\n                                hasStateAttr = True\n                                stateAttrName = _getName(target)\n                    # Collect methods and check __init__ for self.state\n                    if item.get(\"_type\") in (\"FunctionDef\", \"AsyncFunctionDef\"):\n                        methodName = item.get(\"name\")\n                        methods.append({\n                            \"name\": methodName,\n                            \"line\": item.get(\"lineno\"),\n                            \"isAsync\": item.get(\"_type\") == \"AsyncFunctionDef\"\n                        })\n                        # Check __init__ for self.state assignments\n                        if methodName == \"__init__\":\n                            for stmt in item.get(\"body\", []):\n                                if stmt.get(\"_type\") == \"Assign\":\n                                    for t in stmt.get(\"targets\", []):\n                                        if t.get(\"_type\") == \"Attribute\":\n                                            attr = t.get(\"attr\", \"\").lower()\n                                            if any(kw in attr for kw in\n                                                   STATE_KEYWORDS):\n                                                hasStateAttr = True\n                                                stateAttrName = f\"self.{t.get('attr')}\"\n\n            if hasStateAttr:\n                patterns[\"stateClasses\"].append({\n                    \"name\": clsName,\n                    \"stateAttr\": stateAttrName,\n                    \"methods\": methods,\n                    \"line\": node.get(\"lineno\")\n                })\n\n            for item in node.get(\"body\", []):\n                walk(item, node, clsName)\n            return\n\n        # Pattern 2: Module-level state variables\n        if ntype == \"Assign\" and parent and parent.get(\"_type\") == \"Module\":\n            for target in node.get(\"targets\", []):\n                tname = _getName(target).lower()\n                if any(kw in tname for kw in STATE_KEYWORDS):\n                    val = node.get(\"value\", {})\n                    patterns[\"stateVariables\"].append({\n                        \"name\": _getName(target),\n                        \"value\": _getValue(val),\n                        \"line\": node.get(\"lineno\")\n                    })\n\n        # Pattern 3: If-elif chains checking state\n        if ntype == \"If\":\n            chain = _extractIfChain(node)\n            if chain and len(chain) >= 2:\n                stateVar = _findStateVarInChain(chain)\n                if stateVar:\n                    patterns[\"ifChains\"].append({\n                        \"stateVar\": stateVar,\n                        \"branches\": chain,\n                        \"line\": node.get(\"lineno\"),\n                        \"className\": className\n                    })\n\n        # Pattern 4: Match/case statements\n        if ntype == \"Match\":\n            subject = _getName(node.get(\"subject\", {}))\n            if any(kw in subject.lower() for kw in STATE_KEYWORDS):\n                cases = []\n                for case in node.get(\"cases\", []):\n                    pattern = case.get(\"pattern\", {})\n                    cases.append({\n                        \"pattern\": _getPatternValue(pattern),\n                        \"line\": case.get(\"lineno\") if hasattr(case, \"lineno\") else \\\n                            node.get(\"lineno\")\n                    })\n                patterns[\"matchStatements\"].append({\n                    \"subject\": subject,\n                    \"cases\": cases,\n                    \"line\": node.get(\"lineno\"),\n                    \"className\": className\n                })\n\n        # Pattern 5: Event handlers\n        if ntype in (\"FunctionDef\", \"AsyncFunctionDef\"):\n            fname = node.get(\"name\", \"\")\n            if any(fname.startswith(p) for p in EVENT_PREFIXES):\n                eventName = fname\n                for p in EVENT_PREFIXES:\n                    if fname.startswith(p):\n                        eventName = fname[len(p):]\n                        break\n                patterns[\"eventHandlers\"].append({\n                    \"name\": fname,\n                    \"event\": eventName.upper(),\n                    \"line\": node.get(\"lineno\"),\n                    \"className\": className,\n                    \"args\": [a.get(\"arg\") for a in node.get(\"args\", {}).get(\n                        \"args\", [])]\n                })\n\n        # Pattern 6: Enum definitions - handled in Pattern 1 above\n\n        # Pattern 7: Constants (uppercase) that might be states\n        if ntype == \"Assign\" and parent and parent.get(\"_type\") == \"Module\":\n            for target in node.get(\"targets\", []):\n                tname = _getName(target)\n                if tname.isupper() and isinstance(node.get(\"value\"), dict):\n                    val = node.get(\"value\")\n                    if val.get(\"_type\") == \"Constant\" and isinstance(\n                            val.get(\"value\"), str):\n                        patterns[\"constantDefinitions\"].append({\n                            \"name\": tname,\n                            \"value\": val.get(\"value\"),\n                            \"line\": node.get(\"lineno\")\n                        })\n\n        # Walk children\n        for key, value in node.items():\n            if isinstance(value, dict):\n                walk(value, node, className)\n            elif isinstance(value, list):\n                for item in value:\n                    if isinstance(item, dict):\n                        walk(item, node, className)\n\n    walk(astDict)\n\n    # In annotated mode, also scan for comment markers\n    if mode in (\"annotated\", \"hybrid\"):\n        patterns[\"annotations\"] = _findAnnotations(\n            params.get(\"sourceCode\", \"\"))\n\n    return {\"patterns\": patterns}", "args": ["params"], "returns": "dict", "moduleColor": "#9b59b6", "moduleName": "extractor_compute"}, {"id": "extractor_compute.extractStates", "type": "function", "label": "extractStates", "direction": "inbound", "parent": "extractor_compute", "line": 344, "endLine": 454, "signature": "(params) -> dict", "docstring": "Extract state definitions from code.", "source": "def extractStates(params: dict) -> dict:\n    \"\"\"Extract state definitions from code.\"\"\"\n    astDict = params.get(\"ast\", {})\n    patterns = params.get(\"patterns\", {})\n\n    states = []\n    uncertainties = []\n    seenStates: Set[str] = set()\n\n    def addState(stateId: str, name: str, desc: str, source: str, line: int,\n                 confidence: float = 1.0):\n        if stateId in seenStates:\n            return\n        seenStates.add(stateId)\n\n        state = {\n            \"id\": stateId,\n            \"name\": name,\n            \"description\": desc,\n            \"source\": source,\n            \"line\": line,\n            \"confidence\": confidence\n        }\n        states.append(state)\n\n        if confidence < 0.8:\n            uncertainties.append({\n                \"type\": \"state\",\n                \"element\": state,\n                \"reason\": f\"Low confidence ({confidence:.0%}) - needs review\"\n            })\n\n    # Extract from enum definitions (highest confidence)\n    for enum in patterns.get(\"enumDefinitions\", []):\n        enumName = enum.get(\"name\", \"\")\n        if any(kw in enumName.lower() for kw in STATE_KEYWORDS):\n            for member in enum.get(\"members\", []):\n                mname = member.get(\"name\", \"\")\n                stateId = mname.lower()\n                stateName = _toTitleCase(mname)\n                addState(stateId, stateName, f\"From enum {enumName}.{mname}\",\n                         f\"enum:{enumName}\", member.get(\"line\"), 1.0)\n\n    # Extract from state class assignments\n    for cls in patterns.get(\"stateClasses\", []):\n        clsName = cls.get(\"name\", \"\")\n        stateAttr = cls.get(\"stateAttr\", \"\")\n\n        # Find initial state value\n        for body in _getClassBody(astDict, clsName):\n            if body.get(\"_type\") == \"Assign\":\n                for target in body.get(\"targets\", []):\n                    if _getName(target) == stateAttr:\n                        val = _getValue(body.get(\"value\", {}))\n                        if val:\n                            stateId = str(val).lower().replace(\"'\", \"\").replace(\n                                '\"', '')\n                            addState(stateId, _toTitleCase(stateId),\n                                     f\"Initial state of {clsName}\",\n                                     f\"class:{clsName}\", body.get(\"lineno\"), 0.95)\n\n    # Extract from if-chain comparisons\n    for chain in patterns.get(\"ifChains\", []):\n        for branch in chain.get(\"branches\", []):\n            test = branch.get(\"testNode\")\n            if test and test.get(\"_type\") == \"Compare\":\n                comparators = test.get(\"comparators\", [])\n                for comp in comparators:\n                    val = _getValue(comp)\n                    if val and isinstance(val, str):\n                        stateId = val.lower()\n                        addState(stateId, _toTitleCase(val),\n                                 f\"From condition check\",\n                                 \"if-chain\", branch.get(\"line\"), 0.85)\n\n    # Extract from match/case\n    for match in patterns.get(\"matchStatements\", []):\n        for case in match.get(\"cases\", []):\n            patternVal = case.get(\"pattern\")\n            if patternVal and isinstance(patternVal, str):\n                stateId = patternVal.lower()\n                addState(stateId, _toTitleCase(patternVal),\n                         \"From match/case pattern\",\n                         \"match\", case.get(\"line\"), 0.9)\n\n    # Extract from constant definitions\n    for const in patterns.get(\"constantDefinitions\", []):\n        constName = const.get(\"name\", \"\")\n        constVal = const.get(\"value\", \"\")\n\n        # Check if constant name or value matches state keywords\n        for category, keywords in STATE_VALUE_KEYWORDS.items():\n            if any(kw in constName.lower() or kw in constVal.lower()\n                   for kw in keywords):\n                stateId = constVal.lower() if constVal else constName.lower()\n                addState(stateId, _toTitleCase(stateId),\n                         f\"From constant {constName}\",\n                         f\"const:{constName}\", const.get(\"line\"), 0.7)\n                break\n\n    # Extract from annotations (if present)\n    for ann in patterns.get(\"annotations\", []):\n        if ann.get(\"type\") == \"state\":\n            val = ann.get(\"value\", \"\")\n            if val:\n                stateId = val.lower().replace(\" \", \"_\")\n                addState(stateId, _toTitleCase(val),\n                         \"From annotation\",\n                         \"annotation\", ann.get(\"line\"), 1.0)\n\n    return {\"states\": states, \"uncertainties\": uncertainties}", "args": ["params"], "returns": "dict", "moduleColor": "#9b59b6", "moduleName": "extractor_compute"}, {"id": "extractor_compute.extractTransitions", "type": "function", "label": "extractTransitions", "direction": "inbound", "parent": "extractor_compute", "line": 457, "endLine": 559, "signature": "(params) -> dict", "docstring": "Extract state transitions from methods.", "source": "def extractTransitions(params: dict) -> dict:\n    \"\"\"Extract state transitions from methods.\"\"\"\n    astDict = params.get(\"ast\", {})\n    patterns = params.get(\"patterns\", {})\n    existingStates = params.get(\"extractedStates\", [])\n\n    transitions = []\n    uncertainties = params.get(\"uncertainties\", [])\n    stateIds = {s[\"id\"] for s in existingStates}\n    tId = 0\n\n    def addTransition(fromState: str, toState: str, event: str, source: str,\n                      line: int, confidence: float = 1.0):\n        nonlocal tId\n        trans = {\n            \"id\": f\"t_{tId}\",\n            \"from\": fromState,\n            \"to\": toState,\n            \"on_event\": event,\n            \"source\": source,\n            \"line\": line,\n            \"confidence\": confidence,\n            \"gates\": [],\n            \"actions\": []\n        }\n        transitions.append(trans)\n        tId += 1\n\n        if confidence < 0.8:\n            uncertainties.append({\n                \"type\": \"transition\",\n                \"element\": trans,\n                \"reason\": f\"Low confidence ({confidence:.0%}) - needs review\"\n            })\n\n    # Extract from state class methods\n    for cls in patterns.get(\"stateClasses\", []):\n        clsName = cls.get(\"name\", \"\")\n        stateAttr = cls.get(\"stateAttr\", \"\")\n\n        for method in cls.get(\"methods\", []):\n            methodName = method.get(\"name\", \"\")\n            if methodName.startswith(\"_\"):\n                continue\n\n            # Find state changes in method body\n            methodBody = _getMethodBody(astDict, clsName, methodName)\n            stateChanges = _findStateChanges(methodBody, stateAttr)\n\n            for change in stateChanges:\n                fromState = change.get(\"from\", \"*\")\n                toState = change.get(\"to\")\n\n                if toState:\n                    event = methodName.upper()\n                    addTransition(fromState, toState, event,\n                                  f\"method:{clsName}.{methodName}\",\n                                  change.get(\"line\", method.get(\"line\")), 0.9)\n\n    # Extract from if-chains\n    for chain in patterns.get(\"ifChains\", []):\n        stateVar = chain.get(\"stateVar\", \"\")\n        clsName = chain.get(\"className\")\n\n        for branch in chain.get(\"branches\", []):\n            fromState = _extractStateFromCondition(branch.get(\"testNode\"))\n            toState = _findStateAssignment(branch.get(\"body\", []), stateVar)\n\n            if fromState and toState:\n                event = \"AUTO\" if not clsName else \"PROCESS\"\n                addTransition(fromState, toState, event,\n                              \"if-chain\", branch.get(\"line\"), 0.85)\n\n    # Extract from event handlers\n    for handler in patterns.get(\"eventHandlers\", []):\n        eventName = handler.get(\"event\", \"\")\n        clsName = handler.get(\"className\")\n\n        # Find state changes in handler body\n        handlerBody = _getMethodBody(astDict, clsName,\n                                     handler.get(\"name\")) if clsName else []\n\n        stateChanges = _findStateChangesGeneric(handlerBody)\n\n        for change in stateChanges:\n            addTransition(change.get(\"from\", \"*\"), change.get(\"to\"),\n                          eventName, f\"handler:{handler.get('name')}\",\n                          handler.get(\"line\"), 0.8)\n\n    # Extract from annotations\n    for ann in patterns.get(\"annotations\", []):\n        if ann.get(\"type\") == \"transition\":\n            val = ann.get(\"value\", \"\")\n            # Parse \"from -> to ON event\" format\n            match = re.match(r\"(\\w+)\\s*->\\s*(\\w+)(?:\\s+ON\\s+(\\w+))?\", val)\n            if match:\n                fromState = match.group(1).lower()\n                toState = match.group(2).lower()\n                event = match.group(3).upper() if match.group(3) else \"AUTO\"\n                addTransition(fromState, toState, event,\n                              \"annotation\", ann.get(\"line\"), 1.0)\n\n    return {\"transitions\": transitions, \"uncertainties\": uncertainties}", "args": ["params"], "returns": "dict", "moduleColor": "#9b59b6", "moduleName": "extractor_compute"}, {"id": "extractor_compute.extractGates", "type": "function", "label": "extractGates", "direction": "inbound", "parent": "extractor_compute", "line": 672, "endLine": 729, "signature": "(params) -> dict", "docstring": "Extract gate conditions from if statements.", "source": "def extractGates(params: dict) -> dict:\n    \"\"\"Extract gate conditions from if statements.\"\"\"\n    astDict = params.get(\"ast\", {})\n    patterns = params.get(\"patterns\", {})\n    transitions = params.get(\"extractedTransitions\", [])\n\n    gates = []\n    uncertainties = params.get(\"uncertainties\", [])\n    gId = 0\n\n    # Extract from if-chains\n    for chain in patterns.get(\"ifChains\", []):\n        for branch in chain.get(\"branches\", []):\n            condition = branch.get(\"condition\", \"\")\n            if condition and condition != \"else\":\n                gate = {\n                    \"id\": f\"g_{gId}\",\n                    \"type\": \"expression\",\n                    \"expression\": condition,\n                    \"source\": \"if-chain\",\n                    \"line\": branch.get(\"line\"),\n                    \"confidence\": 0.85\n                }\n                gates.append(gate)\n                gId += 1\n\n    # Extract from match cases\n    for match in patterns.get(\"matchStatements\", []):\n        subject = match.get(\"subject\", \"\")\n        for case in match.get(\"cases\", []):\n            patternVal = case.get(\"pattern\")\n            if patternVal:\n                gate = {\n                    \"id\": f\"g_{gId}\",\n                    \"type\": \"expression\",\n                    \"expression\": f\"{subject} == '{patternVal}'\",\n                    \"source\": \"match\",\n                    \"line\": case.get(\"line\"),\n                    \"confidence\": 0.9\n                }\n                gates.append(gate)\n                gId += 1\n\n    # Extract from annotations\n    for ann in patterns.get(\"annotations\", []):\n        if ann.get(\"type\") == \"gate\":\n            gate = {\n                \"id\": f\"g_{gId}\",\n                \"type\": \"expression\",\n                \"expression\": ann.get(\"value\", \"\"),\n                \"source\": \"annotation\",\n                \"line\": ann.get(\"line\"),\n                \"confidence\": 1.0\n            }\n            gates.append(gate)\n            gId += 1\n\n    return {\"gates\": gates, \"uncertainties\": uncertainties}", "args": ["params"], "returns": "dict", "moduleColor": "#9b59b6", "moduleName": "extractor_compute"}, {"id": "extractor_compute.extractActions", "type": "function", "label": "extractActions", "direction": "inbound", "parent": "extractor_compute", "line": 732, "endLine": 823, "signature": "(params) -> dict", "docstring": "Extract actions from side effects.", "source": "def extractActions(params: dict) -> dict:\n    \"\"\"Extract actions from side effects.\"\"\"\n    astDict = params.get(\"ast\", {})\n    patterns = params.get(\"patterns\", {})\n    transitions = params.get(\"extractedTransitions\", [])\n\n    actions = []\n    uncertainties = params.get(\"uncertainties\", [])\n    aId = 0\n    seenActions: Set[str] = set()\n\n    def addAction(name: str, actionType: str, target: str, value: str,\n                  source: str, line: int, confidence: float = 1.0):\n        nonlocal aId\n        if name in seenActions:\n            return\n        seenActions.add(name)\n\n        action = {\n            \"id\": f\"a_{aId}\",\n            \"name\": name,\n            \"type\": actionType,\n            \"target\": target,\n            \"value\": value,\n            \"source\": source,\n            \"line\": line,\n            \"confidence\": confidence\n        }\n        actions.append(action)\n        aId += 1\n\n        if confidence < 0.8:\n            uncertainties.append({\n                \"type\": \"action\",\n                \"element\": action,\n                \"reason\": f\"Low confidence ({confidence:.0%}) - needs review\"\n            })\n\n    # Extract from state class methods\n    for cls in patterns.get(\"stateClasses\", []):\n        clsName = cls.get(\"name\", \"\")\n        stateAttr = cls.get(\"stateAttr\", \"\")\n\n        for method in cls.get(\"methods\", []):\n            methodName = method.get(\"name\", \"\")\n            if methodName.startswith(\"_\"):\n                continue\n\n            methodBody = _getMethodBody(astDict, clsName, methodName)\n            sideEffects = _findSideEffects(methodBody, stateAttr)\n\n            for effect in sideEffects:\n                actionName = f\"{methodName}_{effect['type']}\"\n                addAction(actionName, effect[\"type\"], effect.get(\"target\", \"\"),\n                          effect.get(\"value\", \"\"),\n                          f\"method:{clsName}.{methodName}\",\n                          effect.get(\"line\", method.get(\"line\")), 0.85)\n\n    # Extract from event handlers\n    for handler in patterns.get(\"eventHandlers\", []):\n        clsName = handler.get(\"className\")\n        handlerName = handler.get(\"name\", \"\")\n\n        handlerBody = _getMethodBody(astDict, clsName, handlerName) if \\\n            clsName else []\n        sideEffects = _findSideEffects(handlerBody)\n\n        for effect in sideEffects:\n            actionName = f\"{handlerName}_{effect['type']}\"\n            addAction(actionName, effect[\"type\"], effect.get(\"target\", \"\"),\n                      effect.get(\"value\", \"\"),\n                      f\"handler:{handlerName}\",\n                      effect.get(\"line\", handler.get(\"line\")), 0.8)\n\n    # Extract from annotations\n    for ann in patterns.get(\"annotations\", []):\n        if ann.get(\"type\") == \"action\":\n            val = ann.get(\"value\", \"\")\n            # Parse \"SET target = value\" or \"COMPUTE unit\" format\n            if val.startswith(\"SET \"):\n                match = re.match(r\"SET\\s+(\\w+)\\s*=\\s*(.+)\", val)\n                if match:\n                    addAction(f\"set_{match.group(1)}\", \"set\",\n                              match.group(1), match.group(2),\n                              \"annotation\", ann.get(\"line\"), 1.0)\n            elif val.startswith(\"COMPUTE \"):\n                unit = val[8:].strip()\n                addAction(f\"compute_{unit}\", \"compute\",\n                          \"\", unit,\n                          \"annotation\", ann.get(\"line\"), 1.0)\n\n    return {\"actions\": actions, \"uncertainties\": uncertainties}", "args": ["params"], "returns": "dict", "moduleColor": "#9b59b6", "moduleName": "extractor_compute"}, {"id": "extractor_compute.analyzeEventHandlers", "type": "function", "label": "analyzeEventHandlers", "direction": "inbound", "parent": "extractor_compute", "line": 875, "endLine": 923, "signature": "(params) -> dict", "docstring": "Analyze event handler patterns.", "source": "def analyzeEventHandlers(params: dict) -> dict:\n    \"\"\"Analyze event handler patterns.\"\"\"\n    astDict = params.get(\"ast\", {})\n    patterns = params.get(\"patterns\", {})\n    states = params.get(\"extractedStates\", [])\n\n    events = []\n    uncertainties = params.get(\"uncertainties\", [])\n    stateIds = {s[\"id\"] for s in states}\n\n    for handler in patterns.get(\"eventHandlers\", []):\n        eventName = handler.get(\"event\", \"\")\n        clsName = handler.get(\"className\")\n\n        event = {\n            \"name\": eventName,\n            \"handler\": handler.get(\"name\"),\n            \"args\": handler.get(\"args\", []),\n            \"source\": f\"handler:{handler.get('name')}\",\n            \"line\": handler.get(\"line\"),\n            \"triggersTransitions\": []\n        }\n\n        # Find which transitions this event triggers\n        handlerBody = _getMethodBody(astDict, clsName, handler.get(\"name\")) \\\n            if clsName else []\n        stateChanges = _findStateChangesGeneric(handlerBody)\n\n        for change in stateChanges:\n            event[\"triggersTransitions\"].append({\n                \"from\": change.get(\"from\"),\n                \"to\": change.get(\"to\")\n            })\n\n        events.append(event)\n\n    # Also extract from annotations\n    for ann in patterns.get(\"annotations\", []):\n        if ann.get(\"type\") == \"event\":\n            events.append({\n                \"name\": ann.get(\"value\", \"\").upper(),\n                \"handler\": None,\n                \"args\": [],\n                \"source\": \"annotation\",\n                \"line\": ann.get(\"line\"),\n                \"triggersTransitions\": []\n            })\n\n    return {\"events\": events, \"uncertainties\": uncertainties}", "args": ["params"], "returns": "dict", "moduleColor": "#9b59b6", "moduleName": "extractor_compute"}, {"id": "extractor_compute.inferEntryState", "type": "function", "label": "inferEntryState", "direction": "inbound", "parent": "extractor_compute", "line": 926, "endLine": 974, "signature": "(params) -> dict", "docstring": "Infer entry and terminal states.", "source": "def inferEntryState(params: dict) -> dict:\n    \"\"\"Infer entry and terminal states.\"\"\"\n    astDict = params.get(\"ast\", {})\n    patterns = params.get(\"patterns\", {})\n    states = params.get(\"extractedStates\", [])\n    transitions = params.get(\"extractedTransitions\", [])\n\n    stateIds = [s[\"id\"] for s in states]\n    entryState = None\n    terminalStates = []\n\n    # Rule 1: State with \"init\", \"start\", \"idle\" in name\n    for state in states:\n        sid = state[\"id\"].lower()\n        if any(kw in sid for kw in STATE_VALUE_KEYWORDS[\"initial\"]):\n            entryState = state[\"id\"]\n            break\n\n    # Rule 2: First state defined\n    if not entryState and states:\n        entryState = states[0][\"id\"]\n\n    # Rule 3: State never reached by any transition\n    if not entryState and stateIds:\n        targetStates = {t[\"to\"] for t in transitions}\n        unreachable = [s for s in stateIds if s not in targetStates]\n        if unreachable:\n            entryState = unreachable[0]\n\n    # Terminal states: states with no outgoing transitions\n    sourceStates = {t[\"from\"] for t in transitions if t[\"from\"] != \"*\"}\n    for state in states:\n        sid = state[\"id\"]\n        # Has no outgoing transitions\n        if sid not in sourceStates:\n            terminalStates.append(sid)\n        # Or has terminal keywords\n        elif any(kw in sid.lower() for kw in STATE_VALUE_KEYWORDS[\"terminal\"]):\n            if sid not in terminalStates:\n                terminalStates.append(sid)\n        elif any(kw in sid.lower() for kw in STATE_VALUE_KEYWORDS[\"error\"]):\n            if sid not in terminalStates:\n                terminalStates.append(sid)\n\n    # Ensure entry state is set\n    if not entryState:\n        entryState = \"idle\"\n\n    return {\"entryState\": entryState, \"terminalStates\": terminalStates}", "args": ["params"], "returns": "dict", "moduleColor": "#9b59b6", "moduleName": "extractor_compute"}, {"id": "extractor_compute.generateBlueprint", "type": "function", "label": "generateBlueprint", "direction": "inbound", "parent": "extractor_compute", "line": 977, "endLine": 1070, "signature": "(params) -> dict", "docstring": "Generate L++ blueprint from extracted elements.", "source": "def generateBlueprint(params: dict) -> dict:\n    \"\"\"Generate L++ blueprint from extracted elements.\"\"\"\n    filePath = params.get(\"filePath\", \"extracted\")\n    states = params.get(\"extractedStates\", [])\n    transitions = params.get(\"extractedTransitions\", [])\n    gates = params.get(\"extractedGates\", [])\n    actions = params.get(\"extractedActions\", [])\n    events = params.get(\"extractedEvents\", [])\n    entryState = params.get(\"entryState\", \"idle\")\n    terminalStates = params.get(\"terminalStates\", [])\n\n    baseName = os.path.basename(filePath).replace(\".py\", \"\") if filePath else \\\n        \"extracted\"\n\n    # Build states dict\n    statesDict = {}\n    for s in states:\n        statesDict[s[\"id\"]] = {\n            \"description\": s.get(\"description\", f\"Extracted from {s['source']}\")\n        }\n\n    # Ensure entry state exists\n    if entryState not in statesDict:\n        statesDict[entryState] = {\"description\": \"Entry state (inferred)\"}\n\n    # Build gates dict\n    gatesDict = {}\n    for g in gates:\n        gatesDict[g[\"id\"]] = {\n            \"type\": g.get(\"type\", \"expression\"),\n            \"expression\": g.get(\"expression\", \"true\")\n        }\n\n    # Build actions dict\n    actionsDict = {}\n    for a in actions:\n        if a[\"type\"] == \"set\":\n            actionsDict[a[\"id\"]] = {\n                \"type\": \"set\",\n                \"target\": a.get(\"target\", \"\"),\n                \"value_from\": a.get(\"value\", \"\")\n            }\n        elif a[\"type\"] == \"compute\":\n            actionsDict[a[\"id\"]] = {\n                \"type\": \"compute\",\n                \"compute_unit\": f\"impl:{a.get('target', a['name'])}\",\n                \"input_map\": {},\n                \"output_map\": {}\n            }\n\n    # Build transitions array\n    transArr = []\n    for t in transitions:\n        trans = {\n            \"id\": t[\"id\"],\n            \"from\": t[\"from\"],\n            \"to\": t[\"to\"],\n            \"on_event\": t[\"on_event\"]\n        }\n        if t.get(\"gates\"):\n            trans[\"gates\"] = t[\"gates\"]\n        if t.get(\"actions\"):\n            trans[\"actions\"] = t[\"actions\"]\n        transArr.append(trans)\n\n    # Build context schema from states and actions\n    contextProps = {}\n    for s in states:\n        contextProps[\"currentState\"] = {\"type\": \"string\"}\n    for a in actions:\n        if a[\"type\"] == \"set\":\n            contextProps[a.get(\"target\", \"data\")] = {\"type\": \"object\"}\n    contextProps[\"error\"] = {\"type\": \"string\"}\n\n    blueprint = {\n        \"$schema\": \"lpp/v0.1.2\",\n        \"id\": f\"extracted_{baseName}\",\n        \"name\": f\"Extracted: {_toTitleCase(baseName)}\",\n        \"version\": \"1.0.0\",\n        \"description\": f\"State machine extracted from {filePath}\",\n        \"context_schema\": {\"properties\": contextProps},\n        \"states\": statesDict,\n        \"transitions\": transArr,\n        \"gates\": gatesDict,\n        \"actions\": actionsDict,\n        \"entry_state\": entryState,\n        \"terminal_states\": terminalStates,\n        \"display\": {\"rules\": []}\n    }\n\n    return {\n        \"blueprint\": blueprint,\n        \"blueprintJson\": json.dumps(blueprint, indent=2)\n    }", "args": ["params"], "returns": "dict", "moduleColor": "#9b59b6", "moduleName": "extractor_compute"}, {"id": "extractor_compute.generateMapping", "type": "function", "label": "generateMapping", "direction": "inbound", "parent": "extractor_compute", "line": 1073, "endLine": 1154, "signature": "(params) -> dict", "docstring": "Generate source-to-blueprint mapping.", "source": "def generateMapping(params: dict) -> dict:\n    \"\"\"Generate source-to-blueprint mapping.\"\"\"\n    filePath = params.get(\"filePath\", \"\")\n    states = params.get(\"extractedStates\", [])\n    transitions = params.get(\"extractedTransitions\", [])\n    gates = params.get(\"extractedGates\", [])\n    actions = params.get(\"extractedActions\", [])\n    blueprint = params.get(\"blueprint\", {})\n\n    mapping = {\n        \"source\": filePath,\n        \"blueprint_id\": blueprint.get(\"id\", \"\"),\n        \"elements\": []\n    }\n\n    # Map states\n    for s in states:\n        mapping[\"elements\"].append({\n            \"type\": \"state\",\n            \"source_location\": f\"{filePath}:{s.get('line', '?')}\",\n            \"blueprint_element\": f\"states.{s['id']}\",\n            \"confidence\": s.get(\"confidence\", 1.0),\n            \"source_type\": s.get(\"source\", \"unknown\")\n        })\n\n    # Map transitions\n    for t in transitions:\n        mapping[\"elements\"].append({\n            \"type\": \"transition\",\n            \"source_location\": f\"{filePath}:{t.get('line', '?')}\",\n            \"blueprint_element\": f\"transitions.{t['id']}\",\n            \"confidence\": t.get(\"confidence\", 1.0),\n            \"source_type\": t.get(\"source\", \"unknown\")\n        })\n\n    # Map gates\n    for g in gates:\n        mapping[\"elements\"].append({\n            \"type\": \"gate\",\n            \"source_location\": f\"{filePath}:{g.get('line', '?')}\",\n            \"blueprint_element\": f\"gates.{g['id']}\",\n            \"confidence\": g.get(\"confidence\", 1.0),\n            \"source_type\": g.get(\"source\", \"unknown\")\n        })\n\n    # Map actions\n    for a in actions:\n        mapping[\"elements\"].append({\n            \"type\": \"action\",\n            \"source_location\": f\"{filePath}:{a.get('line', '?')}\",\n            \"blueprint_element\": f\"actions.{a['id']}\",\n            \"confidence\": a.get(\"confidence\", 1.0),\n            \"source_type\": a.get(\"source\", \"unknown\")\n        })\n\n    # Generate report\n    report = {\n        \"source_file\": filePath,\n        \"blueprint_id\": blueprint.get(\"id\", \"\"),\n        \"extraction_summary\": {\n            \"states_extracted\": len(states),\n            \"transitions_extracted\": len(transitions),\n            \"gates_extracted\": len(gates),\n            \"actions_extracted\": len(actions)\n        },\n        \"confidence_summary\": {\n            \"high_confidence\": len([e for e in mapping[\"elements\"]\n                                    if e.get(\"confidence\", 0) >= 0.9]),\n            \"medium_confidence\": len([e for e in mapping[\"elements\"]\n                                      if 0.7 <= e.get(\"confidence\", 0) < 0.9]),\n            \"low_confidence\": len([e for e in mapping[\"elements\"]\n                                   if e.get(\"confidence\", 0) < 0.7])\n        },\n        \"source_coverage\": {\n            \"classes_analyzed\": 0,\n            \"functions_analyzed\": 0,\n            \"lines_mapped\": len(set(e.get(\"source_location\", \"\").split(\":\")[-1]\n                                    for e in mapping[\"elements\"]))\n        }\n    }\n\n    return {\"sourceMapping\": mapping, \"report\": report}", "args": ["params"], "returns": "dict", "moduleColor": "#9b59b6", "moduleName": "extractor_compute"}, {"id": "extractor_compute.exportBlueprint", "type": "function", "label": "exportBlueprint", "direction": "inbound", "parent": "extractor_compute", "line": 1157, "endLine": 1170, "signature": "(params) -> dict", "docstring": "Export blueprint to file.", "source": "def exportBlueprint(params: dict) -> dict:\n    \"\"\"Export blueprint to file.\"\"\"\n    blueprintJson = params.get(\"blueprintJson\", \"\")\n    outputPath = params.get(\"outputPath\")\n\n    if not outputPath:\n        return {\"error\": \"No output path specified\"}\n\n    try:\n        with open(outputPath, \"w\", encoding=\"utf-8\") as f:\n            f.write(blueprintJson)\n        return {\"error\": None}\n    except Exception as e:\n        return {\"error\": f\"Failed to export: {e}\"}", "args": ["params"], "returns": "dict", "moduleColor": "#9b59b6", "moduleName": "extractor_compute"}, {"id": "extractor_compute.exportReport", "type": "function", "label": "exportReport", "direction": "inbound", "parent": "extractor_compute", "line": 1173, "endLine": 1195, "signature": "(params) -> dict", "docstring": "Export extraction report.", "source": "def exportReport(params: dict) -> dict:\n    \"\"\"Export extraction report.\"\"\"\n    report = params.get(\"extractionReport\", {})\n    mapping = params.get(\"sourceMapping\", {})\n    uncertainties = params.get(\"uncertainties\", [])\n    outputPath = params.get(\"outputPath\")\n\n    if not outputPath:\n        return {\"error\": \"No output path specified\"}\n\n    fullReport = {\n        \"summary\": report,\n        \"mapping\": mapping,\n        \"uncertainties\": uncertainties,\n        \"requires_review\": len(uncertainties)\n    }\n\n    try:\n        with open(outputPath, \"w\", encoding=\"utf-8\") as f:\n            json.dump(fullReport, f, indent=2)\n        return {\"error\": None}\n    except Exception as e:\n        return {\"error\": f\"Failed to export report: {e}\"}", "args": ["params"], "returns": "dict", "moduleColor": "#9b59b6", "moduleName": "extractor_compute"}, {"id": "extractor_compute.clearState", "type": "function", "label": "clearState", "direction": "inbound", "parent": "extractor_compute", "line": 1198, "endLine": 1217, "signature": "(params) -> dict", "docstring": "Reset all extraction state.", "source": "def clearState(params: dict) -> dict:\n    \"\"\"Reset all extraction state.\"\"\"\n    return {\n        \"sourceCode\": None,\n        \"ast\": None,\n        \"patterns\": None,\n        \"extractedStates\": None,\n        \"extractedTransitions\": None,\n        \"extractedGates\": None,\n        \"extractedActions\": None,\n        \"extractedEvents\": None,\n        \"entryState\": None,\n        \"terminalStates\": None,\n        \"blueprint\": None,\n        \"blueprintJson\": None,\n        \"sourceMapping\": None,\n        \"uncertainties\": None,\n        \"extractionReport\": None,\n        \"error\": None\n    }", "args": ["params"], "returns": "dict", "moduleColor": "#9b59b6", "moduleName": "extractor_compute"}, {"id": "extractor_compute.walk", "type": "function", "label": "walk", "direction": "inbound", "parent": "extractor_compute", "line": 98, "endLine": 261, "signature": "(node, parent, className)", "docstring": null, "source": "    def walk(node, parent=None, className=None):\n        if not isinstance(node, dict):\n            return\n\n        ntype = node.get(\"_type\")\n\n        # Pattern 1: Class with state attribute OR Enum\n        if ntype == \"ClassDef\":\n            clsName = node.get(\"name\", \"\")\n            bases = [_getName(b) for b in node.get(\"bases\", [])]\n\n            # Check if this is an Enum class (Pattern 6)\n            isEnum = any(\"Enum\" in b for b in bases)\n            if isEnum:\n                members = []\n                for item in node.get(\"body\", []):\n                    if isinstance(item, dict) and item.get(\"_type\") == \"Assign\":\n                        for t in item.get(\"targets\", []):\n                            members.append({\n                                \"name\": _getName(t),\n                                \"line\": item.get(\"lineno\")\n                            })\n                patterns[\"enumDefinitions\"].append({\n                    \"name\": clsName,\n                    \"members\": members,\n                    \"line\": node.get(\"lineno\")\n                })\n                # Don't process enum as state class\n                for item in node.get(\"body\", []):\n                    walk(item, node, clsName)\n                return\n\n            # Regular class - check for state attribute\n            hasStateAttr = False\n            stateAttrName = None\n            methods = []\n\n            for item in node.get(\"body\", []):\n                if isinstance(item, dict):\n                    # Check for state attribute assignments at class level\n                    if item.get(\"_type\") == \"Assign\":\n                        for target in item.get(\"targets\", []):\n                            tname = _getName(target).lower()\n                            if any(kw in tname for kw in STATE_KEYWORDS):\n                                hasStateAttr = True\n                                stateAttrName = _getName(target)\n                    # Collect methods and check __init__ for self.state\n                    if item.get(\"_type\") in (\"FunctionDef\", \"AsyncFunctionDef\"):\n                        methodName = item.get(\"name\")\n                        methods.append({\n                            \"name\": methodName,\n                            \"line\": item.get(\"lineno\"),\n                            \"isAsync\": item.get(\"_type\") == \"AsyncFunctionDef\"\n                        })\n                        # Check __init__ for self.state assignments\n                        if methodName == \"__init__\":\n                            for stmt in item.get(\"body\", []):\n                                if stmt.get(\"_type\") == \"Assign\":\n                                    for t in stmt.get(\"targets\", []):\n                                        if t.get(\"_type\") == \"Attribute\":\n                                            attr = t.get(\"attr\", \"\").lower()\n                                            if any(kw in attr for kw in\n                                                   STATE_KEYWORDS):\n                                                hasStateAttr = True\n                                                stateAttrName = f\"self.{t.get('attr')}\"\n\n            if hasStateAttr:\n                patterns[\"stateClasses\"].append({\n                    \"name\": clsName,\n                    \"stateAttr\": stateAttrName,\n                    \"methods\": methods,\n                    \"line\": node.get(\"lineno\")\n                })\n\n            for item in node.get(\"body\", []):\n                walk(item, node, clsName)\n            return\n\n        # Pattern 2: Module-level state variables\n        if ntype == \"Assign\" and parent and parent.get(\"_type\") == \"Module\":\n            for target in node.get(\"targets\", []):\n                tname = _getName(target).lower()\n                if any(kw in tname for kw in STATE_KEYWORDS):\n                    val = node.get(\"value\", {})\n                    patterns[\"stateVariables\"].append({\n                        \"name\": _getName(target),\n                        \"value\": _getValue(val),\n                        \"line\": node.get(\"lineno\")\n                    })\n\n        # Pattern 3: If-elif chains checking state\n        if ntype == \"If\":\n            chain = _extractIfChain(node)\n            if chain and len(chain) >= 2:\n                stateVar = _findStateVarInChain(chain)\n                if stateVar:\n                    patterns[\"ifChains\"].append({\n                        \"stateVar\": stateVar,\n                        \"branches\": chain,\n                        \"line\": node.get(\"lineno\"),\n                        \"className\": className\n                    })\n\n        # Pattern 4: Match/case statements\n        if ntype == \"Match\":\n            subject = _getName(node.get(\"subject\", {}))\n            if any(kw in subject.lower() for kw in STATE_KEYWORDS):\n                cases = []\n                for case in node.get(\"cases\", []):\n                    pattern = case.get(\"pattern\", {})\n                    cases.append({\n                        \"pattern\": _getPatternValue(pattern),\n                        \"line\": case.get(\"lineno\") if hasattr(case, \"lineno\") else \\\n                            node.get(\"lineno\")\n                    })\n                patterns[\"matchStatements\"].append({\n                    \"subject\": subject,\n                    \"cases\": cases,\n                    \"line\": node.get(\"lineno\"),\n                    \"className\": className\n                })\n\n        # Pattern 5: Event handlers\n        if ntype in (\"FunctionDef\", \"AsyncFunctionDef\"):\n            fname = node.get(\"name\", \"\")\n            if any(fname.startswith(p) for p in EVENT_PREFIXES):\n                eventName = fname\n                for p in EVENT_PREFIXES:\n                    if fname.startswith(p):\n                        eventName = fname[len(p):]\n                        break\n                patterns[\"eventHandlers\"].append({\n                    \"name\": fname,\n                    \"event\": eventName.upper(),\n                    \"line\": node.get(\"lineno\"),\n                    \"className\": className,\n                    \"args\": [a.get(\"arg\") for a in node.get(\"args\", {}).get(\n                        \"args\", [])]\n                })\n\n        # Pattern 6: Enum definitions - handled in Pattern 1 above\n\n        # Pattern 7: Constants (uppercase) that might be states\n        if ntype == \"Assign\" and parent and parent.get(\"_type\") == \"Module\":\n            for target in node.get(\"targets\", []):\n                tname = _getName(target)\n                if tname.isupper() and isinstance(node.get(\"value\"), dict):\n                    val = node.get(\"value\")\n                    if val.get(\"_type\") == \"Constant\" and isinstance(\n                            val.get(\"value\"), str):\n                        patterns[\"constantDefinitions\"].append({\n                            \"name\": tname,\n                            \"value\": val.get(\"value\"),\n                            \"line\": node.get(\"lineno\")\n                        })\n\n        # Walk children\n        for key, value in node.items():\n            if isinstance(value, dict):\n                walk(value, node, className)\n            elif isinstance(value, list):\n                for item in value:\n                    if isinstance(item, dict):\n                        walk(item, node, className)", "args": ["node", "parent", "className"], "returns": null, "moduleColor": "#9b59b6", "moduleName": "extractor_compute"}, {"id": "extractor_compute.addState", "type": "function", "label": "addState", "direction": "inbound", "parent": "extractor_compute", "line": 353, "endLine": 374, "signature": "(stateId, name, desc, source, line, confidence)", "docstring": null, "source": "    def addState(stateId: str, name: str, desc: str, source: str, line: int,\n                 confidence: float = 1.0):\n        if stateId in seenStates:\n            return\n        seenStates.add(stateId)\n\n        state = {\n            \"id\": stateId,\n            \"name\": name,\n            \"description\": desc,\n            \"source\": source,\n            \"line\": line,\n            \"confidence\": confidence\n        }\n        states.append(state)\n\n        if confidence < 0.8:\n            uncertainties.append({\n                \"type\": \"state\",\n                \"element\": state,\n                \"reason\": f\"Low confidence ({confidence:.0%}) - needs review\"\n            })", "args": ["stateId", "name", "desc", "source", "line", "confidence"], "returns": null, "moduleColor": "#9b59b6", "moduleName": "extractor_compute"}, {"id": "extractor_compute.addTransition", "type": "function", "label": "addTransition", "direction": "inbound", "parent": "extractor_compute", "line": 468, "endLine": 490, "signature": "(fromState, toState, event, source, line, confidence)", "docstring": null, "source": "    def addTransition(fromState: str, toState: str, event: str, source: str,\n                      line: int, confidence: float = 1.0):\n        nonlocal tId\n        trans = {\n            \"id\": f\"t_{tId}\",\n            \"from\": fromState,\n            \"to\": toState,\n            \"on_event\": event,\n            \"source\": source,\n            \"line\": line,\n            \"confidence\": confidence,\n            \"gates\": [],\n            \"actions\": []\n        }\n        transitions.append(trans)\n        tId += 1\n\n        if confidence < 0.8:\n            uncertainties.append({\n                \"type\": \"transition\",\n                \"element\": trans,\n                \"reason\": f\"Low confidence ({confidence:.0%}) - needs review\"\n            })", "args": ["fromState", "toState", "event", "source", "line", "confidence"], "returns": null, "moduleColor": "#9b59b6", "moduleName": "extractor_compute"}, {"id": "extractor_compute.walk", "type": "function", "label": "walk", "direction": "inbound", "parent": "extractor_compute", "line": 566, "endLine": 601, "signature": "(nodes, currentFrom)", "docstring": null, "source": "    def walk(nodes, currentFrom=None):\n        for node in nodes:\n            if not isinstance(node, dict):\n                continue\n\n            ntype = node.get(\"_type\")\n\n            # Check for if statements checking current state\n            if ntype == \"If\":\n                test = node.get(\"test\", {})\n                fromState = _extractStateFromCondition(test)\n\n                # Process if body\n                toState = _findStateAssignment(node.get(\"body\", []), stateAttr)\n                if toState:\n                    changes.append({\n                        \"from\": fromState or \"*\",\n                        \"to\": toState,\n                        \"line\": node.get(\"lineno\")\n                    })\n\n                # Process elif/else\n                walk(node.get(\"orelse\", []), currentFrom)\n\n            # Direct state assignment\n            elif ntype == \"Assign\":\n                for target in node.get(\"targets\", []):\n                    targetName = _getName(target)\n                    if stateAttr in targetName or \"state\" in targetName.lower():\n                        toState = _getValue(node.get(\"value\", {}))\n                        if toState:\n                            changes.append({\n                                \"from\": currentFrom or \"*\",\n                                \"to\": str(toState).lower().strip(\"'\\\"\"),\n                                \"line\": node.get(\"lineno\")\n                            })", "args": ["nodes", "currentFrom"], "returns": null, "moduleColor": "#9b59b6", "moduleName": "extractor_compute"}, {"id": "extractor_compute.walk", "type": "function", "label": "walk", "direction": "inbound", "parent": "extractor_compute", "line": 611, "endLine": 633, "signature": "(nodes)", "docstring": null, "source": "    def walk(nodes):\n        for node in nodes:\n            if not isinstance(node, dict):\n                continue\n\n            ntype = node.get(\"_type\")\n\n            if ntype == \"Assign\":\n                for target in node.get(\"targets\", []):\n                    targetName = _getName(target).lower()\n                    if any(kw in targetName for kw in STATE_KEYWORDS):\n                        toState = _getValue(node.get(\"value\", {}))\n                        if toState:\n                            changes.append({\n                                \"from\": \"*\",\n                                \"to\": str(toState).lower().strip(\"'\\\"\"),\n                                \"line\": node.get(\"lineno\")\n                            })\n\n            # Recurse into body elements\n            for key in [\"body\", \"orelse\", \"finalbody\"]:\n                if key in node and isinstance(node[key], list):\n                    walk(node[key])", "args": ["nodes"], "returns": null, "moduleColor": "#9b59b6", "moduleName": "extractor_compute"}, {"id": "extractor_compute.addAction", "type": "function", "label": "addAction", "direction": "inbound", "parent": "extractor_compute", "line": 743, "endLine": 768, "signature": "(name, actionType, target, value, source, line, confidence)", "docstring": null, "source": "    def addAction(name: str, actionType: str, target: str, value: str,\n                  source: str, line: int, confidence: float = 1.0):\n        nonlocal aId\n        if name in seenActions:\n            return\n        seenActions.add(name)\n\n        action = {\n            \"id\": f\"a_{aId}\",\n            \"name\": name,\n            \"type\": actionType,\n            \"target\": target,\n            \"value\": value,\n            \"source\": source,\n            \"line\": line,\n            \"confidence\": confidence\n        }\n        actions.append(action)\n        aId += 1\n\n        if confidence < 0.8:\n            uncertainties.append({\n                \"type\": \"action\",\n                \"element\": action,\n                \"reason\": f\"Low confidence ({confidence:.0%}) - needs review\"\n            })", "args": ["name", "actionType", "target", "value", "source", "line", "confidence"], "returns": null, "moduleColor": "#9b59b6", "moduleName": "extractor_compute"}, {"id": "extractor_compute.walk", "type": "function", "label": "walk", "direction": "inbound", "parent": "extractor_compute", "line": 830, "endLine": 869, "signature": "(nodes)", "docstring": null, "source": "    def walk(nodes):\n        for node in nodes:\n            if not isinstance(node, dict):\n                continue\n\n            ntype = node.get(\"_type\")\n\n            # Assignments (excluding state)\n            if ntype == \"Assign\":\n                for target in node.get(\"targets\", []):\n                    targetName = _getName(target)\n                    if stateAttr and stateAttr in targetName:\n                        continue\n                    if any(kw in targetName.lower() for kw in STATE_KEYWORDS):\n                        continue\n\n                    effects.append({\n                        \"type\": \"set\",\n                        \"target\": targetName,\n                        \"value\": _exprToStr(node.get(\"value\", {})),\n                        \"line\": node.get(\"lineno\")\n                    })\n\n            # Method calls (potential compute actions)\n            elif ntype == \"Expr\":\n                val = node.get(\"value\", {})\n                if val.get(\"_type\") == \"Call\":\n                    funcName = _getName(val.get(\"func\", {}))\n                    if funcName and not funcName.startswith(\"print\"):\n                        effects.append({\n                            \"type\": \"compute\",\n                            \"target\": funcName,\n                            \"value\": \"\",\n                            \"line\": node.get(\"lineno\")\n                        })\n\n            # Recurse\n            for key in [\"body\", \"orelse\", \"finalbody\"]:\n                if key in node and isinstance(node[key], list):\n                    walk(node[key])", "args": ["nodes"], "returns": null, "moduleColor": "#9b59b6", "moduleName": "extractor_compute"}, {"id": "extractor_compute.find", "type": "function", "label": "find", "direction": "inbound", "parent": "extractor_compute", "line": 1311, "endLine": 1324, "signature": "(node)", "docstring": null, "source": "    def find(node):\n        if isinstance(node, dict):\n            if node.get(\"_type\") == \"ClassDef\" and node.get(\"name\") == className:\n                return node.get(\"body\", [])\n            for v in node.values():\n                result = find(v)\n                if result:\n                    return result\n        elif isinstance(node, list):\n            for item in node:\n                result = find(item)\n                if result:\n                    return result\n        return None", "args": ["node"], "returns": null, "moduleColor": "#9b59b6", "moduleName": "extractor_compute"}, {"id": "extractor_compute.find", "type": "function", "label": "find", "direction": "inbound", "parent": "extractor_compute", "line": 1341, "endLine": 1355, "signature": "(node)", "docstring": null, "source": "        def find(node):\n            if isinstance(node, dict):\n                if (node.get(\"_type\") in (\"FunctionDef\", \"AsyncFunctionDef\") and\n                        node.get(\"name\") == methodName):\n                    return node.get(\"body\", [])\n                for v in node.values():\n                    result = find(v)\n                    if result:\n                        return result\n            elif isinstance(node, list):\n                for item in node:\n                    result = find(item)\n                    if result:\n                        return result\n            return None", "args": ["node"], "returns": null, "moduleColor": "#9b59b6", "moduleName": "extractor_compute"}, {"id": "llm_compute", "type": "module", "label": "llm_compute", "metrics": {"fanIn": 8, "fanOut": 5, "instability": 0.385, "internalEdges": 4, "externalCallCount": 8, "localCallCount": 0, "callsByCategory": {"stdlib": 7, "pip": 1}, "localDependencies": []}, "moduleColor": "#1abc9c", "moduleName": "llm_compute"}, {"id": "llm_compute.init_config", "type": "function", "label": "init_config", "direction": "inbound", "parent": "llm_compute", "line": 47, "endLine": 58, "signature": "(params) -> Dict[]", "docstring": "Initialize configuration from environment. Pure function.", "source": "def init_config(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Initialize configuration from environment. Pure function.\"\"\"\n    return {\n        \"api_key\": os.environ.get(\"OPENAI_API_KEY\") or None,\n        \"api_base\": os.environ.get(\n            \"OPENAI_API_BASE\",\n            \"https://api.openai.com/v1\"\n        ),\n        \"model\": os.environ.get(\"LPP_LLM_MODEL\", \"gpt-4o-mini\"),\n        \"temperature\": 0.7,\n        \"max_tokens\": 2048\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#1abc9c", "moduleName": "llm_compute"}, {"id": "llm_compute.load_schema", "type": "function", "label": "load_schema", "direction": "inbound", "parent": "llm_compute", "line": 61, "endLine": 71, "signature": "(params) -> Dict[]", "docstring": "Load L++ schema specification. Pure function.", "source": "def load_schema(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Load L++ schema specification. Pure function.\"\"\"\n    try:\n        if not SCHEMA_PATH.exists():\n            return {\n                \"schema_content\": None,\n                \"error\": f\"Schema not found: {SCHEMA_PATH}\"\n            }\n        return {\"schema_content\": SCHEMA_PATH.read_text(), \"error\": None}\n    except Exception as e:\n        return {\"schema_content\": None, \"error\": str(e)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#1abc9c", "moduleName": "llm_compute"}, {"id": "llm_compute.load_blueprint", "type": "function", "label": "load_blueprint", "direction": "inbound", "parent": "llm_compute", "line": 74, "endLine": 100, "signature": "(params) -> Dict[]", "docstring": "Load blueprint from file. Pure function.", "source": "def load_blueprint(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Load blueprint from file. Pure function.\"\"\"\n    path = params.get(\"path\")\n    if not path:\n        return {\"blueprint\": None, \"blueprint_path\": None, \"error\": \"No path\"}\n    try:\n        p = Path(path)\n        if not p.exists():\n            return {\n                \"blueprint\": None,\n                \"blueprint_path\": None,\n                \"error\": f\"Not found: {path}\"\n            }\n        bp = json.loads(p.read_text())\n        return {\n            \"blueprint\": bp,\n            \"blueprint_path\": str(p.resolve()),\n            \"error\": None\n        }\n    except json.JSONDecodeError as e:\n        return {\n            \"blueprint\": None,\n            \"blueprint_path\": None,\n            \"error\": f\"Invalid JSON: {e}\"\n        }\n    except Exception as e:\n        return {\"blueprint\": None, \"blueprint_path\": None, \"error\": str(e)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#1abc9c", "moduleName": "llm_compute"}, {"id": "llm_compute.query", "type": "function", "label": "query", "direction": "inbound", "parent": "llm_compute", "line": 136, "endLine": 177, "signature": "(params) -> Dict[]", "docstring": "Send query to LLM with context. Pure function.", "source": "def query(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Send query to LLM with context. Pure function.\"\"\"\n    schema = params.get(\"schema_content\")\n    blueprint = params.get(\"blueprint\")\n    conversation = params.get(\"conversation\") or []\n    user_query = params.get(\"query\", \"\")\n\n    # Build system message\n    if schema:\n        sys_msg = SYSTEM_PROMPT_WITH_SCHEMA.format(schema=schema)\n    else:\n        sys_msg = SYSTEM_PROMPT_BASE\n\n    if blueprint:\n        sys_msg += \"\\n\\nCurrent blueprint:\\n\"\n        sys_msg += f\"```json\\n{json.dumps(blueprint, indent=2)}\\n```\"\n\n    messages = [{\"role\": \"system\", \"content\": sys_msg}]\n    messages.extend(conversation)\n    messages.append({\"role\": \"user\", \"content\": user_query})\n\n    result = _call_llm(\n        params.get(\"api_key\"), params.get(\n            \"api_base\", \"https://api.openai.com/v1\"),\n        params.get(\"model\", \"gpt-4o-mini\"), messages,\n        params.get(\"temperature\", 0.7), params.get(\"max_tokens\", 2048)\n    )\n\n    if result[\"response\"]:\n        new_conv = list(conversation)\n        new_conv.append({\"role\": \"user\", \"content\": user_query})\n        new_conv.append({\"role\": \"assistant\", \"content\": result[\"response\"]})\n        return {\n            \"response\": result[\"response\"],\n            \"conversation\": new_conv,\n            \"error\": None\n        }\n    return {\n        \"response\": None,\n        \"conversation\": conversation,\n        \"error\": result[\"error\"]\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#1abc9c", "moduleName": "llm_compute"}, {"id": "llm_compute.explain_blueprint", "type": "function", "label": "explain_blueprint", "direction": "inbound", "parent": "llm_compute", "line": 180, "endLine": 197, "signature": "(params) -> Dict[]", "docstring": "Get detailed explanation of blueprint. Pure function.", "source": "def explain_blueprint(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Get detailed explanation of blueprint. Pure function.\"\"\"\n    if not params.get(\"blueprint\"):\n        return {\n            \"response\": None,\n            \"conversation\": [],\n            \"error\": \"No blueprint loaded\"\n        }\n\n    params[\"query\"] = \"\"\"Explain this L++ blueprint comprehensively:\n1. **Purpose**: What does this state machine do?\n2. **States**: List each state and its role\n3. **Flow**: Describe the transition logic\n4. **Gates**: What conditions guard transitions?\n5. **Actions**: What side effects occur?\n6. **Entry/Terminal**: Lifecycle analysis\"\"\"\n    params[\"conversation\"] = []\n    return query(params)", "args": ["params"], "returns": "Dict[]", "moduleColor": "#1abc9c", "moduleName": "llm_compute"}, {"id": "llm_compute.validate_blueprint", "type": "function", "label": "validate_blueprint", "direction": "inbound", "parent": "llm_compute", "line": 200, "endLine": 214, "signature": "(params) -> Dict[]", "docstring": "Validate blueprint against schema. Pure function.", "source": "def validate_blueprint(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Validate blueprint against schema. Pure function.\"\"\"\n    if not params.get(\"blueprint\"):\n        return {\"response\": None, \"error\": \"No blueprint loaded\"}\n\n    params[\"query\"] = \"\"\"Validate this blueprint against L++ v0.1 schema:\n1. **Schema Compliance**: All required fields present?\n2. **State Integrity**: entry_state valid? terminal_states reachable?\n3. **Transitions**: Well-formed? Any unreachable states?\n4. **Gates**: Expressions valid?\n5. **Actions**: Types correct? References valid?\n\nList all issues with specific fixes.\"\"\"\n    params[\"conversation\"] = []\n    return query(params)", "args": ["params"], "returns": "Dict[]", "moduleColor": "#1abc9c", "moduleName": "llm_compute"}, {"id": "llm_compute.suggest_improvements", "type": "function", "label": "suggest_improvements", "direction": "inbound", "parent": "llm_compute", "line": 217, "endLine": 230, "signature": "(params) -> Dict[]", "docstring": "Suggest blueprint improvements. Pure function.", "source": "def suggest_improvements(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Suggest blueprint improvements. Pure function.\"\"\"\n    if not params.get(\"blueprint\"):\n        return {\"response\": None, \"error\": \"No blueprint loaded\"}\n\n    params[\"query\"] = \"\"\"Analyze this blueprint and suggest improvements:\n1. **Simplification**: Can states/transitions be consolidated?\n2. **Edge Cases**: Missing error handling?\n3. **Gate Optimization**: Simpler expressions?\n4. **Best Practices**: L++ conventions followed?\n\nProvide actionable suggestions with code examples.\"\"\"\n    params[\"conversation\"] = []\n    return query(params)", "args": ["params"], "returns": "Dict[]", "moduleColor": "#1abc9c", "moduleName": "llm_compute"}, {"id": "llm_compute.generate_blueprint", "type": "function", "label": "generate_blueprint", "direction": "inbound", "parent": "llm_compute", "line": 233, "endLine": 253, "signature": "(params) -> Dict[]", "docstring": "Generate blueprint from description. Pure function.", "source": "def generate_blueprint(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Generate blueprint from description. Pure function.\"\"\"\n    desc = params.get(\"description\", \"\")\n    if not desc:\n        return {\"response\": None, \"error\": \"No description provided\"}\n\n    params[\"query\"] = f\"\"\"Generate a complete L++ v0.1 blueprint for:\n\n{desc}\n\nRequirements:\n- Valid JSON following schema_v0.1.md exactly\n- Clear state names and descriptions\n- Appropriate gates for conditions\n- Well-defined actions\n- Proper entry_state and terminal_states\n- Include display rules\n\nOutput the complete JSON in a code block.\"\"\"\n    params[\"conversation\"] = []\n    return query(params)", "args": ["params"], "returns": "Dict[]", "moduleColor": "#1abc9c", "moduleName": "llm_compute"}, {"id": "openai", "type": "dependency", "label": "openai", "direction": "outbound", "category": "pip", "moduleColor": "#1abc9c", "moduleName": "llm_compute"}, {"id": "decoder_compute", "type": "module", "label": "decoder_compute", "metrics": {"fanIn": 19, "fanOut": 4, "instability": 0.174, "internalEdges": 44, "externalCallCount": 4, "localCallCount": 0, "callsByCategory": {"stdlib": 4}, "localDependencies": []}, "moduleColor": "#e74c3c", "moduleName": "decoder_compute"}, {"id": "decoder_compute.hasValue", "type": "function", "label": "hasValue", "direction": "inbound", "parent": "decoder_compute", "line": 70, "endLine": 74, "signature": "(params) -> dict", "docstring": "Gate: check if context field has non-null value.", "source": "def hasValue(params: dict) -> dict:\n    \"\"\"Gate: check if context field has non-null value.\"\"\"\n    field = params.get(\"field\", \"\").strip(\"'\\\"\")\n    val = params.get(field)\n    return {\"result\": val is not None and val != \"\" and val != []}", "args": ["params"], "returns": "dict", "moduleColor": "#e74c3c", "moduleName": "decoder_compute"}, {"id": "decoder_compute.loadFile", "type": "function", "label": "loadFile", "direction": "inbound", "parent": "decoder_compute", "line": 77, "endLine": 88, "signature": "(params) -> dict", "docstring": "Load Python source file from disk.", "source": "def loadFile(params: dict) -> dict:\n    \"\"\"Load Python source file from disk.\"\"\"\n    filePath = params.get(\"filePath\")\n    if not filePath:\n        return {\"sourceCode\": None, \"error\": \"No file path provided\"}\n    try:\n        with open(filePath, \"r\", encoding=\"utf-8\") as f:\n            return {\"sourceCode\": f.read(), \"error\": None}\n    except FileNotFoundError:\n        return {\"sourceCode\": None, \"error\": f\"File not found: {filePath}\"}\n    except Exception as e:\n        return {\"sourceCode\": None, \"error\": str(e)}", "args": ["params"], "returns": "dict", "moduleColor": "#e74c3c", "moduleName": "decoder_compute"}, {"id": "decoder_compute.parseAst", "type": "function", "label": "parseAst", "direction": "inbound", "parent": "decoder_compute", "line": 91, "endLine": 101, "signature": "(params) -> dict", "docstring": "Parse Python source into AST.", "source": "def parseAst(params: dict) -> dict:\n    \"\"\"Parse Python source into AST.\"\"\"\n    source = params.get(\"sourceCode\")\n    if not source:\n        return {\"ast\": None, \"error\": \"No source code\"}\n    try:\n        tree = ast.parse(source)\n        astDict = _astToDict(tree)\n        return {\"ast\": astDict, \"error\": None}\n    except SyntaxError as e:\n        return {\"ast\": None, \"error\": f\"Syntax error: {e}\"}", "args": ["params"], "returns": "dict", "moduleColor": "#e74c3c", "moduleName": "decoder_compute"}, {"id": "decoder_compute.analyzeImports", "type": "function", "label": "analyzeImports", "direction": "inbound", "parent": "decoder_compute", "line": 119, "endLine": 161, "signature": "(params) -> dict", "docstring": "Extract and resolve import semantics.", "source": "def analyzeImports(params: dict) -> dict:\n    \"\"\"Extract and resolve import semantics.\"\"\"\n    astDict = params.get(\"ast\", {})\n    imports = []\n\n    def walk(node):\n        if isinstance(node, dict):\n            ntype = node.get(\"_type\")\n            if ntype == \"Import\":\n                for alias in node.get(\"names\", []):\n                    name = alias.get(\"name\", \"\")\n                    modName = name.split(\".\")[0]\n                    imports.append({\n                        \"module\": name,\n                        \"alias\": alias.get(\"asname\"),\n                        \"semantic\": IMPORT_SEMANTICS.get(modName, {\n                            \"category\": \"unknown\",\n                            \"actions\": []\n                        }),\n                        \"line\": node.get(\"lineno\")\n                    })\n            elif ntype == \"ImportFrom\":\n                mod = node.get(\"module\", \"\")\n                modName = mod.split(\".\")[0] if mod else \"\"\n                for alias in node.get(\"names\", []):\n                    imports.append({\n                        \"module\": mod,\n                        \"name\": alias.get(\"name\"),\n                        \"alias\": alias.get(\"asname\"),\n                        \"semantic\": IMPORT_SEMANTICS.get(modName, {\n                            \"category\": \"unknown\",\n                            \"actions\": []\n                        }),\n                        \"line\": node.get(\"lineno\")\n                    })\n            for v in node.values():\n                walk(v)\n        elif isinstance(node, list):\n            for item in node:\n                walk(item)\n\n    walk(astDict)\n    return {\"imports\": imports}", "args": ["params"], "returns": "dict", "moduleColor": "#e74c3c", "moduleName": "decoder_compute"}, {"id": "decoder_compute.analyzeFunctions", "type": "function", "label": "analyzeFunctions", "direction": "inbound", "parent": "decoder_compute", "line": 164, "endLine": 222, "signature": "(params) -> dict", "docstring": "Extract function and class definitions.", "source": "def analyzeFunctions(params: dict) -> dict:\n    \"\"\"Extract function and class definitions.\"\"\"\n    astDict = params.get(\"ast\", {})\n    imports = params.get(\"imports\", [])\n    functions = []\n    classes = []\n\n    importedNames = {i.get(\"alias\") or i.get(\"name\") or i.get(\"module\", \"\")\n                     .split(\".\")[-1] for i in imports}\n\n    def extractFn(node, className=None):\n        if node.get(\"_type\") in (\"FunctionDef\", \"AsyncFunctionDef\"):\n            args = []\n            for arg in node.get(\"args\", {}).get(\"args\", []):\n                args.append(arg.get(\"arg\"))\n            returns = _extractType(node.get(\"returns\"))\n            decorators = [_extractName(d) for d in node.get(\"decorator_list\",\n                                                            [])]\n            # Analyze body for side effects\n            sideEffects = _findSideEffects(node.get(\"body\", []), importedNames)\n            fnData = {\n                \"name\": node.get(\"name\"),\n                \"args\": args,\n                \"returns\": returns,\n                \"decorators\": decorators,\n                \"isAsync\": node.get(\"_type\") == \"AsyncFunctionDef\",\n                \"line\": node.get(\"lineno\"),\n                \"sideEffects\": sideEffects,\n                \"className\": className,\n                \"docstring\": _extractDocstring(node)\n            }\n            functions.append(fnData)\n\n    def walk(node, className=None):\n        if isinstance(node, dict):\n            ntype = node.get(\"_type\")\n            if ntype == \"ClassDef\":\n                bases = [_extractName(b) for b in node.get(\"bases\", [])]\n                classes.append({\n                    \"name\": node.get(\"name\"),\n                    \"bases\": bases,\n                    \"line\": node.get(\"lineno\"),\n                    \"docstring\": _extractDocstring(node)\n                })\n                for item in node.get(\"body\", []):\n                    walk(item, className=node.get(\"name\"))\n            elif ntype in (\"FunctionDef\", \"AsyncFunctionDef\"):\n                extractFn(node, className)\n                for item in node.get(\"body\", []):\n                    walk(item, className)\n            else:\n                for v in node.values():\n                    walk(v, className)\n        elif isinstance(node, list):\n            for item in node:\n                walk(item, className)\n\n    walk(astDict)\n    return {\"functions\": functions, \"classes\": classes}", "args": ["params"], "returns": "dict", "moduleColor": "#e74c3c", "moduleName": "decoder_compute"}, {"id": "decoder_compute.analyzeControlFlow", "type": "function", "label": "analyzeControlFlow", "direction": "inbound", "parent": "decoder_compute", "line": 306, "endLine": 431, "signature": "(params) -> dict", "docstring": "Build control flow graph from AST.", "source": "def analyzeControlFlow(params: dict) -> dict:\n    \"\"\"Build control flow graph from AST.\"\"\"\n    astDict = params.get(\"ast\", {})\n    functions = params.get(\"functions\", [])\n    cfg = {\"nodes\": [], \"edges\": [], \"patterns\": {}}\n\n    nodeId = [0]\n\n    def addNode(label, ntype, line=None):\n        nid = f\"n{nodeId[0]}\"\n        nodeId[0] += 1\n        cfg[\"nodes\"].append({\n            \"id\": nid,\n            \"label\": label,\n            \"type\": ntype,\n            \"line\": line\n        })\n        return nid\n\n    def addEdge(src, dst, label=\"\"):\n        cfg[\"edges\"].append({\"from\": src, \"to\": dst, \"label\": label})\n\n    def walkBody(body, prevId=None):\n        lastId = prevId\n        for node in body:\n            if isinstance(node, dict):\n                ntype = node.get(\"_type\")\n                line = node.get(\"lineno\")\n\n                if ntype == \"If\":\n                    testStr = _exprToStr(node.get(\"test\", {}))\n                    ifId = addNode(f\"if {testStr}\", \"branch\", line)\n                    if lastId:\n                        addEdge(lastId, ifId)\n                    cfg[\"patterns\"][\"branch\"] = cfg[\"patterns\"].get(\"branch\",\n                                                                    0) + 1\n                    # True branch\n                    thenEnd = walkBody(node.get(\"body\", []), ifId)\n                    # False branch\n                    elseBody = node.get(\"orelse\", [])\n                    if elseBody:\n                        elseEnd = walkBody(elseBody, ifId)\n                        mergeId = addNode(\"merge\", \"merge\", line)\n                        if thenEnd:\n                            addEdge(thenEnd, mergeId, \"then\")\n                        if elseEnd:\n                            addEdge(elseEnd, mergeId, \"else\")\n                        lastId = mergeId\n                    else:\n                        lastId = thenEnd or ifId\n\n                elif ntype == \"For\":\n                    iterStr = _exprToStr(node.get(\"iter\", {}))\n                    forId = addNode(f\"for {iterStr}\", \"loop\", line)\n                    if lastId:\n                        addEdge(lastId, forId)\n                    cfg[\"patterns\"][\"loop\"] = cfg[\"patterns\"].get(\"loop\", 0)+1\n                    bodyEnd = walkBody(node.get(\"body\", []), forId)\n                    if bodyEnd:\n                        addEdge(bodyEnd, forId, \"next\")\n                    lastId = forId\n\n                elif ntype == \"While\":\n                    testStr = _exprToStr(node.get(\"test\", {}))\n                    whileId = addNode(f\"while {testStr}\", \"loop\", line)\n                    if lastId:\n                        addEdge(lastId, whileId)\n                    cfg[\"patterns\"][\"loop\"] = cfg[\"patterns\"].get(\"loop\", 0)+1\n                    bodyEnd = walkBody(node.get(\"body\", []), whileId)\n                    if bodyEnd:\n                        addEdge(bodyEnd, whileId, \"loop\")\n                    lastId = whileId\n\n                elif ntype == \"Try\":\n                    tryId = addNode(\"try\", \"errorHandling\", line)\n                    if lastId:\n                        addEdge(lastId, tryId)\n                    cfg[\"patterns\"][\"errorHandling\"] = cfg[\"patterns\"].get(\n                        \"errorHandling\", 0) + 1\n                    bodyEnd = walkBody(node.get(\"body\", []), tryId)\n                    handlers = node.get(\"handlers\", [])\n                    handlerEnds = []\n                    for h in handlers:\n                        htype = _extractName(h.get(\"type\"))\n                        hId = addNode(f\"except {htype}\", \"errorRecovery\", line)\n                        addEdge(tryId, hId, \"error\")\n                        hEnd = walkBody(h.get(\"body\", []), hId)\n                        if hEnd:\n                            handlerEnds.append(hEnd)\n                    finallyBody = node.get(\"finalbody\", [])\n                    if finallyBody:\n                        finId = addNode(\"finally\", \"cleanup\", line)\n                        if bodyEnd:\n                            addEdge(bodyEnd, finId, \"ok\")\n                        for he in handlerEnds:\n                            addEdge(he, finId)\n                        lastId = walkBody(finallyBody, finId) or finId\n                    else:\n                        lastId = bodyEnd\n\n                elif ntype == \"Return\":\n                    retId = addNode(\"return\", \"terminal\", line)\n                    if lastId:\n                        addEdge(lastId, retId)\n                    lastId = None\n\n                elif ntype in (\"Expr\", \"Assign\", \"AugAssign\"):\n                    label = _stmtLabel(node)\n                    stmtId = addNode(label, \"statement\", line)\n                    if lastId:\n                        addEdge(lastId, stmtId)\n                    lastId = stmtId\n\n        return lastId\n\n    # Process each function\n    for fn in functions:\n        fnName = fn.get(\"name\", \"main\")\n        entryId = addNode(f\"fn:{fnName}\", \"entry\", fn.get(\"line\"))\n        # Re-parse to get body (simplified: walk AST again)\n\n    # Walk module-level\n    moduleBody = astDict.get(\"body\", [])\n    walkBody(moduleBody)\n\n    return {\"controlFlow\": cfg}", "args": ["params"], "returns": "dict", "moduleColor": "#e74c3c", "moduleName": "decoder_compute"}, {"id": "decoder_compute.inferStates", "type": "function", "label": "inferStates", "direction": "inbound", "parent": "decoder_compute", "line": 479, "endLine": 694, "signature": "(params) -> dict", "docstring": "Infer state machine states from code structure.", "source": "def inferStates(params: dict) -> dict:\n    \"\"\"Infer state machine states from code structure.\"\"\"\n    functions = params.get(\"functions\", [])\n    classes = params.get(\"classes\", [])\n    controlFlow = params.get(\"controlFlow\", {})\n    imports = params.get(\"imports\", [])\n\n    states = []\n    stateId = 0\n\n    # Entry state\n    states.append({\n        \"id\": \"idle\",\n        \"name\": \"Idle\",\n        \"description\": \"Initial state\",\n        \"inferred_from\": \"entry_point\"\n    })\n\n    # Infer states from function names\n    for fn in functions:\n        name = fn.get(\"name\", \"\")\n        if name.startswith(\"_\"):\n            continue  # Skip private\n        \n        # Convert function name to readable state name\n        def to_state_name(fn_name):\n            \"\"\"Convert snake_case to Title Case\"\"\"\n            words = fn_name.replace(\"_\", \" \").split()\n            return \" \".join(w.capitalize() for w in words)\n        \n        # Common patterns -> grouped states\n        if any(kw in name.lower() for kw in [\"init\", \"setup\", \"start\"]):\n            states.append({\n                \"id\": f\"initializing\",\n                \"name\": \"Initializing\",\n                \"description\": f\"From function: {name}\",\n                \"inferred_from\": f\"function:{name}\"\n            })\n        elif any(kw in name.lower() for kw in [\"process\", \"handle\", \"run\", \"execute\"]):\n            states.append({\n                \"id\": f\"processing\",\n                \"name\": \"Processing\",\n                \"description\": f\"From function: {name}\",\n                \"inferred_from\": f\"function:{name}\"\n            })\n        elif any(kw in name.lower() for kw in [\"validate\", \"check\", \"verify\"]):\n            states.append({\n                \"id\": f\"validating\",\n                \"name\": \"Validating\",\n                \"description\": f\"From function: {name}\",\n                \"inferred_from\": f\"function:{name}\"\n            })\n        elif any(kw in name.lower() for kw in [\"load\", \"fetch\", \"get\", \"read\"]):\n            states.append({\n                \"id\": f\"loading\",\n                \"name\": \"Loading\",\n                \"description\": f\"From function: {name}\",\n                \"inferred_from\": f\"function:{name}\"\n            })\n        elif any(kw in name.lower() for kw in [\"save\", \"write\", \"store\"]):\n            states.append({\n                \"id\": f\"saving\",\n                \"name\": \"Saving\",\n                \"description\": f\"From function: {name}\",\n                \"inferred_from\": f\"function:{name}\"\n            })\n        elif any(kw in name.lower() for kw in [\"error\", \"fail\", \"except\"]):\n            states.append({\n                \"id\": f\"error\",\n                \"name\": \"Error\",\n                \"description\": f\"From function: {name}\",\n                \"inferred_from\": f\"function:{name}\"\n            })\n        elif any(kw in name.lower() for kw in [\"query\", \"search\", \"find\", \"lookup\"]):\n            states.append({\n                \"id\": f\"querying\",\n                \"name\": \"Querying\",\n                \"description\": f\"From function: {name}\",\n                \"inferred_from\": f\"function:{name}\"\n            })\n        elif any(kw in name.lower() for kw in [\"generate\", \"create\", \"build\", \"make\"]):\n            states.append({\n                \"id\": f\"generating\",\n                \"name\": \"Generating\",\n                \"description\": f\"From function: {name}\",\n                \"inferred_from\": f\"function:{name}\"\n            })\n        elif any(kw in name.lower() for kw in [\"analyze\", \"parse\", \"decode\", \"extract\"]):\n            states.append({\n                \"id\": f\"analyzing\",\n                \"name\": \"Analyzing\",\n                \"description\": f\"From function: {name}\",\n                \"inferred_from\": f\"function:{name}\"\n            })\n        elif any(kw in name.lower() for kw in [\"explain\", \"describe\", \"format\", \"render\"]):\n            states.append({\n                \"id\": f\"explaining\",\n                \"name\": \"Explaining\",\n                \"description\": f\"From function: {name}\",\n                \"inferred_from\": f\"function:{name}\"\n            })\n        elif any(kw in name.lower() for kw in [\"suggest\", \"recommend\", \"improve\"]):\n            states.append({\n                \"id\": f\"suggesting\",\n                \"name\": \"Suggesting\",\n                \"description\": f\"From function: {name}\",\n                \"inferred_from\": f\"function:{name}\"\n            })\n        elif any(kw in name.lower() for kw in [\"register\", \"add\", \"update\", \"set\"]):\n            states.append({\n                \"id\": f\"registering\",\n                \"name\": \"Registering\",\n                \"description\": f\"From function: {name}\",\n                \"inferred_from\": f\"function:{name}\"\n            })\n        elif any(kw in name.lower() for kw in [\"list\", \"show\", \"display\", \"print\"]):\n            states.append({\n                \"id\": f\"listing\",\n                \"name\": \"Listing\",\n                \"description\": f\"From function: {name}\",\n                \"inferred_from\": f\"function:{name}\"\n            })\n        elif any(kw in name.lower() for kw in [\"compile\", \"transform\", \"convert\"]):\n            states.append({\n                \"id\": f\"compiling\",\n                \"name\": \"Compiling\",\n                \"description\": f\"From function: {name}\",\n                \"inferred_from\": f\"function:{name}\"\n            })\n        elif any(kw in name.lower() for kw in [\"visualize\", \"graph\", \"draw\", \"plot\"]):\n            states.append({\n                \"id\": f\"visualizing\",\n                \"name\": \"Visualizing\",\n                \"description\": f\"From function: {name}\",\n                \"inferred_from\": f\"function:{name}\"\n            })\n        elif any(kw in name.lower() for kw in [\"orchestrate\", \"dispatch\", \"schedule\", \"route\"]):\n            states.append({\n                \"id\": f\"orchestrating\",\n                \"name\": \"Orchestrating\",\n                \"description\": f\"From function: {name}\",\n                \"inferred_from\": f\"function:{name}\"\n            })\n        elif any(kw in name.lower() for kw in [\"scrape\", \"crawl\", \"download\"]):\n            states.append({\n                \"id\": f\"scraping\",\n                \"name\": \"Scraping\",\n                \"description\": f\"From function: {name}\",\n                \"inferred_from\": f\"function:{name}\"\n            })\n        elif any(kw in name.lower() for kw in [\"seal\", \"sign\", \"verify\", \"proof\"]):\n            states.append({\n                \"id\": f\"sealing\",\n                \"name\": \"Sealing\",\n                \"description\": f\"From function: {name}\",\n                \"inferred_from\": f\"function:{name}\"\n            })\n        else:\n            # Fallback: create a unique state for each unmatched public function\n            state_id = name.lower().replace(\"_\", \"-\")\n            state_name = to_state_name(name)\n            states.append({\n                \"id\": state_id,\n                \"name\": state_name,\n                \"description\": f\"From function: {name}\",\n                \"inferred_from\": f\"function:{name}\"\n            })\n\n    # Infer from control flow patterns\n    patterns = controlFlow.get(\"patterns\", {})\n    if patterns.get(\"errorHandling\", 0) > 0:\n        if not any(s[\"id\"] == \"error\" for s in states):\n            states.append({\n                \"id\": \"error\",\n                \"name\": \"Error\",\n                \"description\": \"From try/except blocks\",\n                \"inferred_from\": \"pattern:errorHandling\"\n            })\n\n    # Infer from imports\n    for imp in imports:\n        cat = imp.get(\"semantic\", {}).get(\"category\")\n        if cat == \"http\":\n            if not any(s[\"id\"] == \"fetching\" for s in states):\n                states.append({\n                    \"id\": \"fetching\",\n                    \"name\": \"Fetching\",\n                    \"description\": f\"HTTP operations via {imp.get('module')}\",\n                    \"inferred_from\": f\"import:{imp.get('module')}\"\n                })\n        elif cat == \"database\":\n            if not any(s[\"id\"] == \"querying\" for s in states):\n                states.append({\n                    \"id\": \"querying\",\n                    \"name\": \"Querying\",\n                    \"description\": f\"Database ops via {imp.get('module')}\",\n                    \"inferred_from\": f\"import:{imp.get('module')}\"\n                })\n\n    # Terminal state\n    states.append({\n        \"id\": \"complete\",\n        \"name\": \"Complete\",\n        \"description\": \"Terminal state\",\n        \"inferred_from\": \"exit_point\"\n    })\n\n    # Deduplicate\n    seen = set()\n    unique = []\n    for s in states:\n        if s[\"id\"] not in seen:\n            seen.add(s[\"id\"])\n            unique.append(s)\n\n    return {\"states\": unique}", "args": ["params"], "returns": "dict", "moduleColor": "#e74c3c", "moduleName": "decoder_compute"}, {"id": "decoder_compute.inferTransitions", "type": "function", "label": "inferTransitions", "direction": "inbound", "parent": "decoder_compute", "line": 697, "endLine": 782, "signature": "(params) -> dict", "docstring": "Infer transitions and guards from control flow.", "source": "def inferTransitions(params: dict) -> dict:\n    \"\"\"Infer transitions and guards from control flow.\"\"\"\n    controlFlow = params.get(\"controlFlow\", {})\n    states = params.get(\"inferredStates\", [])\n    functions = params.get(\"functions\", [])\n\n    transitions = []\n    gates = []\n    tId = 0\n    gId = 0\n\n    stateIds = [s[\"id\"] for s in states]\n\n    # Infer gates from control flow branches first\n    nodes = controlFlow.get(\"nodes\", [])\n    gateConditions = []\n    for node in nodes:\n        if node.get(\"type\") == \"branch\":\n            label = node.get(\"label\", \"\")\n            if label.startswith(\"if \"):\n                cond = label[3:]\n                gateId = f\"g{gId}\"\n                gates.append({\n                    \"id\": gateId,\n                    \"type\": \"expression\",\n                    \"expression\": cond,\n                    \"inferred_from\": f\"line:{node.get('line')}\"\n                })\n                gateConditions.append(gateId)\n                gId += 1\n\n    # Build transitions from state pairs with optional gate associations\n    gateIdx = 0\n    for i, state in enumerate(states[:-1]):\n        nextState = states[i + 1] if i + 1 < len(states) else None\n        if nextState:\n            event = f\"{state['id'].upper()}_DONE\"\n            trans = {\n                \"id\": f\"t{tId}\",\n                \"from\": state[\"id\"],\n                \"to\": nextState[\"id\"],\n                \"on_event\": event,\n                \"inferred_from\": \"state_sequence\"\n            }\n            # Associate a gate with validation/check transitions\n            if any(kw in state[\"id\"] for kw in [\"validat\", \"check\", \"verify\"]):\n                if gateIdx < len(gateConditions):\n                    trans[\"gates\"] = [gateConditions[gateIdx]]\n                    gateIdx += 1\n            transitions.append(trans)\n            tId += 1\n\n    # Add error transition if error state exists\n    if \"error\" in stateIds:\n        # Add hasError gate\n        errorGateId = f\"g{gId}\"\n        gates.append({\n            \"id\": errorGateId,\n            \"type\": \"expression\",\n            \"expression\": \"error is not None\",\n            \"inferred_from\": \"error_pattern\"\n        })\n        gId += 1\n\n        for state in states:\n            if state[\"id\"] not in (\"error\", \"complete\"):\n                transitions.append({\n                    \"id\": f\"t{tId}\",\n                    \"from\": state[\"id\"],\n                    \"to\": \"error\",\n                    \"on_event\": \"ERROR\",\n                    \"gates\": [errorGateId],\n                    \"inferred_from\": \"error_pattern\"\n                })\n                tId += 1\n\n    # Reset transition\n    transitions.append({\n        \"id\": f\"t{tId}\",\n        \"from\": \"*\",\n        \"to\": \"idle\",\n        \"on_event\": \"RESET\",\n        \"inferred_from\": \"convention\"\n    })\n\n    return {\"transitions\": transitions, \"gates\": gates}", "args": ["params"], "returns": "dict", "moduleColor": "#e74c3c", "moduleName": "decoder_compute"}, {"id": "decoder_compute.inferActions", "type": "function", "label": "inferActions", "direction": "inbound", "parent": "decoder_compute", "line": 785, "endLine": 834, "signature": "(params) -> dict", "docstring": "Infer actions from function calls and side effects.", "source": "def inferActions(params: dict) -> dict:\n    \"\"\"Infer actions from function calls and side effects.\"\"\"\n    functions = params.get(\"functions\", [])\n    imports = params.get(\"imports\", [])\n    controlFlow = params.get(\"controlFlow\", {})\n\n    actions = []\n    aId = 0\n\n    importSemantics = {i.get(\"module\", \"\").split(\".\")[0]: i.get(\"semantic\", {})\n                       for i in imports if i.get(\"module\")}\n\n    for fn in functions:\n        name = fn.get(\"name\", \"\")\n        if name.startswith(\"_\"):\n            continue\n\n        effects = fn.get(\"sideEffects\", [])\n        for effect in effects:\n            if effect.get(\"type\") == \"call\":\n                callName = effect.get(\"name\", \"\")\n                root = callName.split(\".\")[0]\n                semantic = importSemantics.get(root, {})\n                cat = semantic.get(\"category\", \"compute\")\n\n                actionType = \"compute\"\n                if cat == \"observability\":\n                    actionType = \"emit\"\n                elif cat in (\"filesystem\", \"database\"):\n                    actionType = \"compute\"\n\n                actions.append({\n                    \"id\": f\"a{aId}\",\n                    \"name\": f\"call_{callName.replace('.', '_')}\",\n                    \"type\": actionType,\n                    \"compute_unit\": f\"impl:{callName}\",\n                    \"inferred_from\": f\"function:{name}\",\n                    \"line\": effect.get(\"line\")\n                })\n                aId += 1\n\n    # Deduplicate by name\n    seen = set()\n    unique = []\n    for a in actions:\n        if a[\"name\"] not in seen:\n            seen.add(a[\"name\"])\n            unique.append(a)\n\n    return {\"actions\": unique[:20]}  # Limit to 20 actions", "args": ["params"], "returns": "dict", "moduleColor": "#e74c3c", "moduleName": "decoder_compute"}, {"id": "decoder_compute.generateBlueprint", "type": "function", "label": "generateBlueprint", "direction": "inbound", "parent": "decoder_compute", "line": 837, "endLine": 929, "signature": "(params) -> dict", "docstring": "Assemble final L++ blueprint.", "source": "def generateBlueprint(params: dict) -> dict:\n    \"\"\"Assemble final L++ blueprint.\"\"\"\n    filePath = params.get(\"filePath\", \"decoded\")\n    states = params.get(\"inferredStates\", [])\n    transitions = params.get(\"inferredTransitions\", [])\n    gates = params.get(\"inferredGates\", [])\n    actions = params.get(\"inferredActions\", [])\n    imports = params.get(\"imports\", [])\n\n    baseName = os.path.basename(filePath).replace(\".py\", \"\") if filePath else \\\n        \"decoded\"\n\n    # Build context schema from function args\n    contextProps = {}\n    for imp in imports:\n        cat = imp.get(\"semantic\", {}).get(\"category\")\n        if cat == \"http\":\n            contextProps[\"response\"] = {\"type\": \"object\"}\n        elif cat == \"database\":\n            contextProps[\"queryResult\"] = {\"type\": \"array\"}\n    contextProps[\"error\"] = {\"type\": \"string\"}\n    contextProps[\"result\"] = {\"type\": \"object\"}\n\n    # Build states dict\n    statesDict = {}\n    for s in states:\n        statesDict[s[\"id\"]] = {\n            \"name\": s.get(\"name\", s[\"id\"]),\n            \"description\": s.get(\"description\", \"\")\n        }\n\n    # Build gates dict\n    gatesDict = {}\n    for g in gates:\n        gatesDict[g[\"id\"]] = {\n            \"type\": g.get(\"type\", \"expression\"),\n            \"expression\": g.get(\"expression\", \"true\")\n        }\n\n    # Build actions dict\n    actionsDict = {}\n    for a in actions:\n        actionsDict[a[\"id\"]] = {\n            \"type\": a.get(\"type\", \"compute\"),\n            \"compute_unit\": a.get(\"compute_unit\", \"\"),\n            \"description\": f\"Inferred from {a.get('inferred_from', 'code')}\"\n        }\n\n    # Build transitions array\n    transArr = []\n    for t in transitions:\n        trans = {\n            \"id\": t[\"id\"],\n            \"from\": t[\"from\"],\n            \"to\": t[\"to\"],\n            \"on_event\": t[\"on_event\"]\n        }\n        # Include gates if present\n        if t.get(\"gates\"):\n            trans[\"gates\"] = t[\"gates\"]\n        transArr.append(trans)\n\n    blueprint = {\n        \"$schema\": \"lpp/v0.1\",\n        \"id\": f\"decoded_{baseName}\",\n        \"name\": f\"Decoded: {baseName}\",\n        \"version\": \"1.0.0\",\n        \"description\": f\"Auto-decoded from {filePath}\",\n        \"context_schema\": {\"properties\": contextProps},\n        \"states\": statesDict,\n        \"transitions\": transArr,\n        \"gates\": gatesDict,\n        \"actions\": actionsDict,\n        \"entry_state\": states[0][\"id\"] if states else \"idle\",\n        \"terminal_states\": [\"complete\", \"error\"]\n    }\n\n    report = {\n        \"source\": filePath,\n        \"statesCount\": len(states),\n        \"transitionsCount\": len(transitions),\n        \"gatesCount\": len(gates),\n        \"actionsCount\": len(actions),\n        \"importsAnalyzed\": len(imports),\n        \"importCategories\": list(set(i.get(\"semantic\", {}).get(\"category\")\n                                     for i in imports))\n    }\n\n    return {\n        \"blueprint\": blueprint,\n        \"json\": json.dumps(blueprint, indent=2),\n        \"report\": report\n    }", "args": ["params"], "returns": "dict", "moduleColor": "#e74c3c", "moduleName": "decoder_compute"}, {"id": "decoder_compute.clearState", "type": "function", "label": "clearState", "direction": "inbound", "parent": "decoder_compute", "line": 932, "endLine": 948, "signature": "(params) -> dict", "docstring": "Reset all analysis state.", "source": "def clearState(params: dict) -> dict:\n    \"\"\"Reset all analysis state.\"\"\"\n    return {\n        \"ast\": None,\n        \"imports\": None,\n        \"functions\": None,\n        \"classes\": None,\n        \"controlFlow\": None,\n        \"inferredStates\": None,\n        \"inferredTransitions\": None,\n        \"inferredActions\": None,\n        \"inferredGates\": None,\n        \"blueprint\": None,\n        \"blueprintJson\": None,\n        \"analysisReport\": None,\n        \"error\": None\n    }", "args": ["params"], "returns": "dict", "moduleColor": "#e74c3c", "moduleName": "decoder_compute"}, {"id": "decoder_compute.walk", "type": "function", "label": "walk", "direction": "inbound", "parent": "decoder_compute", "line": 124, "endLine": 158, "signature": "(node)", "docstring": null, "source": "    def walk(node):\n        if isinstance(node, dict):\n            ntype = node.get(\"_type\")\n            if ntype == \"Import\":\n                for alias in node.get(\"names\", []):\n                    name = alias.get(\"name\", \"\")\n                    modName = name.split(\".\")[0]\n                    imports.append({\n                        \"module\": name,\n                        \"alias\": alias.get(\"asname\"),\n                        \"semantic\": IMPORT_SEMANTICS.get(modName, {\n                            \"category\": \"unknown\",\n                            \"actions\": []\n                        }),\n                        \"line\": node.get(\"lineno\")\n                    })\n            elif ntype == \"ImportFrom\":\n                mod = node.get(\"module\", \"\")\n                modName = mod.split(\".\")[0] if mod else \"\"\n                for alias in node.get(\"names\", []):\n                    imports.append({\n                        \"module\": mod,\n                        \"name\": alias.get(\"name\"),\n                        \"alias\": alias.get(\"asname\"),\n                        \"semantic\": IMPORT_SEMANTICS.get(modName, {\n                            \"category\": \"unknown\",\n                            \"actions\": []\n                        }),\n                        \"line\": node.get(\"lineno\")\n                    })\n            for v in node.values():\n                walk(v)\n        elif isinstance(node, list):\n            for item in node:\n                walk(item)", "args": ["node"], "returns": null, "moduleColor": "#e74c3c", "moduleName": "decoder_compute"}, {"id": "decoder_compute.extractFn", "type": "function", "label": "extractFn", "direction": "inbound", "parent": "decoder_compute", "line": 174, "endLine": 195, "signature": "(node, className)", "docstring": null, "source": "    def extractFn(node, className=None):\n        if node.get(\"_type\") in (\"FunctionDef\", \"AsyncFunctionDef\"):\n            args = []\n            for arg in node.get(\"args\", {}).get(\"args\", []):\n                args.append(arg.get(\"arg\"))\n            returns = _extractType(node.get(\"returns\"))\n            decorators = [_extractName(d) for d in node.get(\"decorator_list\",\n                                                            [])]\n            # Analyze body for side effects\n            sideEffects = _findSideEffects(node.get(\"body\", []), importedNames)\n            fnData = {\n                \"name\": node.get(\"name\"),\n                \"args\": args,\n                \"returns\": returns,\n                \"decorators\": decorators,\n                \"isAsync\": node.get(\"_type\") == \"AsyncFunctionDef\",\n                \"line\": node.get(\"lineno\"),\n                \"sideEffects\": sideEffects,\n                \"className\": className,\n                \"docstring\": _extractDocstring(node)\n            }\n            functions.append(fnData)", "args": ["node", "className"], "returns": null, "moduleColor": "#e74c3c", "moduleName": "decoder_compute"}, {"id": "decoder_compute.walk", "type": "function", "label": "walk", "direction": "inbound", "parent": "decoder_compute", "line": 197, "endLine": 219, "signature": "(node, className)", "docstring": null, "source": "    def walk(node, className=None):\n        if isinstance(node, dict):\n            ntype = node.get(\"_type\")\n            if ntype == \"ClassDef\":\n                bases = [_extractName(b) for b in node.get(\"bases\", [])]\n                classes.append({\n                    \"name\": node.get(\"name\"),\n                    \"bases\": bases,\n                    \"line\": node.get(\"lineno\"),\n                    \"docstring\": _extractDocstring(node)\n                })\n                for item in node.get(\"body\", []):\n                    walk(item, className=node.get(\"name\"))\n            elif ntype in (\"FunctionDef\", \"AsyncFunctionDef\"):\n                extractFn(node, className)\n                for item in node.get(\"body\", []):\n                    walk(item, className)\n            else:\n                for v in node.values():\n                    walk(v, className)\n        elif isinstance(node, list):\n            for item in node:\n                walk(item, className)", "args": ["node", "className"], "returns": null, "moduleColor": "#e74c3c", "moduleName": "decoder_compute"}, {"id": "decoder_compute.walk", "type": "function", "label": "walk", "direction": "inbound", "parent": "decoder_compute", "line": 275, "endLine": 299, "signature": "(node)", "docstring": null, "source": "    def walk(node):\n        if isinstance(node, dict):\n            ntype = node.get(\"_type\")\n            if ntype == \"Call\":\n                fname = _extractName(node.get(\"func\"))\n                root = fname.split(\".\")[0]\n                effects.append({\n                    \"type\": \"call\",\n                    \"name\": fname,\n                    \"isImported\": root in importedNames,\n                    \"line\": node.get(\"lineno\")\n                })\n            elif ntype == \"Assign\":\n                for t in node.get(\"targets\", []):\n                    tname = _extractName(t)\n                    effects.append({\n                        \"type\": \"assign\",\n                        \"target\": tname,\n                        \"line\": node.get(\"lineno\")\n                    })\n            for v in node.values():\n                walk(v)\n        elif isinstance(node, list):\n            for item in node:\n                walk(item)", "args": ["node"], "returns": null, "moduleColor": "#e74c3c", "moduleName": "decoder_compute"}, {"id": "decoder_compute.addNode", "type": "function", "label": "addNode", "direction": "inbound", "parent": "decoder_compute", "line": 314, "endLine": 323, "signature": "(label, ntype, line)", "docstring": null, "source": "    def addNode(label, ntype, line=None):\n        nid = f\"n{nodeId[0]}\"\n        nodeId[0] += 1\n        cfg[\"nodes\"].append({\n            \"id\": nid,\n            \"label\": label,\n            \"type\": ntype,\n            \"line\": line\n        })\n        return nid", "args": ["label", "ntype", "line"], "returns": null, "moduleColor": "#e74c3c", "moduleName": "decoder_compute"}, {"id": "decoder_compute.addEdge", "type": "function", "label": "addEdge", "direction": "inbound", "parent": "decoder_compute", "line": 325, "endLine": 326, "signature": "(src, dst, label)", "docstring": null, "source": "    def addEdge(src, dst, label=\"\"):\n        cfg[\"edges\"].append({\"from\": src, \"to\": dst, \"label\": label})", "args": ["src", "dst", "label"], "returns": null, "moduleColor": "#e74c3c", "moduleName": "decoder_compute"}, {"id": "decoder_compute.walkBody", "type": "function", "label": "walkBody", "direction": "inbound", "parent": "decoder_compute", "line": 328, "endLine": 419, "signature": "(body, prevId)", "docstring": null, "source": "    def walkBody(body, prevId=None):\n        lastId = prevId\n        for node in body:\n            if isinstance(node, dict):\n                ntype = node.get(\"_type\")\n                line = node.get(\"lineno\")\n\n                if ntype == \"If\":\n                    testStr = _exprToStr(node.get(\"test\", {}))\n                    ifId = addNode(f\"if {testStr}\", \"branch\", line)\n                    if lastId:\n                        addEdge(lastId, ifId)\n                    cfg[\"patterns\"][\"branch\"] = cfg[\"patterns\"].get(\"branch\",\n                                                                    0) + 1\n                    # True branch\n                    thenEnd = walkBody(node.get(\"body\", []), ifId)\n                    # False branch\n                    elseBody = node.get(\"orelse\", [])\n                    if elseBody:\n                        elseEnd = walkBody(elseBody, ifId)\n                        mergeId = addNode(\"merge\", \"merge\", line)\n                        if thenEnd:\n                            addEdge(thenEnd, mergeId, \"then\")\n                        if elseEnd:\n                            addEdge(elseEnd, mergeId, \"else\")\n                        lastId = mergeId\n                    else:\n                        lastId = thenEnd or ifId\n\n                elif ntype == \"For\":\n                    iterStr = _exprToStr(node.get(\"iter\", {}))\n                    forId = addNode(f\"for {iterStr}\", \"loop\", line)\n                    if lastId:\n                        addEdge(lastId, forId)\n                    cfg[\"patterns\"][\"loop\"] = cfg[\"patterns\"].get(\"loop\", 0)+1\n                    bodyEnd = walkBody(node.get(\"body\", []), forId)\n                    if bodyEnd:\n                        addEdge(bodyEnd, forId, \"next\")\n                    lastId = forId\n\n                elif ntype == \"While\":\n                    testStr = _exprToStr(node.get(\"test\", {}))\n                    whileId = addNode(f\"while {testStr}\", \"loop\", line)\n                    if lastId:\n                        addEdge(lastId, whileId)\n                    cfg[\"patterns\"][\"loop\"] = cfg[\"patterns\"].get(\"loop\", 0)+1\n                    bodyEnd = walkBody(node.get(\"body\", []), whileId)\n                    if bodyEnd:\n                        addEdge(bodyEnd, whileId, \"loop\")\n                    lastId = whileId\n\n                elif ntype == \"Try\":\n                    tryId = addNode(\"try\", \"errorHandling\", line)\n                    if lastId:\n                        addEdge(lastId, tryId)\n                    cfg[\"patterns\"][\"errorHandling\"] = cfg[\"patterns\"].get(\n                        \"errorHandling\", 0) + 1\n                    bodyEnd = walkBody(node.get(\"body\", []), tryId)\n                    handlers = node.get(\"handlers\", [])\n                    handlerEnds = []\n                    for h in handlers:\n                        htype = _extractName(h.get(\"type\"))\n                        hId = addNode(f\"except {htype}\", \"errorRecovery\", line)\n                        addEdge(tryId, hId, \"error\")\n                        hEnd = walkBody(h.get(\"body\", []), hId)\n                        if hEnd:\n                            handlerEnds.append(hEnd)\n                    finallyBody = node.get(\"finalbody\", [])\n                    if finallyBody:\n                        finId = addNode(\"finally\", \"cleanup\", line)\n                        if bodyEnd:\n                            addEdge(bodyEnd, finId, \"ok\")\n                        for he in handlerEnds:\n                            addEdge(he, finId)\n                        lastId = walkBody(finallyBody, finId) or finId\n                    else:\n                        lastId = bodyEnd\n\n                elif ntype == \"Return\":\n                    retId = addNode(\"return\", \"terminal\", line)\n                    if lastId:\n                        addEdge(lastId, retId)\n                    lastId = None\n\n                elif ntype in (\"Expr\", \"Assign\", \"AugAssign\"):\n                    label = _stmtLabel(node)\n                    stmtId = addNode(label, \"statement\", line)\n                    if lastId:\n                        addEdge(lastId, stmtId)\n                    lastId = stmtId\n\n        return lastId", "args": ["body", "prevId"], "returns": null, "moduleColor": "#e74c3c", "moduleName": "decoder_compute"}, {"id": "decoder_compute.to_state_name", "type": "function", "label": "to_state_name", "direction": "inbound", "parent": "decoder_compute", "line": 504, "endLine": 507, "signature": "(fn_name)", "docstring": "Convert snake_case to Title Case", "source": "        def to_state_name(fn_name):\n            \"\"\"Convert snake_case to Title Case\"\"\"\n            words = fn_name.replace(\"_\", \" \").split()\n            return \" \".join(w.capitalize() for w in words)", "args": ["fn_name"], "returns": null, "moduleColor": "#e74c3c", "moduleName": "decoder_compute"}, {"id": "scraper_compute", "type": "module", "label": "scraper_compute", "metrics": {"fanIn": 4, "fanOut": 8, "instability": 0.667, "internalEdges": 0, "externalCallCount": 8, "localCallCount": 0, "callsByCategory": {"pip": 2, "stdlib": 6}, "localDependencies": []}, "moduleColor": "#3498db", "moduleName": "scraper_compute"}, {"id": "scraper_compute.arxiv", "type": "function", "label": "arxiv", "direction": "inbound", "parent": "scraper_compute", "line": 40, "endLine": 102, "signature": "(params) -> Dict[]", "docstring": "Search arXiv using their API.\nInput: query, maxResults\nOutput: results (list of papers), error", "source": "def arxiv(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Search arXiv using their API.\n    Input: query, maxResults\n    Output: results (list of papers), error\n    \"\"\"\n    query = params.get(\"query\", \"\")\n    maxResults = params.get(\"maxResults\", 10) or 10\n\n    if not query:\n        return {\"results\": None, \"error\": \"No query provided\"}\n\n    try:\n        # arXiv API\n        q = urllib.parse.quote(query)\n        url = (\n            f\"http://export.arxiv.org/api/query?\"\n            f\"search_query=all:{q}&start=0&max_results={maxResults}\"\n        )\n\n        xml = _httpGet(url)\n        root = ET.fromstring(xml)\n\n        ns = {\"atom\": \"http://www.w3.org/2005/Atom\"}\n        results = []\n\n        for entry in root.findall(\"atom:entry\", ns):\n            title = entry.find(\"atom:title\", ns)\n            summary = entry.find(\"atom:summary\", ns)\n            published = entry.find(\"atom:published\", ns)\n            arxivId = entry.find(\"atom:id\", ns)\n\n            authors = []\n            for author in entry.findall(\"atom:author\", ns):\n                name = author.find(\"atom:name\", ns)\n                if name is not None:\n                    authors.append(name.text)\n\n            # Extract arXiv ID from URL\n            paperId = \"\"\n            if arxivId is not None and arxivId.text:\n                match = re.search(r\"abs/(.+)$\", arxivId.text)\n                if match:\n                    paperId = match.group(1)\n\n            year = \"\"\n            if published is not None and published.text:\n                year = published.text[:4]\n\n            results.append({\n                \"id\": paperId,\n                \"title\": title.text.strip() if title is not None else \"\",\n                \"authors\": authors,\n                \"abstract\": summary.text.strip() if summary is not None else \"\",\n                \"url\": f\"https://arxiv.org/abs/{paperId}\",\n                \"year\": year,\n                \"source\": \"arxiv\"\n            })\n\n        return {\"results\": results, \"error\": None}\n\n    except Exception as e:\n        return {\"results\": None, \"error\": f\"arXiv error: {e}\"}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#3498db", "moduleName": "scraper_compute"}, {"id": "scraper_compute.semanticScholar", "type": "function", "label": "semanticScholar", "direction": "inbound", "parent": "scraper_compute", "line": 105, "endLine": 148, "signature": "(params) -> Dict[]", "docstring": "Search Semantic Scholar using their API.\nInput: query, maxResults\nOutput: results, error", "source": "def semanticScholar(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Search Semantic Scholar using their API.\n    Input: query, maxResults\n    Output: results, error\n    \"\"\"\n    query = params.get(\"query\", \"\")\n    maxResults = params.get(\"maxResults\", 10) or 10\n\n    if not query:\n        return {\"results\": None, \"error\": \"No query provided\"}\n\n    try:\n        q = urllib.parse.quote(query)\n        url = (\n            f\"https://api.semanticscholar.org/graph/v1/paper/search?\"\n            f\"query={q}&limit={maxResults}\"\n            f\"&fields=paperId,title,authors,abstract,year,url\"\n        )\n\n        headers = {\"Accept\": \"application/json\"}\n        resp = _httpGet(url, headers)\n\n        import json\n        data = json.loads(resp)\n        papers = data.get(\"data\", [])\n\n        results = []\n        for p in papers:\n            authors = [a.get(\"name\", \"\") for a in p.get(\"authors\", [])]\n            results.append({\n                \"id\": p.get(\"paperId\", \"\"),\n                \"title\": p.get(\"title\", \"\"),\n                \"authors\": authors,\n                \"abstract\": p.get(\"abstract\", \"\") or \"\",\n                \"url\": p.get(\"url\", \"\"),\n                \"year\": str(p.get(\"year\", \"\")),\n                \"source\": \"semantic_scholar\"\n            })\n\n        return {\"results\": results, \"error\": None}\n\n    except Exception as e:\n        return {\"results\": None, \"error\": f\"Semantic Scholar error: {e}\"}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#3498db", "moduleName": "scraper_compute"}, {"id": "scraper_compute.web", "type": "function", "label": "web", "direction": "inbound", "parent": "scraper_compute", "line": 151, "endLine": 207, "signature": "(params) -> Dict[]", "docstring": "General web search via DuckDuckGo HTML (no API key needed).\nInput: query, maxResults\nOutput: results, error", "source": "def web(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    General web search via DuckDuckGo HTML (no API key needed).\n    Input: query, maxResults\n    Output: results, error\n    \"\"\"\n    query = params.get(\"query\", \"\")\n    maxResults = params.get(\"maxResults\", 10) or 10\n\n    if not query:\n        return {\"results\": None, \"error\": \"No query provided\"}\n\n    if not HAS_BS4:\n        return {\"results\": None, \"error\": \"bs4 not installed: pip install bs4\"}\n\n    try:\n        q = urllib.parse.quote(query)\n        url = f\"https://html.duckduckgo.com/html/?q={q}\"\n\n        headers = {\n            \"User-Agent\": (\n                \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) \"\n                \"AppleWebKit/537.36\"\n            )\n        }\n\n        html = _httpGet(url, headers)\n        soup = BeautifulSoup(html, \"html.parser\")\n\n        results = []\n        for item in soup.select(\".result\")[:maxResults]:\n            titleEl = item.select_one(\".result__title a\")\n            snippetEl = item.select_one(\".result__snippet\")\n\n            if titleEl:\n                title = titleEl.get_text(strip=True)\n                href = titleEl.get(\"href\", \"\")\n                # DDG wraps URLs\n                if \"uddg=\" in href:\n                    match = re.search(r\"uddg=([^&]+)\", href)\n                    if match:\n                        href = urllib.parse.unquote(match.group(1))\n\n                results.append({\n                    \"id\": href,\n                    \"title\": title,\n                    \"authors\": [],\n                    \"abstract\": snippetEl.get_text(strip=True) if snippetEl else \"\",\n                    \"url\": href,\n                    \"year\": \"\",\n                    \"source\": \"web\"\n                })\n\n        return {\"results\": results, \"error\": None}\n\n    except Exception as e:\n        return {\"results\": None, \"error\": f\"Web search error: {e}\"}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#3498db", "moduleName": "scraper_compute"}, {"id": "scraper_compute.fetchDetail", "type": "function", "label": "fetchDetail", "direction": "inbound", "parent": "scraper_compute", "line": 210, "endLine": 309, "signature": "(params) -> Dict[]", "docstring": "Fetch detailed info for a paper.\nInput: id, source\nOutput: detail, error", "source": "def fetchDetail(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Fetch detailed info for a paper.\n    Input: id, source\n    Output: detail, error\n    \"\"\"\n    paperId = params.get(\"id\", \"\")\n    source = params.get(\"source\", \"arxiv\")\n\n    if not paperId:\n        return {\"detail\": None, \"error\": \"No paper ID\"}\n\n    try:\n        if source == \"arxiv\":\n            url = (\n                f\"http://export.arxiv.org/api/query?\"\n                f\"id_list={paperId}\"\n            )\n            xml = _httpGet(url)\n            root = ET.fromstring(xml)\n            ns = {\"atom\": \"http://www.w3.org/2005/Atom\"}\n\n            entry = root.find(\"atom:entry\", ns)\n            if entry is None:\n                return {\"detail\": None, \"error\": \"Paper not found\"}\n\n            title = entry.find(\"atom:title\", ns)\n            summary = entry.find(\"atom:summary\", ns)\n            published = entry.find(\"atom:published\", ns)\n            updated = entry.find(\"atom:updated\", ns)\n\n            authors = []\n            for a in entry.findall(\"atom:author\", ns):\n                name = a.find(\"atom:name\", ns)\n                if name is not None:\n                    authors.append(name.text)\n\n            # Get PDF link\n            pdfUrl = \"\"\n            for link in entry.findall(\"atom:link\", ns):\n                if link.get(\"title\") == \"pdf\":\n                    pdfUrl = link.get(\"href\", \"\")\n\n            categories = []\n            for cat in entry.findall(\"atom:category\", ns):\n                term = cat.get(\"term\")\n                if term:\n                    categories.append(term)\n\n            detail = {\n                \"id\": paperId,\n                \"title\": title.text.strip() if title is not None else \"\",\n                \"authors\": authors,\n                \"abstract\": summary.text.strip() if summary is not None else \"\",\n                \"published\": published.text if published is not None else \"\",\n                \"updated\": updated.text if updated is not None else \"\",\n                \"url\": f\"https://arxiv.org/abs/{paperId}\",\n                \"pdfUrl\": pdfUrl or f\"https://arxiv.org/pdf/{paperId}.pdf\",\n                \"categories\": categories,\n                \"source\": \"arxiv\"\n            }\n\n            return {\"detail\": detail, \"error\": None}\n\n        elif source == \"semantic_scholar\":\n            url = (\n                f\"https://api.semanticscholar.org/graph/v1/paper/{paperId}\"\n                f\"?fields=paperId,title,authors,abstract,year,url,\"\n                f\"citationCount,referenceCount,venue,openAccessPdf\"\n            )\n            headers = {\"Accept\": \"application/json\"}\n            resp = _httpGet(url, headers)\n\n            import json\n            p = json.loads(resp)\n\n            authors = [a.get(\"name\", \"\") for a in p.get(\"authors\", [])]\n            pdfInfo = p.get(\"openAccessPdf\") or {}\n\n            detail = {\n                \"id\": p.get(\"paperId\", \"\"),\n                \"title\": p.get(\"title\", \"\"),\n                \"authors\": authors,\n                \"abstract\": p.get(\"abstract\", \"\") or \"\",\n                \"year\": str(p.get(\"year\", \"\")),\n                \"url\": p.get(\"url\", \"\"),\n                \"pdfUrl\": pdfInfo.get(\"url\", \"\"),\n                \"citationCount\": p.get(\"citationCount\", 0),\n                \"referenceCount\": p.get(\"referenceCount\", 0),\n                \"venue\": p.get(\"venue\", \"\"),\n                \"source\": \"semantic_scholar\"\n            }\n\n            return {\"detail\": detail, \"error\": None}\n\n        else:\n            return {\"detail\": None, \"error\": f\"Unknown source: {source}\"}\n\n    except Exception as e:\n        return {\"detail\": None, \"error\": f\"Fetch error: {e}\"}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#3498db", "moduleName": "scraper_compute"}, {"id": "urllib.parse", "type": "dependency", "label": "parse", "direction": "outbound", "category": "stdlib", "moduleColor": "#3498db", "moduleName": "scraper_compute"}, {"id": "urllib.request", "type": "dependency", "label": "request", "direction": "outbound", "category": "stdlib", "moduleColor": "#3498db", "moduleName": "scraper_compute"}, {"id": "xml.etree.ElementTree", "type": "dependency", "label": "ElementTree", "direction": "outbound", "category": "stdlib", "moduleColor": "#3498db", "moduleName": "scraper_compute"}, {"id": "requests", "type": "dependency", "label": "requests", "direction": "outbound", "category": "pip", "moduleColor": "#3498db", "moduleName": "scraper_compute"}, {"id": "bs4", "type": "dependency", "label": "bs4", "direction": "outbound", "category": "pip", "moduleColor": "#3498db", "moduleName": "scraper_compute"}, {"id": "migrator_compute", "type": "module", "label": "migrator_compute", "metrics": {"fanIn": 15, "fanOut": 7, "instability": 0.318, "internalEdges": 9, "externalCallCount": 14, "localCallCount": 0, "callsByCategory": {"stdlib": 14}, "localDependencies": []}, "moduleColor": "#2ecc71", "moduleName": "migrator_compute"}, {"id": "migrator_compute.ChangeType", "type": "class", "label": "ChangeType", "direction": "inbound", "parent": "migrator_compute", "line": 31, "endLine": 40, "signature": null, "docstring": null, "source": "class ChangeType:\n    ADD_FIELD = \"add_field\"\n    REMOVE_FIELD = \"remove_field\"\n    RENAME_FIELD = \"rename_field\"\n    CONVERT_TYPE = \"convert_type\"\n    MOVE_FIELD = \"move_field\"\n    TRANSFORM_VALUE = \"transform_value\"\n    RENAME_EVENT = \"rename_event\"\n    MERGE_FIELDS = \"merge_fields\"\n    SPLIT_FIELD = \"split_field\"", "args": null, "returns": null, "moduleColor": "#2ecc71", "moduleName": "migrator_compute"}, {"id": "migrator_compute.load_blueprint", "type": "function", "label": "load_blueprint", "direction": "inbound", "parent": "migrator_compute", "line": 115, "endLine": 135, "signature": "(params) -> Dict[]", "docstring": "Load an L++ blueprint from a JSON file for migration.", "source": "def load_blueprint(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Load an L++ blueprint from a JSON file for migration.\"\"\"\n    path = params.get(\"path\")\n    if not path:\n        return {\"blueprint\": None, \"path\": None, \"error\": \"No path provided\"}\n\n    try:\n        filePath = Path(path)\n        if not filePath.exists():\n            return {\"blueprint\": None, \"path\": None,\n                    \"error\": f\"File not found: {path}\"}\n\n        with open(filePath) as f:\n            blueprint = json.load(f)\n\n        return {\"blueprint\": blueprint, \"path\": str(filePath), \"error\": None}\n    except json.JSONDecodeError as e:\n        return {\"blueprint\": None, \"path\": None,\n                \"error\": f\"Invalid JSON: {e}\"}\n    except Exception as e:\n        return {\"blueprint\": None, \"path\": None, \"error\": str(e)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#2ecc71", "moduleName": "migrator_compute"}, {"id": "migrator_compute.detect_version", "type": "function", "label": "detect_version", "direction": "inbound", "parent": "migrator_compute", "line": 138, "endLine": 156, "signature": "(params) -> Dict[]", "docstring": "Detect the schema version of a blueprint.", "source": "def detect_version(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Detect the schema version of a blueprint.\"\"\"\n    blueprint = params.get(\"blueprint\", {})\n\n    if not blueprint:\n        return {\"source_version\": None, \"error\": \"No blueprint provided\"}\n\n    # Check explicit $schema field\n    schema = blueprint.get(\"$schema\")\n    if schema:\n        if schema in SCHEMA_VERSIONS:\n            return {\"source_version\": schema, \"error\": None}\n        # Try to normalize version\n        if schema.startswith(\"lpp/v\"):\n            return {\"source_version\": schema, \"error\": None}\n\n    # Heuristic detection based on structure\n    detected = _detect_version_heuristic(blueprint)\n    return {\"source_version\": detected, \"error\": None}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#2ecc71", "moduleName": "migrator_compute"}, {"id": "migrator_compute.get_latest_version", "type": "function", "label": "get_latest_version", "direction": "inbound", "parent": "migrator_compute", "line": 193, "endLine": 195, "signature": "(params) -> Dict[]", "docstring": "Get the latest schema version.", "source": "def get_latest_version(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Get the latest schema version.\"\"\"\n    return {\"version\": LATEST_VERSION}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#2ecc71", "moduleName": "migrator_compute"}, {"id": "migrator_compute.list_migrations", "type": "function", "label": "list_migrations", "direction": "inbound", "parent": "migrator_compute", "line": 202, "endLine": 235, "signature": "(params) -> Dict[]", "docstring": "List all available migrations (built-in and custom).", "source": "def list_migrations(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"List all available migrations (built-in and custom).\"\"\"\n    migrations = []\n\n    # Add built-in migrations\n    for key, mig in BUILTIN_MIGRATIONS.items():\n        migrations.append({\n            \"key\": key,\n            \"from\": mig[\"from_version\"],\n            \"to\": mig[\"to_version\"],\n            \"description\": mig[\"description\"],\n            \"source\": \"builtin\",\n            \"change_count\": len(mig[\"changes\"])\n        })\n\n    # Load custom migrations from directory\n    if MIGRATIONS_DIR.exists():\n        for migFile in MIGRATIONS_DIR.glob(\"*.json\"):\n            try:\n                with open(migFile) as f:\n                    customMig = json.load(f)\n                key = f\"{customMig['from_version']}->{customMig['to_version']}\"\n                migrations.append({\n                    \"key\": key,\n                    \"from\": customMig[\"from_version\"],\n                    \"to\": customMig[\"to_version\"],\n                    \"description\": customMig.get(\"description\", \"Custom migration\"),\n                    \"source\": str(migFile),\n                    \"change_count\": len(customMig.get(\"changes\", []))\n                })\n            except (json.JSONDecodeError, KeyError):\n                continue\n\n    return {\"migrations\": migrations}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#2ecc71", "moduleName": "migrator_compute"}, {"id": "migrator_compute.plan_migration", "type": "function", "label": "plan_migration", "direction": "inbound", "parent": "migrator_compute", "line": 238, "endLine": 272, "signature": "(params) -> Dict[]", "docstring": "Plan the migration path from source to target version.", "source": "def plan_migration(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Plan the migration path from source to target version.\"\"\"\n    sourceVer = params.get(\"source_version\")\n    targetVer = params.get(\"target_version\")\n    availMigs = params.get(\"available_migrations\", [])\n\n    if not sourceVer:\n        return {\"plan\": [], \"error\": \"Source version not detected\"}\n    if not targetVer:\n        return {\"plan\": [], \"error\": \"Target version not specified\"}\n    if sourceVer == targetVer:\n        return {\"plan\": [], \"error\": None}\n\n    # Build migration graph\n    migGraph = {}\n    for mig in availMigs:\n        migGraph[mig[\"from\"]] = migGraph.get(mig[\"from\"], [])\n        migGraph[mig[\"from\"]].append(mig)\n\n    # Find path using BFS\n    queue = [(sourceVer, [])]\n    visited = {sourceVer}\n\n    while queue:\n        current, path = queue.pop(0)\n        if current == targetVer:\n            return {\"plan\": path, \"error\": None}\n\n        for mig in migGraph.get(current, []):\n            nextVer = mig[\"to\"]\n            if nextVer not in visited:\n                visited.add(nextVer)\n                queue.append((nextVer, path + [mig]))\n\n    return {\"plan\": [], \"error\": f\"No migration path from {sourceVer} to {targetVer}\"}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#2ecc71", "moduleName": "migrator_compute"}, {"id": "migrator_compute.analyze_changes", "type": "function", "label": "analyze_changes", "direction": "inbound", "parent": "migrator_compute", "line": 275, "endLine": 302, "signature": "(params) -> Dict[]", "docstring": "Analyze what changes will be made during migration.", "source": "def analyze_changes(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Analyze what changes will be made during migration.\"\"\"\n    blueprint = params.get(\"blueprint\", {})\n    plan = params.get(\"migration_plan\", [])\n\n    if not plan:\n        return {\"changes\": []}\n\n    allChanges = []\n    tempBp = copy.deepcopy(blueprint)\n\n    for step in plan:\n        migKey = f\"{step['from']}->{step['to']}\"\n        migDef = _get_migration_definition(migKey, step.get(\"source\"))\n\n        if not migDef:\n            continue\n\n        for change in migDef.get(\"changes\", []):\n            analyzed = _analyze_single_change(tempBp, change)\n            if analyzed:\n                analyzed[\"migration\"] = migKey\n                allChanges.append(analyzed)\n\n        # Apply to temp for next step analysis\n        tempBp = _apply_changes(tempBp, migDef.get(\"changes\", []))\n\n    return {\"changes\": allChanges}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#2ecc71", "moduleName": "migrator_compute"}, {"id": "migrator_compute.apply_migration", "type": "function", "label": "apply_migration", "direction": "inbound", "parent": "migrator_compute", "line": 450, "endLine": 479, "signature": "(params) -> Dict[]", "docstring": "Apply the full migration plan to the blueprint.", "source": "def apply_migration(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Apply the full migration plan to the blueprint.\"\"\"\n    blueprint = params.get(\"blueprint\", {})\n    plan = params.get(\"migration_plan\", [])\n\n    if not blueprint:\n        return {\"blueprint\": None, \"error\": \"No blueprint provided\"}\n\n    if not plan:\n        return {\"blueprint\": blueprint, \"error\": None}\n\n    migrated = copy.deepcopy(blueprint)\n\n    for step in plan:\n        migKey = f\"{step['from']}->{step['to']}\"\n        migDef = _get_migration_definition(migKey, step.get(\"source\"))\n\n        if not migDef:\n            return {\"blueprint\": None,\n                    \"error\": f\"Migration definition not found: {migKey}\"}\n\n        try:\n            migrated = _apply_changes(migrated, migDef.get(\"changes\", []))\n            # Update schema version\n            migrated[\"$schema\"] = step[\"to\"]\n        except Exception as e:\n            return {\"blueprint\": None,\n                    \"error\": f\"Migration failed at {migKey}: {str(e)}\"}\n\n    return {\"blueprint\": migrated, \"error\": None}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#2ecc71", "moduleName": "migrator_compute"}, {"id": "migrator_compute.dry_run", "type": "function", "label": "dry_run", "direction": "inbound", "parent": "migrator_compute", "line": 661, "endLine": 677, "signature": "(params) -> Dict[]", "docstring": "Preview migration without applying changes permanently.", "source": "def dry_run(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Preview migration without applying changes permanently.\"\"\"\n    blueprint = params.get(\"blueprint\", {})\n    plan = params.get(\"migration_plan\", [])\n\n    # Analyze changes\n    analysis = analyze_changes({\"blueprint\": blueprint, \"migration_plan\": plan})\n    changes = analysis.get(\"changes\", [])\n\n    # Apply to a copy for preview\n    result = apply_migration({\"blueprint\": blueprint, \"migration_plan\": plan})\n    previewBp = result.get(\"blueprint\")\n\n    return {\n        \"changes\": changes,\n        \"preview_blueprint\": previewBp\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#2ecc71", "moduleName": "migrator_compute"}, {"id": "migrator_compute.validate_blueprint", "type": "function", "label": "validate_blueprint", "direction": "inbound", "parent": "migrator_compute", "line": 684, "endLine": 777, "signature": "(params) -> Dict[]", "docstring": "Validate a blueprint against target schema version.", "source": "def validate_blueprint(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Validate a blueprint against target schema version.\"\"\"\n    blueprint = params.get(\"blueprint\", {})\n    targetVer = params.get(\"target_version\", LATEST_VERSION)\n\n    if not blueprint:\n        return {\"result\": {\"valid\": False, \"errors\": [\"No blueprint\"]}}\n\n    errors = []\n    warnings = []\n\n    # Required fields check\n    required = [\"$schema\", \"id\", \"name\", \"version\", \"states\", \"transitions\",\n                \"entry_state\", \"terminal_states\"]\n\n    for field in required:\n        if field not in blueprint:\n            errors.append(f\"Missing required field: {field}\")\n\n    # Schema version check\n    schema = blueprint.get(\"$schema\")\n    if schema != targetVer:\n        warnings.append(f\"Schema version mismatch: {schema} vs {targetVer}\")\n\n    # States validation\n    states = blueprint.get(\"states\", {})\n    entryState = blueprint.get(\"entry_state\")\n    terminalStates = blueprint.get(\"terminal_states\", [])\n\n    if entryState and entryState not in states:\n        errors.append(f\"Entry state '{entryState}' not in states\")\n\n    if isinstance(terminalStates, list):\n        for ts in terminalStates:\n            if ts not in states:\n                errors.append(f\"Terminal state '{ts}' not in states\")\n    elif isinstance(terminalStates, str):\n        errors.append(\"terminal_states should be array, not string\")\n\n    # Transitions validation\n    transitions = blueprint.get(\"transitions\", [])\n    if not isinstance(transitions, list):\n        errors.append(\"transitions should be an array\")\n    else:\n        for i, t in enumerate(transitions):\n            # Check required transition fields\n            if \"id\" not in t:\n                errors.append(f\"Transition {i} missing 'id'\")\n            if \"from\" not in t:\n                errors.append(f\"Transition {i} missing 'from'\")\n            if \"to\" not in t:\n                errors.append(f\"Transition {i} missing 'to'\")\n            if \"on_event\" not in t:\n                errors.append(f\"Transition {i} missing 'on_event'\")\n\n            # Check state references\n            fromState = t.get(\"from\")\n            toState = t.get(\"to\")\n            if fromState != \"*\" and fromState not in states:\n                errors.append(f\"Transition {t.get('id', i)}: \"\n                             f\"unknown from state '{fromState}'\")\n            if toState != \"*\" and toState not in states:\n                errors.append(f\"Transition {t.get('id', i)}: \"\n                             f\"unknown to state '{toState}'\")\n\n            # v0.1.2 check: gates should be array\n            if targetVer == \"lpp/v0.1.2\":\n                gates = t.get(\"gates\")\n                if gates is not None and not isinstance(gates, list):\n                    errors.append(f\"Transition {t.get('id', i)}: \"\n                                 \"gates should be array\")\n\n    # Gates validation\n    gates = blueprint.get(\"gates\", {})\n    if not isinstance(gates, dict):\n        errors.append(\"gates should be an object\")\n\n    # Actions validation\n    actions = blueprint.get(\"actions\", {})\n    if not isinstance(actions, dict):\n        errors.append(\"actions should be an object\")\n\n    # v0.1.2 specific: display field\n    if targetVer == \"lpp/v0.1.2\":\n        if \"display\" not in blueprint:\n            warnings.append(\"Missing optional 'display' field for v0.1.2\")\n\n    result = {\n        \"valid\": len(errors) == 0,\n        \"errors\": errors,\n        \"warnings\": warnings\n    }\n\n    return {\"result\": result}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#2ecc71", "moduleName": "migrator_compute"}, {"id": "migrator_compute.generate_report", "type": "function", "label": "generate_report", "direction": "inbound", "parent": "migrator_compute", "line": 784, "endLine": 875, "signature": "(params) -> Dict[]", "docstring": "Generate a migration report.", "source": "def generate_report(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Generate a migration report.\"\"\"\n    bpPath = params.get(\"blueprint_path\", \"unknown\")\n    sourceVer = params.get(\"source_version\", \"unknown\")\n    targetVer = params.get(\"target_version\", \"unknown\")\n    plan = params.get(\"migration_plan\", [])\n    changes = params.get(\"migration_changes\", [])\n    validation = params.get(\"validation_result\", {})\n    dryRun = params.get(\"dry_run_mode\", False)\n\n    lines = []\n    lines.append(\"=\" * 70)\n    lines.append(\"  L++ Schema Migration Report\")\n    lines.append(\"=\" * 70)\n    lines.append(\"\")\n    lines.append(f\"  Blueprint: {bpPath}\")\n    lines.append(f\"  Mode: {'DRY RUN (preview only)' if dryRun else 'LIVE'}\")\n    lines.append(\"\")\n    lines.append(f\"  Source Version: {sourceVer}\")\n    lines.append(f\"  Target Version: {targetVer}\")\n    lines.append(\"\")\n\n    # Migration Plan\n    lines.append(\"-\" * 70)\n    lines.append(\"  MIGRATION PLAN\")\n    lines.append(\"-\" * 70)\n\n    if not plan:\n        if sourceVer == targetVer:\n            lines.append(\"  No migration needed - already at target version\")\n        else:\n            lines.append(\"  No migration path found\")\n    else:\n        for i, step in enumerate(plan, 1):\n            lines.append(f\"  Step {i}: {step['from']} -> {step['to']}\")\n            lines.append(f\"          {step.get('description', 'No description')}\")\n    lines.append(\"\")\n\n    # Changes\n    if changes:\n        lines.append(\"-\" * 70)\n        lines.append(\"  CHANGES\")\n        lines.append(\"-\" * 70)\n\n        for change in changes:\n            chType = change.get(\"type\", \"unknown\")\n            desc = change.get(\"description\", \"\")\n            count = change.get(\"affected_count\", 0)\n            mig = change.get(\"migration\", \"\")\n            lines.append(f\"  [{chType.upper()}] {desc}\")\n            if mig:\n                lines.append(f\"          (migration: {mig})\")\n        lines.append(\"\")\n\n    # Validation Results\n    if validation:\n        lines.append(\"-\" * 70)\n        lines.append(\"  VALIDATION\")\n        lines.append(\"-\" * 70)\n\n        if validation.get(\"valid\"):\n            lines.append(\"  Status: PASSED\")\n        else:\n            lines.append(\"  Status: FAILED\")\n\n        errors = validation.get(\"errors\", [])\n        if errors:\n            lines.append(\"  Errors:\")\n            for err in errors:\n                lines.append(f\"    - {err}\")\n\n        warnings = validation.get(\"warnings\", [])\n        if warnings:\n            lines.append(\"  Warnings:\")\n            for warn in warnings:\n                lines.append(f\"    - {warn}\")\n    lines.append(\"\")\n\n    # Summary\n    lines.append(\"-\" * 70)\n    lines.append(\"  SUMMARY\")\n    lines.append(\"-\" * 70)\n    lines.append(f\"  Migration Steps: {len(plan)}\")\n    lines.append(f\"  Total Changes: {len(changes)}\")\n    if validation:\n        lines.append(f\"  Validation: {'PASSED' if validation.get('valid') else 'FAILED'}\")\n    if dryRun:\n        lines.append(\"  Note: This was a dry run. No changes were written.\")\n    lines.append(\"\")\n    lines.append(\"=\" * 70)\n\n    return {\"report\": \"\\n\".join(lines)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#2ecc71", "moduleName": "migrator_compute"}, {"id": "migrator_compute.export_migrated", "type": "function", "label": "export_migrated", "direction": "inbound", "parent": "migrator_compute", "line": 882, "endLine": 901, "signature": "(params) -> Dict[]", "docstring": "Export the migrated blueprint to a file.", "source": "def export_migrated(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Export the migrated blueprint to a file.\"\"\"\n    blueprint = params.get(\"blueprint\")\n    path = params.get(\"path\")\n\n    if not blueprint:\n        return {\"error\": \"No migrated blueprint to export\"}\n    if not path:\n        return {\"error\": \"No export path specified\"}\n\n    try:\n        outPath = Path(path)\n        outPath.parent.mkdir(parents=True, exist_ok=True)\n\n        with open(outPath, \"w\") as f:\n            json.dump(blueprint, f, indent=2)\n\n        return {\"error\": None}\n    except Exception as e:\n        return {\"error\": f\"Export failed: {str(e)}\"}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#2ecc71", "moduleName": "migrator_compute"}, {"id": "migrator_compute.batch_migrate", "type": "function", "label": "batch_migrate", "direction": "inbound", "parent": "migrator_compute", "line": 908, "endLine": 997, "signature": "(params) -> Dict[]", "docstring": "Migrate multiple blueprints.", "source": "def batch_migrate(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Migrate multiple blueprints.\"\"\"\n    paths = params.get(\"paths\", [])\n    targetVer = params.get(\"target_version\", LATEST_VERSION)\n\n    results = []\n\n    for path in paths:\n        result = {\"path\": path}\n\n        # Load\n        loadRes = load_blueprint({\"path\": path})\n        if loadRes.get(\"error\"):\n            result[\"status\"] = \"error\"\n            result[\"message\"] = loadRes[\"error\"]\n            results.append(result)\n            continue\n\n        blueprint = loadRes[\"blueprint\"]\n\n        # Detect version\n        verRes = detect_version({\"blueprint\": blueprint})\n        sourceVer = verRes.get(\"source_version\")\n\n        if sourceVer == targetVer:\n            result[\"status\"] = \"skipped\"\n            result[\"message\"] = \"Already at target version\"\n            results.append(result)\n            continue\n\n        # List and plan\n        migsRes = list_migrations({})\n        planRes = plan_migration({\n            \"source_version\": sourceVer,\n            \"target_version\": targetVer,\n            \"available_migrations\": migsRes.get(\"migrations\", [])\n        })\n\n        if planRes.get(\"error\"):\n            result[\"status\"] = \"error\"\n            result[\"message\"] = planRes[\"error\"]\n            results.append(result)\n            continue\n\n        # Apply\n        migRes = apply_migration({\n            \"blueprint\": blueprint,\n            \"migration_plan\": planRes.get(\"plan\", [])\n        })\n\n        if migRes.get(\"error\"):\n            result[\"status\"] = \"error\"\n            result[\"message\"] = migRes[\"error\"]\n            results.append(result)\n            continue\n\n        # Validate\n        valRes = validate_blueprint({\n            \"blueprint\": migRes[\"blueprint\"],\n            \"target_version\": targetVer\n        })\n\n        if not valRes.get(\"result\", {}).get(\"valid\"):\n            result[\"status\"] = \"warning\"\n            result[\"message\"] = \"Migration complete with validation warnings\"\n            result[\"validation\"] = valRes[\"result\"]\n        else:\n            result[\"status\"] = \"success\"\n            result[\"message\"] = f\"Migrated from {sourceVer} to {targetVer}\"\n\n        # Export (same path, backup original)\n        backupPath = path + \".bak\"\n        try:\n            import shutil\n            shutil.copy(path, backupPath)\n        except Exception:\n            pass\n\n        exportRes = export_migrated({\n            \"blueprint\": migRes[\"blueprint\"],\n            \"path\": path\n        })\n\n        if exportRes.get(\"error\"):\n            result[\"status\"] = \"error\"\n            result[\"message\"] = exportRes[\"error\"]\n\n        results.append(result)\n\n    return {\"results\": results}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#2ecc71", "moduleName": "migrator_compute"}, {"id": "migrator_compute.clear_migration", "type": "function", "label": "clear_migration", "direction": "inbound", "parent": "migrator_compute", "line": 1004, "endLine": 1012, "signature": "(params) -> Dict[]", "docstring": "Clear migration state.", "source": "def clear_migration(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Clear migration state.\"\"\"\n    return {\n        \"plan\": None,\n        \"changes\": None,\n        \"blueprint\": None,\n        \"validation\": None,\n        \"report\": None\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#2ecc71", "moduleName": "migrator_compute"}, {"id": "migrator_compute.unload_blueprint", "type": "function", "label": "unload_blueprint", "direction": "inbound", "parent": "migrator_compute", "line": 1015, "endLine": 1027, "signature": "(params) -> Dict[]", "docstring": "Unload all blueprint state.", "source": "def unload_blueprint(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Unload all blueprint state.\"\"\"\n    return {\n        \"blueprint\": None,\n        \"path\": None,\n        \"version\": None,\n        \"target\": None,\n        \"plan\": None,\n        \"changes\": None,\n        \"migrated\": None,\n        \"validation\": None,\n        \"report\": None\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#2ecc71", "moduleName": "migrator_compute"}, {"id": "packaging", "type": "dependency", "label": "packaging", "direction": "outbound", "category": "pip", "moduleColor": "#2ecc71", "moduleName": "migrator_compute"}, {"id": "scholar_compute", "type": "module", "label": "scholar_compute", "metrics": {"fanIn": 5, "fanOut": 8, "instability": 0.615, "internalEdges": 0, "externalCallCount": 12, "localCallCount": 0, "callsByCategory": {"stdlib": 9, "pip": 3}, "localDependencies": []}, "moduleColor": "#e67e22", "moduleName": "scholar_compute"}, {"id": "scholar_compute.initConfig", "type": "function", "label": "initConfig", "direction": "inbound", "parent": "scholar_compute", "line": 27, "endLine": 34, "signature": "(params) -> Dict[]", "docstring": "Initialize config from environment.", "source": "def initConfig(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Initialize config from environment.\"\"\"\n    return {\n        \"apiKey\": os.environ.get(\"OPENAI_API_KEY\", \"\"),\n        \"apiBase\": os.environ.get(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\"),\n        \"model\": os.environ.get(\"OPENAI_MODEL\", \"gpt-4\"),\n        \"sources\": [\"arxiv\", \"semantic_scholar\"]\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#e67e22", "moduleName": "scholar_compute"}, {"id": "scholar_compute.searchAll", "type": "function", "label": "searchAll", "direction": "inbound", "parent": "scholar_compute", "line": 37, "endLine": 74, "signature": "(params) -> Dict[]", "docstring": "Search multiple academic sources in parallel.\nInput: query, sources\nOutput: searchResults, error", "source": "def searchAll(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Search multiple academic sources in parallel.\n    Input: query, sources\n    Output: searchResults, error\n    \"\"\"\n    query = params.get(\"query\", \"\")\n    sources = params.get(\"sources\", [\"arxiv\"])\n\n    if not query:\n        return {\"searchResults\": None, \"error\": \"No query provided\"}\n\n    if not arxiv or not semanticScholar:\n        return {\"searchResults\": None, \"error\": \"Scraper compute not available\"}\n\n    results = []\n    errors = []\n\n    for source in sources:\n        try:\n            if source == \"arxiv\":\n                r = arxiv({\"query\": query, \"maxResults\": 10})\n            elif source == \"semantic_scholar\":\n                r = semanticScholar({\"query\": query, \"maxResults\": 10})\n            else:\n                continue\n\n            if r.get(\"results\"):\n                results.extend(r[\"results\"])\n            elif r.get(\"error\"):\n                errors.append(f\"{source}: {r['error']}\")\n        except Exception as e:\n            errors.append(f\"{source}: {e}\")\n\n    if not results and errors:\n        return {\"searchResults\": None, \"error\": \"; \".join(errors)}\n\n    return {\"searchResults\": results, \"error\": None}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#e67e22", "moduleName": "scholar_compute"}, {"id": "scholar_compute.fetchDetails", "type": "function", "label": "fetchDetails", "direction": "inbound", "parent": "scholar_compute", "line": 77, "endLine": 125, "signature": "(params) -> Dict[]", "docstring": "Fetch full details for selected papers.\nInput: searchResults, selectedPapers (indices)\nOutput: paperDetails, paperLinks, error", "source": "def fetchDetails(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Fetch full details for selected papers.\n    Input: searchResults, selectedPapers (indices)\n    Output: paperDetails, paperLinks, error\n    \"\"\"\n    results = params.get(\"searchResults\", [])\n    indices = params.get(\"selectedPapers\", [])\n\n    if not results:\n        return {\"paperDetails\": None, \"paperLinks\": None, \"error\": \"No search results\"}\n\n    if not indices:\n        indices = list(range(min(3, len(results))))\n\n    if not fetchDetail:\n        return {\"paperDetails\": None, \"paperLinks\": None, \"error\": \"Fetch compute not available\"}\n\n    details = []\n    links = []\n    for idx in indices:\n        if 0 <= idx < len(results):\n            paper = results[idx]\n            try:\n                r = fetchDetail({\n                    \"id\": paper.get(\"id\"),\n                    \"source\": paper.get(\"source\")\n                })\n                if r.get(\"detail\"):\n                    d = r[\"detail\"]\n                    details.append(d)\n                    links.append({\n                        \"title\": d.get(\"title\", \"\"),\n                        \"url\": d.get(\"url\", \"\"),\n                        \"pdfUrl\": d.get(\"pdfUrl\", \"\")\n                    })\n                else:\n                    details.append(paper)\n                    links.append({\n                        \"title\": paper.get(\"title\", \"\"),\n                        \"url\": paper.get(\"url\", \"\"),\n                        \"pdfUrl\": \"\"\n                    })\n            except:\n                details.append(paper)\n                links.append({\"title\": paper.get(\"title\", \"\"),\n                             \"url\": paper.get(\"url\", \"\"), \"pdfUrl\": \"\"})\n\n    return {\"paperDetails\": details, \"paperLinks\": links, \"error\": None}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#e67e22", "moduleName": "scholar_compute"}, {"id": "scholar_compute.synthesize", "type": "function", "label": "synthesize", "direction": "inbound", "parent": "scholar_compute", "line": 128, "endLine": 211, "signature": "(params) -> Dict[]", "docstring": "Generate research synthesis using LLM.\nInput: query, paperDetails, paperLinks, apiKey, apiBase, model\nOutput: synthesis, followUpQuestions, conversation, error", "source": "def synthesize(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Generate research synthesis using LLM.\n    Input: query, paperDetails, paperLinks, apiKey, apiBase, model\n    Output: synthesis, followUpQuestions, conversation, error\n    \"\"\"\n    query = params.get(\"query\", \"\")\n    papers = params.get(\"paperDetails\", [])\n    links = params.get(\"paperLinks\", [])\n    apiKey = params.get(\"apiKey\", \"\")\n    apiBase = params.get(\"apiBase\", \"\")\n    model = params.get(\"model\", \"gpt-4\")\n\n    if not papers:\n        return {\"synthesis\": None, \"error\": \"No papers to synthesize\"}\n\n    # Build context from papers with links\n    ctx = []\n    for i, p in enumerate(papers):\n        url = links[i].get(\"url\", \"\") if i < len(links) else p.get(\"url\", \"\")\n        pdfUrl = links[i].get(\"pdfUrl\", \"\") if i < len(links) else \"\"\n        ctx.append(f\"[{i+1}] {p.get('title', 'Unknown')}\")\n        ctx.append(f\"    URL: {url}\")\n        if pdfUrl:\n            ctx.append(f\"    PDF: {pdfUrl}\")\n        ctx.append(f\"    Authors: {', '.join(p.get('authors', []))}\")\n        ctx.append(f\"    Year: {p.get('year', 'N/A')}\")\n        abstract = p.get(\"abstract\", \"\")[:500]\n        if abstract:\n            ctx.append(f\"    Abstract: {abstract}...\")\n        ctx.append(\"\")\n\n    paperCtx = \"\\n\".join(ctx)\n\n    systemPrompt = \"\"\"You are a research assistant helping synthesize academic \npapers. Provide concise, accurate summaries. Cite papers by number [1], [2].\nALWAYS include the paper URL when referencing a paper.\nAt the end, list all paper links and suggest 2-3 follow-up research questions.\"\"\"\n\n    userPrompt = f\"\"\"Research Query: {query}\n\nPapers Found:\n{paperCtx}\n\nPlease:\n1. Synthesize the key findings relevant to the query\n2. Note any consensus or disagreements between papers\n3. List all paper links in a References section\n4. Suggest 2-3 follow-up research questions\n\nFormat references as:\nREF: [1] Title - URL\n\nFormat follow-up questions on separate lines starting with \"Q:\"\n\"\"\"\n\n    try:\n        response = _callLlm(apiKey, apiBase, model, systemPrompt, userPrompt)\n\n        # Extract follow-up questions\n        lines = response.split(\"\\n\")\n        followUps = [l[2:].strip()\n                     for l in lines if l.strip().startswith(\"Q:\")]\n\n        conversation = [\n            {\"role\": \"system\", \"content\": systemPrompt},\n            {\"role\": \"user\", \"content\": userPrompt},\n            {\"role\": \"assistant\", \"content\": response}\n        ]\n\n        return {\n            \"synthesis\": response,\n            \"followUpQuestions\": followUps or [],\n            \"conversation\": conversation,\n            \"error\": None\n        }\n\n    except Exception as e:\n        return {\n            \"synthesis\": None,\n            \"followUpQuestions\": None,\n            \"conversation\": None,\n            \"error\": f\"Synthesis error: {e}\"\n        }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#e67e22", "moduleName": "scholar_compute"}, {"id": "scholar_compute.chat", "type": "function", "label": "chat", "direction": "inbound", "parent": "scholar_compute", "line": 214, "endLine": 264, "signature": "(params) -> Dict[]", "docstring": "Continue conversation about research.\nInput: question, conversation, paperDetails, apiKey, apiBase, model\nOutput: synthesis (response), conversation, error", "source": "def chat(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Continue conversation about research.\n    Input: question, conversation, paperDetails, apiKey, apiBase, model\n    Output: synthesis (response), conversation, error\n    \"\"\"\n    question = params.get(\"question\", \"\")\n    conversation = params.get(\"conversation\", [])\n    papers = params.get(\"paperDetails\", [])\n    apiKey = params.get(\"apiKey\", \"\")\n    apiBase = params.get(\"apiBase\", \"\")\n    model = params.get(\"model\", \"gpt-4\")\n\n    if not question:\n        return {\"synthesis\": None, \"conversation\": conversation, \"error\": \"No question\"}\n\n    if not conversation:\n        conversation = [{\"role\": \"system\", \"content\":\n                         \"You are a research assistant. Answer based on the papers discussed.\"}]\n\n    # Add paper context reminder if needed\n    if len(conversation) < 3 and papers:\n        titles = [f\"[{i+1}] {p.get('title','')}\" for i, p in enumerate(papers)]\n        conversation.append({\n            \"role\": \"system\",\n            \"content\": f\"Papers in context: {'; '.join(titles)}\"\n        })\n\n    conversation.append({\"role\": \"user\", \"content\": question})\n\n    try:\n        # Build messages for API\n        messages = [{\"role\": m[\"role\"], \"content\": m[\"content\"]}\n                    for m in conversation]\n\n        response = _callLlmMessages(apiKey, apiBase, model, messages)\n\n        conversation.append({\"role\": \"assistant\", \"content\": response})\n\n        return {\n            \"synthesis\": response,\n            \"conversation\": conversation,\n            \"error\": None\n        }\n\n    except Exception as e:\n        return {\n            \"synthesis\": None,\n            \"conversation\": conversation,\n            \"error\": f\"Chat error: {e}\"\n        }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#e67e22", "moduleName": "scholar_compute"}, {"id": "sys", "type": "dependency", "label": "sys", "direction": "outbound", "category": "stdlib", "moduleColor": "#e67e22", "moduleName": "scholar_compute"}, {"id": "scraper_compute", "type": "dependency", "label": "scraper_compute", "direction": "outbound", "category": "pip", "moduleColor": "#e67e22", "moduleName": "scholar_compute"}, {"id": "llm_compute", "type": "dependency", "label": "llm_compute", "direction": "outbound", "category": "pip", "moduleColor": "#e67e22", "moduleName": "scholar_compute"}, {"id": "urllib.error", "type": "dependency", "label": "error", "direction": "outbound", "category": "stdlib", "moduleColor": "#e67e22", "moduleName": "scholar_compute"}, {"id": "skill_contractor_compute", "type": "module", "label": "skill_contractor_compute", "metrics": {"fanIn": 25, "fanOut": 10, "instability": 0.286, "internalEdges": 1, "externalCallCount": 60, "localCallCount": 4, "callsByCategory": {"stdlib": 57, "pip": 3}, "localDependencies": ["", "prompts"]}, "moduleColor": "#00d4ff", "moduleName": "skill_contractor_compute"}, {"id": "skill_contractor_compute.init", "type": "function", "label": "init", "direction": "inbound", "parent": "skill_contractor_compute", "line": 544, "endLine": 583, "signature": "(params) -> Dict[]", "docstring": "Initialize agent context with new runtime folder.", "source": "def init(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Initialize agent context with new runtime folder.\"\"\"\n    workspace = os.environ.get(\"WORKSPACE_PATH\", os.getcwd())\n\n    # Create new run folder\n    runDir = _getRunDir(workspace)\n    runId = runDir.name\n\n    _logRun(runDir, f\"=== NEW RUN: {runId} ===\")\n    _logRun(runDir, f\"Workspace: {workspace}\")\n\n    print(f\"  [INIT] Run folder: {runDir}\")\n\n    return {\n        \"api_key\": os.environ.get(\"OPENAI_API_KEY\"),\n        \"api_base\": os.environ.get(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\"),\n        \"model\": os.environ.get(\"OPENAI_MODEL\", \"gpt-4o-mini\"),\n        \"workspace_path\": workspace,\n        \"run_id\": runId,\n        \"run_dir\": str(runDir),\n        \"lpp_root\": _findLppRoot(),\n        \"phase\": \"blueprint\",  # Start in blueprint phase\n        \"blueprint_validated\": False,\n        \"threshold\": int(os.environ.get(\"EVAL_THRESHOLD\", \"80\")),\n        \"max_iterations\": int(os.environ.get(\"MAX_ITERATIONS\", \"5\")),\n        \"max_errors\": int(os.environ.get(\"MAX_ERRORS\", \"3\")),\n        \"max_repairs\": int(os.environ.get(\"MAX_REPAIRS\", \"3\")),\n        \"iteration\": 0,\n        \"error_count\": 0,\n        \"step_error_count\": 0,\n        \"repair_attempts\": 0,\n        \"failed_steps\": [],\n        \"execution_log\": [],\n        \"artifacts\": [],\n        \"is_lpp_target\": True,\n        \"lpp_validated\": False,\n        \"raw_output\": None,\n        \"parsed_output\": None,\n        \"parse_error\": None\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "skill_contractor_compute"}, {"id": "skill_contractor_compute.detect_lpp_target", "type": "function", "label": "detect_lpp_target", "direction": "inbound", "parent": "skill_contractor_compute", "line": 586, "endLine": 601, "signature": "(params) -> Dict[]", "docstring": "Detect if target requires L++ output.", "source": "def detect_lpp_target(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Detect if target requires L++ output.\"\"\"\n    target = (params.get(\"target\") or \"\").lower()\n    analysisOnly = [\"explain\", \"what is\", \"describe\", \"list files\", \"show me\"]\n    codeWords = [\"create\", \"build\", \"make\",\n                 \"generate\", \"write\", \"app\", \"skill\"]\n    isAnalysis = any(k in target for k in analysisOnly) and \\\n        not any(w in target for w in codeWords)\n    isLpp = not isAnalysis\n\n    runDir = Path(params.get(\"run_dir\", \".\"))\n    _logRun(runDir, f\"Target: {target[:100]}...\")\n    _logRun(runDir, f\"Mode: {'L++' if isLpp else 'Analysis'}\")\n\n    print(f\"  [{'L++ MODE' if isLpp else 'ANALYSIS MODE'}]\")\n    return {\"is_lpp_target\": isLpp}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "skill_contractor_compute"}, {"id": "skill_contractor_compute.decompose", "type": "function", "label": "decompose", "direction": "inbound", "parent": "skill_contractor_compute", "line": 604, "endLine": 689, "signature": "(params) -> Dict[]", "docstring": "Decompose target into steps via LLM.", "source": "def decompose(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Decompose target into steps via LLM.\"\"\"\n    apiKey = params.get(\"api_key\")\n    apiBase = params.get(\"api_base\")\n    model = params.get(\"model\")\n    target = params.get(\"target\")\n    workspace = params.get(\"workspace_path\", \".\")\n    feedback = params.get(\"feedback\") or \"\"\n    lppRoot = params.get(\"lpp_root\", \"\")\n    iteration = params.get(\"iteration\", 0)\n    phase = params.get(\"phase\", \"blueprint\")\n    runDir = Path(params.get(\"run_dir\", workspace))\n\n    _logRun(runDir, f\"DECOMPOSE iteration={iteration} phase={phase}\")\n\n    failureCtx = \"\"\n    if feedback:\n        fixHints = []\n        if \"'list' object has no attribute 'keys'\" in feedback:\n            fixHints.append(\n                \"FIX: Use DICT format for states/gates/actions, NOT arrays\")\n        if \"'str' object has no attribute 'get'\" in feedback:\n            fixHints.append(\n                \"FIX: Actions with type 'compute' MUST have input_map and output_map\")\n        if \"input_map\" in feedback or \"output_map\" in feedback:\n            fixHints.append(\n                \"FIX: Every compute action needs input_map:{} and output_map:{}\")\n\n        hintsStr = \"\\n\".join(\n            fixHints) if fixHints else \"Review the error and fix the schema format\"\n\n        failureCtx = f\"\"\"\n\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551  CRITICAL: ITERATION {iteration} FAILED - YOU MUST FIX THIS  \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n\nERROR DETAILS:\n{_truncate(feedback, 1200)}\n\nREQUIRED FIXES:\n{hintsStr}\n\nDO NOT generate the same broken output!\n\"\"\"\n        _logRun(runDir, f\"Feedback for decompose:\\n{feedback[:500]}\")\n\n    # Select phase-specific instructions\n    phaseInstructions = prompts.PHASE_BLUEPRINT_INSTRUCTIONS if phase == \"blueprint\" else prompts.PHASE_IMPLEMENTATION_INSTRUCTIONS\n\n    prompt = prompts.DECOMPOSE.format(\n        target=target,\n        workspace=workspace,\n        iteration=iteration + 1,\n        phase=phase,\n        phase_instructions=phaseInstructions,\n        failure_ctx=failureCtx,\n        lpp_root=lppRoot,\n        # Only include LPP_RULES in blueprint phase\n        lpp_rules=prompts.LPP_RULES if phase == \"blueprint\" else \"\",\n        json_rules=prompts.JSON_RULES\n    )\n\n    result = _callLlm(apiKey, apiBase, model,\n                      [{\"role\": \"system\", \"content\": prompts.SYSTEM},\n                       {\"role\": \"user\", \"content\": prompt}], 0.3, 2048)\n\n    if result.get(\"error\"):\n        _logRun(runDir, f\"DECOMPOSE ERROR: {result['error']}\")\n        return {\"plan\": None, \"step_count\": 0, \"step_index\": 0,\n                \"current_step\": None, \"error\": result[\"error\"]}\n\n    try:\n        plan = _extractJson(result[\"response\"])\n        steps = plan.get(\"steps\", [])\n        _logRun(runDir, f\"DECOMPOSE OK: {len(steps)} steps\")\n        return {\n            \"plan\": plan,\n            \"step_count\": len(steps),\n            \"step_index\": 0,\n            \"current_step\": steps[0] if steps else None,\n            \"error\": None\n        }\n    except ValueError as e:\n        _logRun(runDir, f\"DECOMPOSE PARSE ERROR: {e}\")\n        return {\"plan\": None, \"step_count\": 0, \"step_index\": 0,\n                \"current_step\": None, \"error\": f\"Parse error: {e}\"}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "skill_contractor_compute"}, {"id": "skill_contractor_compute.generate_step_output", "type": "function", "label": "generate_step_output", "direction": "inbound", "parent": "skill_contractor_compute", "line": 692, "endLine": 839, "signature": "(params) -> Dict[]", "docstring": "Generate step output via LLM with step-level logging.", "source": "def generate_step_output(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Generate step output via LLM with step-level logging.\"\"\"\n    apiKey = params.get(\"api_key\")\n    apiBase = params.get(\"api_base\")\n    model = params.get(\"model\")\n    target = params.get(\"target\")\n    step = params.get(\"current_step\")\n    stepIdx = params.get(\"step_index\", 0)\n    workspace = params.get(\"workspace_path\", \".\")\n    execLog = params.get(\"execution_log\", [])\n    lppRoot = params.get(\"lpp_root\", \"\")\n    parseError = params.get(\"parse_error\")\n    rawOutput = params.get(\"raw_output\")\n    repairAttempts = params.get(\"repair_attempts\", 0)\n    phase = params.get(\"phase\", \"blueprint\")\n    runDir = Path(params.get(\"run_dir\", workspace))\n\n    if not step:\n        return {\"raw_output\": None, \"error\": \"No step\"}\n\n    # Output goes to runs/<run_id>/output/ for cleaner organization\n    outputDir = runDir / \"output\"\n    outputDir.mkdir(exist_ok=True)\n    plan = params.get(\"plan\", {})\n    iterFeedback = params.get(\"feedback\") or \"\"\n\n    # Log step start\n    _logStep(runDir, stepIdx, \"GENERATE_START\",\n             f\"Action: {step.get('action', 'N/A')}\\nType: {step.get('type', 'N/A')}\\nPhase: {phase}\\nRepair attempt: {repairAttempts}\")\n\n    # Read previous log for this step to give LLM context\n    prevLog = _readStepLog(runDir, stepIdx, maxChars=4000)\n\n    ctx = _condenseForStep(plan, stepIdx, execLog, iterFeedback)\n\n    # Build context for LLM\n    iterCtx = \"\"\n\n    if parseError and rawOutput:\n        # Include step log for better context\n        logContext = f\"\\n\\nPREVIOUS ATTEMPTS LOG:\\n{prevLog}\" if prevLog else \"\"\n\n        iterCtx = f\"\"\"\n\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551  \u26a0\ufe0f  OUTPUT PARSING FAILED (attempt {repairAttempts}) - FIX IT  \u26a0\ufe0f  \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n\nPARSE ERROR:\n{_truncate(parseError, 800)}\n\nYOUR BROKEN OUTPUT:\n```\n{_truncate(rawOutput, 4000)}\n```\n{logContext}\n\nFIX THE JSON STRUCTURE! For L++ blueprints you MUST include:\n- \"$schema\": \"lpp/v0.1.2\"\n- \"id\", \"name\", \"version\", \"description\"\n- \"states\": {{\"state_name\": {{\"description\": \"...\"}}, ...}}  (DICT not array!)\n- \"gates\": {{\"gate_name\": {{\"type\": \"expression\", \"expression\": \"...\"}}, ...}}\n- \"actions\": {{\"action_name\": {{\"type\": \"compute|set\", ...}}, ...}}\n- \"transitions\": [...]\n- \"entry_state\", \"terminal_states\"\n\"\"\"\n        _logStep(runDir, stepIdx, \"PARSE_ERROR_CONTEXT\",\n                 f\"Error: {parseError}\\nBroken output length: {len(rawOutput or '')}\")\n\n    elif ctx.get(\"iteration_feedback\"):\n        fb = ctx['iteration_feedback']\n        lastOut = ctx.get(\"last_output\") or \"\"\n\n        fixHints = []\n        if \"'list' object has no attribute 'keys'\" in fb:\n            fixHints.append(\n                \"\u2192 WRONG: \\\"states\\\": [{...}]  \u2192  RIGHT: \\\"states\\\": {\\\"idle\\\": {...}}\")\n        if \"'str' object has no attribute 'get'\" in fb:\n            fixHints.append(\n                \"\u2192 Actions MUST have: \\\"input_map\\\": {...}, \\\"output_map\\\": {...}\")\n\n        hintsStr = \"\\n\".join(\n            fixHints) if fixHints else \"Fix the validation error below\"\n        brokenOutput = f\"\\nYOUR PREVIOUS OUTPUT:\\n```\\n{_truncate(lastOut, 4000)}\\n```\" if lastOut else \"\"\n\n        iterCtx = f\"\"\"\n\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551  \u26a0\ufe0f  PREVIOUS ATTEMPT FAILED - MUST FIX BEFORE PROCEEDING  \u26a0\ufe0f  \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n\nVALIDATION ERROR:\n{_truncate(fb, 1000)}\n\nSPECIFIC FIXES REQUIRED:\n{hintsStr}\n{brokenOutput}\n\"\"\"\n\n    lastAttemptStr = \"First attempt\"\n    if ctx[\"last_attempt\"]:\n        la = ctx[\"last_attempt\"]\n        lastAttemptStr = f\"Attempt: {la.get('result', 'N/A')[:80]}, success: {la.get('success', 'N/A')}\"\n\n    # Select phase-specific instructions and output format\n    if phase == \"blueprint\":\n        phaseInstructions = prompts.PHASE_BLUEPRINT_INSTRUCTIONS\n        phaseOutputFormat = prompts.BLUEPRINT_OUTPUT_FORMAT\n        lppRules = prompts.LPP_RULES\n    else:\n        phaseInstructions = prompts.PHASE_IMPLEMENTATION_INSTRUCTIONS\n        phaseOutputFormat = prompts.IMPLEMENTATION_OUTPUT_FORMAT\n        lppRules = \"\"  # Don't include L++ schema rules in implementation phase\n\n    prompt = prompts.EXECUTE_STEP.format(\n        target=target,\n        phase=phase.upper(),\n        phase_instructions=phaseInstructions,\n        phase_output_format=phaseOutputFormat,\n        progress=ctx[\"progress\"],\n        action=step.get(\"action\", \"\"),\n        step_type=step.get(\"type\", \"analyze\"),\n        output_dir=str(outputDir),\n        lpp_root=lppRoot,\n        iteration_ctx=iterCtx,\n        prev_step=ctx[\"prev\"][\"action\"] if ctx[\"prev\"] else \"None\",\n        next_step=ctx[\"next\"][\"action\"] if ctx[\"next\"] else \"Final step\",\n        last_attempt=lastAttemptStr,\n        lpp_rules=lppRules,\n        json_rules=prompts.JSON_RULES\n    )\n\n    _logStep(runDir, stepIdx, \"LLM_PROMPT\",\n             f\"Prompt length: {len(prompt)} chars\")\n\n    result = _callLlm(apiKey, apiBase, model,\n                      [{\"role\": \"system\", \"content\": prompts.SYSTEM},\n                       {\"role\": \"user\", \"content\": prompt}], 0.4, 4096)\n\n    if result.get(\"error\"):\n        _logStep(runDir, stepIdx, \"LLM_ERROR\", result[\"error\"])\n        return {\"raw_output\": None, \"error\": result[\"error\"]}\n\n    rawResp = result.get(\"response\", \"\")\n    _logStep(runDir, stepIdx, \"LLM_RESPONSE\",\n             f\"Response length: {len(rawResp)} chars\\n\\n{rawResp[:2000]}\")\n\n    print(f\"  [GENERATE] Step {stepIdx + 1}: {len(rawResp)} chars\")\n\n    return {\"raw_output\": rawResp, \"error\": None}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "skill_contractor_compute"}, {"id": "skill_contractor_compute.parse_and_sanitize", "type": "function", "label": "parse_and_sanitize", "direction": "inbound", "parent": "skill_contractor_compute", "line": 842, "endLine": 933, "signature": "(params) -> Dict[]", "docstring": "Parse and sanitize LLM output with logging.", "source": "def parse_and_sanitize(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Parse and sanitize LLM output with logging.\"\"\"\n    rawOutput = params.get(\"raw_output\", \"\")\n    step = params.get(\"current_step\", {})\n    isLppTarget = params.get(\"is_lpp_target\", True)\n    phase = params.get(\"phase\", \"blueprint\")\n    stepType = step.get(\"type\", \"analyze\") if step else \"analyze\"\n    isLppStep = \"lpp\" in stepType.lower() if stepType else False\n    stepIdx = params.get(\"step_index\", 0)\n    runDir = Path(params.get(\"run_dir\", \".\"))\n\n    # In implementation phase, we're generating Python code, not blueprints\n    inBlueprintPhase = (phase == \"blueprint\")\n\n    if not rawOutput:\n        _logStep(runDir, stepIdx, \"PARSE_FAIL\", \"Empty LLM response\")\n        return {\"parsed_output\": None, \"parse_error\": \"Empty LLM response\"}\n\n    # Step 1: Extract JSON\n    try:\n        parsed = _extractJson(rawOutput)\n        _logStep(runDir, stepIdx, \"JSON_EXTRACTED\",\n                 f\"Keys: {list(parsed.keys())[:10]} Phase: {phase}\")\n    except ValueError as e:\n        _logStep(runDir, stepIdx, \"JSON_EXTRACT_FAIL\",\n                 f\"Error: {e}\\nRaw start: {rawOutput[:500]}\")\n        return {\"parsed_output\": None,\n                \"parse_error\": f\"JSON extraction failed: {e}. Raw output starts with: {rawOutput[:200]}\"}\n\n    # Step 2: In blueprint phase, check if blueprint is nested in 'output' field\n    # This happens regardless of stepType since LLM may return {\"output\": \"<escaped blueprint>\"}\n    if inBlueprintPhase and \"output\" in parsed and isinstance(parsed[\"output\"], str):\n        outputStr = parsed[\"output\"]\n        # Unescape the nested JSON string\n        outputStr = outputStr.replace(\"\\\\\\\\n\", \"\\n\").replace(\"\\\\\\\\t\", \"\\t\")\n        outputStr = outputStr.replace('\\\\\\\\\"', '\"').replace(\"\\\\'\", \"'\")\n        outputStr = outputStr.replace(\"\\\\n\", \"\\n\").replace(\"\\\\t\", \"\\t\")\n        outputStr = outputStr.replace('\\\\\"', '\"')\n\n        # Try to parse the nested blueprint\n        if outputStr.strip().startswith(\"{\") and (\"$schema\" in outputStr or \"states\" in outputStr):\n            try:\n                innerParsed = json.loads(outputStr)\n                _logStep(runDir, stepIdx, \"NESTED_BLUEPRINT\",\n                         f\"Extracted from output field, keys: {list(innerParsed.keys())[:8]}\")\n                # Use the inner blueprint but preserve filename\n                innerParsed[\"_filename\"] = parsed.get(\n                    \"filename\", \"blueprint.json\")\n                parsed = innerParsed\n            except json.JSONDecodeError as e:\n                _logStep(runDir, stepIdx, \"NESTED_PARSE_FAIL\",\n                         f\"Inner JSON parse failed: {e}\\nStart: {outputStr[:300]}\")\n                # Continue with outer parsed, will fail blueprint validation\n\n    # Step 3: Detect blueprint - ONLY in blueprint phase\n    isBlueprint = inBlueprintPhase and (\n        isLppStep or\n        \"$schema\" in parsed or\n        (\"states\" in parsed and \"transitions\" in parsed)\n    )\n\n    # Step 4: Sanitize based on what we have\n    if isBlueprint and isLppTarget:\n        sanitized, corrections, error = _sanitizeBlueprint(parsed)\n\n        # Log corrections for review\n        if corrections:\n            report = _formatCorrectionsReport(corrections)\n            _logStep(runDir, stepIdx, \"BLUEPRINT_CORRECTIONS\", report)\n            print(f\"\\n{report}\\n\")\n\n        if error:\n            _logStep(runDir, stepIdx, \"BLUEPRINT_INVALID\", error)\n            return {\"parsed_output\": None,\n                    \"parse_error\": f\"Blueprint schema errors (cannot auto-fix):\\n{error}\",\n                    \"corrections\": corrections}\n        # Restore filename if we extracted from nested\n        if \"_filename\" in parsed:\n            sanitized[\"_filename\"] = parsed[\"_filename\"]\n        _logStep(runDir, stepIdx, \"BLUEPRINT_VALID\",\n                 f\"States: {list(sanitized.get('states', {}).keys())}, Corrections: {len(corrections)}\")\n        return {\"parsed_output\": sanitized, \"parse_error\": None, \"corrections\": corrections}\n    else:\n        # Implementation phase or non-blueprint step - treat as code/file output\n        sanitized, error = _sanitizeStepOutput(parsed, stepType)\n        if error:\n            _logStep(runDir, stepIdx, \"OUTPUT_INVALID\", error)\n            return {\"parsed_output\": None,\n                    \"parse_error\": f\"Step output errors:\\n{error}\"}\n        _logStep(runDir, stepIdx, \"OUTPUT_VALID\",\n                 f\"Filename: {sanitized.get('filename', 'N/A')} Phase: {phase}\")\n        return {\"parsed_output\": sanitized, \"parse_error\": None}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "skill_contractor_compute"}, {"id": "skill_contractor_compute.write_output", "type": "function", "label": "write_output", "direction": "inbound", "parent": "skill_contractor_compute", "line": 936, "endLine": 1037, "signature": "(params) -> Dict[]", "docstring": "Write validated output to disk.", "source": "def write_output(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Write validated output to disk.\"\"\"\n    parsed = params.get(\"parsed_output\", {})\n    step = params.get(\"current_step\", {})\n    stepIdx = params.get(\"step_index\", 0)\n    workspace = params.get(\"workspace_path\", \".\")\n    execLog = params.get(\"execution_log\", [])\n    artifacts = params.get(\"artifacts\", [])\n    runDir = Path(params.get(\"run_dir\", workspace))\n\n    if not parsed:\n        return {\"execution_log\": execLog, \"artifacts\": artifacts,\n                \"current_step\": step, \"error\": \"No parsed output\"}\n\n    # Output goes to runs/<run_id>/output/ for cleaner organization\n    outputDir = runDir / \"output\"\n    outputDir.mkdir(exist_ok=True)\n\n    stepType = step.get(\"type\", \"analyze\") if step else \"analyze\"\n    # Normalize step type - check if it contains 'lpp'\n    isLppStep = \"lpp\" in stepType.lower() if stepType else False\n    filesWritten = []\n\n    # Handle blueprint output - check for $schema regardless of stepType\n    # (LLM may use \"file\" type but still generate a valid blueprint)\n    if \"$schema\" in parsed:\n        filename = parsed.pop(\"_filename\", None) or parsed.get(\n            \"filename\", f\"{parsed.get('id', 'blueprint')}.json\")\n        # Ensure .json extension\n        if not filename.endswith(\".json\"):\n            filename = f\"{filename}.json\"\n        # Write the blueprint JSON directly\n        bpCopy = {k: v for k, v in parsed.items() if not k.startswith(\"_\")}\n        fp = outputDir / filename\n        fp.parent.mkdir(parents=True, exist_ok=True)\n        fp.write_text(json.dumps(bpCopy, indent=2))\n        filesWritten.append(str(fp))\n        _logStep(runDir, stepIdx, \"BLUEPRINT_WRITTEN\", f\"Path: {fp}\")\n        print(f\"  [WROTE BLUEPRINT] {fp}\")\n    else:\n        # Handle regular code/file output\n        output = parsed.get(\"output\", \"\")\n        filename = parsed.get(\"filename\")\n\n        # Unescape\n        if output:\n            output = output.replace(\"\\\\\\\\\", \"\\x00BACKSLASH\\x00\")\n            output = output.replace('\\\\\"', '\"')\n            output = output.replace(\"\\\\n\", \"\\n\")\n            output = output.replace(\"\\\\t\", \"\\t\")\n            output = output.replace(\"\\x00BACKSLASH\\x00\", \"\\\\\")\n\n        # Also check if this looks like a JSON blueprint in the output field\n        isJsonFile = filename and filename.endswith(\".json\")\n        isPythonFile = filename and filename.endswith(\".py\")\n        if output and filename and (isLppStep or stepType in (\"code\", \"file\") or isJsonFile):\n            # Sanitize Python files to fix common LLM errors (literal newlines in strings)\n            if isPythonFile and HAS_SANITIZER:\n                sanitized_output, fixes = sanitize_python_code(output, filename, verbose=True)\n                if fixes:\n                    _logStep(runDir, stepIdx, \"SANITIZED\", f\"{filename}: {', '.join(fixes)}\")\n                    print(f\"  [SANITIZED] {filename}: {', '.join(fixes)}\")\n                output = sanitized_output\n            fp = outputDir / filename\n            fp.parent.mkdir(parents=True, exist_ok=True)\n            fp.write_text(output)\n            filesWritten.append(str(fp))\n            _logStep(runDir, stepIdx, \"FILE_WRITTEN\",\n                     f\"Path: {fp}\\nSize: {len(output)} bytes\")\n            print(f\"  [WROTE] {fp}\")\n\n    if stepType == \"command\" and parsed.get(\"command\"):\n        cmd = parsed[\"command\"]\n        try:\n            proc = subprocess.run(cmd, shell=True, cwd=str(outputDir),\n                                  capture_output=True, text=True, timeout=30)\n            parsed[\"cmd_output\"] = proc.stdout or proc.stderr\n            _logStep(runDir, stepIdx, \"COMMAND_RUN\",\n                     f\"Cmd: {cmd}\\nExit: {proc.returncode}\\nOutput: {parsed['cmd_output'][:500]}\")\n        except Exception as e:\n            parsed[\"cmd_output\"] = str(e)\n            _logStep(runDir, stepIdx, \"COMMAND_ERROR\", str(e))\n\n    logEntry = {\n        \"step_index\": stepIdx,\n        \"step\": step,\n        \"result\": parsed.get(\"result\", \"\"),\n        \"raw_output\": params.get(\"raw_output\", \"\"),\n        \"files_written\": filesWritten,\n        \"success\": True\n    }\n    execLog = list(execLog) + [logEntry]\n    artifacts = list(artifacts) + filesWritten\n\n    step[\"status\"] = \"done\"\n    step[\"output\"] = parsed.get(\"output\", \"\") if not (\n        \"$schema\" in parsed) else json.dumps(parsed, indent=2)[:500]\n\n    _logRun(runDir, f\"Step {stepIdx + 1} COMPLETE: {filesWritten}\")\n\n    return {\"execution_log\": execLog, \"artifacts\": artifacts,\n            \"current_step\": step, \"error\": None}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "skill_contractor_compute"}, {"id": "skill_contractor_compute.advance_step", "type": "function", "label": "advance_step", "direction": "inbound", "parent": "skill_contractor_compute", "line": 1040, "endLine": 1051, "signature": "(params) -> Dict[]", "docstring": "Advance to next step.", "source": "def advance_step(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Advance to next step.\"\"\"\n    plan = params.get(\"plan\", {})\n    stepIdx = params.get(\"step_index\", 0)\n    steps = plan.get(\"steps\", []) if plan else []\n    nextIdx = stepIdx + 1\n    nextStep = steps[nextIdx] if nextIdx < len(steps) else None\n\n    runDir = Path(params.get(\"run_dir\", \".\"))\n    _logRun(runDir, f\"ADVANCE: {stepIdx} -> {nextIdx}\")\n\n    return {\"step_index\": nextIdx, \"current_step\": nextStep}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "skill_contractor_compute"}, {"id": "skill_contractor_compute.validate_lpp", "type": "function", "label": "validate_lpp", "direction": "inbound", "parent": "skill_contractor_compute", "line": 1054, "endLine": 1134, "signature": "(params) -> Dict[]", "docstring": "Validate L++ artifacts.", "source": "def validate_lpp(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Validate L++ artifacts.\"\"\"\n    workspace = params.get(\"workspace_path\", \".\")\n    artifacts = params.get(\"artifacts\", [])\n    lppRoot = params.get(\"lpp_root\", \"\")\n    phase = params.get(\"phase\", \"blueprint\")\n    runDir = Path(params.get(\"run_dir\", workspace))\n\n    blueprints = [a for a in artifacts if a.endswith(\".json\")]\n    if not blueprints:\n        _logRun(runDir, \"VALIDATE: No blueprints found\")\n        return {\"lpp_validated\": False, \"blueprint_validated\": False,\n                \"feedback\": \"No blueprints found\", \"error\": None}\n\n    # Output is in runs/<run_id>/output/\n    outputDir = runDir / \"output\"\n    skillDir = str(outputDir)\n    for bp in blueprints:\n        bpPath = Path(bp)\n        if bpPath.exists():\n            parent = bpPath.parent\n            if (parent / \"src\").exists():\n                skillDir = str(parent)\n                break\n\n    buildScript = None\n    for p in [Path(lppRoot) / \"utils\" / \"build_skill.sh\" if lppRoot else None,\n              Path(workspace).parent / \"utils\" / \"build_skill.sh\"]:\n        if p and p.exists():\n            buildScript = p\n            break\n\n    if not buildScript:\n        _logRun(runDir, \"VALIDATE: build_skill.sh not found, skipping\")\n        return {\"lpp_validated\": True, \"blueprint_validated\": True,\n                \"feedback\": None, \"error\": None}\n\n    runCwd = lppRoot or str(Path(workspace).parent)\n    _logRun(runDir, f\"VALIDATE [{phase}]: {buildScript} {skillDir} --validate\")\n\n    try:\n        proc = subprocess.run(\n            [str(buildScript), skillDir, \"--validate\"],\n            cwd=runCwd, capture_output=True, text=True, timeout=60\n        )\n        output = proc.stdout + proc.stderr\n\n        if \"PASS\" in output:\n            _logRun(runDir, f\"VALIDATE [{phase}]: PASSED\")\n            # Both phases set lpp_validated=True on pass, but blueprint_validated tracks blueprint specifically\n            if phase == \"blueprint\":\n                return {\"lpp_validated\": True, \"blueprint_validated\": True,\n                        \"feedback\": f\"Blueprint phase PASSED - advancing to implementation\", \"error\": None}\n            else:\n                return {\"lpp_validated\": True, \"blueprint_validated\": True,\n                        \"feedback\": None, \"error\": None}\n        else:\n            _logRun(runDir, f\"VALIDATE [{phase}]: FAILED\\n{output[:1000]}\")\n            errLines = [l.strip() for l in output.split(\"\\n\")\n                        if any(k in l.lower() for k in [\"error\", \"violation\", \"fail\", \"missing\"])]\n            errDetail = \"\\n\".join(\n                errLines[-10:]) if errLines else output[-600:]\n\n            schemaHints = []\n            if \"'list' object has no attribute 'keys'\" in output:\n                schemaHints.append(\n                    \"Use DICT not ARRAY for states/gates/actions\")\n            if \"'str' object has no attribute 'get'\" in output:\n                schemaHints.append(\n                    \"transitions MUST be an ARRAY, not a dict! Use: \\\"transitions\\\": [{\\\"id\\\": \\\"t1\\\", \\\"from\\\": ..., \\\"to\\\": ..., \\\"on_event\\\": ...}, ...]\")\n            if \"AttributeError\" in output and \"transitions\" in output:\n                schemaHints.append(\n                    \"transitions MUST be: [{\\\"id\\\": \\\"t1\\\", \\\"from\\\": \\\"state1\\\", \\\"to\\\": \\\"state2\\\", \\\"on_event\\\": \\\"event_name\\\"}, ...]\")\n\n            feedback = f\"L++ VALIDATION FAILED [{phase}]:\\n{errDetail}\\n{chr(10).join(schemaHints)}\"\n            return {\"lpp_validated\": False, \"blueprint_validated\": False,\n                    \"feedback\": feedback, \"error\": None}\n    except Exception as e:\n        _logRun(runDir, f\"VALIDATE ERROR: {e}\")\n        return {\"lpp_validated\": False, \"blueprint_validated\": False,\n                \"feedback\": f\"Validation exception: {e}\", \"error\": None}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "skill_contractor_compute"}, {"id": "skill_contractor_compute.advance_phase", "type": "function", "label": "advance_phase", "direction": "inbound", "parent": "skill_contractor_compute", "line": 1137, "endLine": 1150, "signature": "(params) -> Dict[]", "docstring": "Advance from blueprint phase to implementation phase.", "source": "def advance_phase(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Advance from blueprint phase to implementation phase.\"\"\"\n    currentPhase = params.get(\"phase\", \"blueprint\")\n    runDir = Path(params.get(\"run_dir\", \".\"))\n\n    if currentPhase == \"blueprint\":\n        newPhase = \"implementation\"\n        _logRun(runDir, f\"PHASE ADVANCE: {currentPhase} -> {newPhase}\")\n        print(f\"  [PHASE] Blueprint validated - advancing to implementation\")\n        return {\"phase\": newPhase}\n    else:\n        # Already in implementation phase\n        _logRun(runDir, f\"PHASE: Already in {currentPhase}\")\n        return {\"phase\": currentPhase}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "skill_contractor_compute"}, {"id": "skill_contractor_compute.evaluate", "type": "function", "label": "evaluate", "direction": "inbound", "parent": "skill_contractor_compute", "line": 1153, "endLine": 1213, "signature": "(params) -> Dict[]", "docstring": "Self-evaluate progress.", "source": "def evaluate(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Self-evaluate progress.\"\"\"\n    apiKey = params.get(\"api_key\")\n    apiBase = params.get(\"api_base\")\n    model = params.get(\"model\")\n    target = params.get(\"target\")\n    plan = params.get(\"plan\")\n    execLog = params.get(\"execution_log\", [])\n    artifacts = params.get(\"artifacts\", [])\n    iteration = params.get(\"iteration\", 0)\n    threshold = params.get(\"threshold\", 80)\n    isLppTarget = params.get(\"is_lpp_target\", True)\n    lppValidated = params.get(\"lpp_validated\", False)\n    runDir = Path(params.get(\"run_dir\", \".\"))\n\n    lppStatus = \"PASSED\" if lppValidated else (\n        \"REQUIRED\" if isLppTarget else \"N/A\")\n    ctx = _condenseForEval(plan, execLog, artifacts)\n\n    _logRun(\n        runDir, f\"EVALUATE: iter={iteration}, lpp={lppStatus}, completed={ctx['completed']}/{ctx['total_steps']}\")\n\n    prompt = prompts.EVALUATE.format(\n        target=target,\n        iteration=iteration + 1,\n        threshold=threshold,\n        lpp_status=lppStatus,\n        total_steps=ctx[\"total_steps\"],\n        completed=ctx[\"completed\"],\n        pending=ctx[\"pending\"],\n        results=json.dumps(ctx[\"results\"], indent=2),\n        artifacts=\", \".join(ctx[\"artifacts\"]) if ctx[\"artifacts\"] else \"None\",\n        json_rules=prompts.JSON_RULES\n    )\n\n    result = _callLlm(apiKey, apiBase, model,\n                      [{\"role\": \"system\", \"content\": prompts.SYSTEM},\n                       {\"role\": \"user\", \"content\": prompt}], 0.2, 2048)\n\n    if result.get(\"error\"):\n        _logRun(runDir, f\"EVALUATE ERROR: {result['error']}\")\n        return {\"evaluation\": None, \"score\": 0, \"is_satisfied\": False,\n                \"feedback\": None, \"error\": result[\"error\"]}\n\n    try:\n        ev = _extractJson(result[\"response\"])\n        score = ev.get(\"score\", 0)\n        satisfied = ev.get(\"satisfied\", False) or score >= threshold\n        _logRun(\n            runDir, f\"EVALUATE RESULT: score={score}, satisfied={satisfied}\")\n        return {\n            \"evaluation\": ev,\n            \"score\": score,\n            \"is_satisfied\": satisfied,\n            \"feedback\": ev.get(\"feedback\"),\n            \"error\": None\n        }\n    except ValueError as e:\n        _logRun(runDir, f\"EVALUATE PARSE ERROR: {e}\")\n        return {\"evaluation\": None, \"score\": 0, \"is_satisfied\": False,\n                \"feedback\": None, \"error\": f\"Parse error: {e}\"}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "skill_contractor_compute"}, {"id": "skill_contractor_compute.incr_iteration", "type": "function", "label": "incr_iteration", "direction": "inbound", "parent": "skill_contractor_compute", "line": 1220, "endLine": 1221, "signature": "(params) -> Dict[]", "docstring": null, "source": "def incr_iteration(params: Dict[str, Any]) -> Dict[str, Any]:\n    return {\"iteration\": params.get(\"iteration\", 0) + 1}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "skill_contractor_compute"}, {"id": "skill_contractor_compute.incr_repair", "type": "function", "label": "incr_repair", "direction": "inbound", "parent": "skill_contractor_compute", "line": 1224, "endLine": 1225, "signature": "(params) -> Dict[]", "docstring": null, "source": "def incr_repair(params: Dict[str, Any]) -> Dict[str, Any]:\n    return {\"repair_attempts\": params.get(\"repair_attempts\", 0) + 1}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "skill_contractor_compute"}, {"id": "skill_contractor_compute.reset_for_refine", "type": "function", "label": "reset_for_refine", "direction": "inbound", "parent": "skill_contractor_compute", "line": 1228, "endLine": 1229, "signature": "(params) -> Dict[]", "docstring": null, "source": "def reset_for_refine(params: Dict[str, Any]) -> Dict[str, Any]:\n    return {\"step_index\": 0, \"current_step\": None}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "skill_contractor_compute"}, {"id": "skill_contractor_compute.capture_error", "type": "function", "label": "capture_error", "direction": "inbound", "parent": "skill_contractor_compute", "line": 1232, "endLine": 1246, "signature": "(params) -> Dict[]", "docstring": null, "source": "def capture_error(params: Dict[str, Any]) -> Dict[str, Any]:\n    error = params.get(\"error\", \"Unknown\")\n    count = params.get(\"error_count\", 0) + 1\n    step = params.get(\"current_step\", {})\n    stepIdx = params.get(\"step_index\", 0)\n    runDir = Path(params.get(\"run_dir\", \".\"))\n\n    stepInfo = f\" at step {stepIdx + 1}: {step.get('action', '')}\" if step else \"\"\n    _logRun(runDir, f\"ERROR ({count}): {error}\")\n\n    return {\n        \"last_error\": error,\n        \"feedback\": f\"Error{stepInfo}: {error}. Adjust plan.\",\n        \"error_count\": count\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "skill_contractor_compute"}, {"id": "skill_contractor_compute.capture_step_error", "type": "function", "label": "capture_step_error", "direction": "inbound", "parent": "skill_contractor_compute", "line": 1249, "endLine": 1261, "signature": "(params) -> Dict[]", "docstring": null, "source": "def capture_step_error(params: Dict[str, Any]) -> Dict[str, Any]:\n    error = params.get(\"error\", \"Unknown\")\n    count = params.get(\"step_error_count\", 0) + 1\n    stepIdx = params.get(\"step_index\", 0)\n    runDir = Path(params.get(\"run_dir\", \".\"))\n\n    _logStep(runDir, stepIdx, \"STEP_ERROR\", f\"Count: {count}\\nError: {error}\")\n\n    return {\n        \"last_error\": error,\n        \"feedback\": f\"Step error: {error}\",\n        \"step_error_count\": count\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "skill_contractor_compute"}, {"id": "skill_contractor_compute.capture_parse_error", "type": "function", "label": "capture_parse_error", "direction": "inbound", "parent": "skill_contractor_compute", "line": 1264, "endLine": 1277, "signature": "(params) -> Dict[]", "docstring": null, "source": "def capture_parse_error(params: Dict[str, Any]) -> Dict[str, Any]:\n    parseError = params.get(\"parse_error\", \"Unknown parse error\")\n    rawOutput = params.get(\"raw_output\", \"\")\n    repairAttempts = params.get(\"repair_attempts\", 0)\n    stepIdx = params.get(\"step_index\", 0)\n    runDir = Path(params.get(\"run_dir\", \".\"))\n\n    _logStep(runDir, stepIdx, \"PARSE_ERROR\",\n             f\"Attempt: {repairAttempts}\\nError: {parseError}\")\n\n    return {\n        \"feedback\": f\"Parse error (attempt {repairAttempts}): {parseError}\",\n        \"step_error_count\": 0\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "skill_contractor_compute"}, {"id": "skill_contractor_compute.prepare_recovery", "type": "function", "label": "prepare_recovery", "direction": "inbound", "parent": "skill_contractor_compute", "line": 1280, "endLine": 1288, "signature": "(params) -> Dict[]", "docstring": null, "source": "def prepare_recovery(params: Dict[str, Any]) -> Dict[str, Any]:\n    feedback = params.get(\"feedback\", \"\")\n    plan = params.get(\"plan\", {})\n    stepIdx = params.get(\"step_index\", 0)\n    if plan:\n        steps = plan.get(\"steps\", [])[stepIdx:]\n        if steps:\n            feedback += f\" Failed: {[s.get('action') for s in steps[:3]]}\"\n    return {\"feedback\": feedback, \"error\": None}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "skill_contractor_compute"}, {"id": "skill_contractor_compute.review_failed_step", "type": "function", "label": "review_failed_step", "direction": "inbound", "parent": "skill_contractor_compute", "line": 1291, "endLine": 1348, "signature": "(params) -> Dict[]", "docstring": "LLM reviews failed step: skip or replan.", "source": "def review_failed_step(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"LLM reviews failed step: skip or replan.\"\"\"\n    apiKey = params.get(\"api_key\")\n    apiBase = params.get(\"api_base\")\n    model = params.get(\"model\")\n    target = params.get(\"target\")\n    step = params.get(\"current_step\") or {}\n    stepIdx = params.get(\"step_index\", 0)\n    stepCount = params.get(\"step_count\", 0)\n    lastError = params.get(\"last_error\", \"Unknown\")\n    failedSteps = params.get(\"failed_steps\") or []\n    execLog = params.get(\"execution_log\") or []\n    runDir = Path(params.get(\"run_dir\", \".\"))\n\n    ctx = _condenseForReview(step, stepIdx, execLog, lastError)\n\n    # Include step log for context\n    stepLog = _readStepLog(runDir, stepIdx, maxChars=2000)\n\n    _logRun(runDir, f\"REVIEW: step {stepIdx + 1}, error: {lastError[:100]}\")\n\n    prompt = prompts.REVIEW_STEP.format(\n        target=target,\n        step_num=f\"{ctx['step_num']}/{stepCount}\",\n        action=ctx[\"action\"],\n        error=ctx[\"last_error\"],\n        attempts=ctx[\"attempts\"],\n        attempt_results=json.dumps(ctx[\"attempt_results\"], indent=2),\n        failed_steps=len(failedSteps),\n        json_rules=prompts.JSON_RULES\n    )\n\n    # Add step log context\n    if stepLog:\n        prompt += f\"\\n\\nSTEP LOG:\\n{stepLog}\"\n\n    result = _callLlm(apiKey, apiBase, model,\n                      [{\"role\": \"system\", \"content\": prompts.SYSTEM},\n                       {\"role\": \"user\", \"content\": prompt}], 0.3, 1024)\n\n    if result.get(\"error\"):\n        _logRun(runDir, \"REVIEW: LLM error, defaulting to skip\")\n        return {\"review_decision\": \"skip\", \"feedback\": f\"Skipping: {lastError}\",\n                \"failed_steps\": failedSteps + [step]}\n\n    try:\n        rv = _extractJson(result[\"response\"])\n        decision = rv.get(\"decision\", \"skip\")\n        if decision not in (\"skip\", \"replan\"):\n            decision = \"skip\"\n        _logRun(runDir, f\"REVIEW DECISION: {decision}\")\n        newFailed = failedSteps + [step] if decision == \"skip\" else failedSteps\n        return {\"review_decision\": decision, \"feedback\": rv.get(\"feedback\", \"\"),\n                \"failed_steps\": newFailed}\n    except ValueError:\n        _logRun(runDir, \"REVIEW: Parse error, defaulting to skip\")\n        return {\"review_decision\": \"skip\", \"feedback\": f\"Skipping: {lastError}\",\n                \"failed_steps\": failedSteps + [step]}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "skill_contractor_compute"}, {"id": "skill_contractor_compute.skip_step", "type": "function", "label": "skip_step", "direction": "inbound", "parent": "skill_contractor_compute", "line": 1351, "endLine": 1364, "signature": "(params) -> Dict[]", "docstring": "Skip current step and advance.", "source": "def skip_step(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Skip current step and advance.\"\"\"\n    plan = params.get(\"plan\", {})\n    stepIdx = params.get(\"step_index\", 0)\n    failedSteps = params.get(\"failed_steps\") or []\n    steps = plan.get(\"steps\", []) if plan else []\n    nextIdx = stepIdx + 1\n    nextStep = steps[nextIdx] if nextIdx < len(steps) else None\n    runDir = Path(params.get(\"run_dir\", \".\"))\n\n    _logRun(runDir, f\"SKIP: step {stepIdx + 1} -> {nextIdx + 1}\")\n\n    return {\"step_index\": nextIdx, \"current_step\": nextStep,\n            \"failed_steps\": failedSteps, \"step_error_count\": 0}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "skill_contractor_compute"}, {"id": "skill_contractor_compute.save_state", "type": "function", "label": "save_state", "direction": "inbound", "parent": "skill_contractor_compute", "line": 1371, "endLine": 1397, "signature": "(params) -> Dict[]", "docstring": "Save state to run folder.", "source": "def save_state(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Save state to run folder.\"\"\"\n    runDir = Path(params.get(\"run_dir\", params.get(\"workspace_path\", \".\")))\n    path = runDir / \"state.json\"\n\n    data = {\n        \"fsm_state\": params.get(\"fsm_state\", \"idle\"),\n        \"run_id\": params.get(\"run_id\"),\n        \"target\": params.get(\"target\"),\n        \"plan\": params.get(\"plan\"),\n        \"step_index\": params.get(\"step_index\"),\n        \"step_count\": params.get(\"step_count\"),\n        \"current_step\": params.get(\"current_step\"),\n        \"execution_log\": params.get(\"execution_log\"),\n        \"artifacts\": params.get(\"artifacts\"),\n        \"iteration\": params.get(\"iteration\"),\n        \"score\": params.get(\"score\"),\n        \"feedback\": params.get(\"feedback\"),\n        \"is_satisfied\": params.get(\"is_satisfied\"),\n        \"repair_attempts\": params.get(\"repair_attempts\"),\n        \"step_error_count\": params.get(\"step_error_count\")\n    }\n    try:\n        path.write_text(json.dumps(data, indent=2))\n        return {\"error\": None}\n    except Exception as e:\n        return {\"error\": str(e)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "skill_contractor_compute"}, {"id": "skill_contractor_compute.load_state", "type": "function", "label": "load_state", "direction": "inbound", "parent": "skill_contractor_compute", "line": 1400, "endLine": 1411, "signature": "(params) -> Dict[]", "docstring": "Load state from run folder.", "source": "def load_state(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Load state from run folder.\"\"\"\n    runDir = Path(params.get(\"run_dir\", params.get(\"workspace_path\", \".\")))\n    path = runDir / \"state.json\"\n    if not path.exists():\n        return {\"has_saved_state\": False}\n    try:\n        data = json.loads(path.read_text())\n        data[\"has_saved_state\"] = True\n        return data\n    except Exception as e:\n        return {\"has_saved_state\": False, \"error\": str(e)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "skill_contractor_compute"}, {"id": "skill_contractor_compute.clear_state", "type": "function", "label": "clear_state", "direction": "inbound", "parent": "skill_contractor_compute", "line": 1414, "endLine": 1420, "signature": "(params) -> Dict[]", "docstring": "Clear saved state.", "source": "def clear_state(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Clear saved state.\"\"\"\n    runDir = Path(params.get(\"run_dir\", params.get(\"workspace_path\", \".\")))\n    path = runDir / \"state.json\"\n    if path.exists():\n        path.unlink()\n    return {\"error\": None}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "skill_contractor_compute"}, {"id": "skill_contractor_compute.log_corrections", "type": "function", "label": "log_corrections", "direction": "inbound", "parent": "skill_contractor_compute", "line": 1423, "endLine": 1441, "signature": "(params) -> Dict[]", "docstring": "Log auto-corrections for review and auto-approve.", "source": "def log_corrections(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Log auto-corrections for review and auto-approve.\"\"\"\n    corrections = params.get(\"corrections\", [])\n    runDir = Path(params.get(\"run_dir\", \".\"))\n    stepIdx = params.get(\"step_index\", 0)\n\n    if not corrections:\n        return {\"corrections_approved\": True}\n\n    # Format and log corrections report\n    report = _formatCorrectionsReport(corrections)\n    _logStep(runDir, stepIdx, \"AUTO_CORRECTIONS\", report)\n\n    # Print for visibility\n    print(f\"\\n{report}\\n\")\n\n    # Auto-approve all corrections (they've been logged for review)\n    # In future, critical corrections could pause for human approval\n    return {\"corrections_approved\": True}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "skill_contractor_compute"}, {"id": "skill_contractor_compute.evaluate_interactive", "type": "function", "label": "evaluate_interactive", "direction": "inbound", "parent": "skill_contractor_compute", "line": 1444, "endLine": 1511, "signature": "(params) -> Dict[]", "docstring": "Evaluate generated interactive.py and related Python files.\nUses frame_py.operational_validator for validation.\n\nValidation stages:\n1. Content - LLM-specific errors (literal newlines, placeholders)\n2. Syntax - AST parsing with line numbers\n3. Import - Module reference validation\n4. Structure - Required elements (COMPUTE_UNITS, etc.)\n\nReturns evaluation results with pass/fail status and feedback.", "source": "def evaluate_interactive(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Evaluate generated interactive.py and related Python files.\n    Uses frame_py.operational_validator for validation.\n\n    Validation stages:\n    1. Content - LLM-specific errors (literal newlines, placeholders)\n    2. Syntax - AST parsing with line numbers\n    3. Import - Module reference validation\n    4. Structure - Required elements (COMPUTE_UNITS, etc.)\n\n    Returns evaluation results with pass/fail status and feedback.\n    \"\"\"\n    runDir = Path(params.get(\"run_dir\", \".\"))\n    outputDir = runDir / \"output\"\n\n    _logRun(runDir, \"EVAL_INTERACTIVE: Starting evaluation\")\n\n    if not outputDir.exists():\n        _logRun(runDir, \"EVAL_INTERACTIVE: No output directory found\")\n        return {\n            \"interactive_valid\": True,  # No output = nothing to fail\n            \"interactive_feedback\": \"No output directory found\",\n            \"error\": None\n        }\n\n    # Use the framework's operational validator\n    try:\n        # Try to import from installed package\n        from frame_py.operational_validator import validate_skill_directory\n    except ImportError:\n        # Fall back to relative import path\n        import sys\n        lpp_root = params.get(\"lpp_root\", \"\")\n        if lpp_root:\n            sys.path.insert(0, os.path.join(lpp_root, \"src\"))\n            from frame_py.operational_validator import validate_skill_directory\n        else:\n            # Cannot import validator, skip this check\n            _logRun(runDir, \"EVAL_INTERACTIVE: Validator not available, skipping\")\n            return {\n                \"interactive_valid\": True,\n                \"interactive_feedback\": \"Validator not available\",\n                \"error\": None\n            }\n\n    # Run validation\n    results = validate_skill_directory(str(outputDir), verbose=True)\n\n    # Log results\n    _logRun(\n        runDir, f\"EVAL_INTERACTIVE: {'PASSED' if results['passed'] else 'FAILED'}\")\n    _logRun(runDir, f\"FEEDBACK: {results['feedback'][:500]}\")\n\n    if results[\"passed\"]:\n        print(f\"  [EVAL_INTERACTIVE] \u2713 {results['feedback']}\")\n    else:\n        print(\n            f\"  [EVAL_INTERACTIVE] \u2717 FAILED - {len(results['errors'])} errors\")\n        # Print first few lines of feedback\n        for line in results['feedback'].split('\\n')[:8]:\n            print(f\"    {line}\")\n\n    return {\n        \"interactive_valid\": results[\"passed\"],\n        \"interactive_feedback\": results[\"feedback\"],\n        \"error\": None\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#00d4ff", "moduleName": "skill_contractor_compute"}, {"id": "skill_contractor_compute.sanitize_python_code", "type": "function", "label": "sanitize_python_code", "direction": "inbound", "parent": "skill_contractor_compute", "line": 35, "endLine": 36, "signature": "(code, filename, verbose)", "docstring": null, "source": "    def sanitize_python_code(code, filename=\"code.py\", verbose=False):\n        return code, []  # No-op fallback", "args": ["code", "filename", "verbose"], "returns": null, "moduleColor": "#00d4ff", "moduleName": "skill_contractor_compute"}, {"id": "subprocess", "type": "dependency", "label": "subprocess", "direction": "outbound", "category": "stdlib", "moduleColor": "#00d4ff", "moduleName": "skill_contractor_compute"}, {"id": "relative.level1", "type": "dependency", "label": "level1", "direction": "outbound", "category": "local", "moduleColor": "#00d4ff", "moduleName": "skill_contractor_compute"}, {"id": "frame_py.operational_validator", "type": "dependency", "label": "operational_validator", "direction": "outbound", "category": "pip", "moduleColor": "#00d4ff", "moduleName": "skill_contractor_compute"}, {"id": "registry_compute", "type": "module", "label": "registry_compute", "metrics": {"fanIn": 4, "fanOut": 5, "instability": 0.556, "internalEdges": 1, "externalCallCount": 7, "localCallCount": 0, "callsByCategory": {"stdlib": 7}, "localDependencies": []}, "moduleColor": "#ff6b6b", "moduleName": "registry_compute"}, {"id": "registry_compute.scan", "type": "function", "label": "scan", "direction": "inbound", "parent": "registry_compute", "line": 13, "endLine": 57, "signature": "(params) -> Dict[]", "docstring": "Scan directory for L++ skill blueprints.\nInput: basePath\nOutput: skills (list of skill summaries), error", "source": "def scan(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Scan directory for L++ skill blueprints.\n    Input: basePath\n    Output: skills (list of skill summaries), error\n    \"\"\"\n    basePath = params.get(\"basePath\", \"\")\n    if not basePath:\n        return {\"skills\": None, \"error\": \"No basePath provided\"}\n\n    try:\n        base = Path(basePath)\n        if not base.exists():\n            return {\"skills\": None, \"error\": f\"Path not found: {basePath}\"}\n\n        skills = []\n        for item in base.iterdir():\n            if not item.is_dir():\n                continue\n            # Look for blueprint JSON\n            for f in item.glob(\"*.json\"):\n                if f.name.startswith(\".\") or \"compiled\" in f.name:\n                    continue\n                try:\n                    bp = json.loads(f.read_text())\n                    if bp.get(\"$schema\", \"\").startswith(\"lpp\"):\n                        skills.append({\n                            \"id\": bp.get(\"id\", f.stem),\n                            \"name\": bp.get(\"name\", f.stem),\n                            \"version\": bp.get(\"version\", \"0.0.0\"),\n                            \"description\": bp.get(\"description\", \"\"),\n                            \"path\": str(f),\n                            \"dir\": str(item),\n                            \"stateCount\": len(bp.get(\"states\", {})),\n                            \"transitionCount\": len(bp.get(\"transitions\", [])),\n                            \"gateCount\": len(bp.get(\"gates\", {})),\n                            \"actionCount\": len(bp.get(\"actions\", {}))\n                        })\n                except (json.JSONDecodeError, KeyError):\n                    continue\n\n        return {\"skills\": skills, \"error\": None}\n\n    except Exception as e:\n        return {\"skills\": None, \"error\": f\"Scan error: {e}\"}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#ff6b6b", "moduleName": "registry_compute"}, {"id": "registry_compute.loadDetail", "type": "function", "label": "loadDetail", "direction": "inbound", "parent": "registry_compute", "line": 60, "endLine": 163, "signature": "(params) -> Dict[]", "docstring": "Load full detail for a skill.\nInput: skillId, basePath\nOutput: selectedSkill (full metadata), error", "source": "def loadDetail(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Load full detail for a skill.\n    Input: skillId, basePath\n    Output: selectedSkill (full metadata), error\n    \"\"\"\n    skillId = params.get(\"skillId\", \"\")\n    basePath = params.get(\"basePath\", \"\")\n\n    if not skillId:\n        return {\"selectedSkill\": None, \"error\": \"No skillId provided\"}\n\n    try:\n        base = Path(basePath)\n        skillDir = base / skillId\n        if not skillDir.exists():\n            # Try finding by ID in any subdir\n            for d in base.iterdir():\n                for f in d.glob(\"*.json\"):\n                    try:\n                        bp = json.loads(f.read_text())\n                        if bp.get(\"id\") == skillId:\n                            skillDir = d\n                            break\n                    except:\n                        continue\n\n        bpFile = None\n        for f in skillDir.glob(\"*.json\"):\n            if not f.name.startswith(\".\") and \"compiled\" not in f.name:\n                try:\n                    bp = json.loads(f.read_text())\n                    if bp.get(\"$schema\", \"\").startswith(\"lpp\"):\n                        bpFile = f\n                        break\n                except:\n                    continue\n\n        if not bpFile:\n            return {\"selectedSkill\": None, \"error\": f\"Blueprint not found: {skillId}\"}\n\n        bp = json.loads(bpFile.read_text())\n\n        # Extract context schema for flange spec\n        ctxSchema = bp.get(\"context_schema\", {}).get(\"properties\", {})\n        flangeSpec = {k: v.get(\"type\", \"any\") for k, v in ctxSchema.items()}\n\n        # Extract compute units from actions\n        computeUnits = []\n        for aName, action in bp.get(\"actions\", {}).items():\n            if action.get(\"type\") == \"compute\":\n                computeUnits.append({\n                    \"action\": aName,\n                    \"unit\": action.get(\"compute_unit\", \"\"),\n                    \"inputs\": list(action.get(\"input_map\", {}).keys()),\n                    \"outputs\": list(action.get(\"output_map\", {}).keys())\n                })\n\n        # Load COMPUTE registry if exists\n        srcDir = skillDir / \"src\"\n        registryFns = []\n        if srcDir.exists():\n            for pyFile in srcDir.glob(\"*_compute.py\"):\n                content = pyFile.read_text()\n                # Parse COMPUTE_REGISTRY\n                if \"COMPUTE_REGISTRY\" in content:\n                    import re\n                    matches = re.findall(\n                        r'\"([^\"]+)\":\\s*(\\w+)',\n                        content.split(\"COMPUTE_REGISTRY\")[1][:500]\n                    )\n                    registryFns = [{\"key\": m[0], \"fn\": m[1]} for m in matches]\n\n        detail = {\n            \"id\": bp.get(\"id\"),\n            \"name\": bp.get(\"name\"),\n            \"version\": bp.get(\"version\"),\n            \"description\": bp.get(\"description\"),\n            \"path\": str(bpFile),\n            \"states\": list(bp.get(\"states\", {}).keys()),\n            \"entryState\": bp.get(\"entry_state\"),\n            \"terminalStates\": bp.get(\"terminal_states\", []),\n            \"gates\": list(bp.get(\"gates\", {}).keys()),\n            \"actions\": list(bp.get(\"actions\", {}).keys()),\n            \"transitions\": [\n                {\n                    \"id\": t.get(\"id\"),\n                    \"from\": t.get(\"from\"),\n                    \"to\": t.get(\"to\"),\n                    \"event\": t.get(\"on_event\"),\n                    \"gates\": t.get(\"gates\", []),\n                    \"actions\": t.get(\"actions\", [])\n                }\n                for t in bp.get(\"transitions\", [])\n            ],\n            \"flangeSpec\": flangeSpec,\n            \"computeUnits\": computeUnits,\n            \"registryFunctions\": registryFns\n        }\n\n        return {\"selectedSkill\": detail, \"error\": None}\n\n    except Exception as e:\n        return {\"selectedSkill\": None, \"error\": f\"Load error: {e}\"}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#ff6b6b", "moduleName": "registry_compute"}, {"id": "registry_compute.export", "type": "function", "label": "export", "direction": "inbound", "parent": "registry_compute", "line": 166, "endLine": 245, "signature": "(params) -> Dict[]", "docstring": "Export full registry as agent context.\nInput: skills, basePath\nOutput: registry (structured context for agent), error", "source": "def export(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Export full registry as agent context.\n    Input: skills, basePath\n    Output: registry (structured context for agent), error\n    \"\"\"\n    skills = params.get(\"skills\", [])\n    basePath = params.get(\"basePath\", \"\")\n\n    if not skills:\n        return {\"registry\": None, \"error\": \"No skills to export\"}\n\n    try:\n        registry = {\n            \"meta\": {\n                \"basePath\": basePath,\n                \"skillCount\": len(skills),\n                \"generatedAt\": __import__(\"datetime\").datetime.now().isoformat()\n            },\n            \"skills\": {},\n            \"patterns\": {\n                \"commonStates\": {},\n                \"commonGates\": {},\n                \"commonActions\": {}\n            }\n        }\n\n        allStates = {}\n        allGates = {}\n        allActions = {}\n\n        for skill in skills:\n            # Load full detail for each skill\n            detail = loadDetail({\n                \"skillId\": skill[\"id\"],\n                \"basePath\": basePath\n            })[\"selectedSkill\"]\n\n            if not detail:\n                continue\n\n            registry[\"skills\"][skill[\"id\"]] = {\n                \"name\": detail[\"name\"],\n                \"version\": detail[\"version\"],\n                \"description\": detail[\"description\"],\n                \"states\": detail[\"states\"],\n                \"entryState\": detail[\"entryState\"],\n                \"gates\": detail[\"gates\"],\n                \"actions\": detail[\"actions\"],\n                \"flangeSpec\": detail[\"flangeSpec\"],\n                \"computeUnits\": detail[\"computeUnits\"],\n                \"transitionGraph\": [\n                    f\"{t['from']} --[{t['event']}]--> {t['to']}\"\n                    for t in detail[\"transitions\"]\n                ]\n            }\n\n            # Collect patterns\n            for s in detail[\"states\"]:\n                allStates[s] = allStates.get(s, 0) + 1\n            for g in detail[\"gates\"]:\n                allGates[g] = allGates.get(g, 0) + 1\n            for a in detail[\"actions\"]:\n                allActions[a] = allActions.get(a, 0) + 1\n\n        # Find common patterns (appear in > 1 skill)\n        registry[\"patterns\"][\"commonStates\"] = {\n            k: v for k, v in allStates.items() if v > 1\n        }\n        registry[\"patterns\"][\"commonGates\"] = {\n            k: v for k, v in allGates.items() if v > 1\n        }\n        registry[\"patterns\"][\"commonActions\"] = {\n            k: v for k, v in allActions.items() if v > 1\n        }\n\n        return {\"registry\": registry, \"error\": None}\n\n    except Exception as e:\n        return {\"registry\": None, \"error\": f\"Export error: {e}\"}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#ff6b6b", "moduleName": "registry_compute"}, {"id": "registry_compute.formatContext", "type": "function", "label": "formatContext", "direction": "inbound", "parent": "registry_compute", "line": 248, "endLine": 300, "signature": "(params) -> Dict[]", "docstring": "Format registry as markdown for agent context.\nInput: registry\nOutput: markdown, error", "source": "def formatContext(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Format registry as markdown for agent context.\n    Input: registry\n    Output: markdown, error\n    \"\"\"\n    registry = params.get(\"registry\")\n    if not registry:\n        return {\"markdown\": None, \"error\": \"No registry provided\"}\n\n    try:\n        lines = [\n            \"# L++ Skill Registry\",\n            f\"Generated: {registry['meta']['generatedAt']}\",\n            f\"Skills: {registry['meta']['skillCount']}\",\n            \"\",\n            \"## Available Skills\",\n            \"\"\n        ]\n\n        for sid, skill in registry.get(\"skills\", {}).items():\n            lines.append(f\"### {skill['name']} ({sid})\")\n            lines.append(f\"_{skill['description']}_\")\n            lines.append(\"\")\n            lines.append(f\"**States**: {', '.join(skill['states'])}\")\n            lines.append(f\"**Entry**: {skill['entryState']}\")\n            lines.append(\"\")\n            lines.append(\"**Flange Spec (Context Schema)**:\")\n            for k, v in skill.get(\"flangeSpec\", {}).items():\n                lines.append(f\"  - `{k}`: {v}\")\n            lines.append(\"\")\n            lines.append(\"**COMPUTE Units**:\")\n            for cu in skill.get(\"computeUnits\", []):\n                lines.append(\n                    f\"  - `{cu['unit']}`: {cu['inputs']} -> {cu['outputs']}\")\n            lines.append(\"\")\n            lines.append(\"**Transition Graph**:\")\n            for t in skill.get(\"transitionGraph\", []):\n                lines.append(f\"  - {t}\")\n            lines.append(\"\")\n\n        if registry.get(\"patterns\", {}).get(\"commonStates\"):\n            lines.append(\"## Common Patterns\")\n            lines.append(\"\")\n            lines.append(\"**Reusable States**:\")\n            for s, cnt in registry[\"patterns\"][\"commonStates\"].items():\n                lines.append(f\"  - `{s}` (used in {cnt} skills)\")\n            lines.append(\"\")\n\n        return {\"markdown\": \"\\n\".join(lines), \"error\": None}\n\n    except Exception as e:\n        return {\"markdown\": None, \"error\": f\"Format error: {e}\"}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#ff6b6b", "moduleName": "registry_compute"}, {"id": "orchestrator_compute", "type": "module", "label": "orchestrator_compute", "metrics": {"fanIn": 12, "fanOut": 7, "instability": 0.368, "internalEdges": 0, "externalCallCount": 14, "localCallCount": 0, "callsByCategory": {"pip": 1, "stdlib": 13}, "localDependencies": []}, "moduleColor": "#4ecdc4", "moduleName": "orchestrator_compute"}, {"id": "orchestrator_compute.init", "type": "function", "label": "init", "direction": "inbound", "parent": "orchestrator_compute", "line": 63, "endLine": 76, "signature": "(params) -> Dict[]", "docstring": "Initialize orchestrator config from environment.", "source": "def init(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Initialize orchestrator config from environment.\"\"\"\n    return {\n        \"api_key\": os.environ.get(\"OPENAI_API_KEY\"),\n        \"api_base\": os.environ.get(\n            \"OPENAI_API_BASE\",\n            \"https://api.openai.com/v1\"\n        ),\n        \"model\": os.environ.get(\"OPENAI_MODEL\", \"gpt-4o-mini\"),\n        \"max_depth\": int(os.environ.get(\"ORCH_MAX_DEPTH\", \"3\")),\n        \"max_iterations\": int(os.environ.get(\"ORCH_MAX_ITER\", \"5\")),\n        \"iteration\": 0,\n        \"workspace_path\": os.environ.get(\"ORCH_WORKSPACE\", os.getcwd())\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#4ecdc4", "moduleName": "orchestrator_compute"}, {"id": "orchestrator_compute.analyze_root", "type": "function", "label": "analyze_root", "direction": "inbound", "parent": "orchestrator_compute", "line": 83, "endLine": 133, "signature": "(params) -> Dict[]", "docstring": "Analyze task and create root feature tree.", "source": "def analyze_root(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Analyze task and create root feature tree.\"\"\"\n    task = params.get(\"task\", \"\")\n\n    prompt = f\"\"\"Analyze this task and identify top-level features.\n\nTASK: {task}\n\nReturn a feature tree as JSON:\n```json\n{{\n  \"id\": \"root\",\n  \"name\": \"Root Task\",\n  \"desc\": \"...\",\n  \"children\": [\n    {{\"id\": \"f1\", \"name\": \"Feature 1\", \"desc\": \"...\", \"children\": []}},\n    {{\"id\": \"f2\", \"name\": \"Feature 2\", \"desc\": \"...\", \"children\": []}}\n  ],\n  \"status\": \"pending\"\n}}\n```\n\nRules:\n- Break into 2-5 top-level features\n- Each feature should be independently verifiable\n- Order by dependency (foundational first)\n- Leave children empty for now (will expand later)\"\"\"\n\n    try:\n        resp = _llm(\n            params[\"api_key\"], params[\"api_base\"], params[\"model\"], prompt\n        )\n        tree = _json(resp)\n        has_children = len(tree.get(\"children\", [])) > 0\n        return {\n            \"feature_tree\": tree,\n            \"current_path\": [],\n            \"current_feature\": tree,\n            \"depth\": 0,\n            \"is_leaf\": not has_children,\n            \"error\": None\n        }\n    except Exception as e:\n        return {\n            \"feature_tree\": None,\n            \"current_path\": [],\n            \"current_feature\": None,\n            \"depth\": 0,\n            \"is_leaf\": True,\n            \"error\": str(e)\n        }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#4ecdc4", "moduleName": "orchestrator_compute"}, {"id": "orchestrator_compute.expand", "type": "function", "label": "expand", "direction": "inbound", "parent": "orchestrator_compute", "line": 140, "endLine": 208, "signature": "(params) -> Dict[]", "docstring": "Expand a feature into sub-features (one level deeper).", "source": "def expand(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Expand a feature into sub-features (one level deeper).\"\"\"\n    tree = params.get(\"feature_tree\", {})\n    path = params.get(\"current_path\", [])\n    feature = params.get(\"current_feature\", {})\n    depth = params.get(\"depth\", 0)\n    max_depth = params.get(\"max_depth\", 3)\n\n    # Find next unexpanded node\n    node, new_path = _find_unexpanded(tree, max_depth)\n    if node is None:\n        return {\n            \"feature_tree\": tree,\n            \"current_feature\": feature,\n            \"depth\": depth,\n            \"is_leaf\": True,\n            \"error\": None\n        }\n\n    prompt = f\"\"\"Expand this feature into atomic sub-features.\n\nFEATURE: {node.get('name', '')}\nDESCRIPTION: {node.get('desc', '')}\nCURRENT DEPTH: {len(new_path)}\n\nReturn expanded children as JSON array:\n```json\n[\n  {{\"id\": \"sf1\", \"name\": \"Sub-feature 1\", \"desc\": \"...\", \"children\": []}},\n  {{\"id\": \"sf2\", \"name\": \"Sub-feature 2\", \"desc\": \"...\", \"children\": []}}\n]\n```\n\nRules:\n- Break into 2-4 sub-features\n- Make each sub-feature as atomic as possible\n- If already atomic, return empty array []\n- Each should be a single, verifiable unit of work\"\"\"\n\n    try:\n        resp = _llm(\n            params[\"api_key\"], params[\"api_base\"], params[\"model\"], prompt, 0.5\n        )\n        children = _json(resp)\n        node[\"children\"] = children\n        node[\"status\"] = \"expanded\"\n\n        # Update tree at path\n        _set_at_path(tree, new_path, node)\n\n        # Check if more to expand\n        next_node, _ = _find_unexpanded(tree, max_depth)\n        is_leaf = next_node is None\n\n        return {\n            \"feature_tree\": tree,\n            \"current_feature\": node,\n            \"depth\": len(new_path),\n            \"is_leaf\": is_leaf,\n            \"error\": None\n        }\n    except Exception as e:\n        return {\n            \"feature_tree\": tree,\n            \"current_feature\": feature,\n            \"depth\": depth,\n            \"is_leaf\": True,\n            \"error\": str(e)\n        }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#4ecdc4", "moduleName": "orchestrator_compute"}, {"id": "orchestrator_compute.collect", "type": "function", "label": "collect", "direction": "inbound", "parent": "orchestrator_compute", "line": 242, "endLine": 253, "signature": "(params) -> Dict[]", "docstring": "Collect all leaf nodes from feature tree.", "source": "def collect(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Collect all leaf nodes from feature tree.\"\"\"\n    tree = params.get(\"feature_tree\", {})\n    leaves = []\n    _collect_leaves(tree, [], leaves)\n\n    return {\n        \"leaf_queue\": leaves,\n        \"leaf_count\": len(leaves),\n        \"exec_count\": 0,\n        \"error\": None\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#4ecdc4", "moduleName": "orchestrator_compute"}, {"id": "orchestrator_compute.plan_leaf", "type": "function", "label": "plan_leaf", "direction": "inbound", "parent": "orchestrator_compute", "line": 276, "endLine": 335, "signature": "(params) -> Dict[]", "docstring": "Plan execution for current leaf node.", "source": "def plan_leaf(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Plan execution for current leaf node.\"\"\"\n    queue = params.get(\"leaf_queue\", [])\n    idx = params.get(\"exec_count\", 0)\n    ws = params.get(\"workspace_path\", \".\")\n\n    if idx >= len(queue):\n        return {\n            \"current_feature\": None,\n            \"tools_needed\": [],\n            \"tools_pending\": 0,\n            \"error\": None\n        }\n\n    leaf = queue[idx]\n\n    prompt = f\"\"\"Plan implementation for this atomic feature.\n\nFEATURE: {leaf.get('name', '')}\nDESCRIPTION: {leaf.get('desc', '')}\nWORKSPACE: {ws}\n\nReturn JSON plan:\n```json\n{{\n  \"steps\": [\n    {{\"id\": \"s1\", \"action\": \"...\", \"details\": \"...\"}}\n  ],\n  \"tools_needed\": [\n    {{\"name\": \"tool_name\", \"purpose\": \"...\"}}\n  ]\n}}\n```\n\nRules:\n- Keep steps minimal and concrete\n- Only list tools if truly needed (prefer existing)\n- Each step should be independently executable\"\"\"\n\n    try:\n        resp = _llm(\n            params[\"api_key\"], params[\"api_base\"], params[\"model\"], prompt, 0.3\n        )\n        plan = _json(resp)\n        leaf[\"plan\"] = plan\n        tools = plan.get(\"tools_needed\", [])\n\n        return {\n            \"current_feature\": leaf,\n            \"tools_needed\": tools,\n            \"tools_pending\": len(tools),\n            \"error\": None\n        }\n    except Exception as e:\n        return {\n            \"current_feature\": leaf,\n            \"tools_needed\": [],\n            \"tools_pending\": 0,\n            \"error\": str(e)\n        }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#4ecdc4", "moduleName": "orchestrator_compute"}, {"id": "orchestrator_compute.build", "type": "function", "label": "build", "direction": "inbound", "parent": "orchestrator_compute", "line": 342, "endLine": 407, "signature": "(params) -> Dict[]", "docstring": "Build one tool from the needed list.", "source": "def build(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Build one tool from the needed list.\"\"\"\n    tools = params.get(\"tools_needed\", [])\n    pending = params.get(\"tools_pending\", 0)\n    built = params.get(\"tools_built\", []) or []\n    ws = params.get(\"workspace_path\", \".\")\n\n    if not tools:\n        return {\n            \"tools_needed\": [],\n            \"tools_pending\": 0,\n            \"tools_built\": built,\n            \"error\": None\n        }\n\n    tool = tools[0]\n    name = tool.get(\"name\", \"tool\")\n\n    prompt = f\"\"\"Generate L++ skill blueprint for: {name}\nPurpose: {tool.get('purpose', '')}\n\nReturn valid JSON blueprint (schema v0.1.2):\n```json\n{{\n  \"$schema\": \"lpp/v0.1.2\",\n  \"id\": \"{name}\",\n  \"name\": \"...\",\n  \"description\": \"...\",\n  \"context_schema\": {{\"properties\": {{}}}},\n  \"states\": {{}},\n  \"entry_state\": \"idle\",\n  \"terminal_states\": [],\n  \"gates\": {{}},\n  \"actions\": {{}},\n  \"transitions\": []\n}}\n```\"\"\"\n\n    try:\n        resp = _llm(\n            params[\"api_key\"], params[\"api_base\"], params[\"model\"], prompt, 0.3\n        )\n        bp = _json(resp)\n\n        # Save\n        d = Path(ws) / \"utils\" / name\n        d.mkdir(parents=True, exist_ok=True)\n        p = d / f\"{name}.json\"\n        p.write_text(json.dumps(bp, indent=2))\n\n        built.append({\"name\": name, \"path\": str(p), \"status\": \"created\"})\n        remaining = tools[1:]\n\n        return {\n            \"tools_needed\": remaining,\n            \"tools_pending\": len(remaining),\n            \"tools_built\": built,\n            \"error\": None\n        }\n    except Exception as e:\n        return {\n            \"tools_needed\": tools,\n            \"tools_pending\": pending,\n            \"tools_built\": built,\n            \"error\": f\"Build failed: {e}\"\n        }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#4ecdc4", "moduleName": "orchestrator_compute"}, {"id": "orchestrator_compute.exec_leaf", "type": "function", "label": "exec_leaf", "direction": "inbound", "parent": "orchestrator_compute", "line": 414, "endLine": 469, "signature": "(params) -> Dict[]", "docstring": "Execute current leaf feature.", "source": "def exec_leaf(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Execute current leaf feature.\"\"\"\n    feature = params.get(\"current_feature\", {})\n    queue = params.get(\"leaf_queue\", [])\n    idx = params.get(\"exec_count\", 0)\n    log = params.get(\"exec_log\", []) or []\n    ws = params.get(\"workspace_path\", \".\")\n\n    if idx >= len(queue):\n        return {\n            \"leaf_queue\": queue,\n            \"exec_count\": idx,\n            \"exec_log\": log,\n            \"error\": None\n        }\n\n    prompt = f\"\"\"Execute this atomic feature and report result.\n\nFEATURE: {feature.get('name', '')}\nDESCRIPTION: {feature.get('desc', '')}\nPLAN: {json.dumps(feature.get('plan', {}), indent=2)}\nWORKSPACE: {ws}\n\nDescribe actions taken and outcomes. Be specific.\"\"\"\n\n    try:\n        resp = _llm(\n            params[\"api_key\"], params[\"api_base\"], params[\"model\"], prompt\n        )\n\n        # Update queue\n        queue[idx][\"status\"] = \"complete\"\n        queue[idx][\"result\"] = resp[:500]\n\n        # Add to log\n        log.append({\n            \"id\": feature.get(\"id\", \"\"),\n            \"name\": feature.get(\"name\", \"\"),\n            \"status\": \"complete\",\n            \"result\": resp[:200]\n        })\n\n        return {\n            \"leaf_queue\": queue,\n            \"exec_count\": idx + 1,\n            \"exec_log\": log,\n            \"error\": None\n        }\n    except Exception as e:\n        queue[idx][\"status\"] = \"failed\"\n        return {\n            \"leaf_queue\": queue,\n            \"exec_count\": idx,\n            \"exec_log\": log,\n            \"error\": str(e)\n        }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#4ecdc4", "moduleName": "orchestrator_compute"}, {"id": "orchestrator_compute.next_leaf", "type": "function", "label": "next_leaf", "direction": "inbound", "parent": "orchestrator_compute", "line": 476, "endLine": 498, "signature": "(params) -> Dict[]", "docstring": "Prepare next leaf for execution.", "source": "def next_leaf(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Prepare next leaf for execution.\"\"\"\n    queue = params.get(\"leaf_queue\", [])\n    idx = params.get(\"exec_count\", 0)\n    count = params.get(\"leaf_count\", 0)\n\n    if idx >= count:\n        return {\n            \"current_feature\": None,\n            \"tools_pending\": 0,\n            \"is_complete\": True,\n            \"error\": None\n        }\n\n    leaf = queue[idx]\n    tools = leaf.get(\"plan\", {}).get(\"tools_needed\", [])\n\n    return {\n        \"current_feature\": leaf,\n        \"tools_pending\": len(tools),\n        \"is_complete\": False,\n        \"error\": None\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#4ecdc4", "moduleName": "orchestrator_compute"}, {"id": "orchestrator_compute.reflect", "type": "function", "label": "reflect", "direction": "inbound", "parent": "orchestrator_compute", "line": 505, "endLine": 545, "signature": "(params) -> Dict[]", "docstring": "Reflect on execution progress.", "source": "def reflect(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Reflect on execution progress.\"\"\"\n    task = params.get(\"task\", \"\")\n    tree = params.get(\"feature_tree\", {})\n    logs = params.get(\"exec_log\", [])\n    iteration = params.get(\"iteration\", 0)\n\n    done = [\n        ls for ls in logs if ls.get(\"status\") == \"complete\"\n    ]\n\n    prompt = f\"\"\"Reflect on task progress.\n\nTASK: {task}\nITERATION: {iteration + 1}\nCOMPLETED: {len(done)}/{len(logs)} features\n\nEXECUTION LOG:\n{json.dumps(logs[-5:], indent=2)}\n\nProvide:\n1. Progress assessment\n2. What worked\n3. What needs adjustment\n4. Recommended next steps\"\"\"\n\n    try:\n        resp = _llm(\n            params[\"api_key\"], params[\"api_base\"], params[\"model\"], prompt\n        )\n        return {\n            \"reflection\": resp,\n            \"feature_tree\": tree,\n            \"error\": None\n        }\n    except Exception as e:\n        return {\n            \"reflection\": \"\",\n            \"feature_tree\": tree,\n            \"error\": str(e)\n        }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#4ecdc4", "moduleName": "orchestrator_compute"}, {"id": "orchestrator_compute.evaluate", "type": "function", "label": "evaluate", "direction": "inbound", "parent": "orchestrator_compute", "line": 552, "endLine": 596, "signature": "(params) -> Dict[]", "docstring": "Evaluate task completion.", "source": "def evaluate(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Evaluate task completion.\"\"\"\n    task = params.get(\"task\", \"\")\n    logs = params.get(\"exec_log\", [])\n    reflection = params.get(\"reflection\", \"\")\n    iteration = params.get(\"iteration\", 0)\n    max_iter = params.get(\"max_iterations\", 5)\n\n    done = [ls for ls in logs if ls.get(\"status\") == \"complete\"]\n\n    prompt = f\"\"\"Evaluate task completion.\n\nTASK: {task}\nITERATION: {iteration + 1}/{max_iter}\nCOMPLETED: {len(done)}/{len(log)} features\nREFLECTION: {reflection[:500]}\n\nReturn JSON:\n```json\n{{\n  \"complete\": true/false,\n  \"score\": 0.0-1.0,\n  \"reason\": \"...\",\n  \"remaining\": []\n}}\n```\n\nMark complete=true ONLY if task objectives are fully met.\"\"\"\n\n    try:\n        resp = _llm(\n            params[\"api_key\"], params[\"api_base\"], params[\"model\"], prompt, 0.3\n        )\n        ev = _json(resp)\n        return {\n            \"evaluation\": ev,\n            \"is_complete\": ev.get(\"complete\", False),\n            \"error\": None\n        }\n    except Exception as e:\n        return {\n            \"evaluation\": {\"complete\": False, \"score\": 0, \"reason\": str(e)},\n            \"is_complete\": False,\n            \"error\": None\n        }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#4ecdc4", "moduleName": "orchestrator_compute"}, {"id": "orchestrator_compute.incr", "type": "function", "label": "incr", "direction": "inbound", "parent": "orchestrator_compute", "line": 603, "endLine": 605, "signature": "(params) -> Dict[]", "docstring": "Increment iteration counter.", "source": "def incr(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Increment iteration counter.\"\"\"\n    return {\"iteration\": params.get(\"iteration\", 0) + 1}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#4ecdc4", "moduleName": "orchestrator_compute"}, {"id": "orchestrator_compute.reset_exec", "type": "function", "label": "reset_exec", "direction": "inbound", "parent": "orchestrator_compute", "line": 608, "endLine": 610, "signature": "(params) -> Dict[]", "docstring": "Reset execution state for next iteration.", "source": "def reset_exec(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Reset execution state for next iteration.\"\"\"\n    return {\"exec_count\": 0, \"tools_pending\": 0}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#4ecdc4", "moduleName": "orchestrator_compute"}, {"id": "email.mime", "type": "dependency", "label": "mime", "direction": "outbound", "category": "stdlib", "moduleColor": "#4ecdc4", "moduleName": "orchestrator_compute"}, {"id": "logging", "type": "dependency", "label": "logging", "direction": "outbound", "category": "stdlib", "moduleColor": "#4ecdc4", "moduleName": "orchestrator_compute"}, {"id": "test_compute", "type": "module", "label": "test_compute", "metrics": {"fanIn": 14, "fanOut": 6, "instability": 0.3, "internalEdges": 0, "externalCallCount": 11, "localCallCount": 0, "callsByCategory": {"stdlib": 10, "pip": 1}, "localDependencies": []}, "moduleColor": "#f39c12", "moduleName": "test_compute"}, {"id": "test_compute.load_blueprint", "type": "function", "label": "load_blueprint", "direction": "inbound", "parent": "test_compute", "line": 22, "endLine": 80, "signature": "(params) -> Dict[]", "docstring": "Load an L++ blueprint from a JSON file.", "source": "def load_blueprint(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Load an L++ blueprint from a JSON file.\"\"\"\n    path = params.get(\"path\")\n    if not path:\n        return {\"blueprint\": None, \"path\": None, \"error\": \"No path provided\"}\n\n    try:\n        path = Path(path)\n        if not path.exists():\n            return {\"blueprint\": None, \"path\": None,\n                    \"error\": f\"File not found: {path}\"}\n\n        with open(path) as f:\n            raw = json.load(f)\n\n        loader = BlueprintLoader(raw)\n        blueprint, loadError = loader.load()\n\n        if loadError:\n            return {\"blueprint\": None, \"path\": None, \"error\": loadError}\n\n        # Convert to dict structure for processing\n        bpData = {\n            \"id\": blueprint.id,\n            \"name\": blueprint.name,\n            \"version\": blueprint.version,\n            \"description\": blueprint.description,\n            \"context_schema\": raw.get(\"context_schema\", {}),\n            \"states\": {\n                sid: {\"description\": s.description}\n                for sid, s in blueprint.states.items()\n            },\n            \"transitions\": [\n                {\n                    \"id\": t.id,\n                    \"from\": t.from_state,\n                    \"to\": t.to_state,\n                    \"on_event\": t.on_event,\n                    \"gates\": list(t.gates),\n                    \"actions\": list(t.actions)\n                }\n                for t in blueprint.transitions\n            ],\n            \"gates\": {\n                gid: {\"type\": \"expression\", \"expression\": g.expression}\n                for gid, g in blueprint.gates.items()\n            },\n            \"actions\": {\n                aid: {\"type\": a.type.value}\n                for aid, a in blueprint.actions.items()\n            },\n            \"entry_state\": blueprint.entry_state,\n            \"terminal_states\": list(blueprint.terminal_states)\n        }\n\n        return {\"blueprint\": bpData, \"path\": str(path), \"error\": None}\n\n    except Exception as e:\n        return {\"blueprint\": None, \"path\": None, \"error\": str(e)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#f39c12", "moduleName": "test_compute"}, {"id": "test_compute.build_graph", "type": "function", "label": "build_graph", "direction": "inbound", "parent": "test_compute", "line": 87, "endLine": 135, "signature": "(params) -> Dict[]", "docstring": "Build adjacency graph from blueprint transitions.", "source": "def build_graph(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Build adjacency graph from blueprint transitions.\"\"\"\n    bp = params.get(\"blueprint\")\n    if not bp:\n        return {\"graph\": None}\n\n    # Build adjacency list: state -> [(event, target, transition_id, gates)]\n    adj = {sid: [] for sid in bp[\"states\"]}\n    wildcardEdges = []\n\n    for t in bp[\"transitions\"]:\n        fromState = t[\"from\"]\n        toState = t[\"to\"]\n        edge = {\n            \"event\": t[\"on_event\"],\n            \"to\": toState,\n            \"id\": t[\"id\"],\n            \"gates\": t.get(\"gates\", []),\n            \"actions\": t.get(\"actions\", [])\n        }\n\n        if fromState == \"*\":\n            wildcardEdges.append(edge)\n        else:\n            if fromState not in adj:\n                adj[fromState] = []\n            adj[fromState].append(edge)\n\n    # Apply wildcard edges to all states\n    for sid in adj:\n        adj[sid].extend(wildcardEdges)\n\n    # Build reverse adjacency for reachability analysis\n    reverseAdj = {sid: [] for sid in bp[\"states\"]}\n    for sid, edges in adj.items():\n        for edge in edges:\n            if edge[\"to\"] in reverseAdj:\n                reverseAdj[edge[\"to\"]].append({\"from\": sid, \"event\": edge[\"event\"]})\n\n    return {\n        \"graph\": {\n            \"adjacency\": adj,\n            \"reverse\": reverseAdj,\n            \"entry\": bp[\"entry_state\"],\n            \"terminals\": bp[\"terminal_states\"],\n            \"states\": list(bp[\"states\"].keys()),\n            \"transition_count\": len(bp[\"transitions\"])\n        }\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#f39c12", "moduleName": "test_compute"}, {"id": "test_compute.analyze_paths", "type": "function", "label": "analyze_paths", "direction": "inbound", "parent": "test_compute", "line": 138, "endLine": 228, "signature": "(params) -> Dict[]", "docstring": "Find all paths through the state machine using BFS for efficiency.", "source": "def analyze_paths(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Find all paths through the state machine using BFS for efficiency.\"\"\"\n    bp = params.get(\"blueprint\")\n    graph = params.get(\"graph\")\n\n    if not bp or not graph:\n        return {\"paths\": []}\n\n    adj = graph[\"adjacency\"]\n    entry = graph[\"entry\"]\n    terminals = set(graph[\"terminals\"])\n    allStates = set(graph[\"states\"])\n\n    paths = []\n\n    # Strategy 1: Find shortest path to each reachable state (state coverage)\n    # This gives us minimum paths needed to visit all states\n    for targetState in allStates:\n        if targetState == entry:\n            paths.append({\n                \"states\": [entry],\n                \"events\": [],\n                \"transitions\": [],\n                \"is_complete\": targetState in terminals\n            })\n            continue\n\n        shortestPath = _bfsPath(adj, entry, targetState)\n        if shortestPath:\n            paths.append({\n                \"states\": shortestPath[\"states\"],\n                \"events\": shortestPath[\"events\"],\n                \"transitions\": shortestPath[\"transitions\"],\n                \"is_complete\": targetState in terminals\n            })\n\n    # Strategy 2: Find paths that cover all transitions\n    # Build set of all transitions\n    allTransitions = set()\n    for t in bp[\"transitions\"]:\n        allTransitions.add(t[\"id\"])\n\n    coveredTransitions = set()\n    for p in paths:\n        coveredTransitions.update(p[\"transitions\"])\n\n    # Find additional paths to cover uncovered transitions\n    uncovered = allTransitions - coveredTransitions\n    for transId in uncovered:\n        # Find the transition details\n        trans = next((t for t in bp[\"transitions\"] if t[\"id\"] == transId), None)\n        if not trans:\n            continue\n\n        fromState = trans[\"from\"]\n        toState = trans[\"to\"]\n\n        # Skip wildcard transitions for now\n        if fromState == \"*\":\n            continue\n\n        # Find path to from_state, then add this transition\n        if fromState == entry:\n            pathToFrom = {\"states\": [entry], \"events\": [], \"transitions\": []}\n        else:\n            pathToFrom = _bfsPath(adj, entry, fromState)\n\n        if pathToFrom:\n            paths.append({\n                \"states\": pathToFrom[\"states\"] + [toState],\n                \"events\": pathToFrom[\"events\"] + [trans[\"on_event\"]],\n                \"transitions\": pathToFrom[\"transitions\"] + [transId],\n                \"is_complete\": toState in terminals\n            })\n            coveredTransitions.add(transId)\n\n    # Strategy 3: If terminal states exist, ensure paths to them\n    if terminals:\n        for term in terminals:\n            termPaths = [p for p in paths if p[\"states\"][-1] == term]\n            if not termPaths:\n                shortestPath = _bfsPath(adj, entry, term)\n                if shortestPath:\n                    paths.append({\n                        \"states\": shortestPath[\"states\"],\n                        \"events\": shortestPath[\"events\"],\n                        \"transitions\": shortestPath[\"transitions\"],\n                        \"is_complete\": True\n                    })\n\n    return {\"paths\": paths}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#f39c12", "moduleName": "test_compute"}, {"id": "test_compute.analyze_gates", "type": "function", "label": "analyze_gates", "direction": "inbound", "parent": "test_compute", "line": 266, "endLine": 289, "signature": "(params) -> Dict[]", "docstring": "Analyze gate expressions to extract boundary conditions.", "source": "def analyze_gates(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Analyze gate expressions to extract boundary conditions.\"\"\"\n    bp = params.get(\"blueprint\")\n    if not bp:\n        return {\"analysis\": None}\n\n    gates = bp.get(\"gates\", {})\n    analysis = {}\n\n    for gateId, gate in gates.items():\n        expr = gate.get(\"expression\", \"\")\n        boundaries = _extractBoundaries(expr)\n        booleans = _extractBooleans(expr)\n        nullChecks = _extractNullChecks(expr)\n\n        analysis[gateId] = {\n            \"expression\": expr,\n            \"boundaries\": boundaries,\n            \"booleans\": booleans,\n            \"null_checks\": nullChecks,\n            \"variables\": _extractVariables(expr)\n        }\n\n    return {\"analysis\": analysis}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#f39c12", "moduleName": "test_compute"}, {"id": "test_compute.generate_path_tests", "type": "function", "label": "generate_path_tests", "direction": "inbound", "parent": "test_compute", "line": 394, "endLine": 425, "signature": "(params) -> Dict[]", "docstring": "Generate tests for path coverage.", "source": "def generate_path_tests(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Generate tests for path coverage.\"\"\"\n    bp = params.get(\"blueprint\")\n    paths = params.get(\"paths\", [])\n\n    if not bp or not paths:\n        return {\"tests\": []}\n\n    tests = []\n    for i, path in enumerate(paths):\n        if not path[\"events\"]:\n            continue\n\n        testId = f\"path_{i+1}\"\n        finalState = path[\"states\"][-1] if path[\"states\"] else bp[\"entry_state\"]\n\n        test = {\n            \"id\": testId,\n            \"type\": \"path_coverage\",\n            \"description\": f\"Path: {' -> '.join(path['states'])}\",\n            \"initial_context\": _genDefaultContext(bp),\n            \"events\": [\n                {\"event\": evt, \"payload\": {}}\n                for evt in path[\"events\"]\n            ],\n            \"expected_final_state\": finalState,\n            \"transitions_covered\": path[\"transitions\"],\n            \"is_complete_path\": path.get(\"is_complete\", False)\n        }\n        tests.append(test)\n\n    return {\"tests\": tests}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#f39c12", "moduleName": "test_compute"}, {"id": "test_compute.generate_state_tests", "type": "function", "label": "generate_state_tests", "direction": "inbound", "parent": "test_compute", "line": 428, "endLine": 478, "signature": "(params) -> Dict[]", "docstring": "Generate tests for state coverage.", "source": "def generate_state_tests(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Generate tests for state coverage.\"\"\"\n    bp = params.get(\"blueprint\")\n    paths = params.get(\"paths\", [])\n\n    if not bp:\n        return {\"tests\": []}\n\n    # Find minimum set of paths that cover all states\n    allStates = set(bp[\"states\"].keys())\n    coveredStates = set()\n    selectedPaths = []\n\n    # Sort paths by number of unique states covered\n    sortedPaths = sorted(\n        paths,\n        key=lambda p: len(set(p[\"states\"]) - coveredStates),\n        reverse=True\n    )\n\n    for path in sortedPaths:\n        pathStates = set(path[\"states\"])\n        newStates = pathStates - coveredStates\n\n        if newStates:\n            selectedPaths.append(path)\n            coveredStates.update(pathStates)\n\n        if coveredStates >= allStates:\n            break\n\n    tests = []\n    for i, path in enumerate(selectedPaths):\n        if not path[\"events\"]:\n            continue\n\n        test = {\n            \"id\": f\"state_coverage_{i+1}\",\n            \"type\": \"state_coverage\",\n            \"description\": f\"Covers states: {', '.join(path['states'])}\",\n            \"initial_context\": _genDefaultContext(bp),\n            \"events\": [\n                {\"event\": evt, \"payload\": {}}\n                for evt in path[\"events\"]\n            ],\n            \"expected_final_state\": path[\"states\"][-1],\n            \"states_covered\": path[\"states\"]\n        }\n        tests.append(test)\n\n    return {\"tests\": tests}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#f39c12", "moduleName": "test_compute"}, {"id": "test_compute.generate_gate_tests", "type": "function", "label": "generate_gate_tests", "direction": "inbound", "parent": "test_compute", "line": 481, "endLine": 564, "signature": "(params) -> Dict[]", "docstring": "Generate boundary condition tests for gates.", "source": "def generate_gate_tests(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Generate boundary condition tests for gates.\"\"\"\n    bp = params.get(\"blueprint\")\n    gateAnalysis = params.get(\"gate_analysis\")\n\n    if not bp or not gateAnalysis:\n        return {\"tests\": []}\n\n    tests = []\n    testIdx = 0\n\n    for gateId, analysis in gateAnalysis.items():\n        # Find transitions that use this gate\n        gateTransitions = [\n            t for t in bp[\"transitions\"]\n            if gateId in t.get(\"gates\", [])\n        ]\n\n        if not gateTransitions:\n            continue\n\n        trans = gateTransitions[0]  # Use first transition for testing\n\n        # Generate boundary tests\n        for boundary in analysis.get(\"boundaries\", []):\n            for i, val in enumerate(boundary[\"test_values\"]):\n                testIdx += 1\n                ctx = _genDefaultContext(bp)\n                ctx[boundary[\"variable\"]] = val\n\n                # Determine expected outcome\n                expected = _evalBoundary(boundary[\"operator\"], val,\n                                         boundary[\"value\"])\n\n                tests.append({\n                    \"id\": f\"gate_boundary_{testIdx}\",\n                    \"type\": \"gate_boundary\",\n                    \"description\": (f\"Gate {gateId}: {boundary['variable']} \"\n                                    f\"{boundary['operator']} {boundary['value']} \"\n                                    f\"with value={val}\"),\n                    \"gate_id\": gateId,\n                    \"initial_context\": ctx,\n                    \"events\": [{\"event\": trans[\"on_event\"], \"payload\": {}}],\n                    \"expected_gate_result\": expected,\n                    \"from_state\": trans[\"from\"]\n                })\n\n        # Generate boolean tests\n        for boolVar in analysis.get(\"booleans\", []):\n            for val in boolVar[\"test_values\"]:\n                testIdx += 1\n                ctx = _genDefaultContext(bp)\n                ctx[boolVar[\"variable\"]] = val\n\n                tests.append({\n                    \"id\": f\"gate_boolean_{testIdx}\",\n                    \"type\": \"gate_boolean\",\n                    \"description\": (f\"Gate {gateId}: {boolVar['variable']} \"\n                                    f\"= {val}\"),\n                    \"gate_id\": gateId,\n                    \"initial_context\": ctx,\n                    \"events\": [{\"event\": trans[\"on_event\"], \"payload\": {}}],\n                    \"from_state\": trans[\"from\"]\n                })\n\n        # Generate null check tests\n        for nullCheck in analysis.get(\"null_checks\", []):\n            for val in nullCheck[\"test_values\"]:\n                testIdx += 1\n                ctx = _genDefaultContext(bp)\n                ctx[nullCheck[\"variable\"]] = val\n\n                tests.append({\n                    \"id\": f\"gate_null_{testIdx}\",\n                    \"type\": \"gate_null_check\",\n                    \"description\": (f\"Gate {gateId}: {nullCheck['variable']} \"\n                                    f\"= {val}\"),\n                    \"gate_id\": gateId,\n                    \"initial_context\": ctx,\n                    \"events\": [{\"event\": trans[\"on_event\"], \"payload\": {}}],\n                    \"from_state\": trans[\"from\"]\n                })\n\n    return {\"tests\": tests}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#f39c12", "moduleName": "test_compute"}, {"id": "test_compute.generate_negative_tests", "type": "function", "label": "generate_negative_tests", "direction": "inbound", "parent": "test_compute", "line": 584, "endLine": 635, "signature": "(params) -> Dict[]", "docstring": "Generate tests for invalid inputs and edge cases.", "source": "def generate_negative_tests(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Generate tests for invalid inputs and edge cases.\"\"\"\n    bp = params.get(\"blueprint\")\n    graph = params.get(\"graph\")\n\n    if not bp or not graph:\n        return {\"tests\": []}\n\n    tests = []\n    adj = graph[\"adjacency\"]\n    allEvents = set()\n\n    # Collect all valid events\n    for edges in adj.values():\n        for edge in edges:\n            allEvents.add(edge[\"event\"])\n\n    # For each state, find events that are NOT valid\n    testIdx = 0\n    for state in bp[\"states\"]:\n        validEvents = {e[\"event\"] for e in adj.get(state, [])}\n        invalidEvents = allEvents - validEvents\n\n        for evt in list(invalidEvents)[:3]:  # Limit to 3 per state\n            testIdx += 1\n            tests.append({\n                \"id\": f\"negative_invalid_event_{testIdx}\",\n                \"type\": \"negative_invalid_event\",\n                \"description\": (f\"Invalid event '{evt}' in state '{state}'\"),\n                \"initial_state\": state,\n                \"initial_context\": _genDefaultContext(bp),\n                \"events\": [{\"event\": evt, \"payload\": {}}],\n                \"expected_behavior\": \"no_transition\",\n                \"expected_state\": state\n            })\n\n    # Test gate failures (events that should fail due to guards)\n    for trans in bp[\"transitions\"]:\n        if trans.get(\"gates\"):\n            testIdx += 1\n            tests.append({\n                \"id\": f\"negative_gate_fail_{testIdx}\",\n                \"type\": \"negative_gate_failure\",\n                \"description\": (f\"Gate should block transition {trans['id']}\"),\n                \"from_state\": trans[\"from\"],\n                \"initial_context\": {},  # Empty context likely fails gates\n                \"events\": [{\"event\": trans[\"on_event\"], \"payload\": {}}],\n                \"expected_behavior\": \"gate_blocked\",\n                \"gates\": trans[\"gates\"]\n            })\n\n    return {\"tests\": tests}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#f39c12", "moduleName": "test_compute"}, {"id": "test_compute.generate_property_tests", "type": "function", "label": "generate_property_tests", "direction": "inbound", "parent": "test_compute", "line": 638, "endLine": 688, "signature": "(params) -> Dict[]", "docstring": "Generate property-based tests from context schema.", "source": "def generate_property_tests(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Generate property-based tests from context schema.\"\"\"\n    bp = params.get(\"blueprint\")\n    if not bp:\n        return {\"tests\": []}\n\n    schema = bp.get(\"context_schema\", {})\n    props = schema.get(\"properties\", {})\n\n    tests = []\n    testIdx = 0\n\n    # Generate tests based on property types\n    for propName, propDef in props.items():\n        propType = propDef.get(\"type\", \"string\")\n        enumVals = propDef.get(\"enum\")\n\n        # Generate sample values based on type\n        if enumVals:\n            sampleVals = enumVals[:3]\n        elif propType == \"number\":\n            sampleVals = [0, 1, -1, 100, 0.5]\n        elif propType == \"boolean\":\n            sampleVals = [True, False]\n        elif propType == \"string\":\n            sampleVals = [\"\", \"test\", \"a\" * 100]\n        elif propType == \"array\":\n            sampleVals = [[], [\"item\"], [\"a\", \"b\", \"c\"]]\n        elif propType == \"object\":\n            sampleVals = [{}, {\"key\": \"value\"}]\n        else:\n            sampleVals = [None]\n\n        for val in sampleVals[:2]:  # Limit samples per property\n            testIdx += 1\n            ctx = _genDefaultContext(bp)\n            ctx[propName] = val\n\n            tests.append({\n                \"id\": f\"property_{testIdx}\",\n                \"type\": \"property_based\",\n                \"description\": f\"Property {propName} = {repr(val)[:30]}\",\n                \"property\": propName,\n                \"property_type\": propType,\n                \"initial_context\": ctx,\n                \"invariants\": [\n                    f\"context['{propName}'] maintains type {propType}\"\n                ]\n            })\n\n    return {\"tests\": tests}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#f39c12", "moduleName": "test_compute"}, {"id": "test_compute.combine_tests", "type": "function", "label": "combine_tests", "direction": "inbound", "parent": "test_compute", "line": 723, "endLine": 778, "signature": "(params) -> Dict[]", "docstring": "Combine all test types and compute coverage.", "source": "def combine_tests(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Combine all test types and compute coverage.\"\"\"\n    bp = params.get(\"blueprint\")\n    pathTests = params.get(\"path_tests\", []) or []\n    stateTests = params.get(\"state_tests\", []) or []\n    gateTests = params.get(\"gate_tests\", []) or []\n    negativeTests = params.get(\"negative_tests\", []) or []\n    propertyTests = params.get(\"property_tests\", []) or []\n\n    allTests = pathTests + stateTests + gateTests + negativeTests + propertyTests\n\n    # Compute coverage metrics\n    allStates = set(bp[\"states\"].keys()) if bp else set()\n    allTransitions = {t[\"id\"] for t in bp[\"transitions\"]} if bp else set()\n    allGates = set(bp.get(\"gates\", {}).keys()) if bp else set()\n\n    coveredStates = set()\n    coveredTransitions = set()\n    coveredGates = set()\n\n    for test in allTests:\n        coveredStates.update(test.get(\"states_covered\", []))\n        coveredTransitions.update(test.get(\"transitions_covered\", []))\n        if test.get(\"gate_id\"):\n            coveredGates.add(test[\"gate_id\"])\n\n    coverage = {\n        \"total_tests\": len(allTests),\n        \"by_type\": {\n            \"path_coverage\": len(pathTests),\n            \"state_coverage\": len(stateTests),\n            \"gate_boundary\": len(gateTests),\n            \"negative\": len(negativeTests),\n            \"property_based\": len(propertyTests)\n        },\n        \"state_coverage\": {\n            \"total\": len(allStates),\n            \"covered\": len(coveredStates),\n            \"percentage\": (len(coveredStates) / len(allStates) * 100\n                          if allStates else 0)\n        },\n        \"transition_coverage\": {\n            \"total\": len(allTransitions),\n            \"covered\": len(coveredTransitions),\n            \"percentage\": (len(coveredTransitions) / len(allTransitions) * 100\n                          if allTransitions else 0)\n        },\n        \"gate_coverage\": {\n            \"total\": len(allGates),\n            \"covered\": len(coveredGates),\n            \"percentage\": (len(coveredGates) / len(allGates) * 100\n                          if allGates else 0)\n        }\n    }\n\n    return {\"tests\": allTests, \"coverage\": coverage}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#f39c12", "moduleName": "test_compute"}, {"id": "test_compute.format_json", "type": "function", "label": "format_json", "direction": "inbound", "parent": "test_compute", "line": 785, "endLine": 819, "signature": "(params) -> Dict[]", "docstring": "Format tests as L++ JSON test suite.", "source": "def format_json(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Format tests as L++ JSON test suite.\"\"\"\n    bp = params.get(\"blueprint\")\n    tests = params.get(\"tests\", [])\n\n    if not bp:\n        return {\"output\": \"{}\"}\n\n    testSuite = {\n        \"test_suite\": f\"{bp['id']}_tests\",\n        \"blueprint_id\": bp[\"id\"],\n        \"blueprint_version\": bp[\"version\"],\n        \"generated_at\": \"auto\",\n        \"tests\": []\n    }\n\n    for test in tests:\n        formatted = {\n            \"id\": test[\"id\"],\n            \"type\": test[\"type\"],\n            \"description\": test[\"description\"],\n            \"initial_context\": test.get(\"initial_context\", {}),\n            \"events\": test.get(\"events\", [])\n        }\n\n        if test.get(\"expected_final_state\"):\n            formatted[\"expected_final_state\"] = test[\"expected_final_state\"]\n        if test.get(\"expected_context\"):\n            formatted[\"expected_context\"] = test[\"expected_context\"]\n        if test.get(\"expected_behavior\"):\n            formatted[\"expected_behavior\"] = test[\"expected_behavior\"]\n\n        testSuite[\"tests\"].append(formatted)\n\n    return {\"output\": json.dumps(testSuite, indent=2)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#f39c12", "moduleName": "test_compute"}, {"id": "test_compute.format_pytest", "type": "function", "label": "format_pytest", "direction": "inbound", "parent": "test_compute", "line": 822, "endLine": 904, "signature": "(params) -> Dict[]", "docstring": "Format tests as Python pytest module.", "source": "def format_pytest(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Format tests as Python pytest module.\"\"\"\n    bp = params.get(\"blueprint\")\n    tests = params.get(\"tests\", [])\n\n    if not bp:\n        return {\"output\": \"# No blueprint loaded\"}\n\n    lines = [\n        '\"\"\"',\n        f\"Auto-generated pytest tests for {bp['name']}\",\n        f\"Blueprint ID: {bp['id']}\",\n        f\"Blueprint Version: {bp['version']}\",\n        '\"\"\"',\n        \"\",\n        \"import pytest\",\n        \"from pathlib import Path\",\n        \"\",\n        \"# Import your operator creation function here\",\n        \"# from your_module import create_operator\",\n        \"\",\n        \"\",\n        \"# Fixture for creating fresh operator instance\",\n        \"@pytest.fixture\",\n        \"def operator():\",\n        '    \"\"\"Create a fresh operator instance for each test.\"\"\"',\n        \"    # TODO: Implement operator creation\",\n        \"    # return create_operator()\",\n        \"    pass\",\n        \"\",\n        \"\"\n    ]\n\n    for test in tests:\n        testName = _toPythonName(test[\"id\"])\n        lines.append(f\"def test_{testName}(operator):\")\n        lines.append(f'    \"\"\"')\n        lines.append(f\"    {test['description']}\")\n        lines.append(f\"    Type: {test['type']}\")\n        lines.append(f'    \"\"\"')\n\n        # Set initial context\n        if test.get(\"initial_context\"):\n            lines.append(\"    # Set initial context\")\n            for key, val in test[\"initial_context\"].items():\n                lines.append(f\"    operator.context['{key}'] = {repr(val)}\")\n            lines.append(\"\")\n\n        # Set initial state if specified\n        if test.get(\"initial_state\"):\n            lines.append(f\"    operator._state = '{test['initial_state']}'\")\n            lines.append(\"\")\n\n        # Dispatch events\n        if test.get(\"events\"):\n            lines.append(\"    # Dispatch events\")\n            for evt in test[\"events\"]:\n                payload = evt.get(\"payload\", {})\n                lines.append(f\"    operator.dispatch('{evt['event']}', {payload})\")\n            lines.append(\"\")\n\n        # Assertions\n        if test.get(\"expected_final_state\"):\n            lines.append(\"    # Verify final state\")\n            lines.append(\n                f\"    assert operator.state == '{test['expected_final_state']}'\"\n            )\n        elif test.get(\"expected_state\"):\n            lines.append(\"    # Verify state unchanged\")\n            lines.append(\n                f\"    assert operator.state == '{test['expected_state']}'\"\n            )\n\n        if test.get(\"expected_behavior\") == \"no_transition\":\n            lines.append(\"    # Verify no transition occurred\")\n            lines.append(\n                f\"    assert operator.state == '{test.get('initial_state', 'unknown')}'\"\n            )\n\n        lines.append(\"\")\n        lines.append(\"\")\n\n    return {\"output\": \"\\n\".join(lines)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#f39c12", "moduleName": "test_compute"}, {"id": "test_compute.export_tests", "type": "function", "label": "export_tests", "direction": "inbound", "parent": "test_compute", "line": 916, "endLine": 940, "signature": "(params) -> Dict[]", "docstring": "Write formatted tests to file.", "source": "def export_tests(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Write formatted tests to file.\"\"\"\n    content = params.get(\"content\", \"\")\n    path = params.get(\"path\")\n    fmt = params.get(\"format\", \"json\")\n\n    if not path:\n        return {\"path\": None}\n\n    try:\n        outPath = Path(path)\n\n        # Add appropriate extension if missing\n        if fmt == \"json\" and not outPath.suffix:\n            outPath = outPath.with_suffix(\".json\")\n        elif fmt == \"pytest\" and not outPath.suffix:\n            outPath = outPath.with_suffix(\".py\")\n\n        outPath.parent.mkdir(parents=True, exist_ok=True)\n        outPath.write_text(content)\n\n        return {\"path\": str(outPath)}\n\n    except Exception as e:\n        return {\"path\": None, \"error\": str(e)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#f39c12", "moduleName": "test_compute"}, {"id": "test_compute.clear_state", "type": "function", "label": "clear_state", "direction": "inbound", "parent": "test_compute", "line": 947, "endLine": 962, "signature": "(params) -> Dict[]", "docstring": "Reset all analysis state.", "source": "def clear_state(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Reset all analysis state.\"\"\"\n    return {\n        \"blueprint\": None,\n        \"graph\": None,\n        \"paths\": None,\n        \"gate_analysis\": None,\n        \"path_tests\": None,\n        \"state_tests\": None,\n        \"gate_tests\": None,\n        \"negative_tests\": None,\n        \"property_tests\": None,\n        \"all_tests\": None,\n        \"formatted_output\": None,\n        \"error\": None\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#f39c12", "moduleName": "test_compute"}, {"id": "seal_compute", "type": "module", "label": "seal_compute", "metrics": {"fanIn": 13, "fanOut": 7, "instability": 0.35, "internalEdges": 3, "externalCallCount": 9, "localCallCount": 0, "callsByCategory": {"stdlib": 9}, "localDependencies": []}, "moduleColor": "#9b59b6", "moduleName": "seal_compute"}, {"id": "seal_compute.loadBlueprint", "type": "function", "label": "loadBlueprint", "direction": "inbound", "parent": "seal_compute", "line": 14, "endLine": 28, "signature": "(params) -> dict", "docstring": "Load and parse L++ blueprint JSON file.", "source": "def loadBlueprint(params: dict) -> dict:\n    \"\"\"Load and parse L++ blueprint JSON file.\"\"\"\n    path = params.get(\"blueprintPath\")\n    if not path:\n        return {\"blueprint\": None, \"error\": \"No blueprint path provided\"}\n    try:\n        with open(path, \"r\", encoding=\"utf-8\") as f:\n            bp = json.load(f)\n        return {\"blueprint\": bp, \"error\": None}\n    except FileNotFoundError:\n        return {\"blueprint\": None, \"error\": f\"File not found: {path}\"}\n    except json.JSONDecodeError as e:\n        return {\"blueprint\": None, \"error\": f\"Invalid JSON: {e}\"}\n    except Exception as e:\n        return {\"blueprint\": None, \"error\": str(e)}", "args": ["params"], "returns": "dict", "moduleColor": "#9b59b6", "moduleName": "seal_compute"}, {"id": "seal_compute.auditTrinity", "type": "function", "label": "auditTrinity", "direction": "inbound", "parent": "seal_compute", "line": 31, "endLine": 134, "signature": "(params) -> dict", "docstring": "Audit the Trinity: Transitions, Gates, Actions.", "source": "def auditTrinity(params: dict) -> dict:\n    \"\"\"Audit the Trinity: Transitions, Gates, Actions.\"\"\"\n    bp = params.get(\"blueprint\")\n    if not bp:\n        return {\"trinityAudit\": None, \"error\": \"No blueprint loaded\"}\n\n    audit = {\n        \"valid\": True,\n        \"transitions\": {\"count\": 0, \"issues\": []},\n        \"gates\": {\"count\": 0, \"issues\": []},\n        \"actions\": {\"count\": 0, \"issues\": []},\n        \"coverage\": {}\n    }\n\n    # Audit Transitions\n    transitions = bp.get(\"transitions\", [])\n    audit[\"transitions\"][\"count\"] = len(transitions)\n    states = set(bp.get(\"states\", {}).keys())\n    entry = bp.get(\"entry_state\")\n    terminals = set(bp.get(\"terminal_states\", []))\n\n    usedTids = set()\n    for t in transitions:\n        tid = t.get(\"id\")\n        if not tid:\n            audit[\"transitions\"][\"issues\"].append(\"Missing transition ID\")\n            audit[\"valid\"] = False\n        elif tid in usedTids:\n            audit[\"transitions\"][\"issues\"].append(f\"Duplicate ID: {tid}\")\n            audit[\"valid\"] = False\n        usedTids.add(tid)\n\n        fromState = t.get(\"from\")\n        toState = t.get(\"to\")\n        if fromState != \"*\" and fromState not in states:\n            audit[\"transitions\"][\"issues\"].append(\n                f\"{tid}: unknown from state '{fromState}'\")\n            audit[\"valid\"] = False\n        if toState not in states:\n            audit[\"transitions\"][\"issues\"].append(\n                f\"{tid}: unknown to state '{toState}'\")\n            audit[\"valid\"] = False\n\n    # Check reachability\n    reachable = {entry}\n    changed = True\n    while changed:\n        changed = False\n        for t in transitions:\n            if t.get(\"from\") in reachable or t.get(\"from\") == \"*\":\n                if t.get(\"to\") not in reachable:\n                    reachable.add(t.get(\"to\"))\n                    changed = True\n\n    unreachable = states - reachable\n    if unreachable:\n        audit[\"transitions\"][\"issues\"].append(\n            f\"Unreachable states: {unreachable}\")\n\n    # Audit Gates\n    gates = bp.get(\"gates\", {})\n    audit[\"gates\"][\"count\"] = len(gates)\n    usedGates = set()\n    for t in transitions:\n        for g in t.get(\"gates\", []):\n            usedGates.add(g)\n\n    for gid in usedGates:\n        if gid not in gates:\n            audit[\"gates\"][\"issues\"].append(f\"Undefined gate: {gid}\")\n            audit[\"valid\"] = False\n\n    unusedGates = set(gates.keys()) - usedGates\n    if unusedGates:\n        audit[\"gates\"][\"issues\"].append(f\"Unused gates: {unusedGates}\")\n\n    # Audit Actions\n    actions = bp.get(\"actions\", {})\n    audit[\"actions\"][\"count\"] = len(actions)\n    usedActions = set()\n    for t in transitions:\n        for a in t.get(\"actions\", []):\n            usedActions.add(a)\n\n    for aid in usedActions:\n        if aid not in actions:\n            audit[\"actions\"][\"issues\"].append(f\"Undefined action: {aid}\")\n            audit[\"valid\"] = False\n\n    unusedActions = set(actions.keys()) - usedActions\n    if unusedActions:\n        audit[\"actions\"][\"issues\"].append(f\"Unused actions: {unusedActions}\")\n\n    # Coverage metrics\n    audit[\"coverage\"] = {\n        \"statesReachable\": len(reachable),\n        \"statesTotal\": len(states),\n        \"gatesUsed\": len(usedGates),\n        \"gatesTotal\": len(gates),\n        \"actionsUsed\": len(usedActions),\n        \"actionsTotal\": len(actions)\n    }\n\n    return {\"trinityAudit\": audit, \"error\": None}", "args": ["params"], "returns": "dict", "moduleColor": "#9b59b6", "moduleName": "seal_compute"}, {"id": "seal_compute.auditFlange", "type": "function", "label": "auditFlange", "direction": "inbound", "parent": "seal_compute", "line": 137, "endLine": 188, "signature": "(params) -> dict", "docstring": "Audit the Flange (context_schema) for hermeticity.", "source": "def auditFlange(params: dict) -> dict:\n    \"\"\"Audit the Flange (context_schema) for hermeticity.\"\"\"\n    bp = params.get(\"blueprint\")\n    if not bp:\n        return {\"flangeAudit\": None, \"error\": \"No blueprint loaded\"}\n\n    schema = bp.get(\"context_schema\", {})\n    props = schema.get(\"properties\", {})\n\n    audit = {\n        \"valid\": True,\n        \"properties\": {\"count\": len(props), \"issues\": []},\n        \"hermeticity\": {\"score\": 0, \"issues\": []},\n        \"boundaries\": []\n    }\n\n    # Check property definitions\n    for name, spec in props.items():\n        if \"type\" not in spec:\n            audit[\"properties\"][\"issues\"].append(f\"{name}: missing type\")\n            audit[\"valid\"] = False\n        audit[\"boundaries\"].append({\n            \"name\": name,\n            \"type\": spec.get(\"type\", \"unknown\"),\n            \"enum\": spec.get(\"enum\"),\n            \"bounded\": \"enum\" in spec or \"minimum\" in spec or \"maximum\" in spec\n        })\n\n    # Check action mutations reference valid context\n    actions = bp.get(\"actions\", {})\n    for aid, aspec in actions.items():\n        if aspec.get(\"type\") == \"set\":\n            target = aspec.get(\"target\")\n            if target and target not in props:\n                audit[\"properties\"][\"issues\"].append(\n                    f\"Action {aid} targets undefined property: {target}\")\n\n        if aspec.get(\"type\") == \"compute\":\n            for outKey in aspec.get(\"output_map\", {}).keys():\n                if outKey not in props:\n                    audit[\"properties\"][\"issues\"].append(\n                        f\"Action {aid} outputs to undefined: {outKey}\")\n\n    # Hermeticity score\n    boundedCount = sum(1 for b in audit[\"boundaries\"] if b[\"bounded\"])\n    total = len(audit[\"boundaries\"])\n    audit[\"hermeticity\"][\"score\"] = boundedCount / total if total else 1.0\n    if audit[\"hermeticity\"][\"score\"] < 0.5:\n        audit[\"hermeticity\"][\"issues\"].append(\n            \"Low hermeticity: consider adding type constraints\")\n\n    return {\"flangeAudit\": audit, \"error\": None}", "args": ["params"], "returns": "dict", "moduleColor": "#9b59b6", "moduleName": "seal_compute"}, {"id": "seal_compute.generateTla", "type": "function", "label": "generateTla", "direction": "inbound", "parent": "seal_compute", "line": 191, "endLine": 373, "signature": "(params) -> dict", "docstring": "Generate TLA+ specification from blueprint.", "source": "def generateTla(params: dict) -> dict:\n    \"\"\"Generate TLA+ specification from blueprint.\"\"\"\n    bp = params.get(\"blueprint\")\n    bpPath = params.get(\"blueprintPath\")\n    if not bp:\n        return {\"tlaSpec\": None, \"tlaPath\": None, \"error\": \"No blueprint\"}\n\n    bpId = bp.get(\"id\", \"spec\")\n    states = list(bp.get(\"states\", {}).keys())\n    transitions = bp.get(\"transitions\", [])\n    gates = bp.get(\"gates\", {})\n    props = bp.get(\"context_schema\", {}).get(\"properties\", {})\n    entry = bp.get(\"entry_state\", states[0] if states else \"idle\")\n    terminals = bp.get(\"terminal_states\", [])\n\n    # Collect events\n    events = set()\n    for t in transitions:\n        events.add(t.get(\"on_event\", \"AUTO\"))\n\n    # Generate TLA+ spec\n    def tlaStr(s):\n        return f'\"{s}\"'\n\n    lines = [\n        f\"---------------------------- MODULE {bpId} ----------------------------\",\n        f\"\\\\* L++ Blueprint: {bp.get('name', bpId)}\",\n        f\"\\\\* Version: {bp.get('version', '1.0.0')}\",\n        f\"\\\\* TLAPS Seal Specification\",\n        \"\",\n        \"EXTENDS Integers, Sequences, TLC\",\n        \"\",\n        \"\\\\* Bounds for model checking\",\n        \"MAX_HISTORY == 3\",\n        \"CONSTANT NULL\",\n        \"\",\n        f\"States == {{{', '.join(tlaStr(s) for s in states)}}}\",\n        f\"Events == {{{', '.join(tlaStr(e) for e in sorted(events))}}}\",\n        f\"TerminalStates == {{{', '.join(tlaStr(t) for t in terminals)}}}\",\n        \"\",\n        \"VARIABLES\",\n        \"    state,\",\n    ]\n\n    # Context variables\n    propNames = list(props.keys())\n    for i, p in enumerate(propNames):\n        comma = \",\" if i < len(propNames) - 1 else \"\"\n        lines.append(f\"    {p}{comma}\")\n    lines.append(\"\")\n\n    # vars tuple\n    varsStr = \", \".join([\"state\"] + propNames)\n    lines.append(f\"vars == <<{varsStr}>>\")\n    lines.append(\"\")\n\n    # Type invariant\n    lines.append(\"\\\\* Type Invariant - Structural Correctness\")\n    lines.append(\"TypeInvariant ==\")\n    lines.append(\"    /\\\\ state \\\\in States\")\n    for p in propNames:\n        lines.append(f\"    /\\\\ TRUE  \\\\* {p}\")\n    lines.append(\"\")\n\n    # Init\n    lines.append(\"\\\\* Initial State\")\n    lines.append(\"Init ==\")\n    lines.append(f\"    /\\\\ state = \\\"{entry}\\\"\")\n    for p in propNames:\n        lines.append(f\"    /\\\\ {p} = NULL\")\n    lines.append(\"\")\n\n    # Transitions\n    lines.append(\"\\\\* Transitions\")\n    for t in transitions:\n        tid = t.get(\"id\", \"t_unknown\")\n        fromS = t.get(\"from\")\n        toS = t.get(\"to\")\n        event = t.get(\"on_event\", \"AUTO\")\n        tGates = t.get(\"gates\", [])\n\n        lines.append(f\"\\\\* {tid}: {fromS} --({event})--> {toS}\")\n        lines.append(f\"{tid} ==\")\n        if fromS == \"*\":\n            lines.append(f\"    /\\\\ TRUE  \\\\* Global transition\")\n        else:\n            lines.append(f\"    /\\\\ state = \\\"{fromS}\\\"\")\n        lines.append(f\"    /\\\\ state' = \\\"{toS}\\\"\")\n\n        # Gate conditions (simplified)\n        for g in tGates:\n            gspec = gates.get(g, {})\n            if gspec.get(\"type\") == \"expression\":\n                expr = gspec.get(\"expression\", \"TRUE\")\n                # Simple translation\n                tlaExpr = expr.replace(\" is not None\", \" # NULL\")\n                tlaExpr = tlaExpr.replace(\" is None\", \" = NULL\")\n                tlaExpr = tlaExpr.replace(\" and \", \" /\\\\ \")\n                tlaExpr = tlaExpr.replace(\" or \", \" \\\\/ \")\n                tlaExpr = tlaExpr.replace(\"not \", \"~\")\n                tlaExpr = tlaExpr.replace(\".get(\", \"[\")\n                tlaExpr = tlaExpr.replace(\", False)\", \"]\")\n                tlaExpr = tlaExpr.replace(\")\", \"\")\n                tlaExpr = tlaExpr.replace(\"'\", \"\\\"\")\n                lines.append(f\"    /\\\\ {tlaExpr}  \\\\* Gate: {g}\")\n\n        # Unchanged vars\n        lines.append(f\"    /\\\\ UNCHANGED <<{', '.join(propNames)}>>\")\n        lines.append(\"\")\n\n    # Next\n    lines.append(\"\\\\* Next State Relation\")\n    lines.append(\"Next ==\")\n    tids = [t.get(\"id\", f\"t{i}\") for i, t in enumerate(transitions)]\n    lines.append(\"    \\\\/ \" + \"\\n    \\\\/ \".join(tids))\n    lines.append(\"\")\n\n    # Safety Invariant (no deadlock except terminals) - after Next is defined\n    lines.append(\"\\\\* Safety Invariant - Convergence Guarantee\")\n    lines.append(\"SafetyInvariant ==\")\n    lines.append(\"    state \\\\in TerminalStates \\\\/\")\n    lines.append(\"    \\\\E e \\\\in Events : ENABLED(Next)\")\n    lines.append(\"\")\n\n    # Spec\n    lines.append(\"\\\\* Temporal Specification\")\n    lines.append(\"Spec == Init /\\\\ [][Next]_vars /\\\\ WF_vars(Next)\")\n    lines.append(\"\")\n\n    # TLAPS Theorems\n    lines.append(\n        \"\\\\* =========================================================\")\n    lines.append(\"\\\\* TLAPS THEOREMS - Axiomatic Certification\")\n    lines.append(\n        \"\\\\* =========================================================\")\n    lines.append(\"\")\n    lines.append(\"\\\\* Theorem 1: Type Safety\")\n    lines.append(\"THEOREM TypeSafety == Spec => []TypeInvariant\")\n    lines.append(\"PROOF OMITTED  \\\\* To be proven by TLAPS\")\n    lines.append(\"\")\n    lines.append(\"\\\\* Theorem 2: Convergence (No unhandled deadlock)\")\n    lines.append(\"THEOREM Convergence == Spec => []SafetyInvariant\")\n    lines.append(\"PROOF OMITTED  \\\\* To be proven by TLAPS\")\n    lines.append(\"\")\n    lines.append(\"\\\\* Theorem 3: Terminal Reachability\")\n    tReach = \"TRUE\" if not terminals else \" \\\\/ \".join(\n        f\"state = \\\"{t}\\\"\" for t in terminals)\n    lines.append(f\"THEOREM TerminalReachable == Spec => <>({tReach})\")\n    lines.append(\"PROOF OMITTED  \\\\* To be proven by TLAPS\")\n    lines.append(\"\")\n    lines.append(\"=\" * 76)\n\n    spec = \"\\n\".join(lines)\n\n    # Write TLA+ file\n    if bpPath:\n        tlaDir = Path(bpPath).parent / \"tla\"\n        tlaDir.mkdir(exist_ok=True)\n        tlaPath = str(tlaDir / f\"{bpId}.tla\")\n        with open(tlaPath, \"w\") as f:\n            f.write(spec)\n\n        # Generate CFG file\n        cfgLines = [\n            f\"\\\\* TLC Configuration for {bpId}\",\n            \"\",\n            \"SPECIFICATION Spec\",\n            \"\",\n            \"CONSTANTS\",\n            \"    NULL = NULL\",\n            \"\",\n            \"INVARIANTS\",\n            \"    TypeInvariant\",\n            \"\",\n            \"PROPERTIES\",\n        ]\n        cfgPath = str(tlaDir / f\"{bpId}.cfg\")\n        with open(cfgPath, \"w\") as f:\n            f.write(\"\\n\".join(cfgLines))\n    else:\n        tlaPath = None\n\n    return {\"tlaSpec\": spec, \"tlaPath\": tlaPath, \"error\": None}", "args": ["params"], "returns": "dict", "moduleColor": "#9b59b6", "moduleName": "seal_compute"}, {"id": "seal_compute.runTlc", "type": "function", "label": "runTlc", "direction": "inbound", "parent": "seal_compute", "line": 376, "endLine": 445, "signature": "(params) -> dict", "docstring": "Run TLC model checker on TLA+ specification.", "source": "def runTlc(params: dict) -> dict:\n    \"\"\"Run TLC model checker on TLA+ specification.\"\"\"\n    tlaPath = params.get(\"tlaPath\")\n    if not tlaPath:\n        return {\"tlcResult\": None, \"sealStatus\": None,\n                \"error\": \"No TLA+ path\"}\n\n    result = {\n        \"passed\": False,\n        \"statesExplored\": 0,\n        \"distinctStates\": 0,\n        \"errors\": [],\n        \"warnings\": [],\n        \"duration\": 0\n    }\n\n    try:\n        tlaDir = Path(tlaPath).parent\n        tlaFile = Path(tlaPath).name\n\n        proc = subprocess.run(\n            [\"tlc\", \"-workers\", \"auto\", tlaFile],\n            cwd=str(tlaDir),\n            capture_output=True,\n            text=True,\n            timeout=120\n        )\n\n        output = proc.stdout + proc.stderr\n\n        # Parse TLC output\n        if \"Model checking completed\" in output:\n            result[\"passed\"] = True\n        if \"Error:\" in output or \"Invariant\" in output and \"violated\" in output:\n            result[\"passed\"] = False\n            result[\"errors\"].append(\"TLC found violations\")\n\n        # Extract stats\n        for line in output.split(\"\\n\"):\n            if \"states generated\" in line.lower():\n                try:\n                    result[\"statesExplored\"] = int(\n                        line.split()[0].replace(\",\", \"\"))\n                except (ValueError, IndexError):\n                    pass\n            if \"distinct states\" in line.lower():\n                try:\n                    result[\"distinctStates\"] = int(\n                        line.split()[0].replace(\",\", \"\"))\n                except (ValueError, IndexError):\n                    pass\n\n        result[\"rawOutput\"] = output[:2000]\n        status = \"tlc_verified\" if result[\"passed\"] else \"rejected\"\n        return {\"tlcResult\": result, \"sealStatus\": status, \"error\": None}\n\n    except subprocess.TimeoutExpired:\n        result[\"errors\"].append(\"TLC timeout (120s)\")\n        return {\"tlcResult\": result, \"sealStatus\": \"rejected\",\n                \"error\": \"TLC timeout\"}\n    except FileNotFoundError:\n        result[\"errors\"].append(\"TLC not installed\")\n        # Fallback: mark as verified for demo\n        result[\"passed\"] = True\n        result[\"warnings\"].append(\"TLC not found - verification simulated\")\n        return {\"tlcResult\": result, \"sealStatus\": \"tlc_verified\",\n                \"error\": None}\n    except Exception as e:\n        return {\"tlcResult\": result, \"sealStatus\": \"rejected\",\n                \"error\": str(e)}", "args": ["params"], "returns": "dict", "moduleColor": "#9b59b6", "moduleName": "seal_compute"}, {"id": "seal_compute.runTlaps", "type": "function", "label": "runTlaps", "direction": "inbound", "parent": "seal_compute", "line": 448, "endLine": 506, "signature": "(params) -> dict", "docstring": "Run TLAPS theorem prover (or simulate if not installed).", "source": "def runTlaps(params: dict) -> dict:\n    \"\"\"Run TLAPS theorem prover (or simulate if not installed).\"\"\"\n    tlaPath = params.get(\"tlaPath\")\n    if not tlaPath:\n        return {\"tlapsResult\": None, \"sealStatus\": None,\n                \"error\": \"No TLA+ path\"}\n\n    result = {\n        \"passed\": False,\n        \"theorems\": {\n            \"TypeSafety\": \"pending\",\n            \"Convergence\": \"pending\",\n            \"TerminalReachable\": \"pending\"\n        },\n        \"proofObligations\": 0,\n        \"provedObligations\": 0\n    }\n\n    try:\n        proc = subprocess.run(\n            [\"tlapm\", \"--threads\", \"4\", tlaPath],\n            capture_output=True,\n            text=True,\n            timeout=300\n        )\n\n        output = proc.stdout + proc.stderr\n\n        # Parse TLAPS output\n        if \"All obligations proved\" in output:\n            result[\"passed\"] = True\n            for t in result[\"theorems\"]:\n                result[\"theorems\"][t] = \"proved\"\n\n        result[\"rawOutput\"] = output[:2000]\n        status = \"tlaps_certified\" if result[\"passed\"] else \"rejected\"\n        return {\"tlapsResult\": result, \"sealStatus\": status, \"error\": None}\n\n    except FileNotFoundError:\n        # TLAPS not installed - provide advisory\n        result[\"passed\"] = True\n        result[\"theorems\"] = {\n            \"TypeSafety\": \"assumed\",\n            \"Convergence\": \"assumed\",\n            \"TerminalReachable\": \"assumed\"\n        }\n        result[\"advisory\"] = (\n            \"TLAPS not installed. Theorems assumed based on TLC verification. \"\n            \"For production certification, install TLAPS and run full proofs.\"\n        )\n        return {\"tlapsResult\": result, \"sealStatus\": \"tlaps_certified\",\n                \"error\": None}\n    except subprocess.TimeoutExpired:\n        result[\"theorems\"][\"status\"] = \"timeout\"\n        return {\"tlapsResult\": result, \"sealStatus\": \"rejected\",\n                \"error\": \"TLAPS timeout\"}\n    except Exception as e:\n        return {\"tlapsResult\": result, \"sealStatus\": \"rejected\",\n                \"error\": str(e)}", "args": ["params"], "returns": "dict", "moduleColor": "#9b59b6", "moduleName": "seal_compute"}, {"id": "seal_compute.generateCertificate", "type": "function", "label": "generateCertificate", "direction": "inbound", "parent": "seal_compute", "line": 509, "endLine": 573, "signature": "(params) -> dict", "docstring": "Generate the TLAPS Seal certificate.", "source": "def generateCertificate(params: dict) -> dict:\n    \"\"\"Generate the TLAPS Seal certificate.\"\"\"\n    bp = params.get(\"blueprint\", {})\n    trinity = params.get(\"trinityAudit\", {})\n    flange = params.get(\"flangeAudit\", {})\n    tlc = params.get(\"tlcResult\", {})\n    tlaps = params.get(\"tlapsResult\", {})\n\n    # Generate content hash\n    content = json.dumps(bp, sort_keys=True)\n    contentHash = hashlib.sha256(content.encode()).hexdigest()[:16]\n\n    # Determine seal level\n    if tlaps and tlaps.get(\"passed\"):\n        level = \"TLAPS_CERTIFIED\"\n        seal = \"AXIOMATIC\"\n    elif tlc and tlc.get(\"passed\"):\n        level = \"TLC_VERIFIED\"\n        seal = \"EMPIRICAL\"\n    else:\n        level = \"REJECTED\"\n        seal = None\n\n    cert = {\n        \"seal\": seal,\n        \"level\": level,\n        \"timestamp\": datetime.utcnow().isoformat() + \"Z\",\n        \"blueprint\": {\n            \"id\": bp.get(\"id\") if bp else None,\n            \"name\": bp.get(\"name\") if bp else None,\n            \"version\": bp.get(\"version\") if bp else None,\n            \"hash\": contentHash\n        },\n        \"verification\": {\n            \"trinity\": {\n                \"transitions\": trinity.get(\"transitions\", {}).get(\"count\", 0) if trinity else 0,\n                \"gates\": trinity.get(\"gates\", {}).get(\"count\", 0) if trinity else 0,\n                \"actions\": trinity.get(\"actions\", {}).get(\"count\", 0) if trinity else 0,\n                \"valid\": trinity.get(\"valid\", False) if trinity else False\n            },\n            \"flange\": {\n                \"properties\": flange.get(\"properties\", {}).get(\"count\", 0) if flange else 0,\n                \"hermeticity\": flange.get(\"hermeticity\", {}).get(\"score\", 0) if flange else 0,\n                \"valid\": flange.get(\"valid\", False) if flange else False\n            },\n            \"tlc\": {\n                \"passed\": tlc.get(\"passed\", False) if tlc else False,\n                \"statesExplored\": tlc.get(\"statesExplored\", 0) if tlc else 0\n            },\n            \"tlaps\": {\n                \"passed\": tlaps.get(\"passed\", False) if tlaps else False,\n                \"theorems\": tlaps.get(\"theorems\", {}) if tlaps else {}\n            }\n        },\n        \"oath\": [\n            \"The Logic is Converged: No path leads to unhandled deadlock.\",\n            \"The Context is Hermetic: No data violates schema boundaries.\",\n            \"The Flesh is Governed: Volatile compute is bound by bone.\"\n        ]\n    }\n\n    status = \"tlaps_certified\" if seal == \"AXIOMATIC\" else (\n        \"tlc_verified\" if seal == \"EMPIRICAL\" else \"rejected\")\n\n    return {\"sealCertificate\": cert, \"sealStatus\": status}", "args": ["params"], "returns": "dict", "moduleColor": "#9b59b6", "moduleName": "seal_compute"}, {"id": "seal_compute.resetContext", "type": "function", "label": "resetContext", "direction": "inbound", "parent": "seal_compute", "line": 576, "endLine": 588, "signature": "(params) -> dict", "docstring": "Reset all context to initial state.", "source": "def resetContext(params: dict) -> dict:\n    \"\"\"Reset all context to initial state.\"\"\"\n    return {\n        \"blueprint\": None,\n        \"tlaSpec\": None,\n        \"tlcResult\": None,\n        \"tlapsResult\": None,\n        \"trinityAudit\": None,\n        \"flangeAudit\": None,\n        \"sealCertificate\": None,\n        \"sealStatus\": \"pending\",\n        \"error\": None\n    }", "args": ["params"], "returns": "dict", "moduleColor": "#9b59b6", "moduleName": "seal_compute"}, {"id": "seal_compute.checkTrinityValid", "type": "function", "label": "checkTrinityValid", "direction": "inbound", "parent": "seal_compute", "line": 591, "endLine": 594, "signature": "(params) -> dict", "docstring": "Gate: check if trinity audit passed.", "source": "def checkTrinityValid(params: dict) -> dict:\n    \"\"\"Gate: check if trinity audit passed.\"\"\"\n    audit = params.get(\"trinityAudit\")\n    return {\"result\": audit is not None and audit.get(\"valid\", False)}", "args": ["params"], "returns": "dict", "moduleColor": "#9b59b6", "moduleName": "seal_compute"}, {"id": "seal_compute.checkFlangeValid", "type": "function", "label": "checkFlangeValid", "direction": "inbound", "parent": "seal_compute", "line": 597, "endLine": 600, "signature": "(params) -> dict", "docstring": "Gate: check if flange audit passed.", "source": "def checkFlangeValid(params: dict) -> dict:\n    \"\"\"Gate: check if flange audit passed.\"\"\"\n    audit = params.get(\"flangeAudit\")\n    return {\"result\": audit is not None and audit.get(\"valid\", False)}", "args": ["params"], "returns": "dict", "moduleColor": "#9b59b6", "moduleName": "seal_compute"}, {"id": "seal_compute.checkTlcPassed", "type": "function", "label": "checkTlcPassed", "direction": "inbound", "parent": "seal_compute", "line": 603, "endLine": 606, "signature": "(params) -> dict", "docstring": "Gate: check if TLC verification passed.", "source": "def checkTlcPassed(params: dict) -> dict:\n    \"\"\"Gate: check if TLC verification passed.\"\"\"\n    result = params.get(\"tlcResult\")\n    return {\"result\": result is not None and result.get(\"passed\", False)}", "args": ["params"], "returns": "dict", "moduleColor": "#9b59b6", "moduleName": "seal_compute"}, {"id": "seal_compute.checkTlapsPassed", "type": "function", "label": "checkTlapsPassed", "direction": "inbound", "parent": "seal_compute", "line": 609, "endLine": 612, "signature": "(params) -> dict", "docstring": "Gate: check if TLAPS proof passed.", "source": "def checkTlapsPassed(params: dict) -> dict:\n    \"\"\"Gate: check if TLAPS proof passed.\"\"\"\n    result = params.get(\"tlapsResult\")\n    return {\"result\": result is not None and result.get(\"passed\", False)}", "args": ["params"], "returns": "dict", "moduleColor": "#9b59b6", "moduleName": "seal_compute"}, {"id": "seal_compute.tlaStr", "type": "function", "label": "tlaStr", "direction": "inbound", "parent": "seal_compute", "line": 212, "endLine": 213, "signature": "(s)", "docstring": null, "source": "    def tlaStr(s):\n        return f'\"{s}\"'", "args": ["s"], "returns": null, "moduleColor": "#9b59b6", "moduleName": "seal_compute"}, {"id": "hashlib", "type": "dependency", "label": "hashlib", "direction": "outbound", "category": "stdlib", "moduleColor": "#9b59b6", "moduleName": "seal_compute"}, {"id": "viz_compute", "type": "module", "label": "viz_compute", "metrics": {"fanIn": 10, "fanOut": 4, "instability": 0.286, "internalEdges": 0, "externalCallCount": 5, "localCallCount": 7, "callsByCategory": {"stdlib": 4, "pip": 1}, "localDependencies": ["readme_compute"]}, "moduleColor": "#1abc9c", "moduleName": "viz_compute"}, {"id": "viz_compute.load_blueprint", "type": "function", "label": "load_blueprint", "direction": "inbound", "parent": "viz_compute", "line": 16, "endLine": 75, "signature": "(params) -> Dict[]", "docstring": "Load an L++ blueprint from a JSON file.", "source": "def load_blueprint(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Load an L++ blueprint from a JSON file.\"\"\"\n    path = params.get(\"path\")\n    if not path:\n        return {\"blueprint\": None, \"error\": \"No path provided\"}\n\n    try:\n        path = Path(path)\n        if not path.exists():\n            return {\"blueprint\": None, \"error\": f\"File not found: {path}\"}\n\n        with open(path) as f:\n            raw = json.load(f)\n\n        loader = BlueprintLoader(raw)\n        blueprint = loader.load()\n\n        # Convert to a dict-like structure for easy access in gates/display\n        bp_data = {\n            \"id\": blueprint.id,\n            \"name\": blueprint.name,\n            \"version\": blueprint.version,\n            \"description\": blueprint.description,\n            \"states\": {\n                sid: {\n                    \"description\": s.description\n                } for sid, s in blueprint.states.items()},\n            \"transitions\": [\n                {\n                    \"id\": t.id,\n                    \"from\": t.from_state,\n                    \"to\": t.to_state,\n                    \"on_event\": t.on_event,\n                    \"gate\": t.gates[0] if t.gates else None,\n                    \"gates\": list(t.gates),\n                    \"actions\": list(t.actions)\n                }\n                for t in blueprint.transitions\n            ],\n            \"gates\": {\n                gid: {\n                    \"expression\": g.expression\n                } for gid, g in blueprint.gates.items()\n            },\n            \"actions\": {\n                aid: {\n                    \"type\": a.type.value\n                } for aid, a in blueprint.actions.items()\n            },\n            \"entry_state\": blueprint.entry_state,\n            \"terminal_states\": list(blueprint.terminal_states)\n        }\n        return {\n            \"blueprint\": bp_data,\n            \"blueprint_name\": blueprint.name,\n            \"blueprint_id\": blueprint.id,\n            \"error\": None\n        }\n    except Exception as e:\n        return {\"blueprint\": None, \"error\": str(e)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#1abc9c", "moduleName": "viz_compute"}, {"id": "viz_compute.zoom", "type": "function", "label": "zoom", "direction": "inbound", "parent": "viz_compute", "line": 78, "endLine": 84, "signature": "(params) -> Dict[]", "docstring": "Adjust zoom level.", "source": "def zoom(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Adjust zoom level.\"\"\"\n    current = params.get(\"current\", 1.0)\n    direction = params.get(\"direction\", 0)\n    step = 0.25\n    new_level = max(0.5, min(2.0, current + (direction * step)))\n    return {\"new_level\": round(new_level, 2)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#1abc9c", "moduleName": "viz_compute"}, {"id": "viz_compute.toggle", "type": "function", "label": "toggle", "direction": "inbound", "parent": "viz_compute", "line": 87, "endLine": 90, "signature": "(params) -> Dict[]", "docstring": "Toggle a boolean value.", "source": "def toggle(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Toggle a boolean value.\"\"\"\n    current = params.get(\"current\", False)\n    return {\"result\": not current}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#1abc9c", "moduleName": "viz_compute"}, {"id": "viz_compute.init_defaults", "type": "function", "label": "init_defaults", "direction": "inbound", "parent": "viz_compute", "line": 93, "endLine": 100, "signature": "(params) -> Dict[]", "docstring": "Initialize default visualization settings.", "source": "def init_defaults(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Initialize default visualization settings.\"\"\"\n    return {\n        \"view_mode\": \"graph\",\n        \"zoom_level\": 1.0,\n        \"show_gates\": True,\n        \"show_actions\": True\n    }", "args": ["params"], "returns": "Dict[]", "moduleColor": "#1abc9c", "moduleName": "viz_compute"}, {"id": "viz_compute.render_graph", "type": "function", "label": "render_graph", "direction": "inbound", "parent": "viz_compute", "line": 103, "endLine": 151, "signature": "(params) -> Dict[]", "docstring": "Render blueprint as ASCII graph.", "source": "def render_graph(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Render blueprint as ASCII graph.\"\"\"\n    bp = params.get(\"blueprint\")\n    selected = params.get(\"selected\")\n    show_gates = params.get(\"show_gates\", True)\n    show_actions = params.get(\"show_actions\", True)\n\n    if not bp:\n        return {\"rendered\": \"No blueprint loaded\"}\n\n    lines = []\n    lines.append(\"=\" * 60)\n    lines.append(f\"  \ud83d\udcca {bp['name']} (v{bp['version']})\")\n    lines.append(\"=\" * 60)\n\n    # States section\n    lines.append(\n        \"\\n\u250c\u2500 STATES \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\")\n    for sid, state in bp[\"states\"].items():\n        marker = \"\u25cf\" if sid == bp[\"entry_state\"] else \"\u25cb\"\n        if sid in bp[\"terminal_states\"]:\n            marker = \"\u25c9\"\n        sel = \" \u25c0\" if sid == selected else \"\"\n        desc = state.get(\"description\", \"\")[:40]\n        lines.append(f\"\u2502  {marker} {sid:20} {desc}{sel}\")\n    lines.append(\n        \"\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\")\n\n    # Transitions section\n    lines.append(\n        \"\\n\u250c\u2500 TRANSITIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\")\n    for t in bp[\"transitions\"]:\n        arrow = f\"{t['from']} \u2500\u2500[{t['on_event']}]\u2500\u2500\u25b6 {t['to']}\"\n        sel = \" \u25c0\" if t[\"id\"] == selected else \"\"\n        lines.append(f\"\u2502  {arrow}{sel}\")\n\n        if show_gates and t.get(\"gate\"):\n            gate_expr = bp[\"gates\"].get(t[\"gate\"], {}).get(\"expression\", \"?\")\n            lines.append(f\"\u2502    \u2514\u2500 gate: {t['gate']} = {gate_expr[:35]}\")\n\n        if show_actions and t.get(\"actions\"):\n            actions_str = \", \".join(t[\"actions\"][:3])\n            if len(t[\"actions\"]) > 3:\n                actions_str += f\" (+{len(t['actions'])-3} more)\"\n            lines.append(f\"\u2502    \u2514\u2500 actions: {actions_str}\")\n    lines.append(\n        \"\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\")\n\n    return {\"rendered\": \"\\n\".join(lines)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#1abc9c", "moduleName": "viz_compute"}, {"id": "viz_compute.render_table", "type": "function", "label": "render_table", "direction": "inbound", "parent": "viz_compute", "line": 154, "endLine": 171, "signature": "(params) -> Dict[]", "docstring": "Render blueprint as markdown tables - delegates to readme_compute.", "source": "def render_table(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Render blueprint as markdown tables - delegates to readme_compute.\"\"\"\n    bp = params.get(\"blueprint\")\n    if not bp:\n        return {\"rendered\": \"No blueprint loaded\"}\n\n    from .readme_compute import (\n        states_table, gates_table, actions_table, transitions_table\n    )\n\n    parts = [\n        states_table({\"blueprint\": bp})[\"table\"],\n        gates_table({\"blueprint\": bp})[\"table\"],\n        actions_table({\"blueprint\": bp})[\"table\"],\n        transitions_table({\"blueprint\": bp})[\"table\"],\n    ]\n\n    return {\"rendered\": \"\\n\".join(parts)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#1abc9c", "moduleName": "viz_compute"}, {"id": "viz_compute.render_mermaid", "type": "function", "label": "render_mermaid", "direction": "inbound", "parent": "viz_compute", "line": 174, "endLine": 181, "signature": "(params) -> Dict[]", "docstring": "Render blueprint as Mermaid diagram - delegates to readme_compute.", "source": "def render_mermaid(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Render blueprint as Mermaid diagram - delegates to readme_compute.\"\"\"\n    bp = params.get(\"blueprint\")\n    if not bp:\n        return {\"rendered\": \"No blueprint loaded\"}\n\n    from .readme_compute import mermaid\n    return {\"rendered\": mermaid({\"blueprint\": bp})[\"mermaid\"]}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#1abc9c", "moduleName": "viz_compute"}, {"id": "viz_compute.render_tree", "type": "function", "label": "render_tree", "direction": "inbound", "parent": "viz_compute", "line": 184, "endLine": 195, "signature": "(params) -> Dict[]", "docstring": "Render hierarchical tree as ASCII - delegates to readme_compute.", "source": "def render_tree(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Render hierarchical tree as ASCII - delegates to readme_compute.\"\"\"\n    tree = params.get(\"tree\")\n    if not tree:\n        return {\"rendered\": \"No tree provided\"}\n\n    from .readme_compute import tree_ascii\n    return {\"rendered\": tree_ascii({\n        \"tree\": tree,\n        \"show_status\": params.get(\"show_status\", True),\n        \"show_desc\": params.get(\"show_desc\", False)\n    })[\"rendered\"]}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#1abc9c", "moduleName": "viz_compute"}, {"id": "viz_compute.render_tree_mermaid", "type": "function", "label": "render_tree_mermaid", "direction": "inbound", "parent": "viz_compute", "line": 198, "endLine": 209, "signature": "(params) -> Dict[]", "docstring": "Render hierarchical tree as Mermaid flowchart.", "source": "def render_tree_mermaid(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Render hierarchical tree as Mermaid flowchart.\"\"\"\n    tree = params.get(\"tree\")\n    if not tree:\n        return {\"rendered\": \"No tree provided\"}\n\n    from .readme_compute import tree_mermaid\n    return {\"rendered\": tree_mermaid({\n        \"tree\": tree,\n        \"title\": params.get(\"title\", \"Feature Tree\"),\n        \"direction\": params.get(\"direction\", \"TB\")\n    })[\"mermaid\"]}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#1abc9c", "moduleName": "viz_compute"}, {"id": "viz_compute.load_tree", "type": "function", "label": "load_tree", "direction": "inbound", "parent": "viz_compute", "line": 212, "endLine": 235, "signature": "(params) -> Dict[]", "docstring": "Load a hierarchical tree from JSON file or context.", "source": "def load_tree(params: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Load a hierarchical tree from JSON file or context.\"\"\"\n    path = params.get(\"path\")\n    tree_key = params.get(\"tree_key\", \"feature_tree\")\n\n    if not path:\n        return {\"tree\": None, \"error\": \"No path provided\"}\n\n    try:\n        path = Path(path)\n        if not path.exists():\n            return {\"tree\": None, \"error\": f\"File not found: {path}\"}\n\n        with open(path) as f:\n            data = json.load(f)\n\n        # Check if it's a context dump or direct tree\n        tree = data.get(tree_key) if tree_key in data else data\n        if not tree:\n            return {\"tree\": None, \"error\": f\"No tree found at key: {tree_key}\"}\n\n        return {\"tree\": tree, \"tree_name\": tree.get(\"name\", \"Untitled\"), \"error\": None}\n    except Exception as e:\n        return {\"tree\": None, \"error\": str(e)}", "args": ["params"], "returns": "Dict[]", "moduleColor": "#1abc9c", "moduleName": "viz_compute"}, {"id": "readme_compute", "type": "dependency", "label": "readme_compute", "direction": "outbound", "category": "local", "moduleColor": "#1abc9c", "moduleName": "viz_compute"}];
const edges = [{"from": "composer_compute.load_manifest", "to": "composer_compute.load_parent", "type": "internal", "line": 770}, {"from": "composer_compute.load_manifest", "to": "composer_compute.load_child", "type": "internal", "line": 788}, {"from": "composer_compute.load_parent", "to": "pathlib", "type": "external", "category": "stdlib", "line": 32}, {"from": "composer_compute.load_parent", "to": "json", "type": "external", "category": "stdlib", "line": 38}, {"from": "composer_compute.load_child", "to": "pathlib", "type": "external", "category": "stdlib", "line": 56}, {"from": "composer_compute.load_child", "to": "json", "type": "external", "category": "stdlib", "line": 62}, {"from": "composer_compute.set_input_contract", "to": "copy", "type": "external", "category": "stdlib", "line": 124}, {"from": "composer_compute.set_output_contract", "to": "copy", "type": "external", "category": "stdlib", "line": 136}, {"from": "composer_compute.set_event_map", "to": "copy", "type": "external", "category": "stdlib", "line": 148}, {"from": "composer_compute.finalize_embedding", "to": "copy", "type": "external", "category": "stdlib", "line": 160}, {"from": "composer_compute.compose", "to": "copy", "type": "external", "category": "stdlib", "line": 193}, {"from": "composer_compute._apply_embedding", "to": "copy", "type": "external", "category": "stdlib", "line": 217}, {"from": "composer_compute._prefix_child", "to": "copy", "type": "external", "category": "stdlib", "line": 277}, {"from": "composer_compute._prefix_child", "to": "copy", "type": "external", "category": "stdlib", "line": 306}, {"from": "composer_compute._prefix_child", "to": "copy", "type": "external", "category": "stdlib", "line": 312}, {"from": "composer_compute._map_action_contracts", "to": "copy", "type": "external", "category": "stdlib", "line": 371}, {"from": "composer_compute._map_transitions", "to": "copy", "type": "external", "category": "stdlib", "line": 407}, {"from": "composer_compute._rewire_parent_transitions", "to": "copy", "type": "external", "category": "stdlib", "line": 436}, {"from": "composer_compute._rewire_parent_transitions", "to": "copy", "type": "external", "category": "stdlib", "line": 448}, {"from": "composer_compute.flatten", "to": "copy", "type": "external", "category": "stdlib", "line": 692}, {"from": "composer_compute.export_composed", "to": "pathlib", "type": "external", "category": "stdlib", "line": 713}, {"from": "composer_compute.export_composed", "to": "json", "type": "external", "category": "stdlib", "line": 717}, {"from": "composer_compute.load_manifest", "to": "pathlib", "type": "external", "category": "stdlib", "line": 742}, {"from": "composer_compute.load_manifest", "to": "json", "type": "external", "category": "stdlib", "line": 753}, {"from": "composer_compute.export_manifest", "to": "pathlib", "type": "external", "category": "stdlib", "line": 900}, {"from": "composer_compute.export_manifest", "to": "json", "type": "external", "category": "stdlib", "line": 904}, {"from": "debugger_compute.reset_session", "to": "debugger_compute.init_debug_session", "type": "internal", "line": 156}, {"from": "debugger_compute.step_over", "to": "debugger_compute.step", "type": "internal", "line": 587}, {"from": "debugger_compute.run_to_breakpoint", "to": "debugger_compute.step", "type": "internal", "line": 662}, {"from": "debugger_compute.continue_execution", "to": "debugger_compute.step", "type": "internal", "line": 739}, {"from": "debugger_compute.continue_execution", "to": "debugger_compute.run_to_breakpoint", "type": "internal", "line": 755}, {"from": "debugger_compute.load_blueprint", "to": "pathlib", "type": "external", "category": "stdlib", "line": 30}, {"from": "debugger_compute.load_blueprint", "to": "json", "type": "external", "category": "stdlib", "line": 35}, {"from": "debugger_compute.load_blueprint", "to": "frame_py", "type": "external", "category": "pip", "line": 37}, {"from": "debugger_compute.init_debug_session", "to": "datetime", "type": "external", "category": "stdlib", "line": 123}, {"from": "debugger_compute.init_debug_session", "to": "copy", "type": "external", "category": "stdlib", "line": 125}, {"from": "debugger_compute.set_breakpoint", "to": "uuid", "type": "external", "category": "stdlib", "line": 188}, {"from": "debugger_compute._check_breakpoint", "to": "frame_py", "type": "external", "category": "pip", "line": 283}, {"from": "debugger_compute._check_breakpoint", "to": "frame_py", "type": "external", "category": "pip", "line": 288}, {"from": "debugger_compute._evaluate_gate", "to": "frame_py", "type": "external", "category": "pip", "line": 306}, {"from": "debugger_compute._get_available_transitions", "to": "copy", "type": "external", "category": "stdlib", "line": 330}, {"from": "debugger_compute._execute_action", "to": "copy", "type": "external", "category": "stdlib", "line": 379}, {"from": "debugger_compute._update_watches", "to": "frame_py", "type": "external", "category": "pip", "line": 423}, {"from": "debugger_compute.step", "to": "copy", "type": "external", "category": "stdlib", "line": 470}, {"from": "debugger_compute.step", "to": "copy", "type": "external", "category": "stdlib", "line": 509}, {"from": "debugger_compute.step", "to": "datetime", "type": "external", "category": "stdlib", "line": 524}, {"from": "debugger_compute.step", "to": "copy", "type": "external", "category": "stdlib", "line": 527}, {"from": "debugger_compute.step_back", "to": "copy", "type": "external", "category": "stdlib", "line": 608}, {"from": "debugger_compute.run_to_breakpoint", "to": "copy", "type": "external", "category": "stdlib", "line": 643}, {"from": "debugger_compute.run_to_breakpoint", "to": "copy", "type": "external", "category": "stdlib", "line": 644}, {"from": "debugger_compute.inspect_context", "to": "json", "type": "external", "category": "stdlib", "line": 814}, {"from": "debugger_compute.inspect_context", "to": "json", "type": "external", "category": "stdlib", "line": 819}, {"from": "debugger_compute.evaluate_expression", "to": "frame_py", "type": "external", "category": "pip", "line": 838}, {"from": "debugger_compute.goto_step", "to": "copy", "type": "external", "category": "stdlib", "line": 960}, {"from": "debugger_compute.compare_states", "to": "json", "type": "external", "category": "stdlib", "line": 1009}, {"from": "debugger_compute.compare_states", "to": "json", "type": "external", "category": "stdlib", "line": 1010}, {"from": "differ_compute._diff_dict", "to": "differ_compute.make_change", "type": "internal", "line": 135}, {"from": "differ_compute._diff_dict", "to": "differ_compute.make_change", "type": "internal", "line": 142}, {"from": "differ_compute._diff_dict", "to": "differ_compute.make_change", "type": "internal", "line": 150}, {"from": "differ_compute._diff_transitions", "to": "differ_compute.make_change", "type": "internal", "line": 175}, {"from": "differ_compute._diff_transitions", "to": "differ_compute.make_change", "type": "internal", "line": 182}, {"from": "differ_compute._diff_transitions", "to": "differ_compute.make_change", "type": "internal", "line": 199}, {"from": "differ_compute._diff_terminal_states", "to": "differ_compute.make_change", "type": "internal", "line": 229}, {"from": "differ_compute._diff_terminal_states", "to": "differ_compute.make_change", "type": "internal", "line": 234}, {"from": "differ_compute.compute_diff", "to": "differ_compute.make_change", "type": "internal", "line": 256}, {"from": "differ_compute.compute_diff", "to": "differ_compute.make_change", "type": "internal", "line": 263}, {"from": "differ_compute.detect_conflicts", "to": "differ_compute.compute_diff", "type": "internal", "line": 562}, {"from": "differ_compute.detect_conflicts", "to": "differ_compute.compute_diff", "type": "internal", "line": 563}, {"from": "differ_compute.load_blueprint", "to": "pathlib", "type": "external", "category": "stdlib", "line": 73}, {"from": "differ_compute.load_blueprint", "to": "json", "type": "external", "category": "stdlib", "line": 79}, {"from": "differ_compute._format_value", "to": "json", "type": "external", "category": "stdlib", "line": 453}, {"from": "differ_compute._format_value", "to": "json", "type": "external", "category": "stdlib", "line": 455}, {"from": "differ_compute._format_value_inline", "to": "json", "type": "external", "category": "stdlib", "line": 463}, {"from": "differ_compute._format_value_inline", "to": "json", "type": "external", "category": "stdlib", "line": 465}, {"from": "differ_compute.generate_json_patch", "to": "json", "type": "external", "category": "stdlib", "line": 527}, {"from": "differ_compute.merge_blueprints", "to": "copy", "type": "external", "category": "stdlib", "line": 605}, {"from": "differ_compute._merge_dict", "to": "copy", "type": "external", "category": "stdlib", "line": 678}, {"from": "differ_compute._merge_dict", "to": "copy", "type": "external", "category": "stdlib", "line": 683}, {"from": "differ_compute._merge_dict", "to": "copy", "type": "external", "category": "stdlib", "line": 687}, {"from": "differ_compute._merge_dict", "to": "copy", "type": "external", "category": "stdlib", "line": 693}, {"from": "differ_compute._merge_transitions", "to": "copy", "type": "external", "category": "stdlib", "line": 720}, {"from": "differ_compute._merge_transitions", "to": "copy", "type": "external", "category": "stdlib", "line": 722}, {"from": "differ_compute._merge_transitions", "to": "copy", "type": "external", "category": "stdlib", "line": 724}, {"from": "differ_compute._merge_transitions", "to": "copy", "type": "external", "category": "stdlib", "line": 730}, {"from": "differ_compute.export_merged", "to": "pathlib", "type": "external", "category": "stdlib", "line": 763}, {"from": "differ_compute.export_merged", "to": "json", "type": "external", "category": "stdlib", "line": 767}, {"from": "linter_compute.check_unreachable_states", "to": "linter_compute.make_finding", "type": "internal", "line": 139}, {"from": "linter_compute.check_dead_end_states", "to": "linter_compute.make_finding", "type": "internal", "line": 181}, {"from": "linter_compute.check_unused_gates", "to": "linter_compute.make_finding", "type": "internal", "line": 223}, {"from": "linter_compute.check_unused_actions", "to": "linter_compute.make_finding", "type": "internal", "line": 253}, {"from": "linter_compute.check_unused_context", "to": "linter_compute.make_finding", "type": "internal", "line": 324}, {"from": "linter_compute.check_orphaned_transitions", "to": "linter_compute.make_finding", "type": "internal", "line": 352}, {"from": "linter_compute.check_orphaned_transitions", "to": "linter_compute.make_finding", "type": "internal", "line": 363}, {"from": "linter_compute.check_missing_gate_refs", "to": "linter_compute.make_finding", "type": "internal", "line": 391}, {"from": "linter_compute.check_missing_gate_refs", "to": "linter_compute.make_finding", "type": "internal", "line": 403}, {"from": "linter_compute.check_missing_action_refs", "to": "linter_compute.make_finding", "type": "internal", "line": 431}, {"from": "linter_compute.check_duplicate_ids", "to": "linter_compute.make_finding", "type": "internal", "line": 457}, {"from": "linter_compute.check_naming_conventions", "to": "linter_compute.make_finding", "type": "internal", "line": 486}, {"from": "linter_compute.check_naming_conventions", "to": "linter_compute.make_finding", "type": "internal", "line": 497}, {"from": "linter_compute.check_naming_conventions", "to": "linter_compute.make_finding", "type": "internal", "line": 508}, {"from": "linter_compute.check_naming_conventions", "to": "linter_compute.make_finding", "type": "internal", "line": 520}, {"from": "linter_compute.check_naming_conventions", "to": "linter_compute.make_finding", "type": "internal", "line": 535}, {"from": "linter_compute.load_blueprint", "to": "pathlib", "type": "external", "category": "stdlib", "line": 68}, {"from": "linter_compute.load_blueprint", "to": "json", "type": "external", "category": "stdlib", "line": 74}, {"from": "linter_compute.check_naming_conventions", "to": "re", "type": "external", "category": "stdlib", "line": 480}, {"from": "linter_compute.check_naming_conventions", "to": "re", "type": "external", "category": "stdlib", "line": 481}, {"from": "playground_compute.load_blueprint", "to": "pathlib", "type": "external", "category": "stdlib", "line": 36}, {"from": "playground_compute.load_blueprint", "to": "json", "type": "external", "category": "stdlib", "line": 67}, {"from": "playground_compute.validate_json", "to": "json", "type": "external", "category": "stdlib", "line": 101}, {"from": "playground_compute.validate_blueprint", "to": "json", "type": "external", "category": "stdlib", "line": 131}, {"from": "playground_compute.format_blueprint", "to": "json", "type": "external", "category": "stdlib", "line": 275}, {"from": "playground_compute.format_blueprint", "to": "json", "type": "external", "category": "stdlib", "line": 276}, {"from": "playground_compute.init_simulation", "to": "datetime", "type": "external", "category": "stdlib", "line": 375}, {"from": "playground_compute.init_simulation", "to": "copy", "type": "external", "category": "stdlib", "line": 377}, {"from": "playground_compute._evaluate_gate", "to": "frame_py", "type": "external", "category": "pip", "line": 401}, {"from": "playground_compute._get_available_events", "to": "copy", "type": "external", "category": "stdlib", "line": 417}, {"from": "playground_compute._execute_action", "to": "copy", "type": "external", "category": "stdlib", "line": 476}, {"from": "playground_compute.dispatch_event", "to": "copy", "type": "external", "category": "stdlib", "line": 516}, {"from": "playground_compute.dispatch_event", "to": "copy", "type": "external", "category": "stdlib", "line": 549}, {"from": "playground_compute.dispatch_event", "to": "copy", "type": "external", "category": "stdlib", "line": 558}, {"from": "playground_compute.dispatch_event", "to": "datetime", "type": "external", "category": "stdlib", "line": 561}, {"from": "playground_compute.dispatch_event", "to": "copy", "type": "external", "category": "stdlib", "line": 567}, {"from": "playground_compute.encode_share_url", "to": "zlib", "type": "external", "category": "stdlib", "line": 602}, {"from": "playground_compute.encode_share_url", "to": "base64", "type": "external", "category": "stdlib", "line": 603}, {"from": "playground_compute.decode_share_url", "to": "base64", "type": "external", "category": "stdlib", "line": 640}, {"from": "playground_compute.decode_share_url", "to": "zlib", "type": "external", "category": "stdlib", "line": 641}, {"from": "playground_compute.decode_share_url", "to": "json", "type": "external", "category": "stdlib", "line": 644}, {"from": "playground_compute.export_blueprint", "to": "json", "type": "external", "category": "stdlib", "line": 683}, {"from": "playground_compute.export_blueprint", "to": "json", "type": "external", "category": "stdlib", "line": 691}, {"from": "playground_compute.export_blueprint", "to": "json", "type": "external", "category": "stdlib", "line": 692}, {"from": "playground_compute.export_blueprint", "to": "pathlib", "type": "external", "category": "stdlib", "line": 694}, {"from": "registry_compute.dfs", "to": "registry_compute.dfs", "type": "internal", "line": 927}, {"from": "registry_compute._detect_cycle", "to": "registry_compute.dfs", "type": "internal", "line": 934}, {"from": "registry_compute.init_registry", "to": "pathlib", "type": "external", "category": "stdlib", "line": 26}, {"from": "registry_compute.init_registry", "to": "datetime", "type": "external", "category": "stdlib", "line": 31}, {"from": "registry_compute.init_registry", "to": "datetime", "type": "external", "category": "stdlib", "line": 32}, {"from": "registry_compute.init_registry", "to": "json", "type": "external", "category": "stdlib", "line": 38}, {"from": "registry_compute.load_registry", "to": "pathlib", "type": "external", "category": "stdlib", "line": 61}, {"from": "registry_compute.load_registry", "to": "json", "type": "external", "category": "stdlib", "line": 68}, {"from": "registry_compute.save_registry", "to": "pathlib", "type": "external", "category": "stdlib", "line": 93}, {"from": "registry_compute.save_registry", "to": "datetime", "type": "external", "category": "stdlib", "line": 94}, {"from": "registry_compute.save_registry", "to": "json", "type": "external", "category": "stdlib", "line": 98}, {"from": "registry_compute.register_blueprint", "to": "pathlib", "type": "external", "category": "stdlib", "line": 121}, {"from": "registry_compute.register_blueprint", "to": "json", "type": "external", "category": "stdlib", "line": 126}, {"from": "registry_compute.register_blueprint", "to": "datetime", "type": "external", "category": "stdlib", "line": 137}, {"from": "registry_compute.register_blueprint", "to": "pathlib", "type": "external", "category": "stdlib", "line": 162}, {"from": "registry_compute.register_blueprint", "to": "shutil", "type": "external", "category": "stdlib", "line": 165}, {"from": "registry_compute.update_blueprint", "to": "pathlib", "type": "external", "category": "stdlib", "line": 191}, {"from": "registry_compute.update_blueprint", "to": "json", "type": "external", "category": "stdlib", "line": 196}, {"from": "registry_compute.update_blueprint", "to": "datetime", "type": "external", "category": "stdlib", "line": 212}, {"from": "registry_compute.update_blueprint", "to": "pathlib", "type": "external", "category": "stdlib", "line": 222}, {"from": "registry_compute.update_blueprint", "to": "shutil", "type": "external", "category": "stdlib", "line": 225}, {"from": "registry_compute.get_blueprint", "to": "pathlib", "type": "external", "category": "stdlib", "line": 263}, {"from": "registry_compute.get_blueprint", "to": "json", "type": "external", "category": "stdlib", "line": 268}, {"from": "registry_compute.get_blueprint", "to": "pathlib", "type": "external", "category": "stdlib", "line": 273}, {"from": "registry_compute.get_blueprint", "to": "json", "type": "external", "category": "stdlib", "line": 275}, {"from": "registry_compute.compare_versions", "to": "pathlib", "type": "external", "category": "stdlib", "line": 431}, {"from": "registry_compute.compare_versions", "to": "json", "type": "external", "category": "stdlib", "line": 441}, {"from": "registry_compute.compare_versions", "to": "json", "type": "external", "category": "stdlib", "line": 443}, {"from": "registry_compute.rollback_version", "to": "pathlib", "type": "external", "category": "stdlib", "line": 475}, {"from": "registry_compute.rollback_version", "to": "shutil", "type": "external", "category": "stdlib", "line": 480}, {"from": "registry_compute.rollback_version", "to": "datetime", "type": "external", "category": "stdlib", "line": 484}, {"from": "registry_compute.deprecate_blueprint", "to": "datetime", "type": "external", "category": "stdlib", "line": 614}, {"from": "registry_compute.delete_blueprint", "to": "pathlib", "type": "external", "category": "stdlib", "line": 660}, {"from": "registry_compute.delete_blueprint", "to": "shutil", "type": "external", "category": "stdlib", "line": 662}, {"from": "registry_compute.export_registry", "to": "datetime", "type": "external", "category": "stdlib", "line": 691}, {"from": "compliance_compute.check_policy", "to": "compliance_compute.evaluate_rule", "type": "internal", "line": 424}, {"from": "compliance_compute.check_all_policies", "to": "compliance_compute.check_policy", "type": "internal", "line": 443}, {"from": "compliance_compute.generate_report", "to": "compliance_compute.calculate_score", "type": "internal", "line": 487}, {"from": "compliance_compute.load_blueprint", "to": "pathlib", "type": "external", "category": "stdlib", "line": 22}, {"from": "compliance_compute.load_blueprint", "to": "json", "type": "external", "category": "stdlib", "line": 27}, {"from": "compliance_compute.load_policy", "to": "pathlib", "type": "external", "category": "stdlib", "line": 48}, {"from": "compliance_compute.load_policy", "to": "json", "type": "external", "category": "stdlib", "line": 53}, {"from": "compliance_compute.load_policies", "to": "pathlib", "type": "external", "category": "stdlib", "line": 74}, {"from": "compliance_compute.load_policies", "to": "pathlib", "type": "external", "category": "stdlib", "line": 76}, {"from": "compliance_compute.load_policies", "to": "json", "type": "external", "category": "stdlib", "line": 87}, {"from": "compliance_compute._check_transition_requires_gate", "to": "re", "type": "external", "category": "stdlib", "line": 176}, {"from": "compliance_compute._check_transition_requires_gate", "to": "re", "type": "external", "category": "stdlib", "line": 177}, {"from": "compliance_compute._check_transition_requires_action", "to": "re", "type": "external", "category": "stdlib", "line": 230}, {"from": "compliance_compute._check_transition_requires_action", "to": "re", "type": "external", "category": "stdlib", "line": 231}, {"from": "compliance_compute._check_gate_expression", "to": "re", "type": "external", "category": "stdlib", "line": 274}, {"from": "compliance_compute._check_gate_expression", "to": "re", "type": "external", "category": "stdlib", "line": 275}, {"from": "compliance_compute.generate_report", "to": "datetime", "type": "external", "category": "stdlib", "line": 507}, {"from": "compliance_compute.export_report", "to": "pathlib", "type": "external", "category": "stdlib", "line": 550}, {"from": "compliance_compute.export_report", "to": "json", "type": "external", "category": "stdlib", "line": 554}, {"from": "coverage_compute.export_html", "to": "coverage_compute.covColor", "type": "internal", "line": 676}, {"from": "coverage_compute.export_html", "to": "coverage_compute.covColor", "type": "internal", "line": 712}, {"from": "coverage_compute.export_html", "to": "coverage_compute.covColor", "type": "internal", "line": 717}, {"from": "coverage_compute.export_html", "to": "coverage_compute.covColor", "type": "internal", "line": 722}, {"from": "coverage_compute.export_html", "to": "coverage_compute.covColor", "type": "internal", "line": 727}, {"from": "coverage_compute.reset_coverage", "to": "coverage_compute.init_coverage", "type": "internal", "line": 863}, {"from": "coverage_compute.load_blueprint", "to": "pathlib", "type": "external", "category": "stdlib", "line": 28}, {"from": "coverage_compute.load_blueprint", "to": "json", "type": "external", "category": "stdlib", "line": 34}, {"from": "coverage_compute.load_blueprint", "to": "frame_py", "type": "external", "category": "pip", "line": 36}, {"from": "coverage_compute.init_coverage", "to": "datetime", "type": "external", "category": "stdlib", "line": 120}, {"from": "coverage_compute.import_trace", "to": "pathlib", "type": "external", "category": "stdlib", "line": 235}, {"from": "coverage_compute.import_trace", "to": "json", "type": "external", "category": "stdlib", "line": 248}, {"from": "coverage_compute.compute_metrics", "to": "datetime", "type": "external", "category": "stdlib", "line": 378}, {"from": "coverage_compute.export_html", "to": "pathlib", "type": "external", "category": "stdlib", "line": 796}, {"from": "coverage_compute.export_json", "to": "datetime", "type": "external", "category": "stdlib", "line": 827}, {"from": "coverage_compute.export_json", "to": "json", "type": "external", "category": "stdlib", "line": 839}, {"from": "coverage_compute.export_json", "to": "pathlib", "type": "external", "category": "stdlib", "line": 844}, {"from": "dashboard_compute.scanTools", "to": "os", "type": "external", "category": "stdlib", "line": 30}, {"from": "dashboard_compute.scanTools", "to": "os", "type": "external", "category": "stdlib", "line": 34}, {"from": "dashboard_compute.scanTools", "to": "os", "type": "external", "category": "stdlib", "line": 35}, {"from": "dashboard_compute.scanTools", "to": "os", "type": "external", "category": "stdlib", "line": 36}, {"from": "dashboard_compute.scanTools", "to": "os", "type": "external", "category": "stdlib", "line": 46}, {"from": "dashboard_compute.scanTools", "to": "os", "type": "external", "category": "stdlib", "line": 47}, {"from": "dashboard_compute._findVisualizations", "to": "os", "type": "external", "category": "stdlib", "line": 69}, {"from": "dashboard_compute._findVisualizations", "to": "os", "type": "external", "category": "stdlib", "line": 77}, {"from": "dashboard_compute._findVisualizations", "to": "os", "type": "external", "category": "stdlib", "line": 90}, {"from": "dashboard_compute._findVisualizations", "to": "os", "type": "external", "category": "stdlib", "line": 91}, {"from": "dashboard_compute._findSimpleMmd", "to": "os", "type": "external", "category": "stdlib", "line": 100}, {"from": "dashboard_compute._findSimpleMmd", "to": "os", "type": "external", "category": "stdlib", "line": 101}, {"from": "dashboard_compute._findSimpleMmd", "to": "os", "type": "external", "category": "stdlib", "line": 105}, {"from": "dashboard_compute._findSimpleMmd", "to": "os", "type": "external", "category": "stdlib", "line": 106}, {"from": "dashboard_compute.analyzeTools", "to": "json", "type": "external", "category": "stdlib", "line": 131}, {"from": "dashboard_compute.categorizeTools", "to": "collections", "type": "external", "category": "stdlib", "line": 196}, {"from": "dashboard_compute.generateDashboard", "to": "os", "type": "external", "category": "stdlib", "line": 240}, {"from": "dashboard_compute._buildDashboardHtml", "to": "json", "type": "external", "category": "stdlib", "line": 254}, {"from": "dashboard_compute._buildDashboardHtml", "to": "os", "type": "external", "category": "stdlib", "line": 263}, {"from": "dashboard_compute._buildDashboardHtml", "to": "os", "type": "external", "category": "stdlib", "line": 267}, {"from": "dashboard_compute._buildDashboardHtml", "to": "os", "type": "external", "category": "stdlib", "line": 268}, {"from": "dashboard_compute._buildDashboardHtml", "to": "json", "type": "external", "category": "stdlib", "line": 273}, {"from": "dashboard_compute._buildDashboardHtml", "to": "json", "type": "external", "category": "stdlib", "line": 278}, {"from": "doc_compute.assemble_html", "to": "doc_compute.assemble_markdown", "type": "internal", "line": 553}, {"from": "doc_compute.load_blueprint", "to": "pathlib", "type": "external", "category": "stdlib", "line": 27}, {"from": "doc_compute.load_blueprint", "to": "json", "type": "external", "category": "stdlib", "line": 32}, {"from": "doc_compute.load_blueprint", "to": "frame_py", "type": "external", "category": "pip", "line": 34}, {"from": "doc_compute.extract_metadata", "to": "datetime", "type": "external", "category": "stdlib", "line": 138}, {"from": "doc_compute._format_inline", "to": "re", "type": "external", "category": "stdlib", "line": 725}, {"from": "doc_compute._format_inline", "to": "re", "type": "external", "category": "stdlib", "line": 727}, {"from": "doc_compute._format_inline", "to": "re", "type": "external", "category": "stdlib", "line": 729}, {"from": "doc_compute.assemble_json", "to": "json", "type": "external", "category": "stdlib", "line": 784}, {"from": "doc_compute.export_docs", "to": "pathlib", "type": "external", "category": "stdlib", "line": 802}, {"from": "simulator_compute.reset_simulation", "to": "simulator_compute.init_simulation", "type": "internal", "line": 150}, {"from": "simulator_compute.run_sequence", "to": "simulator_compute.dispatch_event", "type": "internal", "line": 516}, {"from": "simulator_compute.fuzz_run", "to": "simulator_compute.dispatch_event", "type": "internal", "line": 582}, {"from": "simulator_compute.load_blueprint", "to": "pathlib", "type": "external", "category": "stdlib", "line": 32}, {"from": "simulator_compute.load_blueprint", "to": "json", "type": "external", "category": "stdlib", "line": 37}, {"from": "simulator_compute.load_blueprint", "to": "frame_py", "type": "external", "category": "pip", "line": 39}, {"from": "simulator_compute.init_simulation", "to": "datetime", "type": "external", "category": "stdlib", "line": 125}, {"from": "simulator_compute.init_simulation", "to": "copy", "type": "external", "category": "stdlib", "line": 127}, {"from": "simulator_compute.set_context", "to": "copy", "type": "external", "category": "stdlib", "line": 168}, {"from": "simulator_compute._evaluate_gate", "to": "frame_py", "type": "external", "category": "pip", "line": 186}, {"from": "simulator_compute._get_available_transitions", "to": "copy", "type": "external", "category": "stdlib", "line": 200}, {"from": "simulator_compute.evaluate_gates", "to": "frame_py", "type": "external", "category": "pip", "line": 257}, {"from": "simulator_compute._execute_action", "to": "copy", "type": "external", "category": "stdlib", "line": 288}, {"from": "simulator_compute.dispatch_event", "to": "copy", "type": "external", "category": "stdlib", "line": 323}, {"from": "simulator_compute.dispatch_event", "to": "copy", "type": "external", "category": "stdlib", "line": 356}, {"from": "simulator_compute.dispatch_event", "to": "copy", "type": "external", "category": "stdlib", "line": 365}, {"from": "simulator_compute.dispatch_event", "to": "datetime", "type": "external", "category": "stdlib", "line": 368}, {"from": "simulator_compute.dispatch_event", "to": "copy", "type": "external", "category": "stdlib", "line": 371}, {"from": "simulator_compute.fork_simulation", "to": "copy", "type": "external", "category": "stdlib", "line": 410}, {"from": "simulator_compute.fork_simulation", "to": "copy", "type": "external", "category": "stdlib", "line": 413}, {"from": "simulator_compute.fork_simulation", "to": "copy", "type": "external", "category": "stdlib", "line": 414}, {"from": "simulator_compute.fork_simulation", "to": "datetime", "type": "external", "category": "stdlib", "line": 415}, {"from": "simulator_compute.switch_fork", "to": "copy", "type": "external", "category": "stdlib", "line": 439}, {"from": "simulator_compute.switch_fork", "to": "copy", "type": "external", "category": "stdlib", "line": 440}, {"from": "simulator_compute.step_back", "to": "copy", "type": "external", "category": "stdlib", "line": 466}, {"from": "simulator_compute.run_sequence", "to": "copy", "type": "external", "category": "stdlib", "line": 512}, {"from": "simulator_compute.run_sequence", "to": "copy", "type": "external", "category": "stdlib", "line": 513}, {"from": "simulator_compute.fuzz_run", "to": "random", "type": "external", "category": "stdlib", "line": 562}, {"from": "simulator_compute.fuzz_run", "to": "copy", "type": "external", "category": "stdlib", "line": 565}, {"from": "simulator_compute.fuzz_run", "to": "copy", "type": "external", "category": "stdlib", "line": 566}, {"from": "simulator_compute.fuzz_run", "to": "random", "type": "external", "category": "stdlib", "line": 579}, {"from": "simulator_compute.explore_state_space", "to": "collections", "type": "external", "category": "stdlib", "line": 653}, {"from": "simulator_compute.explore_state_space", "to": "copy", "type": "external", "category": "stdlib", "line": 653}, {"from": "simulator_compute.explore_state_space", "to": "copy", "type": "external", "category": "stdlib", "line": 684}, {"from": "simulator_compute.find_path", "to": "collections", "type": "external", "category": "stdlib", "line": 740}, {"from": "simulator_compute.find_path", "to": "copy", "type": "external", "category": "stdlib", "line": 740}, {"from": "simulator_compute.find_path", "to": "copy", "type": "external", "category": "stdlib", "line": 785}, {"from": "simulator_compute.export_trace", "to": "datetime", "type": "external", "category": "stdlib", "line": 809}, {"from": "simulator_compute.export_trace", "to": "pathlib", "type": "external", "category": "stdlib", "line": 812}, {"from": "simulator_compute.export_trace", "to": "datetime", "type": "external", "category": "stdlib", "line": 826}, {"from": "simulator_compute.export_trace", "to": "json", "type": "external", "category": "stdlib", "line": 833}, {"from": "simulator_compute.import_trace", "to": "pathlib", "type": "external", "category": "stdlib", "line": 845}, {"from": "simulator_compute.import_trace", "to": "json", "type": "external", "category": "stdlib", "line": 851}, {"from": "tracer_compute.export_trace", "to": "tracer_compute.format_otlp", "type": "internal", "line": 1011}, {"from": "tracer_compute.export_trace", "to": "tracer_compute.format_jsonl", "type": "internal", "line": 1013}, {"from": "tracer_compute.export_trace", "to": "tracer_compute.format_timeline", "type": "internal", "line": 1015}, {"from": "tracer_compute.export_trace", "to": "tracer_compute.format_human", "type": "internal", "line": 1017}, {"from": "tracer_compute._now_iso", "to": "datetime", "type": "external", "category": "stdlib", "line": 42}, {"from": "tracer_compute._now_ns", "to": "datetime", "type": "external", "category": "stdlib", "line": 47}, {"from": "tracer_compute._gen_id", "to": "uuid", "type": "external", "category": "stdlib", "line": 52}, {"from": "tracer_compute._gen_trace_id", "to": "uuid", "type": "external", "category": "stdlib", "line": 57}, {"from": "tracer_compute._gen_span_id", "to": "uuid", "type": "external", "category": "stdlib", "line": 62}, {"from": "tracer_compute._parse_iso", "to": "datetime", "type": "external", "category": "stdlib", "line": 69}, {"from": "tracer_compute._parse_iso", "to": "datetime", "type": "external", "category": "stdlib", "line": 72}, {"from": "tracer_compute.format_otlp", "to": "json", "type": "external", "category": "stdlib", "line": 678}, {"from": "tracer_compute._attrs_to_otlp", "to": "json", "type": "external", "category": "stdlib", "line": 709}, {"from": "tracer_compute.format_jsonl", "to": "json", "type": "external", "category": "stdlib", "line": 738}, {"from": "tracer_compute.format_jsonl", "to": "json", "type": "external", "category": "stdlib", "line": 750}, {"from": "tracer_compute.export_trace", "to": "pathlib", "type": "external", "category": "stdlib", "line": 1023}, {"from": "function_decoder_compute.extractExports", "to": "function_decoder_compute.get_source", "type": "internal", "line": 104}, {"from": "function_decoder_compute.extractExports", "to": "function_decoder_compute.get_source", "type": "internal", "line": 118}, {"from": "function_decoder_compute.extractExports", "to": "function_decoder_compute.get_source", "type": "internal", "line": 138}, {"from": "function_decoder_compute.traceInternalCalls", "to": "function_decoder_compute.CallVisitor", "type": "internal", "line": 235}, {"from": "function_decoder_compute.traceExternalCalls", "to": "function_decoder_compute.ExternalCallVisitor", "type": "internal", "line": 322}, {"from": "function_decoder_compute.parseAst", "to": "ast", "type": "external", "category": "stdlib", "line": 63}, {"from": "function_decoder_compute.extractExports", "to": "pathlib", "type": "external", "category": "stdlib", "line": 77}, {"from": "function_decoder_compute.extractExports", "to": "ast", "type": "external", "category": "stdlib", "line": 91}, {"from": "function_decoder_compute.extractExports", "to": "ast", "type": "external", "category": "stdlib", "line": 102}, {"from": "function_decoder_compute.extractExports", "to": "ast", "type": "external", "category": "stdlib", "line": 116}, {"from": "function_decoder_compute.extractExports", "to": "ast", "type": "external", "category": "stdlib", "line": 137}, {"from": "function_decoder_compute.extractExports", "to": "ast", "type": "external", "category": "stdlib", "line": 142}, {"from": "function_decoder_compute.extractImports", "to": "ast", "type": "external", "category": "stdlib", "line": 165}, {"from": "function_decoder_compute.computeCoupling", "to": "collections", "type": "external", "category": "stdlib", "line": 344}, {"from": "function_decoder_compute.generateModuleGraph", "to": "pathlib", "type": "external", "category": "stdlib", "line": 383}, {"from": "function_decoder_compute._get_annotation", "to": "ast", "type": "external", "category": "stdlib", "line": 488}, {"from": "function_decoder_compute._build_function_html", "to": "json", "type": "external", "category": "stdlib", "line": 616}, {"from": "function_decoder_compute._build_function_html", "to": "json", "type": "external", "category": "stdlib", "line": 617}, {"from": "function_decoder_compute._build_function_html", "to": "json", "type": "external", "category": "stdlib", "line": 618}, {"from": "graph_visualizer_compute.process", "to": "json", "type": "external", "category": "stdlib", "line": 24}, {"from": "graph_visualizer_compute.process", "to": "collections", "type": "external", "category": "stdlib", "line": 40}, {"from": "graph_visualizer_compute.process", "to": "collections", "type": "external", "category": "stdlib", "line": 41}, {"from": "graph_visualizer_compute._calculate_layers", "to": "collections", "type": "external", "category": "stdlib", "line": 116}, {"from": "graph_visualizer_compute._build_html", "to": "json", "type": "external", "category": "stdlib", "line": 146}, {"from": "graph_visualizer_compute._build_html", "to": "json", "type": "external", "category": "stdlib", "line": 147}, {"from": "graph_visualizer_compute._build_html", "to": "json", "type": "external", "category": "stdlib", "line": 148}, {"from": "extractor_compute.walk", "to": "extractor_compute.walk", "type": "internal", "line": 127}, {"from": "extractor_compute.walk", "to": "extractor_compute.walk", "type": "internal", "line": 173}, {"from": "extractor_compute.walk", "to": "extractor_compute.walk", "type": "internal", "line": 257}, {"from": "extractor_compute.walk", "to": "extractor_compute.walk", "type": "internal", "line": 261}, {"from": "extractor_compute.findStatePatterns", "to": "extractor_compute.walk", "type": "internal", "line": 263}, {"from": "extractor_compute.extractStates", "to": "extractor_compute.addState", "type": "internal", "line": 384}, {"from": "extractor_compute.extractStates", "to": "extractor_compute.addState", "type": "internal", "line": 401}, {"from": "extractor_compute.extractStates", "to": "extractor_compute.addState", "type": "internal", "line": 415}, {"from": "extractor_compute.extractStates", "to": "extractor_compute.addState", "type": "internal", "line": 425}, {"from": "extractor_compute.extractStates", "to": "extractor_compute.addState", "type": "internal", "line": 439}, {"from": "extractor_compute.extractStates", "to": "extractor_compute.addState", "type": "internal", "line": 450}, {"from": "extractor_compute.extractTransitions", "to": "extractor_compute.addTransition", "type": "internal", "line": 512}, {"from": "extractor_compute.extractTransitions", "to": "extractor_compute.addTransition", "type": "internal", "line": 527}, {"from": "extractor_compute.extractTransitions", "to": "extractor_compute.addTransition", "type": "internal", "line": 542}, {"from": "extractor_compute.extractTransitions", "to": "extractor_compute.addTransition", "type": "internal", "line": 556}, {"from": "extractor_compute.walk", "to": "extractor_compute.walk", "type": "internal", "line": 588}, {"from": "extractor_compute._findStateChanges", "to": "extractor_compute.walk", "type": "internal", "line": 603}, {"from": "extractor_compute.walk", "to": "extractor_compute.walk", "type": "internal", "line": 633}, {"from": "extractor_compute._findStateChangesGeneric", "to": "extractor_compute.walk", "type": "internal", "line": 635}, {"from": "extractor_compute.extractActions", "to": "extractor_compute.addAction", "type": "internal", "line": 785}, {"from": "extractor_compute.extractActions", "to": "extractor_compute.addAction", "type": "internal", "line": 801}, {"from": "extractor_compute.extractActions", "to": "extractor_compute.addAction", "type": "internal", "line": 814}, {"from": "extractor_compute.extractActions", "to": "extractor_compute.addAction", "type": "internal", "line": 819}, {"from": "extractor_compute.walk", "to": "extractor_compute.walk", "type": "internal", "line": 869}, {"from": "extractor_compute._findSideEffects", "to": "extractor_compute.walk", "type": "internal", "line": 871}, {"from": "extractor_compute.find", "to": "extractor_compute.find", "type": "internal", "line": 1316}, {"from": "extractor_compute.find", "to": "extractor_compute.find", "type": "internal", "line": 1321}, {"from": "extractor_compute._getClassBody", "to": "extractor_compute.find", "type": "internal", "line": 1326}, {"from": "extractor_compute.find", "to": "extractor_compute.find", "type": "internal", "line": 1347}, {"from": "extractor_compute.find", "to": "extractor_compute.find", "type": "internal", "line": 1352}, {"from": "extractor_compute._getMethodBody", "to": "extractor_compute.find", "type": "internal", "line": 1357}, {"from": "extractor_compute.parseAst", "to": "ast", "type": "external", "category": "stdlib", "line": 57}, {"from": "extractor_compute._astToDict", "to": "ast", "type": "external", "category": "stdlib", "line": 68}, {"from": "extractor_compute.extractTransitions", "to": "re", "type": "external", "category": "stdlib", "line": 551}, {"from": "extractor_compute.extractActions", "to": "re", "type": "external", "category": "stdlib", "line": 812}, {"from": "extractor_compute.generateBlueprint", "to": "os", "type": "external", "category": "stdlib", "line": 988}, {"from": "extractor_compute.generateBlueprint", "to": "json", "type": "external", "category": "stdlib", "line": 1069}, {"from": "extractor_compute.exportReport", "to": "json", "type": "external", "category": "stdlib", "line": 1192}, {"from": "llm_compute.explain_blueprint", "to": "llm_compute.query", "type": "internal", "line": 197}, {"from": "llm_compute.validate_blueprint", "to": "llm_compute.query", "type": "internal", "line": 214}, {"from": "llm_compute.suggest_improvements", "to": "llm_compute.query", "type": "internal", "line": 230}, {"from": "llm_compute.generate_blueprint", "to": "llm_compute.query", "type": "internal", "line": 253}, {"from": "llm_compute", "to": "pathlib", "type": "external", "category": "stdlib", "line": 21}, {"from": "llm_compute.init_config", "to": "os", "type": "external", "category": "stdlib", "line": 50}, {"from": "llm_compute.init_config", "to": "os", "type": "external", "category": "stdlib", "line": 51}, {"from": "llm_compute.init_config", "to": "os", "type": "external", "category": "stdlib", "line": 55}, {"from": "llm_compute.load_blueprint", "to": "pathlib", "type": "external", "category": "stdlib", "line": 80}, {"from": "llm_compute.load_blueprint", "to": "json", "type": "external", "category": "stdlib", "line": 87}, {"from": "llm_compute._call_llm", "to": "openai", "type": "external", "category": "pip", "line": 120}, {"from": "llm_compute.query", "to": "json", "type": "external", "category": "stdlib", "line": 151}, {"from": "decoder_compute.walk", "to": "decoder_compute.walk", "type": "internal", "line": 155}, {"from": "decoder_compute.walk", "to": "decoder_compute.walk", "type": "internal", "line": 158}, {"from": "decoder_compute.analyzeImports", "to": "decoder_compute.walk", "type": "internal", "line": 160}, {"from": "decoder_compute.walk", "to": "decoder_compute.walk", "type": "internal", "line": 209}, {"from": "decoder_compute.walk", "to": "decoder_compute.extractFn", "type": "internal", "line": 211}, {"from": "decoder_compute.walk", "to": "decoder_compute.walk", "type": "internal", "line": 213}, {"from": "decoder_compute.walk", "to": "decoder_compute.walk", "type": "internal", "line": 216}, {"from": "decoder_compute.walk", "to": "decoder_compute.walk", "type": "internal", "line": 219}, {"from": "decoder_compute.analyzeFunctions", "to": "decoder_compute.walk", "type": "internal", "line": 221}, {"from": "decoder_compute.walk", "to": "decoder_compute.walk", "type": "internal", "line": 296}, {"from": "decoder_compute.walk", "to": "decoder_compute.walk", "type": "internal", "line": 299}, {"from": "decoder_compute._findSideEffects", "to": "decoder_compute.walk", "type": "internal", "line": 302}, {"from": "decoder_compute.walkBody", "to": "decoder_compute.addNode", "type": "internal", "line": 337}, {"from": "decoder_compute.walkBody", "to": "decoder_compute.addEdge", "type": "internal", "line": 339}, {"from": "decoder_compute.walkBody", "to": "decoder_compute.walkBody", "type": "internal", "line": 343}, {"from": "decoder_compute.walkBody", "to": "decoder_compute.walkBody", "type": "internal", "line": 347}, {"from": "decoder_compute.walkBody", "to": "decoder_compute.addNode", "type": "internal", "line": 348}, {"from": "decoder_compute.walkBody", "to": "decoder_compute.addEdge", "type": "internal", "line": 350}, {"from": "decoder_compute.walkBody", "to": "decoder_compute.addEdge", "type": "internal", "line": 352}, {"from": "decoder_compute.walkBody", "to": "decoder_compute.addNode", "type": "internal", "line": 359}, {"from": "decoder_compute.walkBody", "to": "decoder_compute.addEdge", "type": "internal", "line": 361}, {"from": "decoder_compute.walkBody", "to": "decoder_compute.walkBody", "type": "internal", "line": 363}, {"from": "decoder_compute.walkBody", "to": "decoder_compute.addEdge", "type": "internal", "line": 365}, {"from": "decoder_compute.walkBody", "to": "decoder_compute.addNode", "type": "internal", "line": 370}, {"from": "decoder_compute.walkBody", "to": "decoder_compute.addEdge", "type": "internal", "line": 372}, {"from": "decoder_compute.walkBody", "to": "decoder_compute.walkBody", "type": "internal", "line": 374}, {"from": "decoder_compute.walkBody", "to": "decoder_compute.addEdge", "type": "internal", "line": 376}, {"from": "decoder_compute.walkBody", "to": "decoder_compute.addNode", "type": "internal", "line": 380}, {"from": "decoder_compute.walkBody", "to": "decoder_compute.addEdge", "type": "internal", "line": 382}, {"from": "decoder_compute.walkBody", "to": "decoder_compute.walkBody", "type": "internal", "line": 385}, {"from": "decoder_compute.walkBody", "to": "decoder_compute.addNode", "type": "internal", "line": 390}, {"from": "decoder_compute.walkBody", "to": "decoder_compute.addEdge", "type": "internal", "line": 391}, {"from": "decoder_compute.walkBody", "to": "decoder_compute.walkBody", "type": "internal", "line": 392}, {"from": "decoder_compute.walkBody", "to": "decoder_compute.addNode", "type": "internal", "line": 397}, {"from": "decoder_compute.walkBody", "to": "decoder_compute.addEdge", "type": "internal", "line": 399}, {"from": "decoder_compute.walkBody", "to": "decoder_compute.addEdge", "type": "internal", "line": 401}, {"from": "decoder_compute.walkBody", "to": "decoder_compute.walkBody", "type": "internal", "line": 402}, {"from": "decoder_compute.walkBody", "to": "decoder_compute.addNode", "type": "internal", "line": 407}, {"from": "decoder_compute.walkBody", "to": "decoder_compute.addEdge", "type": "internal", "line": 409}, {"from": "decoder_compute.walkBody", "to": "decoder_compute.addNode", "type": "internal", "line": 414}, {"from": "decoder_compute.walkBody", "to": "decoder_compute.addEdge", "type": "internal", "line": 416}, {"from": "decoder_compute.analyzeControlFlow", "to": "decoder_compute.addNode", "type": "internal", "line": 424}, {"from": "decoder_compute.analyzeControlFlow", "to": "decoder_compute.walkBody", "type": "internal", "line": 429}, {"from": "decoder_compute.inferStates", "to": "decoder_compute.to_state_name", "type": "internal", "line": 639}, {"from": "decoder_compute.parseAst", "to": "ast", "type": "external", "category": "stdlib", "line": 97}, {"from": "decoder_compute._astToDict", "to": "ast", "type": "external", "category": "stdlib", "line": 108}, {"from": "decoder_compute.generateBlueprint", "to": "os", "type": "external", "category": "stdlib", "line": 846}, {"from": "decoder_compute.generateBlueprint", "to": "json", "type": "external", "category": "stdlib", "line": 927}, {"from": "scraper_compute._httpGet", "to": "requests", "type": "external", "category": "pip", "line": 31}, {"from": "scraper_compute.arxiv", "to": "xml", "type": "external", "category": "stdlib", "line": 61}, {"from": "scraper_compute.arxiv", "to": "re", "type": "external", "category": "stdlib", "line": 81}, {"from": "scraper_compute.semanticScholar", "to": "json", "type": "external", "category": "stdlib", "line": 129}, {"from": "scraper_compute.web", "to": "bs4", "type": "external", "category": "pip", "line": 178}, {"from": "scraper_compute.web", "to": "re", "type": "external", "category": "stdlib", "line": 190}, {"from": "scraper_compute.fetchDetail", "to": "xml", "type": "external", "category": "stdlib", "line": 229}, {"from": "scraper_compute.fetchDetail", "to": "json", "type": "external", "category": "stdlib", "line": 284}, {"from": "migrator_compute.dry_run", "to": "migrator_compute.analyze_changes", "type": "internal", "line": 667}, {"from": "migrator_compute.dry_run", "to": "migrator_compute.apply_migration", "type": "internal", "line": 671}, {"from": "migrator_compute.batch_migrate", "to": "migrator_compute.load_blueprint", "type": "internal", "line": 919}, {"from": "migrator_compute.batch_migrate", "to": "migrator_compute.detect_version", "type": "internal", "line": 929}, {"from": "migrator_compute.batch_migrate", "to": "migrator_compute.list_migrations", "type": "internal", "line": 939}, {"from": "migrator_compute.batch_migrate", "to": "migrator_compute.plan_migration", "type": "internal", "line": 940}, {"from": "migrator_compute.batch_migrate", "to": "migrator_compute.apply_migration", "type": "internal", "line": 953}, {"from": "migrator_compute.batch_migrate", "to": "migrator_compute.validate_blueprint", "type": "internal", "line": 965}, {"from": "migrator_compute.batch_migrate", "to": "migrator_compute.export_migrated", "type": "internal", "line": 986}, {"from": "migrator_compute", "to": "pathlib", "type": "external", "category": "stdlib", "line": 24}, {"from": "migrator_compute.load_blueprint", "to": "pathlib", "type": "external", "category": "stdlib", "line": 122}, {"from": "migrator_compute.load_blueprint", "to": "json", "type": "external", "category": "stdlib", "line": 128}, {"from": "migrator_compute.list_migrations", "to": "json", "type": "external", "category": "stdlib", "line": 222}, {"from": "migrator_compute.analyze_changes", "to": "copy", "type": "external", "category": "stdlib", "line": 284}, {"from": "migrator_compute._get_migration_definition", "to": "json", "type": "external", "category": "stdlib", "line": 316}, {"from": "migrator_compute.apply_migration", "to": "copy", "type": "external", "category": "stdlib", "line": 461}, {"from": "migrator_compute._apply_changes", "to": "copy", "type": "external", "category": "stdlib", "line": 485}, {"from": "migrator_compute._apply_add_field", "to": "copy", "type": "external", "category": "stdlib", "line": 551}, {"from": "migrator_compute._apply_add_field", "to": "copy", "type": "external", "category": "stdlib", "line": 553}, {"from": "migrator_compute._apply_transform", "to": "re", "type": "external", "category": "stdlib", "line": 653}, {"from": "migrator_compute.export_migrated", "to": "pathlib", "type": "external", "category": "stdlib", "line": 893}, {"from": "migrator_compute.export_migrated", "to": "json", "type": "external", "category": "stdlib", "line": 897}, {"from": "migrator_compute.batch_migrate", "to": "shutil", "type": "external", "category": "stdlib", "line": 982}, {"from": "scholar_compute", "to": "sys", "type": "external", "category": "stdlib", "line": 13}, {"from": "scholar_compute", "to": "sys", "type": "external", "category": "stdlib", "line": 14}, {"from": "scholar_compute.initConfig", "to": "os", "type": "external", "category": "stdlib", "line": 30}, {"from": "scholar_compute.initConfig", "to": "os", "type": "external", "category": "stdlib", "line": 31}, {"from": "scholar_compute.initConfig", "to": "os", "type": "external", "category": "stdlib", "line": 32}, {"from": "scholar_compute.searchAll", "to": "scraper_compute", "type": "external", "category": "pip", "line": 58}, {"from": "scholar_compute.searchAll", "to": "scraper_compute", "type": "external", "category": "pip", "line": 60}, {"from": "scholar_compute.fetchDetails", "to": "scraper_compute", "type": "external", "category": "pip", "line": 101}, {"from": "scholar_compute._callLlm", "to": "json", "type": "external", "category": "stdlib", "line": 291}, {"from": "scholar_compute._callLlm", "to": "json", "type": "external", "category": "stdlib", "line": 297}, {"from": "scholar_compute._callLlmMessages", "to": "json", "type": "external", "category": "stdlib", "line": 321}, {"from": "scholar_compute._callLlmMessages", "to": "json", "type": "external", "category": "stdlib", "line": 327}, {"from": "skill_contractor_compute.write_output", "to": "skill_contractor_compute.sanitize_python_code", "type": "internal", "line": 994}, {"from": "skill_contractor_compute._getRunDir", "to": "pathlib", "type": "external", "category": "stdlib", "line": 45}, {"from": "skill_contractor_compute._getRunDir", "to": "datetime", "type": "external", "category": "stdlib", "line": 52}, {"from": "skill_contractor_compute._logStep", "to": "datetime", "type": "external", "category": "stdlib", "line": 62}, {"from": "skill_contractor_compute._logRun", "to": "datetime", "type": "external", "category": "stdlib", "line": 90}, {"from": "skill_contractor_compute._condenseForEval", "to": "pathlib", "type": "external", "category": "stdlib", "line": 148}, {"from": "skill_contractor_compute._extractJson", "to": "json", "type": "external", "category": "stdlib", "line": 198}, {"from": "skill_contractor_compute._extractJson", "to": "json", "type": "external", "category": "stdlib", "line": 205}, {"from": "skill_contractor_compute._extractJson", "to": "re", "type": "external", "category": "stdlib", "line": 213}, {"from": "skill_contractor_compute._extractJson", "to": "re", "type": "external", "category": "stdlib", "line": 214}, {"from": "skill_contractor_compute._extractJson", "to": "json", "type": "external", "category": "stdlib", "line": 216}, {"from": "skill_contractor_compute._extractJson", "to": "json", "type": "external", "category": "stdlib", "line": 221}, {"from": "skill_contractor_compute._callLlm", "to": "openai", "type": "external", "category": "pip", "line": 236}, {"from": "skill_contractor_compute._findLppRoot", "to": "os", "type": "external", "category": "stdlib", "line": 248}, {"from": "skill_contractor_compute._findLppRoot", "to": "pathlib", "type": "external", "category": "stdlib", "line": 251}, {"from": "skill_contractor_compute._findLppRoot", "to": "os", "type": "external", "category": "stdlib", "line": 251}, {"from": "skill_contractor_compute.init", "to": "os", "type": "external", "category": "stdlib", "line": 546}, {"from": "skill_contractor_compute.init", "to": "os", "type": "external", "category": "stdlib", "line": 546}, {"from": "skill_contractor_compute.init", "to": "os", "type": "external", "category": "stdlib", "line": 558}, {"from": "skill_contractor_compute.init", "to": "os", "type": "external", "category": "stdlib", "line": 559}, {"from": "skill_contractor_compute.init", "to": "os", "type": "external", "category": "stdlib", "line": 560}, {"from": "skill_contractor_compute.init", "to": "os", "type": "external", "category": "stdlib", "line": 567}, {"from": "skill_contractor_compute.init", "to": "os", "type": "external", "category": "stdlib", "line": 568}, {"from": "skill_contractor_compute.init", "to": "os", "type": "external", "category": "stdlib", "line": 569}, {"from": "skill_contractor_compute.init", "to": "os", "type": "external", "category": "stdlib", "line": 570}, {"from": "skill_contractor_compute.detect_lpp_target", "to": "pathlib", "type": "external", "category": "stdlib", "line": 596}, {"from": "skill_contractor_compute.decompose", "to": "pathlib", "type": "external", "category": "stdlib", "line": 615}, {"from": "skill_contractor_compute.generate_step_output", "to": "pathlib", "type": "external", "category": "stdlib", "line": 707}, {"from": "skill_contractor_compute.parse_and_sanitize", "to": "pathlib", "type": "external", "category": "stdlib", "line": 851}, {"from": "skill_contractor_compute.parse_and_sanitize", "to": "json", "type": "external", "category": "stdlib", "line": 884}, {"from": "skill_contractor_compute.write_output", "to": "pathlib", "type": "external", "category": "stdlib", "line": 944}, {"from": "skill_contractor_compute.write_output", "to": "json", "type": "external", "category": "stdlib", "line": 971}, {"from": "skill_contractor_compute.write_output", "to": "frame_py", "type": "external", "category": "pip", "line": 994}, {"from": "skill_contractor_compute.write_output", "to": "subprocess", "type": "external", "category": "stdlib", "line": 1010}, {"from": "skill_contractor_compute.write_output", "to": "json", "type": "external", "category": "stdlib", "line": 1032}, {"from": "skill_contractor_compute.advance_step", "to": "pathlib", "type": "external", "category": "stdlib", "line": 1048}, {"from": "skill_contractor_compute.validate_lpp", "to": "pathlib", "type": "external", "category": "stdlib", "line": 1060}, {"from": "skill_contractor_compute.validate_lpp", "to": "pathlib", "type": "external", "category": "stdlib", "line": 1072}, {"from": "skill_contractor_compute.validate_lpp", "to": "pathlib", "type": "external", "category": "stdlib", "line": 1080}, {"from": "skill_contractor_compute.validate_lpp", "to": "pathlib", "type": "external", "category": "stdlib", "line": 1081}, {"from": "skill_contractor_compute.validate_lpp", "to": "pathlib", "type": "external", "category": "stdlib", "line": 1091}, {"from": "skill_contractor_compute.validate_lpp", "to": "subprocess", "type": "external", "category": "stdlib", "line": 1095}, {"from": "skill_contractor_compute.advance_phase", "to": "pathlib", "type": "external", "category": "stdlib", "line": 1140}, {"from": "skill_contractor_compute.evaluate", "to": "pathlib", "type": "external", "category": "stdlib", "line": 1166}, {"from": "skill_contractor_compute.evaluate", "to": "json", "type": "external", "category": "stdlib", "line": 1183}, {"from": "skill_contractor_compute.capture_error", "to": "pathlib", "type": "external", "category": "stdlib", "line": 1237}, {"from": "skill_contractor_compute.capture_step_error", "to": "pathlib", "type": "external", "category": "stdlib", "line": 1253}, {"from": "skill_contractor_compute.capture_parse_error", "to": "pathlib", "type": "external", "category": "stdlib", "line": 1269}, {"from": "skill_contractor_compute.review_failed_step", "to": "pathlib", "type": "external", "category": "stdlib", "line": 1303}, {"from": "skill_contractor_compute.review_failed_step", "to": "json", "type": "external", "category": "stdlib", "line": 1318}, {"from": "skill_contractor_compute.skip_step", "to": "pathlib", "type": "external", "category": "stdlib", "line": 1359}, {"from": "skill_contractor_compute.save_state", "to": "pathlib", "type": "external", "category": "stdlib", "line": 1373}, {"from": "skill_contractor_compute.save_state", "to": "json", "type": "external", "category": "stdlib", "line": 1394}, {"from": "skill_contractor_compute.load_state", "to": "pathlib", "type": "external", "category": "stdlib", "line": 1402}, {"from": "skill_contractor_compute.load_state", "to": "json", "type": "external", "category": "stdlib", "line": 1407}, {"from": "skill_contractor_compute.clear_state", "to": "pathlib", "type": "external", "category": "stdlib", "line": 1416}, {"from": "skill_contractor_compute.log_corrections", "to": "pathlib", "type": "external", "category": "stdlib", "line": 1426}, {"from": "skill_contractor_compute.evaluate_interactive", "to": "pathlib", "type": "external", "category": "stdlib", "line": 1457}, {"from": "skill_contractor_compute.evaluate_interactive", "to": "sys", "type": "external", "category": "stdlib", "line": 1479}, {"from": "skill_contractor_compute.evaluate_interactive", "to": "os", "type": "external", "category": "stdlib", "line": 1479}, {"from": "skill_contractor_compute.evaluate_interactive", "to": "frame_py", "type": "external", "category": "pip", "line": 1491}, {"from": "skill_contractor_compute.decompose", "to": "prompts", "type": "local", "line": 653}, {"from": "skill_contractor_compute.generate_step_output", "to": "prompts", "type": "local", "line": 804}, {"from": "skill_contractor_compute.evaluate", "to": "prompts", "type": "local", "line": 1175}, {"from": "skill_contractor_compute.review_failed_step", "to": "prompts", "type": "local", "line": 1312}, {"from": "registry_compute.export", "to": "registry_compute.loadDetail", "type": "internal", "line": 199}, {"from": "registry_compute.scan", "to": "pathlib", "type": "external", "category": "stdlib", "line": 24}, {"from": "registry_compute.scan", "to": "json", "type": "external", "category": "stdlib", "line": 37}, {"from": "registry_compute.loadDetail", "to": "pathlib", "type": "external", "category": "stdlib", "line": 73}, {"from": "registry_compute.loadDetail", "to": "json", "type": "external", "category": "stdlib", "line": 80}, {"from": "registry_compute.loadDetail", "to": "json", "type": "external", "category": "stdlib", "line": 91}, {"from": "registry_compute.loadDetail", "to": "json", "type": "external", "category": "stdlib", "line": 101}, {"from": "registry_compute.loadDetail", "to": "re", "type": "external", "category": "stdlib", "line": 127}, {"from": "orchestrator_compute._llm", "to": "openai", "type": "external", "category": "pip", "line": 36}, {"from": "orchestrator_compute._json", "to": "json", "type": "external", "category": "stdlib", "line": 56}, {"from": "orchestrator_compute.init", "to": "os", "type": "external", "category": "stdlib", "line": 66}, {"from": "orchestrator_compute.init", "to": "os", "type": "external", "category": "stdlib", "line": 67}, {"from": "orchestrator_compute.init", "to": "os", "type": "external", "category": "stdlib", "line": 71}, {"from": "orchestrator_compute.init", "to": "os", "type": "external", "category": "stdlib", "line": 72}, {"from": "orchestrator_compute.init", "to": "os", "type": "external", "category": "stdlib", "line": 73}, {"from": "orchestrator_compute.init", "to": "os", "type": "external", "category": "stdlib", "line": 75}, {"from": "orchestrator_compute.init", "to": "os", "type": "external", "category": "stdlib", "line": 75}, {"from": "orchestrator_compute.build", "to": "pathlib", "type": "external", "category": "stdlib", "line": 387}, {"from": "orchestrator_compute.build", "to": "json", "type": "external", "category": "stdlib", "line": 390}, {"from": "orchestrator_compute.exec_leaf", "to": "json", "type": "external", "category": "stdlib", "line": 434}, {"from": "orchestrator_compute.exec_leaf", "to": "logging", "type": "external", "category": "stdlib", "line": 449}, {"from": "orchestrator_compute.reflect", "to": "json", "type": "external", "category": "stdlib", "line": 523}, {"from": "test_compute.load_blueprint", "to": "pathlib", "type": "external", "category": "stdlib", "line": 29}, {"from": "test_compute.load_blueprint", "to": "json", "type": "external", "category": "stdlib", "line": 35}, {"from": "test_compute.load_blueprint", "to": "frame_py", "type": "external", "category": "pip", "line": 37}, {"from": "test_compute._bfsPath", "to": "collections", "type": "external", "category": "stdlib", "line": 236}, {"from": "test_compute._extractBoundaries", "to": "re", "type": "external", "category": "stdlib", "line": 307}, {"from": "test_compute._extractBooleans", "to": "re", "type": "external", "category": "stdlib", "line": 347}, {"from": "test_compute._extractNullChecks", "to": "re", "type": "external", "category": "stdlib", "line": 370}, {"from": "test_compute._extractVariables", "to": "re", "type": "external", "category": "stdlib", "line": 386}, {"from": "test_compute.format_json", "to": "json", "type": "external", "category": "stdlib", "line": 819}, {"from": "test_compute._toPythonName", "to": "re", "type": "external", "category": "stdlib", "line": 909}, {"from": "test_compute.export_tests", "to": "pathlib", "type": "external", "category": "stdlib", "line": 926}, {"from": "seal_compute.generateTla", "to": "seal_compute.tlaStr", "type": "internal", "line": 227}, {"from": "seal_compute.generateTla", "to": "seal_compute.tlaStr", "type": "internal", "line": 228}, {"from": "seal_compute.generateTla", "to": "seal_compute.tlaStr", "type": "internal", "line": 229}, {"from": "seal_compute.loadBlueprint", "to": "json", "type": "external", "category": "stdlib", "line": 21}, {"from": "seal_compute.generateTla", "to": "pathlib", "type": "external", "category": "stdlib", "line": 347}, {"from": "seal_compute.runTlc", "to": "pathlib", "type": "external", "category": "stdlib", "line": 393}, {"from": "seal_compute.runTlc", "to": "pathlib", "type": "external", "category": "stdlib", "line": 394}, {"from": "seal_compute.runTlc", "to": "subprocess", "type": "external", "category": "stdlib", "line": 396}, {"from": "seal_compute.runTlaps", "to": "subprocess", "type": "external", "category": "stdlib", "line": 467}, {"from": "seal_compute.generateCertificate", "to": "json", "type": "external", "category": "stdlib", "line": 518}, {"from": "seal_compute.generateCertificate", "to": "hashlib", "type": "external", "category": "stdlib", "line": 519}, {"from": "seal_compute.generateCertificate", "to": "datetime", "type": "external", "category": "stdlib", "line": 535}, {"from": "viz_compute.load_blueprint", "to": "pathlib", "type": "external", "category": "stdlib", "line": 23}, {"from": "viz_compute.load_blueprint", "to": "json", "type": "external", "category": "stdlib", "line": 28}, {"from": "viz_compute.load_blueprint", "to": "frame_py", "type": "external", "category": "pip", "line": 30}, {"from": "viz_compute.load_tree", "to": "pathlib", "type": "external", "category": "stdlib", "line": 221}, {"from": "viz_compute.load_tree", "to": "json", "type": "external", "category": "stdlib", "line": 226}, {"from": "viz_compute.render_table", "to": "readme_compute", "type": "local", "line": 165}, {"from": "viz_compute.render_table", "to": "readme_compute", "type": "local", "line": 166}, {"from": "viz_compute.render_table", "to": "readme_compute", "type": "local", "line": 167}, {"from": "viz_compute.render_table", "to": "readme_compute", "type": "local", "line": 168}, {"from": "viz_compute.render_mermaid", "to": "readme_compute", "type": "local", "line": 181}, {"from": "viz_compute.render_tree", "to": "readme_compute", "type": "local", "line": 191}, {"from": "viz_compute.render_tree_mermaid", "to": "readme_compute", "type": "local", "line": 205}];
const moduleColors = {"composer_compute": "#00d4ff", "debugger_compute": "#ff6b6b", "differ_compute": "#4ecdc4", "linter_compute": "#f39c12", "playground_compute": "#9b59b6", "registry_compute": "#ff6b6b", "compliance_compute": "#e74c3c", "coverage_compute": "#3498db", "dashboard_compute": "#2ecc71", "doc_compute": "#e67e22", "simulator_compute": "#00d4ff", "tracer_compute": "#ff6b6b", "function_decoder_compute": "#4ecdc4", "graph_visualizer_compute": "#f39c12", "extractor_compute": "#9b59b6", "llm_compute": "#1abc9c", "decoder_compute": "#e74c3c", "scraper_compute": "#3498db", "migrator_compute": "#2ecc71", "scholar_compute": "#e67e22", "skill_contractor_compute": "#00d4ff", "orchestrator_compute": "#4ecdc4", "test_compute": "#f39c12", "seal_compute": "#9b59b6", "viz_compute": "#1abc9c"};

// Edge type visibility
const edgeVisibility = { internal: true, external: true, local: true };
let currentLayout = 'force';

// Create node lookup
const nodeById = {};
nodes.forEach(n => nodeById[n.id] = n);

// Setup SVG
const container = document.getElementById('graph');
const width = container.clientWidth;
const height = container.clientHeight || 600;

const svg = d3.select("svg").attr("viewBox", [0, 0, width, height]);
const g = svg.append("g");

// Zoom behavior
const zoom = d3.zoom()
    .scaleExtent([0.1, 4])
    .filter(e => !e.target.closest('.node'))
    .on("zoom", e => g.attr("transform", e.transform));
svg.call(zoom);

// Arrow markers
const defs = svg.append("defs");
["internal", "external", "local"].forEach(type => {
    const color = type === "internal" ? "#4ecdc4" : type === "external" ? "#f39c12" : "#9b59b6";
    defs.append("marker")
        .attr("id", `arrow-${type}`)
        .attr("viewBox", "0 -5 10 10")
        .attr("refX", 20)
        .attr("refY", 0)
        .attr("markerWidth", 6)
        .attr("markerHeight", 6)
        .attr("orient", "auto")
        .append("path")
        .attr("d", "M0,-4L10,0L0,4")
        .attr("fill", color);
});

// Build module legend
const legendDiv = document.getElementById('module-legend');
Object.entries(moduleColors).forEach(([mod, color]) => {
    const item = document.createElement('div');
    item.className = 'module-item';
    item.innerHTML = `<div class="module-dot" style="background:${color}"></div><span class="module-name">${mod}</span>`;
    item.onclick = () => highlightModule(mod);
    legendDiv.appendChild(item);
});

// Process edges - resolve node references
const processedEdges = edges.map(e => ({
    ...e,
    source: nodeById[e.from] || { id: e.from, x: 0, y: 0 },
    target: nodeById[e.to] || { id: e.to, x: 0, y: 0 }
})).filter(e => e.source && e.target);

// Force simulation
const simulation = d3.forceSimulation(nodes)
    .force("link", d3.forceLink(processedEdges).id(d => d.id).distance(80).strength(0.5))
    .force("charge", d3.forceManyBody().strength(-300))
    .force("center", d3.forceCenter(width / 2, height / 2))
    .force("collision", d3.forceCollide().radius(40));

// Draw edges
const edge = g.append("g").selectAll("path")
    .data(processedEdges)
    .join("path")
    .attr("class", d => `edge edge-${d.type || 'internal'}`)
    .attr("marker-end", d => `url(#arrow-${d.type || 'internal'})`);

// Node size based on type
function nodeSize(d) {
    if (d.type === 'module') return { w: 120, h: 40 };
    if (d.type === 'function' || d.type === 'async_function') return { w: 100, h: 30 };
    if (d.type === 'class') return { w: 110, h: 35 };
    return { w: 80, h: 25 };  // dependency
}

// Draw nodes
const node = g.append("g").selectAll("g")
    .data(nodes)
    .join("g")
    .attr("class", "node")
    .call(d3.drag()
        .on("start", dragStart)
        .on("drag", dragging)
        .on("end", dragEnd));

node.append("rect")
    .attr("class", d => `node-${d.type === 'dependency' ? 'dependency' : d.type === 'module' ? 'module' : 'function'}`)
    .attr("width", d => nodeSize(d).w)
    .attr("height", d => nodeSize(d).h)
    .attr("x", d => -nodeSize(d).w / 2)
    .attr("y", d => -nodeSize(d).h / 2)
    .attr("rx", 6)
    .attr("stroke", d => d.moduleColor || "#666");

node.append("text")
    .attr("class", "node-label")
    .attr("text-anchor", "middle")
    .attr("dy", d => d.signature ? -3 : 4)
    .text(d => d.label || d.id);

node.filter(d => d.signature).append("text")
    .attr("class", "node-sublabel")
    .attr("text-anchor", "middle")
    .attr("dy", 10)
    .text(d => d.signature.length > 20 ? d.signature.slice(0, 18) + ".." : d.signature);

// Tooltip
const tooltip = d3.select("#tooltip");
node.on("mouseover", (e, d) => {
    let html = `<b>${d.label || d.id}</b>`;
    if (d.type) html += `<br><span style="color:#888">${d.type}</span>`;
    if (d.signature) html += `<br><code>${d.signature}</code>`;
    if (d.direction) html += `<br>Direction: ${d.direction}`;
    tooltip.style("display", "block").html(html);
})
.on("mousemove", e => {
    tooltip.style("left", (e.pageX + 15) + "px").style("top", (e.pageY - 10) + "px");
})
.on("mouseout", () => tooltip.style("display", "none"));

// Click to select
node.on("click", (e, d) => {
    e.stopPropagation();
    selectNode(d);
});

svg.on("click", () => clearSelection());

// Update positions
simulation.on("tick", () => {
    edge.attr("d", d => {
        if (!d.source || !d.target) return "";
        const dx = d.target.x - d.source.x;
        const dy = d.target.y - d.source.y;
        const dr = Math.sqrt(dx * dx + dy * dy) * 1.5;
        return `M${d.source.x},${d.source.y}A${dr},${dr} 0 0,1 ${d.target.x},${d.target.y}`;
    });
    node.attr("transform", d => `translate(${d.x},${d.y})`);
});

// Drag functions
function dragStart(e, d) {
    if (!e.active) simulation.alphaTarget(0.3).restart();
    d.fx = d.x;
    d.fy = d.y;
}
function dragging(e, d) {
    d.fx = e.x;
    d.fy = e.y;
}
function dragEnd(e, d) {
    if (!e.active) simulation.alphaTarget(0);
    d.fx = null;
    d.fy = null;
}

// Selection functions
let selectedNode = null;

function selectNode(d) {
    selectedNode = d;
    
    // Highlight node
    node.classed("dim", n => n.id !== d.id && !isConnected(d, n));
    node.select("rect").attr("stroke-width", n => n.id === d.id ? 4 : 2);
    
    // Highlight edges
    edge.classed("dim", e => e.source.id !== d.id && e.target.id !== d.id);
    edge.classed("highlight", e => e.source.id === d.id || e.target.id === d.id);
    
    // Update info panel
    updateNodeInfo(d);
    updateEdgeList(d);
}

function clearSelection() {
    selectedNode = null;
    node.classed("dim", false);
    node.select("rect").attr("stroke-width", 2);
    edge.classed("dim", false).classed("highlight", false);
    document.getElementById('node-info').innerHTML = 'Click a node to see details';
    document.getElementById('edge-list').innerHTML = '';
}

function isConnected(a, b) {
    return processedEdges.some(e => 
        (e.source.id === a.id && e.target.id === b.id) ||
        (e.source.id === b.id && e.target.id === a.id)
    );
}

function updateNodeInfo(d) {
    let html = `<div class="metric"><span class="info-label">ID:</span><span class="info-value">${d.id}</span></div>`;
    html += `<div class="metric"><span class="info-label">Type:</span><span class="info-value">${d.type}</span></div>`;
    if (d.moduleName) html += `<div class="metric"><span class="info-label">Module:</span><span class="info-value">${d.moduleName}</span></div>`;
    if (d.line) html += `<div class="metric"><span class="info-label">Line:</span><span class="info-value">${d.line}${d.endLine ? '-' + d.endLine : ''}</span></div>`;
    if (d.signature) html += `<div class="metric"><span class="info-label">Signature:</span><span class="info-value" style="font-family:monospace">${d.signature}</span></div>`;
    if (d.direction) html += `<div class="metric"><span class="info-label">Direction:</span><span class="info-value">${d.direction}</span></div>`;
    if (d.category) html += `<div class="metric"><span class="info-label">Category:</span><span class="info-value">${d.category}</span></div>`;

    if (d.metrics) {
        html += `<div style="margin-top:10px"><b>Coupling Metrics</b></div>`;
        html += `<div class="metric"><span class="info-label">Fan-In:</span><span class="info-value">${d.metrics.fanIn}</span></div>`;
        html += `<div class="metric"><span class="info-label">Fan-Out:</span><span class="info-value">${d.metrics.fanOut}</span></div>`;
        html += `<div class="metric"><span class="info-label">Instability:</span><span class="info-value">${(d.metrics.instability * 100).toFixed(1)}%</span></div>`;
        html += `<div class="metric-bar"><div class="metric-fill" style="width:${d.metrics.instability * 100}%;background:${d.metrics.instability > 0.5 ? '#ff6b6b' : '#4ecdc4'}"></div></div>`;
        html += `<div class="metric"><span class="info-label">Internal Edges:</span><span class="info-value">${d.metrics.internalEdges}</span></div>`;
    }

    document.getElementById('node-info').innerHTML = html;

    // Update source code panel
    updateSourcePanel(d);
}

function escapeHtml(str) {
    if (!str) return '';
    return str.replace(/&/g, '&amp;').replace(/</g, '&lt;').replace(/>/g, '&gt;');
}

function updateSourcePanel(d) {
    const panel = document.getElementById('source-content');

    if (d.source) {
        let sourceHtml = '';
        if (d.docstring) {
            sourceHtml += `<div class="docstring" style="margin-bottom:8px;padding:5px;background:#1a1a2a;border-radius:3px">${escapeHtml(d.docstring)}</div>`;
        }
        sourceHtml += `<div class="source-code">${escapeHtml(d.source)}</div>`;
        panel.innerHTML = sourceHtml;
    } else if (d.type === 'module') {
        panel.innerHTML = `<div style="color:#888;font-size:11px">Module: ${d.label}<br>Click a function to view its source code.</div>`;
    } else if (d.type === 'dependency') {
        panel.innerHTML = `<div style="color:#888;font-size:11px">External dependency: ${d.label}<br>Category: ${d.category || 'unknown'}</div>`;
    } else {
        panel.innerHTML = `<div style="color:#666;font-size:11px">No source available for this node</div>`;
    }
}

function updateEdgeList(d) {
    const outgoing = processedEdges.filter(e => e.source.id === d.id);
    const incoming = processedEdges.filter(e => e.target.id === d.id);
    
    let html = '';
    if (outgoing.length) {
        html += '<div style="color:#4ecdc4;font-weight:bold;margin-bottom:5px">Outgoing →</div>';
        outgoing.forEach(e => {
            html += `<div class="edge-item">→ <span class="to">${e.target.id || e.to}</span> <span class="type">[${e.type}]</span></div>`;
        });
    }
    if (incoming.length) {
        html += '<div style="color:#f39c12;font-weight:bold;margin:10px 0 5px 0">← Incoming</div>';
        incoming.forEach(e => {
            html += `<div class="edge-item">← <span class="from">${e.source.id || e.from}</span> <span class="type">[${e.type}]</span></div>`;
        });
    }
    if (!outgoing.length && !incoming.length) {
        html = '<div style="color:#666">No connections</div>';
    }
    
    document.getElementById('edge-list').innerHTML = html;
}

function highlightModule(modName) {
    node.classed("dim", n => n.moduleName !== modName && n.type !== 'dependency');
    edge.classed("dim", e => {
        const srcMod = nodeById[e.source.id]?.moduleName;
        const tgtMod = nodeById[e.target.id]?.moduleName;
        return srcMod !== modName && tgtMod !== modName;
    });
}

// Layout functions
function toggleLayout(layout) {
    currentLayout = layout;
    document.querySelectorAll('.controls button').forEach(b => {
        if (b.id.startsWith('btn-') && ['force', 'horizontal', 'vertical'].includes(b.id.replace('btn-', ''))) {
            b.classList.toggle('active', b.id === `btn-${layout}`);
        }
    });
    
    if (layout === 'force') {
        simulation.alpha(1).restart();
    } else {
        simulation.stop();
        layoutNodes(layout);
    }
}

function layoutNodes(layout) {
    const modules = [...new Set(nodes.filter(n => n.type === 'module').map(n => n.id))];
    const padding = 50;
    
    if (layout === 'horizontal') {
        // Group by module, spread horizontally
        modules.forEach((mod, mi) => {
            const modNodes = nodes.filter(n => n.moduleName === mod || n.id === mod);
            const x = padding + mi * (width - padding * 2) / Math.max(modules.length - 1, 1);
            modNodes.forEach((n, ni) => {
                n.x = x;
                n.y = padding + ni * 50;
            });
        });
        // Dependencies on the right
        const deps = nodes.filter(n => n.type === 'dependency');
        deps.forEach((n, i) => {
            n.x = width - padding;
            n.y = padding + i * 40;
        });
    } else if (layout === 'vertical') {
        // Modules at top, functions below, dependencies at bottom
        const modNodes = nodes.filter(n => n.type === 'module');
        const funcNodes = nodes.filter(n => n.type === 'function' || n.type === 'async_function' || n.type === 'class');
        const depNodes = nodes.filter(n => n.type === 'dependency');
        
        modNodes.forEach((n, i) => {
            n.x = padding + i * 150;
            n.y = padding;
        });
        funcNodes.forEach((n, i) => {
            n.x = padding + (i % 6) * 130;
            n.y = 120 + Math.floor(i / 6) * 60;
        });
        depNodes.forEach((n, i) => {
            n.x = padding + (i % 8) * 100;
            n.y = height - padding - 50;
        });
    }
    
    // Update positions
    node.transition().duration(500).attr("transform", d => `translate(${d.x},${d.y})`);
    edge.transition().duration(500).attr("d", d => {
        if (!d.source || !d.target) return "";
        const dx = d.target.x - d.source.x;
        const dy = d.target.y - d.source.y;
        const dr = Math.sqrt(dx * dx + dy * dy) * 1.5;
        return `M${d.source.x},${d.source.y}A${dr},${dr} 0 0,1 ${d.target.x},${d.target.y}`;
    });
}

// Edge type toggle
function toggleEdgeType(type) {
    edgeVisibility[type] = !edgeVisibility[type];
    document.getElementById(`btn-${type}`).classList.toggle('active', edgeVisibility[type]);
    edge.style("display", d => edgeVisibility[d.type || 'internal'] ? null : "none");
}

// View controls
function resetView() {
    svg.transition().duration(500).call(zoom.transform, d3.zoomIdentity);
}

function fitToView() {
    const bounds = g.node().getBBox();
    const scale = Math.min(width / bounds.width, height / bounds.height) * 0.9;
    const tx = (width - bounds.width * scale) / 2 - bounds.x * scale;
    const ty = (height - bounds.height * scale) / 2 - bounds.y * scale;
    svg.transition().duration(500).call(zoom.transform, d3.zoomIdentity.translate(tx, ty).scale(scale));
}

// Initial fit
setTimeout(fitToView, 1000);
</script>
</body>
</html>