"""
CLI module for L++ LLM Schema Assistant.
Separated from interactive.py per build_rules.md (keep extrusion minimal).
"""

from pathlib import Path
from typing import Any

from .llm_compute import (
    init_config, load_schema, load_blueprint,
    query, explain_blueprint, validate_blueprint,
    suggest_improvements, generate_blueprint
)

ICONS = {"init": "âš™ï¸", "ready": "âœ…", "querying": "ğŸ”„", "error": "âŒ"}


def print_help():
    print("""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  L++ LLM Schema Assistant                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  help              Show this help                                   â”‚
â”‚  status            Show configuration                               â”‚
â”‚  quit/q            Exit                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  key <api_key>     Set API key                                      â”‚
â”‚  base <url>        Set API base URL                                 â”‚
â”‚  model <name>      Set model (gpt-4o, gpt-4o-mini, etc.)            â”‚
â”‚  temp <0.0-2.0>    Set temperature                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  load <path>       Load blueprint file                              â”‚
â”‚  self              Load this assistant's blueprint                  â”‚
â”‚  clear             Clear blueprint & conversation                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ask <question>    Ask about L++ or loaded blueprint                â”‚
â”‚  explain           Explain loaded blueprint                         â”‚
â”‚  validate          Validate blueprint against schema                â”‚
â”‚  suggest           Get improvement suggestions                      â”‚
â”‚  generate <desc>   Generate new blueprint from description          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Env: OPENAI_API_KEY, OPENAI_API_BASE, LPP_LLM_MODEL                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
""")


def print_status(ctx: dict):
    print(f"\n  API Key: {'âœ“' if ctx.get('api_key') else 'âœ—'}")
    print(f"  Model: {ctx.get('model', 'not set')}")
    print(f"  Base: {ctx.get('api_base', 'not set')}")
    print(f"  Schema: {'âœ“' if ctx.get('schema_content') else 'âœ—'}")
    print(f"  Blueprint: {ctx.get('blueprint_path') or 'none'}")
    print(f"  Conversation: {len(ctx.get('conversation', [])) // 2} turns")
    if ctx.get('error'):
        print(f"  Error: {ctx['error']}")


def format_response(text: str) -> str:
    lines = [
        "\nâ”Œâ”€ Response â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”"
    ]
    for line in text.split('\n'):
        while len(line) > 70:
            lines.append(f"â”‚ {line[:70]}")
            line = line[70:]
        lines.append(f"â”‚ {line}")
    lines.append(
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
    return '\n'.join(lines)


def run_cli(op: Any, here: Path):
    """Main CLI loop. Dispatches events to operator."""
    print("\nğŸ¤– L++ LLM Schema Assistant\nType 'help' for commands.\n")

    # Initialize from environment
    cfg = init_config({})
    op.context.update(cfg)
    op.context["conversation"] = []

    # Load schema
    schema_res = load_schema({})
    if schema_res["schema_content"]:
        op.context["schema_content"] = schema_res["schema_content"]
        print("âœ… Schema loaded")

    # Check API key
    if op.context.get("api_key"):
        print(f"âœ… Model: {op.context['model']}")
        op.context["_state"] = "ready"
    else:
        print("âš ï¸  Set OPENAI_API_KEY or use: key <your-key>")

    while True:
        icon = ICONS.get(op.state, "â“")
        bp = Path(op.context.get('blueprint_path', '')
                  ).stem if op.context.get('blueprint_path') else ''
        prompt = f"\n{icon} [{op.state}]{f' ğŸ“‹{bp}' if bp else ''} > "

        try:
            cmd = input(prompt).strip()
        except (EOFError, KeyboardInterrupt):
            print("\nğŸ‘‹ Bye!")
            break

        if not cmd:
            continue

        parts = cmd.split(maxsplit=1)
        action, arg = parts[0].lower(), parts[1] if len(parts) > 1 else None

        if action in ("q", "quit", "exit"):
            print("ğŸ‘‹ Bye!")
            break
        elif action == "help":
            print_help()
        elif action == "status":
            print_status(op.context)
        elif action == "key" and arg:
            op.context["api_key"] = arg
            op.context["_state"] = "ready"
            print("âœ… API key set")
        elif action == "base" and arg:
            op.context["api_base"] = arg
            print(f"âœ… Base: {arg}")
        elif action == "model" and arg:
            op.context["model"] = arg
            print(f"âœ… Model: {arg}")
        elif action == "temp" and arg:
            try:
                t = float(arg)
                if 0 <= t <= 2:
                    op.context["temperature"] = t
                    print(f"âœ… Temperature: {t}")
                else:
                    print("âŒ Range: 0.0-2.0")
            except ValueError:
                print("âŒ Invalid number")
        elif action == "load" and arg:
            res = load_blueprint({"path": arg})
            if res["blueprint"]:
                op.context.update(res)
                op.context["conversation"] = []
                print(f"âœ… Loaded: {res['blueprint'].get('name', 'Unnamed')}")
            else:
                print(f"âŒ {res['error']}")
        elif action == "self":
            res = load_blueprint({"path": str(here / "llm_assistant.json")})
            if res["blueprint"]:
                op.context.update(res)
                op.context["conversation"] = []
                print("âœ… Loaded: llm_assistant (self)")
        elif action == "clear":
            op.context["blueprint"] = None
            op.context["blueprint_path"] = None
            op.context["conversation"] = []
            print("âœ… Cleared")
        elif action in ("ask", "explain", "validate", "suggest", "generate"):
            if not op.context.get("api_key"):
                print("âŒ No API key")
                continue

            params = {k: op.context.get(k) for k in [
                "api_key", "api_base", "model", "temperature",
                "max_tokens", "schema_content", "blueprint", "conversation"
            ]}

            print("ğŸ”„ Querying...")
            if action == "ask" and arg:
                params["query"] = arg
                res = query(params)
            elif action == "explain":
                if not op.context.get("blueprint"):
                    print("âŒ No blueprint loaded")
                    continue
                res = explain_blueprint(params)
            elif action == "validate":
                if not op.context.get("blueprint"):
                    print("âŒ No blueprint loaded")
                    continue
                res = validate_blueprint(params)
            elif action == "suggest":
                if not op.context.get("blueprint"):
                    print("âŒ No blueprint loaded")
                    continue
                res = suggest_improvements(params)
            elif action == "generate" and arg:
                params["description"] = arg
                res = generate_blueprint(params)
            else:
                print("âŒ Missing argument")
                continue

            if res.get("response"):
                if res.get("conversation"):
                    op.context["conversation"] = res["conversation"]
                print(format_response(res["response"]))
            else:
                print(f"âŒ {res.get('error', 'Unknown error')}")
        else:
            # Treat as freeform query if API key set
            if op.context.get("api_key") and op.state == "ready":
                print("ğŸ”„ Querying...")
                params = {k: op.context.get(k) for k in [
                    "api_key", "api_base", "model", "temperature",
                    "max_tokens", "schema_content", "blueprint", "conversation"
                ]}
                params["query"] = cmd
                res = query(params)
                if res.get("response"):
                    op.context["conversation"] = res["conversation"]
                    print(format_response(res["response"]))
                else:
                    print(f"âŒ {res.get('error')}")
            else:
                print(f"â“ Unknown: {action}. Type 'help'.")
