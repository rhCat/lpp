"""
Compute Unit Tests for logic_vulnerability_pointer

Tests for the Python compute functions (feature implementation).
Generated by L++ Comprehensive Test Generator.
"""

import pytest
import sys
from pathlib import Path
from typing import Any, Dict

# Add project root to path
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# Import compute functions from discovered module
try:
    from workflows.logic_vulnerability_pointer.src.lvp_compute import init, set_target_name, extract_logic, define_invariants, generate_tla, run_tlc, analyze_traces, generate_exploits, generate_patches, verify_fix_tlaps, generate_report, generate_secure_report, capture_error
    COMPUTE_AVAILABLE = True
except ImportError as e:
    COMPUTE_AVAILABLE = False
    IMPORT_ERROR = str(e)


# =============================================================================
# Compute Unit Test Fixtures
# =============================================================================

@pytest.fixture
def mock_context():
    """Create a mock context with default values."""
    return {
        "target_path": "",
        "target_name": "",
        "output_dir": "",
        "run_id": "",
        "bone_json": {},
        "bone_path": "",
        "extraction_error": "",
        "invariants": [],
        "threat_model": {},
        "invariant_count": 0,
        "tla_spec": "",
        "tla_path": "",
        "tlc_result": {},
        "counter_examples": [],
        "vulnerability_count": 0,
        "exploits": [],
        "exploit_paths": [],
        "poc_generated": False,
        "patches": [],
        "patched_json": {},
        "tlaps_proof": "",
        "fix_verified": False,
        "audit_report": {},
        "severity_score": 0,
        "phase": "",
        "error": "",
        "api_key": "",
        "api_base": "",
        "model": "",
        "lpp_root": "",
        "auto_fix": False,
    }


# =============================================================================
# Tests for compute unit: lvp:init
# =============================================================================

class TestCompute_Init:
    """Tests for lvp:init compute function."""

    def test_init_input_contract(self, mock_context):
        """Test that init validates required inputs."""
        inputs = {
        }

        # Verify inputs structure
        assert inputs is not None

        # Call actual compute function if available
        if COMPUTE_AVAILABLE:
            result = init(inputs)
            assert result is not None
            assert isinstance(result, dict)

    def test_init_output_contract(self, mock_context):
        """Test that init returns expected output fields."""
        expected_outputs = ['run_id', 'output_dir', 'phase', 'lpp_root', 'api_key', 'api_base', 'model', 'auto_fix']

        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
        }

        result = init(inputs)
        assert result is not None

        # Verify expected outputs are present
        for field in expected_outputs:
            assert field in result, f"Missing output field: {field}"

    def test_init_error_handling(self, mock_context):
        """Test that init handles errors gracefully."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        # Test with empty inputs
        invalid_inputs = {}

        try:
            result = init(invalid_inputs)
            # Should either return error dict or handle gracefully
            if result is not None:
                assert isinstance(result, dict)
        except (KeyError, TypeError, ValueError):
            # Expected - function requires inputs
            pass


# =============================================================================
# Tests for compute unit: lvp:set_target_name
# =============================================================================

class TestCompute_SetTargetName:
    """Tests for lvp:set_target_name compute function."""

    def test_set_target_name_input_contract(self, mock_context):
        """Test that set_target_name validates required inputs."""
        inputs = {
            "target_path": mock_context.get("target_path"),
        }

        # Verify inputs structure
        assert inputs is not None
        assert "target_path" in inputs

        # Call actual compute function if available
        if COMPUTE_AVAILABLE:
            result = set_target_name(inputs)
            assert result is not None
            assert isinstance(result, dict)

    def test_set_target_name_output_contract(self, mock_context):
        """Test that set_target_name returns expected output fields."""
        expected_outputs = ['target_name']

        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "target_path": mock_context.get("target_path"),
        }

        result = set_target_name(inputs)
        assert result is not None

        # Verify expected outputs are present
        for field in expected_outputs:
            assert field in result, f"Missing output field: {field}"

    def test_set_target_name_error_handling(self, mock_context):
        """Test that set_target_name handles errors gracefully."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        # Test with empty inputs
        invalid_inputs = {}

        try:
            result = set_target_name(invalid_inputs)
            # Should either return error dict or handle gracefully
            if result is not None:
                assert isinstance(result, dict)
        except (KeyError, TypeError, ValueError):
            # Expected - function requires inputs
            pass

    def test_set_target_name_target_path_null(self, mock_context):
        """Test set_target_name with null target_path."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "target_path": None,
        }

        try:
            result = set_target_name(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - target_path is required
            pass


# =============================================================================
# Tests for compute unit: lvp:extract_logic
# =============================================================================

class TestCompute_ExtractLogic:
    """Tests for lvp:extract_logic compute function."""

    def test_extract_logic_input_contract(self, mock_context):
        """Test that extract_logic validates required inputs."""
        inputs = {
            "target_path": mock_context.get("target_path"),
            "output_dir": mock_context.get("output_dir"),
            "lpp_root": mock_context.get("lpp_root"),
        }

        # Verify inputs structure
        assert inputs is not None
        assert "target_path" in inputs
        assert "output_dir" in inputs
        assert "lpp_root" in inputs

        # Call actual compute function if available
        if COMPUTE_AVAILABLE:
            result = extract_logic(inputs)
            assert result is not None
            assert isinstance(result, dict)

    def test_extract_logic_output_contract(self, mock_context):
        """Test that extract_logic returns expected output fields."""
        expected_outputs = ['bone_json', 'bone_path', 'error']

        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "target_path": mock_context.get("target_path"),
            "output_dir": mock_context.get("output_dir"),
            "lpp_root": mock_context.get("lpp_root"),
        }

        result = extract_logic(inputs)
        assert result is not None

        # Verify expected outputs are present
        for field in expected_outputs:
            assert field in result, f"Missing output field: {field}"

    def test_extract_logic_error_handling(self, mock_context):
        """Test that extract_logic handles errors gracefully."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        # Test with empty inputs
        invalid_inputs = {}

        try:
            result = extract_logic(invalid_inputs)
            # Should either return error dict or handle gracefully
            if result is not None:
                assert isinstance(result, dict)
        except (KeyError, TypeError, ValueError):
            # Expected - function requires inputs
            pass

    def test_extract_logic_target_path_null(self, mock_context):
        """Test extract_logic with null target_path."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "target_path": None,
            "output_dir": mock_context.get("output_dir"),
            "lpp_root": mock_context.get("lpp_root"),
        }

        try:
            result = extract_logic(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - target_path is required
            pass

    def test_extract_logic_output_dir_null(self, mock_context):
        """Test extract_logic with null output_dir."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "target_path": mock_context.get("target_path"),
            "output_dir": None,
            "lpp_root": mock_context.get("lpp_root"),
        }

        try:
            result = extract_logic(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - output_dir is required
            pass

    def test_extract_logic_lpp_root_null(self, mock_context):
        """Test extract_logic with null lpp_root."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "target_path": mock_context.get("target_path"),
            "output_dir": mock_context.get("output_dir"),
            "lpp_root": None,
        }

        try:
            result = extract_logic(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - lpp_root is required
            pass


# =============================================================================
# Tests for compute unit: lvp:define_invariants
# =============================================================================

class TestCompute_DefineInvariants:
    """Tests for lvp:define_invariants compute function."""

    def test_define_invariants_input_contract(self, mock_context):
        """Test that define_invariants validates required inputs."""
        inputs = {
            "bone_json": mock_context.get("bone_json"),
            "target_name": mock_context.get("target_name"),
            "api_key": mock_context.get("api_key"),
            "api_base": mock_context.get("api_base"),
            "model": mock_context.get("model"),
            "output_dir": mock_context.get("output_dir"),
        }

        # Verify inputs structure
        assert inputs is not None
        assert "bone_json" in inputs
        assert "target_name" in inputs
        assert "api_key" in inputs
        assert "api_base" in inputs
        assert "model" in inputs
        assert "output_dir" in inputs

        # Call actual compute function if available
        if COMPUTE_AVAILABLE:
            result = define_invariants(inputs)
            assert result is not None
            assert isinstance(result, dict)

    def test_define_invariants_output_contract(self, mock_context):
        """Test that define_invariants returns expected output fields."""
        expected_outputs = ['invariants', 'threat_model', 'invariant_count', 'error']

        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "bone_json": mock_context.get("bone_json"),
            "target_name": mock_context.get("target_name"),
            "api_key": mock_context.get("api_key"),
            "api_base": mock_context.get("api_base"),
            "model": mock_context.get("model"),
            "output_dir": mock_context.get("output_dir"),
        }

        result = define_invariants(inputs)
        assert result is not None

        # Verify expected outputs are present
        for field in expected_outputs:
            assert field in result, f"Missing output field: {field}"

    def test_define_invariants_error_handling(self, mock_context):
        """Test that define_invariants handles errors gracefully."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        # Test with empty inputs
        invalid_inputs = {}

        try:
            result = define_invariants(invalid_inputs)
            # Should either return error dict or handle gracefully
            if result is not None:
                assert isinstance(result, dict)
        except (KeyError, TypeError, ValueError):
            # Expected - function requires inputs
            pass

    def test_define_invariants_bone_json_null(self, mock_context):
        """Test define_invariants with null bone_json."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "bone_json": None,
            "target_name": mock_context.get("target_name"),
            "api_key": mock_context.get("api_key"),
            "api_base": mock_context.get("api_base"),
            "model": mock_context.get("model"),
            "output_dir": mock_context.get("output_dir"),
        }

        try:
            result = define_invariants(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - bone_json is required
            pass

    def test_define_invariants_target_name_null(self, mock_context):
        """Test define_invariants with null target_name."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "bone_json": mock_context.get("bone_json"),
            "target_name": None,
            "api_key": mock_context.get("api_key"),
            "api_base": mock_context.get("api_base"),
            "model": mock_context.get("model"),
            "output_dir": mock_context.get("output_dir"),
        }

        try:
            result = define_invariants(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - target_name is required
            pass

    def test_define_invariants_api_key_null(self, mock_context):
        """Test define_invariants with null api_key."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "bone_json": mock_context.get("bone_json"),
            "target_name": mock_context.get("target_name"),
            "api_key": None,
            "api_base": mock_context.get("api_base"),
            "model": mock_context.get("model"),
            "output_dir": mock_context.get("output_dir"),
        }

        try:
            result = define_invariants(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - api_key is required
            pass

    def test_define_invariants_api_base_null(self, mock_context):
        """Test define_invariants with null api_base."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "bone_json": mock_context.get("bone_json"),
            "target_name": mock_context.get("target_name"),
            "api_key": mock_context.get("api_key"),
            "api_base": None,
            "model": mock_context.get("model"),
            "output_dir": mock_context.get("output_dir"),
        }

        try:
            result = define_invariants(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - api_base is required
            pass

    def test_define_invariants_model_null(self, mock_context):
        """Test define_invariants with null model."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "bone_json": mock_context.get("bone_json"),
            "target_name": mock_context.get("target_name"),
            "api_key": mock_context.get("api_key"),
            "api_base": mock_context.get("api_base"),
            "model": None,
            "output_dir": mock_context.get("output_dir"),
        }

        try:
            result = define_invariants(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - model is required
            pass

    def test_define_invariants_output_dir_null(self, mock_context):
        """Test define_invariants with null output_dir."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "bone_json": mock_context.get("bone_json"),
            "target_name": mock_context.get("target_name"),
            "api_key": mock_context.get("api_key"),
            "api_base": mock_context.get("api_base"),
            "model": mock_context.get("model"),
            "output_dir": None,
        }

        try:
            result = define_invariants(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - output_dir is required
            pass


# =============================================================================
# Tests for compute unit: lvp:generate_tla
# =============================================================================

class TestCompute_GenerateTla:
    """Tests for lvp:generate_tla compute function."""

    def test_generate_tla_input_contract(self, mock_context):
        """Test that generate_tla validates required inputs."""
        inputs = {
            "bone_json": mock_context.get("bone_json"),
            "invariants": mock_context.get("invariants"),
            "output_dir": mock_context.get("output_dir"),
            "lpp_root": mock_context.get("lpp_root"),
        }

        # Verify inputs structure
        assert inputs is not None
        assert "bone_json" in inputs
        assert "invariants" in inputs
        assert "output_dir" in inputs
        assert "lpp_root" in inputs

        # Call actual compute function if available
        if COMPUTE_AVAILABLE:
            result = generate_tla(inputs)
            assert result is not None
            assert isinstance(result, dict)

    def test_generate_tla_output_contract(self, mock_context):
        """Test that generate_tla returns expected output fields."""
        expected_outputs = ['tla_spec', 'tla_path', 'error']

        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "bone_json": mock_context.get("bone_json"),
            "invariants": mock_context.get("invariants"),
            "output_dir": mock_context.get("output_dir"),
            "lpp_root": mock_context.get("lpp_root"),
        }

        result = generate_tla(inputs)
        assert result is not None

        # Verify expected outputs are present
        for field in expected_outputs:
            assert field in result, f"Missing output field: {field}"

    def test_generate_tla_error_handling(self, mock_context):
        """Test that generate_tla handles errors gracefully."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        # Test with empty inputs
        invalid_inputs = {}

        try:
            result = generate_tla(invalid_inputs)
            # Should either return error dict or handle gracefully
            if result is not None:
                assert isinstance(result, dict)
        except (KeyError, TypeError, ValueError):
            # Expected - function requires inputs
            pass

    def test_generate_tla_bone_json_null(self, mock_context):
        """Test generate_tla with null bone_json."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "bone_json": None,
            "invariants": mock_context.get("invariants"),
            "output_dir": mock_context.get("output_dir"),
            "lpp_root": mock_context.get("lpp_root"),
        }

        try:
            result = generate_tla(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - bone_json is required
            pass

    def test_generate_tla_invariants_null(self, mock_context):
        """Test generate_tla with null invariants."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "bone_json": mock_context.get("bone_json"),
            "invariants": None,
            "output_dir": mock_context.get("output_dir"),
            "lpp_root": mock_context.get("lpp_root"),
        }

        try:
            result = generate_tla(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - invariants is required
            pass

    def test_generate_tla_output_dir_null(self, mock_context):
        """Test generate_tla with null output_dir."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "bone_json": mock_context.get("bone_json"),
            "invariants": mock_context.get("invariants"),
            "output_dir": None,
            "lpp_root": mock_context.get("lpp_root"),
        }

        try:
            result = generate_tla(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - output_dir is required
            pass

    def test_generate_tla_lpp_root_null(self, mock_context):
        """Test generate_tla with null lpp_root."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "bone_json": mock_context.get("bone_json"),
            "invariants": mock_context.get("invariants"),
            "output_dir": mock_context.get("output_dir"),
            "lpp_root": None,
        }

        try:
            result = generate_tla(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - lpp_root is required
            pass


# =============================================================================
# Tests for compute unit: lvp:run_tlc
# =============================================================================

class TestCompute_RunTlc:
    """Tests for lvp:run_tlc compute function."""

    def test_run_tlc_input_contract(self, mock_context):
        """Test that run_tlc validates required inputs."""
        inputs = {
            "tla_path": mock_context.get("tla_path"),
            "tla_spec": mock_context.get("tla_spec"),
            "invariants": mock_context.get("invariants"),
            "output_dir": mock_context.get("output_dir"),
            "lpp_root": mock_context.get("lpp_root"),
        }

        # Verify inputs structure
        assert inputs is not None
        assert "tla_path" in inputs
        assert "tla_spec" in inputs
        assert "invariants" in inputs
        assert "output_dir" in inputs
        assert "lpp_root" in inputs

        # Call actual compute function if available
        if COMPUTE_AVAILABLE:
            result = run_tlc(inputs)
            assert result is not None
            assert isinstance(result, dict)

    def test_run_tlc_output_contract(self, mock_context):
        """Test that run_tlc returns expected output fields."""
        expected_outputs = ['tlc_result', 'counter_examples', 'vulnerability_count', 'error']

        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "tla_path": mock_context.get("tla_path"),
            "tla_spec": mock_context.get("tla_spec"),
            "invariants": mock_context.get("invariants"),
            "output_dir": mock_context.get("output_dir"),
            "lpp_root": mock_context.get("lpp_root"),
        }

        result = run_tlc(inputs)
        assert result is not None

        # Verify expected outputs are present
        for field in expected_outputs:
            assert field in result, f"Missing output field: {field}"

    def test_run_tlc_error_handling(self, mock_context):
        """Test that run_tlc handles errors gracefully."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        # Test with empty inputs
        invalid_inputs = {}

        try:
            result = run_tlc(invalid_inputs)
            # Should either return error dict or handle gracefully
            if result is not None:
                assert isinstance(result, dict)
        except (KeyError, TypeError, ValueError):
            # Expected - function requires inputs
            pass

    def test_run_tlc_tla_path_null(self, mock_context):
        """Test run_tlc with null tla_path."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "tla_path": None,
            "tla_spec": mock_context.get("tla_spec"),
            "invariants": mock_context.get("invariants"),
            "output_dir": mock_context.get("output_dir"),
            "lpp_root": mock_context.get("lpp_root"),
        }

        try:
            result = run_tlc(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - tla_path is required
            pass

    def test_run_tlc_tla_spec_null(self, mock_context):
        """Test run_tlc with null tla_spec."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "tla_path": mock_context.get("tla_path"),
            "tla_spec": None,
            "invariants": mock_context.get("invariants"),
            "output_dir": mock_context.get("output_dir"),
            "lpp_root": mock_context.get("lpp_root"),
        }

        try:
            result = run_tlc(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - tla_spec is required
            pass

    def test_run_tlc_invariants_null(self, mock_context):
        """Test run_tlc with null invariants."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "tla_path": mock_context.get("tla_path"),
            "tla_spec": mock_context.get("tla_spec"),
            "invariants": None,
            "output_dir": mock_context.get("output_dir"),
            "lpp_root": mock_context.get("lpp_root"),
        }

        try:
            result = run_tlc(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - invariants is required
            pass

    def test_run_tlc_output_dir_null(self, mock_context):
        """Test run_tlc with null output_dir."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "tla_path": mock_context.get("tla_path"),
            "tla_spec": mock_context.get("tla_spec"),
            "invariants": mock_context.get("invariants"),
            "output_dir": None,
            "lpp_root": mock_context.get("lpp_root"),
        }

        try:
            result = run_tlc(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - output_dir is required
            pass

    def test_run_tlc_lpp_root_null(self, mock_context):
        """Test run_tlc with null lpp_root."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "tla_path": mock_context.get("tla_path"),
            "tla_spec": mock_context.get("tla_spec"),
            "invariants": mock_context.get("invariants"),
            "output_dir": mock_context.get("output_dir"),
            "lpp_root": None,
        }

        try:
            result = run_tlc(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - lpp_root is required
            pass


# =============================================================================
# Tests for compute unit: lvp:analyze_traces
# =============================================================================

class TestCompute_AnalyzeTraces:
    """Tests for lvp:analyze_traces compute function."""

    def test_analyze_traces_input_contract(self, mock_context):
        """Test that analyze_traces validates required inputs."""
        inputs = {
            "counter_examples": mock_context.get("counter_examples"),
            "bone_json": mock_context.get("bone_json"),
            "threat_model": mock_context.get("threat_model"),
            "api_key": mock_context.get("api_key"),
            "api_base": mock_context.get("api_base"),
            "model": mock_context.get("model"),
        }

        # Verify inputs structure
        assert inputs is not None
        assert "counter_examples" in inputs
        assert "bone_json" in inputs
        assert "threat_model" in inputs
        assert "api_key" in inputs
        assert "api_base" in inputs
        assert "model" in inputs

        # Call actual compute function if available
        if COMPUTE_AVAILABLE:
            result = analyze_traces(inputs)
            assert result is not None
            assert isinstance(result, dict)

    def test_analyze_traces_output_contract(self, mock_context):
        """Test that analyze_traces returns expected output fields."""
        expected_outputs = ['counter_examples', 'severity_score', 'error']

        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "counter_examples": mock_context.get("counter_examples"),
            "bone_json": mock_context.get("bone_json"),
            "threat_model": mock_context.get("threat_model"),
            "api_key": mock_context.get("api_key"),
            "api_base": mock_context.get("api_base"),
            "model": mock_context.get("model"),
        }

        result = analyze_traces(inputs)
        assert result is not None

        # Verify expected outputs are present
        for field in expected_outputs:
            assert field in result, f"Missing output field: {field}"

    def test_analyze_traces_error_handling(self, mock_context):
        """Test that analyze_traces handles errors gracefully."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        # Test with empty inputs
        invalid_inputs = {}

        try:
            result = analyze_traces(invalid_inputs)
            # Should either return error dict or handle gracefully
            if result is not None:
                assert isinstance(result, dict)
        except (KeyError, TypeError, ValueError):
            # Expected - function requires inputs
            pass

    def test_analyze_traces_counter_examples_null(self, mock_context):
        """Test analyze_traces with null counter_examples."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "counter_examples": None,
            "bone_json": mock_context.get("bone_json"),
            "threat_model": mock_context.get("threat_model"),
            "api_key": mock_context.get("api_key"),
            "api_base": mock_context.get("api_base"),
            "model": mock_context.get("model"),
        }

        try:
            result = analyze_traces(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - counter_examples is required
            pass

    def test_analyze_traces_bone_json_null(self, mock_context):
        """Test analyze_traces with null bone_json."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "counter_examples": mock_context.get("counter_examples"),
            "bone_json": None,
            "threat_model": mock_context.get("threat_model"),
            "api_key": mock_context.get("api_key"),
            "api_base": mock_context.get("api_base"),
            "model": mock_context.get("model"),
        }

        try:
            result = analyze_traces(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - bone_json is required
            pass

    def test_analyze_traces_threat_model_null(self, mock_context):
        """Test analyze_traces with null threat_model."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "counter_examples": mock_context.get("counter_examples"),
            "bone_json": mock_context.get("bone_json"),
            "threat_model": None,
            "api_key": mock_context.get("api_key"),
            "api_base": mock_context.get("api_base"),
            "model": mock_context.get("model"),
        }

        try:
            result = analyze_traces(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - threat_model is required
            pass

    def test_analyze_traces_api_key_null(self, mock_context):
        """Test analyze_traces with null api_key."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "counter_examples": mock_context.get("counter_examples"),
            "bone_json": mock_context.get("bone_json"),
            "threat_model": mock_context.get("threat_model"),
            "api_key": None,
            "api_base": mock_context.get("api_base"),
            "model": mock_context.get("model"),
        }

        try:
            result = analyze_traces(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - api_key is required
            pass

    def test_analyze_traces_api_base_null(self, mock_context):
        """Test analyze_traces with null api_base."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "counter_examples": mock_context.get("counter_examples"),
            "bone_json": mock_context.get("bone_json"),
            "threat_model": mock_context.get("threat_model"),
            "api_key": mock_context.get("api_key"),
            "api_base": None,
            "model": mock_context.get("model"),
        }

        try:
            result = analyze_traces(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - api_base is required
            pass

    def test_analyze_traces_model_null(self, mock_context):
        """Test analyze_traces with null model."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "counter_examples": mock_context.get("counter_examples"),
            "bone_json": mock_context.get("bone_json"),
            "threat_model": mock_context.get("threat_model"),
            "api_key": mock_context.get("api_key"),
            "api_base": mock_context.get("api_base"),
            "model": None,
        }

        try:
            result = analyze_traces(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - model is required
            pass


# =============================================================================
# Tests for compute unit: lvp:generate_exploits
# =============================================================================

class TestCompute_GenerateExploits:
    """Tests for lvp:generate_exploits compute function."""

    def test_generate_exploits_input_contract(self, mock_context):
        """Test that generate_exploits validates required inputs."""
        inputs = {
            "counter_examples": mock_context.get("counter_examples"),
            "bone_json": mock_context.get("bone_json"),
            "target_path": mock_context.get("target_path"),
            "target_name": mock_context.get("target_name"),
            "output_dir": mock_context.get("output_dir"),
            "api_key": mock_context.get("api_key"),
            "api_base": mock_context.get("api_base"),
            "model": mock_context.get("model"),
        }

        # Verify inputs structure
        assert inputs is not None
        assert "counter_examples" in inputs
        assert "bone_json" in inputs
        assert "target_path" in inputs
        assert "target_name" in inputs
        assert "output_dir" in inputs
        assert "api_key" in inputs
        assert "api_base" in inputs
        assert "model" in inputs

        # Call actual compute function if available
        if COMPUTE_AVAILABLE:
            result = generate_exploits(inputs)
            assert result is not None
            assert isinstance(result, dict)

    def test_generate_exploits_output_contract(self, mock_context):
        """Test that generate_exploits returns expected output fields."""
        expected_outputs = ['exploits', 'exploit_paths', 'poc_generated', 'error']

        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "counter_examples": mock_context.get("counter_examples"),
            "bone_json": mock_context.get("bone_json"),
            "target_path": mock_context.get("target_path"),
            "target_name": mock_context.get("target_name"),
            "output_dir": mock_context.get("output_dir"),
            "api_key": mock_context.get("api_key"),
            "api_base": mock_context.get("api_base"),
            "model": mock_context.get("model"),
        }

        result = generate_exploits(inputs)
        assert result is not None

        # Verify expected outputs are present
        for field in expected_outputs:
            assert field in result, f"Missing output field: {field}"

    def test_generate_exploits_error_handling(self, mock_context):
        """Test that generate_exploits handles errors gracefully."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        # Test with empty inputs
        invalid_inputs = {}

        try:
            result = generate_exploits(invalid_inputs)
            # Should either return error dict or handle gracefully
            if result is not None:
                assert isinstance(result, dict)
        except (KeyError, TypeError, ValueError):
            # Expected - function requires inputs
            pass

    def test_generate_exploits_counter_examples_null(self, mock_context):
        """Test generate_exploits with null counter_examples."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "counter_examples": None,
            "bone_json": mock_context.get("bone_json"),
            "target_path": mock_context.get("target_path"),
            "target_name": mock_context.get("target_name"),
            "output_dir": mock_context.get("output_dir"),
            "api_key": mock_context.get("api_key"),
            "api_base": mock_context.get("api_base"),
            "model": mock_context.get("model"),
        }

        try:
            result = generate_exploits(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - counter_examples is required
            pass

    def test_generate_exploits_bone_json_null(self, mock_context):
        """Test generate_exploits with null bone_json."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "counter_examples": mock_context.get("counter_examples"),
            "bone_json": None,
            "target_path": mock_context.get("target_path"),
            "target_name": mock_context.get("target_name"),
            "output_dir": mock_context.get("output_dir"),
            "api_key": mock_context.get("api_key"),
            "api_base": mock_context.get("api_base"),
            "model": mock_context.get("model"),
        }

        try:
            result = generate_exploits(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - bone_json is required
            pass

    def test_generate_exploits_target_path_null(self, mock_context):
        """Test generate_exploits with null target_path."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "counter_examples": mock_context.get("counter_examples"),
            "bone_json": mock_context.get("bone_json"),
            "target_path": None,
            "target_name": mock_context.get("target_name"),
            "output_dir": mock_context.get("output_dir"),
            "api_key": mock_context.get("api_key"),
            "api_base": mock_context.get("api_base"),
            "model": mock_context.get("model"),
        }

        try:
            result = generate_exploits(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - target_path is required
            pass

    def test_generate_exploits_target_name_null(self, mock_context):
        """Test generate_exploits with null target_name."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "counter_examples": mock_context.get("counter_examples"),
            "bone_json": mock_context.get("bone_json"),
            "target_path": mock_context.get("target_path"),
            "target_name": None,
            "output_dir": mock_context.get("output_dir"),
            "api_key": mock_context.get("api_key"),
            "api_base": mock_context.get("api_base"),
            "model": mock_context.get("model"),
        }

        try:
            result = generate_exploits(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - target_name is required
            pass

    def test_generate_exploits_output_dir_null(self, mock_context):
        """Test generate_exploits with null output_dir."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "counter_examples": mock_context.get("counter_examples"),
            "bone_json": mock_context.get("bone_json"),
            "target_path": mock_context.get("target_path"),
            "target_name": mock_context.get("target_name"),
            "output_dir": None,
            "api_key": mock_context.get("api_key"),
            "api_base": mock_context.get("api_base"),
            "model": mock_context.get("model"),
        }

        try:
            result = generate_exploits(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - output_dir is required
            pass

    def test_generate_exploits_api_key_null(self, mock_context):
        """Test generate_exploits with null api_key."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "counter_examples": mock_context.get("counter_examples"),
            "bone_json": mock_context.get("bone_json"),
            "target_path": mock_context.get("target_path"),
            "target_name": mock_context.get("target_name"),
            "output_dir": mock_context.get("output_dir"),
            "api_key": None,
            "api_base": mock_context.get("api_base"),
            "model": mock_context.get("model"),
        }

        try:
            result = generate_exploits(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - api_key is required
            pass

    def test_generate_exploits_api_base_null(self, mock_context):
        """Test generate_exploits with null api_base."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "counter_examples": mock_context.get("counter_examples"),
            "bone_json": mock_context.get("bone_json"),
            "target_path": mock_context.get("target_path"),
            "target_name": mock_context.get("target_name"),
            "output_dir": mock_context.get("output_dir"),
            "api_key": mock_context.get("api_key"),
            "api_base": None,
            "model": mock_context.get("model"),
        }

        try:
            result = generate_exploits(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - api_base is required
            pass

    def test_generate_exploits_model_null(self, mock_context):
        """Test generate_exploits with null model."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "counter_examples": mock_context.get("counter_examples"),
            "bone_json": mock_context.get("bone_json"),
            "target_path": mock_context.get("target_path"),
            "target_name": mock_context.get("target_name"),
            "output_dir": mock_context.get("output_dir"),
            "api_key": mock_context.get("api_key"),
            "api_base": mock_context.get("api_base"),
            "model": None,
        }

        try:
            result = generate_exploits(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - model is required
            pass


# =============================================================================
# Tests for compute unit: lvp:generate_patches
# =============================================================================

class TestCompute_GeneratePatches:
    """Tests for lvp:generate_patches compute function."""

    def test_generate_patches_input_contract(self, mock_context):
        """Test that generate_patches validates required inputs."""
        inputs = {
            "counter_examples": mock_context.get("counter_examples"),
            "bone_json": mock_context.get("bone_json"),
            "invariants": mock_context.get("invariants"),
            "api_key": mock_context.get("api_key"),
            "api_base": mock_context.get("api_base"),
            "model": mock_context.get("model"),
            "output_dir": mock_context.get("output_dir"),
        }

        # Verify inputs structure
        assert inputs is not None
        assert "counter_examples" in inputs
        assert "bone_json" in inputs
        assert "invariants" in inputs
        assert "api_key" in inputs
        assert "api_base" in inputs
        assert "model" in inputs
        assert "output_dir" in inputs

        # Call actual compute function if available
        if COMPUTE_AVAILABLE:
            result = generate_patches(inputs)
            assert result is not None
            assert isinstance(result, dict)

    def test_generate_patches_output_contract(self, mock_context):
        """Test that generate_patches returns expected output fields."""
        expected_outputs = ['patches', 'patched_json', 'error']

        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "counter_examples": mock_context.get("counter_examples"),
            "bone_json": mock_context.get("bone_json"),
            "invariants": mock_context.get("invariants"),
            "api_key": mock_context.get("api_key"),
            "api_base": mock_context.get("api_base"),
            "model": mock_context.get("model"),
            "output_dir": mock_context.get("output_dir"),
        }

        result = generate_patches(inputs)
        assert result is not None

        # Verify expected outputs are present
        for field in expected_outputs:
            assert field in result, f"Missing output field: {field}"

    def test_generate_patches_error_handling(self, mock_context):
        """Test that generate_patches handles errors gracefully."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        # Test with empty inputs
        invalid_inputs = {}

        try:
            result = generate_patches(invalid_inputs)
            # Should either return error dict or handle gracefully
            if result is not None:
                assert isinstance(result, dict)
        except (KeyError, TypeError, ValueError):
            # Expected - function requires inputs
            pass

    def test_generate_patches_counter_examples_null(self, mock_context):
        """Test generate_patches with null counter_examples."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "counter_examples": None,
            "bone_json": mock_context.get("bone_json"),
            "invariants": mock_context.get("invariants"),
            "api_key": mock_context.get("api_key"),
            "api_base": mock_context.get("api_base"),
            "model": mock_context.get("model"),
            "output_dir": mock_context.get("output_dir"),
        }

        try:
            result = generate_patches(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - counter_examples is required
            pass

    def test_generate_patches_bone_json_null(self, mock_context):
        """Test generate_patches with null bone_json."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "counter_examples": mock_context.get("counter_examples"),
            "bone_json": None,
            "invariants": mock_context.get("invariants"),
            "api_key": mock_context.get("api_key"),
            "api_base": mock_context.get("api_base"),
            "model": mock_context.get("model"),
            "output_dir": mock_context.get("output_dir"),
        }

        try:
            result = generate_patches(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - bone_json is required
            pass

    def test_generate_patches_invariants_null(self, mock_context):
        """Test generate_patches with null invariants."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "counter_examples": mock_context.get("counter_examples"),
            "bone_json": mock_context.get("bone_json"),
            "invariants": None,
            "api_key": mock_context.get("api_key"),
            "api_base": mock_context.get("api_base"),
            "model": mock_context.get("model"),
            "output_dir": mock_context.get("output_dir"),
        }

        try:
            result = generate_patches(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - invariants is required
            pass

    def test_generate_patches_api_key_null(self, mock_context):
        """Test generate_patches with null api_key."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "counter_examples": mock_context.get("counter_examples"),
            "bone_json": mock_context.get("bone_json"),
            "invariants": mock_context.get("invariants"),
            "api_key": None,
            "api_base": mock_context.get("api_base"),
            "model": mock_context.get("model"),
            "output_dir": mock_context.get("output_dir"),
        }

        try:
            result = generate_patches(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - api_key is required
            pass

    def test_generate_patches_api_base_null(self, mock_context):
        """Test generate_patches with null api_base."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "counter_examples": mock_context.get("counter_examples"),
            "bone_json": mock_context.get("bone_json"),
            "invariants": mock_context.get("invariants"),
            "api_key": mock_context.get("api_key"),
            "api_base": None,
            "model": mock_context.get("model"),
            "output_dir": mock_context.get("output_dir"),
        }

        try:
            result = generate_patches(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - api_base is required
            pass

    def test_generate_patches_model_null(self, mock_context):
        """Test generate_patches with null model."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "counter_examples": mock_context.get("counter_examples"),
            "bone_json": mock_context.get("bone_json"),
            "invariants": mock_context.get("invariants"),
            "api_key": mock_context.get("api_key"),
            "api_base": mock_context.get("api_base"),
            "model": None,
            "output_dir": mock_context.get("output_dir"),
        }

        try:
            result = generate_patches(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - model is required
            pass

    def test_generate_patches_output_dir_null(self, mock_context):
        """Test generate_patches with null output_dir."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "counter_examples": mock_context.get("counter_examples"),
            "bone_json": mock_context.get("bone_json"),
            "invariants": mock_context.get("invariants"),
            "api_key": mock_context.get("api_key"),
            "api_base": mock_context.get("api_base"),
            "model": mock_context.get("model"),
            "output_dir": None,
        }

        try:
            result = generate_patches(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - output_dir is required
            pass


# =============================================================================
# Tests for compute unit: lvp:verify_fix_tlaps
# =============================================================================

class TestCompute_VerifyFixTlaps:
    """Tests for lvp:verify_fix_tlaps compute function."""

    def test_verify_fix_tlaps_input_contract(self, mock_context):
        """Test that verify_fix_tlaps validates required inputs."""
        inputs = {
            "patched_json": mock_context.get("patched_json"),
            "invariants": mock_context.get("invariants"),
            "output_dir": mock_context.get("output_dir"),
            "lpp_root": mock_context.get("lpp_root"),
        }

        # Verify inputs structure
        assert inputs is not None
        assert "patched_json" in inputs
        assert "invariants" in inputs
        assert "output_dir" in inputs
        assert "lpp_root" in inputs

        # Call actual compute function if available
        if COMPUTE_AVAILABLE:
            result = verify_fix_tlaps(inputs)
            assert result is not None
            assert isinstance(result, dict)

    def test_verify_fix_tlaps_output_contract(self, mock_context):
        """Test that verify_fix_tlaps returns expected output fields."""
        expected_outputs = ['tlaps_proof', 'fix_verified', 'error']

        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "patched_json": mock_context.get("patched_json"),
            "invariants": mock_context.get("invariants"),
            "output_dir": mock_context.get("output_dir"),
            "lpp_root": mock_context.get("lpp_root"),
        }

        result = verify_fix_tlaps(inputs)
        assert result is not None

        # Verify expected outputs are present
        for field in expected_outputs:
            assert field in result, f"Missing output field: {field}"

    def test_verify_fix_tlaps_error_handling(self, mock_context):
        """Test that verify_fix_tlaps handles errors gracefully."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        # Test with empty inputs
        invalid_inputs = {}

        try:
            result = verify_fix_tlaps(invalid_inputs)
            # Should either return error dict or handle gracefully
            if result is not None:
                assert isinstance(result, dict)
        except (KeyError, TypeError, ValueError):
            # Expected - function requires inputs
            pass

    def test_verify_fix_tlaps_patched_json_null(self, mock_context):
        """Test verify_fix_tlaps with null patched_json."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "patched_json": None,
            "invariants": mock_context.get("invariants"),
            "output_dir": mock_context.get("output_dir"),
            "lpp_root": mock_context.get("lpp_root"),
        }

        try:
            result = verify_fix_tlaps(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - patched_json is required
            pass

    def test_verify_fix_tlaps_invariants_null(self, mock_context):
        """Test verify_fix_tlaps with null invariants."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "patched_json": mock_context.get("patched_json"),
            "invariants": None,
            "output_dir": mock_context.get("output_dir"),
            "lpp_root": mock_context.get("lpp_root"),
        }

        try:
            result = verify_fix_tlaps(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - invariants is required
            pass

    def test_verify_fix_tlaps_output_dir_null(self, mock_context):
        """Test verify_fix_tlaps with null output_dir."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "patched_json": mock_context.get("patched_json"),
            "invariants": mock_context.get("invariants"),
            "output_dir": None,
            "lpp_root": mock_context.get("lpp_root"),
        }

        try:
            result = verify_fix_tlaps(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - output_dir is required
            pass

    def test_verify_fix_tlaps_lpp_root_null(self, mock_context):
        """Test verify_fix_tlaps with null lpp_root."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "patched_json": mock_context.get("patched_json"),
            "invariants": mock_context.get("invariants"),
            "output_dir": mock_context.get("output_dir"),
            "lpp_root": None,
        }

        try:
            result = verify_fix_tlaps(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - lpp_root is required
            pass


# =============================================================================
# Tests for compute unit: lvp:generate_report
# =============================================================================

class TestCompute_GenerateReport:
    """Tests for lvp:generate_report compute function."""

    def test_generate_report_input_contract(self, mock_context):
        """Test that generate_report validates required inputs."""
        inputs = {
            "target_name": mock_context.get("target_name"),
            "target_path": mock_context.get("target_path"),
            "bone_json": mock_context.get("bone_json"),
            "threat_model": mock_context.get("threat_model"),
            "invariants": mock_context.get("invariants"),
            "counter_examples": mock_context.get("counter_examples"),
            "vulnerability_count": mock_context.get("vulnerability_count"),
            "exploits": mock_context.get("exploits"),
            "patches": mock_context.get("patches"),
            "fix_verified": mock_context.get("fix_verified"),
            "severity_score": mock_context.get("severity_score"),
            "output_dir": mock_context.get("output_dir"),
            "run_id": mock_context.get("run_id"),
        }

        # Verify inputs structure
        assert inputs is not None
        assert "target_name" in inputs
        assert "target_path" in inputs
        assert "bone_json" in inputs
        assert "threat_model" in inputs
        assert "invariants" in inputs
        assert "counter_examples" in inputs
        assert "vulnerability_count" in inputs
        assert "exploits" in inputs
        assert "patches" in inputs
        assert "fix_verified" in inputs
        assert "severity_score" in inputs
        assert "output_dir" in inputs
        assert "run_id" in inputs

        # Call actual compute function if available
        if COMPUTE_AVAILABLE:
            result = generate_report(inputs)
            assert result is not None
            assert isinstance(result, dict)

    def test_generate_report_output_contract(self, mock_context):
        """Test that generate_report returns expected output fields."""
        expected_outputs = ['audit_report', 'error']

        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "target_name": mock_context.get("target_name"),
            "target_path": mock_context.get("target_path"),
            "bone_json": mock_context.get("bone_json"),
            "threat_model": mock_context.get("threat_model"),
            "invariants": mock_context.get("invariants"),
            "counter_examples": mock_context.get("counter_examples"),
            "vulnerability_count": mock_context.get("vulnerability_count"),
            "exploits": mock_context.get("exploits"),
            "patches": mock_context.get("patches"),
            "fix_verified": mock_context.get("fix_verified"),
            "severity_score": mock_context.get("severity_score"),
            "output_dir": mock_context.get("output_dir"),
            "run_id": mock_context.get("run_id"),
        }

        result = generate_report(inputs)
        assert result is not None

        # Verify expected outputs are present
        for field in expected_outputs:
            assert field in result, f"Missing output field: {field}"

    def test_generate_report_error_handling(self, mock_context):
        """Test that generate_report handles errors gracefully."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        # Test with empty inputs
        invalid_inputs = {}

        try:
            result = generate_report(invalid_inputs)
            # Should either return error dict or handle gracefully
            if result is not None:
                assert isinstance(result, dict)
        except (KeyError, TypeError, ValueError):
            # Expected - function requires inputs
            pass

    def test_generate_report_target_name_null(self, mock_context):
        """Test generate_report with null target_name."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "target_name": None,
            "target_path": mock_context.get("target_path"),
            "bone_json": mock_context.get("bone_json"),
            "threat_model": mock_context.get("threat_model"),
            "invariants": mock_context.get("invariants"),
            "counter_examples": mock_context.get("counter_examples"),
            "vulnerability_count": mock_context.get("vulnerability_count"),
            "exploits": mock_context.get("exploits"),
            "patches": mock_context.get("patches"),
            "fix_verified": mock_context.get("fix_verified"),
            "severity_score": mock_context.get("severity_score"),
            "output_dir": mock_context.get("output_dir"),
            "run_id": mock_context.get("run_id"),
        }

        try:
            result = generate_report(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - target_name is required
            pass

    def test_generate_report_target_path_null(self, mock_context):
        """Test generate_report with null target_path."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "target_name": mock_context.get("target_name"),
            "target_path": None,
            "bone_json": mock_context.get("bone_json"),
            "threat_model": mock_context.get("threat_model"),
            "invariants": mock_context.get("invariants"),
            "counter_examples": mock_context.get("counter_examples"),
            "vulnerability_count": mock_context.get("vulnerability_count"),
            "exploits": mock_context.get("exploits"),
            "patches": mock_context.get("patches"),
            "fix_verified": mock_context.get("fix_verified"),
            "severity_score": mock_context.get("severity_score"),
            "output_dir": mock_context.get("output_dir"),
            "run_id": mock_context.get("run_id"),
        }

        try:
            result = generate_report(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - target_path is required
            pass

    def test_generate_report_bone_json_null(self, mock_context):
        """Test generate_report with null bone_json."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "target_name": mock_context.get("target_name"),
            "target_path": mock_context.get("target_path"),
            "bone_json": None,
            "threat_model": mock_context.get("threat_model"),
            "invariants": mock_context.get("invariants"),
            "counter_examples": mock_context.get("counter_examples"),
            "vulnerability_count": mock_context.get("vulnerability_count"),
            "exploits": mock_context.get("exploits"),
            "patches": mock_context.get("patches"),
            "fix_verified": mock_context.get("fix_verified"),
            "severity_score": mock_context.get("severity_score"),
            "output_dir": mock_context.get("output_dir"),
            "run_id": mock_context.get("run_id"),
        }

        try:
            result = generate_report(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - bone_json is required
            pass

    def test_generate_report_threat_model_null(self, mock_context):
        """Test generate_report with null threat_model."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "target_name": mock_context.get("target_name"),
            "target_path": mock_context.get("target_path"),
            "bone_json": mock_context.get("bone_json"),
            "threat_model": None,
            "invariants": mock_context.get("invariants"),
            "counter_examples": mock_context.get("counter_examples"),
            "vulnerability_count": mock_context.get("vulnerability_count"),
            "exploits": mock_context.get("exploits"),
            "patches": mock_context.get("patches"),
            "fix_verified": mock_context.get("fix_verified"),
            "severity_score": mock_context.get("severity_score"),
            "output_dir": mock_context.get("output_dir"),
            "run_id": mock_context.get("run_id"),
        }

        try:
            result = generate_report(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - threat_model is required
            pass

    def test_generate_report_invariants_null(self, mock_context):
        """Test generate_report with null invariants."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "target_name": mock_context.get("target_name"),
            "target_path": mock_context.get("target_path"),
            "bone_json": mock_context.get("bone_json"),
            "threat_model": mock_context.get("threat_model"),
            "invariants": None,
            "counter_examples": mock_context.get("counter_examples"),
            "vulnerability_count": mock_context.get("vulnerability_count"),
            "exploits": mock_context.get("exploits"),
            "patches": mock_context.get("patches"),
            "fix_verified": mock_context.get("fix_verified"),
            "severity_score": mock_context.get("severity_score"),
            "output_dir": mock_context.get("output_dir"),
            "run_id": mock_context.get("run_id"),
        }

        try:
            result = generate_report(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - invariants is required
            pass

    def test_generate_report_counter_examples_null(self, mock_context):
        """Test generate_report with null counter_examples."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "target_name": mock_context.get("target_name"),
            "target_path": mock_context.get("target_path"),
            "bone_json": mock_context.get("bone_json"),
            "threat_model": mock_context.get("threat_model"),
            "invariants": mock_context.get("invariants"),
            "counter_examples": None,
            "vulnerability_count": mock_context.get("vulnerability_count"),
            "exploits": mock_context.get("exploits"),
            "patches": mock_context.get("patches"),
            "fix_verified": mock_context.get("fix_verified"),
            "severity_score": mock_context.get("severity_score"),
            "output_dir": mock_context.get("output_dir"),
            "run_id": mock_context.get("run_id"),
        }

        try:
            result = generate_report(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - counter_examples is required
            pass

    def test_generate_report_vulnerability_count_null(self, mock_context):
        """Test generate_report with null vulnerability_count."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "target_name": mock_context.get("target_name"),
            "target_path": mock_context.get("target_path"),
            "bone_json": mock_context.get("bone_json"),
            "threat_model": mock_context.get("threat_model"),
            "invariants": mock_context.get("invariants"),
            "counter_examples": mock_context.get("counter_examples"),
            "vulnerability_count": None,
            "exploits": mock_context.get("exploits"),
            "patches": mock_context.get("patches"),
            "fix_verified": mock_context.get("fix_verified"),
            "severity_score": mock_context.get("severity_score"),
            "output_dir": mock_context.get("output_dir"),
            "run_id": mock_context.get("run_id"),
        }

        try:
            result = generate_report(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - vulnerability_count is required
            pass

    def test_generate_report_exploits_null(self, mock_context):
        """Test generate_report with null exploits."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "target_name": mock_context.get("target_name"),
            "target_path": mock_context.get("target_path"),
            "bone_json": mock_context.get("bone_json"),
            "threat_model": mock_context.get("threat_model"),
            "invariants": mock_context.get("invariants"),
            "counter_examples": mock_context.get("counter_examples"),
            "vulnerability_count": mock_context.get("vulnerability_count"),
            "exploits": None,
            "patches": mock_context.get("patches"),
            "fix_verified": mock_context.get("fix_verified"),
            "severity_score": mock_context.get("severity_score"),
            "output_dir": mock_context.get("output_dir"),
            "run_id": mock_context.get("run_id"),
        }

        try:
            result = generate_report(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - exploits is required
            pass

    def test_generate_report_patches_null(self, mock_context):
        """Test generate_report with null patches."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "target_name": mock_context.get("target_name"),
            "target_path": mock_context.get("target_path"),
            "bone_json": mock_context.get("bone_json"),
            "threat_model": mock_context.get("threat_model"),
            "invariants": mock_context.get("invariants"),
            "counter_examples": mock_context.get("counter_examples"),
            "vulnerability_count": mock_context.get("vulnerability_count"),
            "exploits": mock_context.get("exploits"),
            "patches": None,
            "fix_verified": mock_context.get("fix_verified"),
            "severity_score": mock_context.get("severity_score"),
            "output_dir": mock_context.get("output_dir"),
            "run_id": mock_context.get("run_id"),
        }

        try:
            result = generate_report(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - patches is required
            pass

    def test_generate_report_fix_verified_null(self, mock_context):
        """Test generate_report with null fix_verified."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "target_name": mock_context.get("target_name"),
            "target_path": mock_context.get("target_path"),
            "bone_json": mock_context.get("bone_json"),
            "threat_model": mock_context.get("threat_model"),
            "invariants": mock_context.get("invariants"),
            "counter_examples": mock_context.get("counter_examples"),
            "vulnerability_count": mock_context.get("vulnerability_count"),
            "exploits": mock_context.get("exploits"),
            "patches": mock_context.get("patches"),
            "fix_verified": None,
            "severity_score": mock_context.get("severity_score"),
            "output_dir": mock_context.get("output_dir"),
            "run_id": mock_context.get("run_id"),
        }

        try:
            result = generate_report(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - fix_verified is required
            pass

    def test_generate_report_severity_score_null(self, mock_context):
        """Test generate_report with null severity_score."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "target_name": mock_context.get("target_name"),
            "target_path": mock_context.get("target_path"),
            "bone_json": mock_context.get("bone_json"),
            "threat_model": mock_context.get("threat_model"),
            "invariants": mock_context.get("invariants"),
            "counter_examples": mock_context.get("counter_examples"),
            "vulnerability_count": mock_context.get("vulnerability_count"),
            "exploits": mock_context.get("exploits"),
            "patches": mock_context.get("patches"),
            "fix_verified": mock_context.get("fix_verified"),
            "severity_score": None,
            "output_dir": mock_context.get("output_dir"),
            "run_id": mock_context.get("run_id"),
        }

        try:
            result = generate_report(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - severity_score is required
            pass

    def test_generate_report_output_dir_null(self, mock_context):
        """Test generate_report with null output_dir."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "target_name": mock_context.get("target_name"),
            "target_path": mock_context.get("target_path"),
            "bone_json": mock_context.get("bone_json"),
            "threat_model": mock_context.get("threat_model"),
            "invariants": mock_context.get("invariants"),
            "counter_examples": mock_context.get("counter_examples"),
            "vulnerability_count": mock_context.get("vulnerability_count"),
            "exploits": mock_context.get("exploits"),
            "patches": mock_context.get("patches"),
            "fix_verified": mock_context.get("fix_verified"),
            "severity_score": mock_context.get("severity_score"),
            "output_dir": None,
            "run_id": mock_context.get("run_id"),
        }

        try:
            result = generate_report(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - output_dir is required
            pass

    def test_generate_report_run_id_null(self, mock_context):
        """Test generate_report with null run_id."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "target_name": mock_context.get("target_name"),
            "target_path": mock_context.get("target_path"),
            "bone_json": mock_context.get("bone_json"),
            "threat_model": mock_context.get("threat_model"),
            "invariants": mock_context.get("invariants"),
            "counter_examples": mock_context.get("counter_examples"),
            "vulnerability_count": mock_context.get("vulnerability_count"),
            "exploits": mock_context.get("exploits"),
            "patches": mock_context.get("patches"),
            "fix_verified": mock_context.get("fix_verified"),
            "severity_score": mock_context.get("severity_score"),
            "output_dir": mock_context.get("output_dir"),
            "run_id": None,
        }

        try:
            result = generate_report(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - run_id is required
            pass


# =============================================================================
# Tests for compute unit: lvp:generate_secure_report
# =============================================================================

class TestCompute_GenerateSecureReport:
    """Tests for lvp:generate_secure_report compute function."""

    def test_generate_secure_report_input_contract(self, mock_context):
        """Test that generate_secure_report validates required inputs."""
        inputs = {
            "target_name": mock_context.get("target_name"),
            "target_path": mock_context.get("target_path"),
            "bone_json": mock_context.get("bone_json"),
            "invariants": mock_context.get("invariants"),
            "output_dir": mock_context.get("output_dir"),
            "run_id": mock_context.get("run_id"),
        }

        # Verify inputs structure
        assert inputs is not None
        assert "target_name" in inputs
        assert "target_path" in inputs
        assert "bone_json" in inputs
        assert "invariants" in inputs
        assert "output_dir" in inputs
        assert "run_id" in inputs

        # Call actual compute function if available
        if COMPUTE_AVAILABLE:
            result = generate_secure_report(inputs)
            assert result is not None
            assert isinstance(result, dict)

    def test_generate_secure_report_output_contract(self, mock_context):
        """Test that generate_secure_report returns expected output fields."""
        expected_outputs = ['audit_report']

        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "target_name": mock_context.get("target_name"),
            "target_path": mock_context.get("target_path"),
            "bone_json": mock_context.get("bone_json"),
            "invariants": mock_context.get("invariants"),
            "output_dir": mock_context.get("output_dir"),
            "run_id": mock_context.get("run_id"),
        }

        result = generate_secure_report(inputs)
        assert result is not None

        # Verify expected outputs are present
        for field in expected_outputs:
            assert field in result, f"Missing output field: {field}"

    def test_generate_secure_report_error_handling(self, mock_context):
        """Test that generate_secure_report handles errors gracefully."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        # Test with empty inputs
        invalid_inputs = {}

        try:
            result = generate_secure_report(invalid_inputs)
            # Should either return error dict or handle gracefully
            if result is not None:
                assert isinstance(result, dict)
        except (KeyError, TypeError, ValueError):
            # Expected - function requires inputs
            pass

    def test_generate_secure_report_target_name_null(self, mock_context):
        """Test generate_secure_report with null target_name."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "target_name": None,
            "target_path": mock_context.get("target_path"),
            "bone_json": mock_context.get("bone_json"),
            "invariants": mock_context.get("invariants"),
            "output_dir": mock_context.get("output_dir"),
            "run_id": mock_context.get("run_id"),
        }

        try:
            result = generate_secure_report(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - target_name is required
            pass

    def test_generate_secure_report_target_path_null(self, mock_context):
        """Test generate_secure_report with null target_path."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "target_name": mock_context.get("target_name"),
            "target_path": None,
            "bone_json": mock_context.get("bone_json"),
            "invariants": mock_context.get("invariants"),
            "output_dir": mock_context.get("output_dir"),
            "run_id": mock_context.get("run_id"),
        }

        try:
            result = generate_secure_report(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - target_path is required
            pass

    def test_generate_secure_report_bone_json_null(self, mock_context):
        """Test generate_secure_report with null bone_json."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "target_name": mock_context.get("target_name"),
            "target_path": mock_context.get("target_path"),
            "bone_json": None,
            "invariants": mock_context.get("invariants"),
            "output_dir": mock_context.get("output_dir"),
            "run_id": mock_context.get("run_id"),
        }

        try:
            result = generate_secure_report(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - bone_json is required
            pass

    def test_generate_secure_report_invariants_null(self, mock_context):
        """Test generate_secure_report with null invariants."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "target_name": mock_context.get("target_name"),
            "target_path": mock_context.get("target_path"),
            "bone_json": mock_context.get("bone_json"),
            "invariants": None,
            "output_dir": mock_context.get("output_dir"),
            "run_id": mock_context.get("run_id"),
        }

        try:
            result = generate_secure_report(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - invariants is required
            pass

    def test_generate_secure_report_output_dir_null(self, mock_context):
        """Test generate_secure_report with null output_dir."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "target_name": mock_context.get("target_name"),
            "target_path": mock_context.get("target_path"),
            "bone_json": mock_context.get("bone_json"),
            "invariants": mock_context.get("invariants"),
            "output_dir": None,
            "run_id": mock_context.get("run_id"),
        }

        try:
            result = generate_secure_report(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - output_dir is required
            pass

    def test_generate_secure_report_run_id_null(self, mock_context):
        """Test generate_secure_report with null run_id."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "target_name": mock_context.get("target_name"),
            "target_path": mock_context.get("target_path"),
            "bone_json": mock_context.get("bone_json"),
            "invariants": mock_context.get("invariants"),
            "output_dir": mock_context.get("output_dir"),
            "run_id": None,
        }

        try:
            result = generate_secure_report(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - run_id is required
            pass


# =============================================================================
# Tests for compute unit: lvp:capture_error
# =============================================================================

class TestCompute_CaptureError:
    """Tests for lvp:capture_error compute function."""

    def test_capture_error_input_contract(self, mock_context):
        """Test that capture_error validates required inputs."""
        inputs = {
            "error": mock_context.get("error"),
            "phase": mock_context.get("phase"),
            "output_dir": mock_context.get("output_dir"),
        }

        # Verify inputs structure
        assert inputs is not None
        assert "error" in inputs
        assert "phase" in inputs
        assert "output_dir" in inputs

        # Call actual compute function if available
        if COMPUTE_AVAILABLE:
            result = capture_error(inputs)
            assert result is not None
            assert isinstance(result, dict)

    def test_capture_error_output_contract(self, mock_context):
        """Test that capture_error returns expected output fields."""
        expected_outputs = ['audit_report']

        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "error": mock_context.get("error"),
            "phase": mock_context.get("phase"),
            "output_dir": mock_context.get("output_dir"),
        }

        result = capture_error(inputs)
        assert result is not None

        # Verify expected outputs are present
        for field in expected_outputs:
            assert field in result, f"Missing output field: {field}"

    def test_capture_error_error_handling(self, mock_context):
        """Test that capture_error handles errors gracefully."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        # Test with empty inputs
        invalid_inputs = {}

        try:
            result = capture_error(invalid_inputs)
            # Should either return error dict or handle gracefully
            if result is not None:
                assert isinstance(result, dict)
        except (KeyError, TypeError, ValueError):
            # Expected - function requires inputs
            pass

    def test_capture_error_error_null(self, mock_context):
        """Test capture_error with null error."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "error": None,
            "phase": mock_context.get("phase"),
            "output_dir": mock_context.get("output_dir"),
        }

        try:
            result = capture_error(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - error is required
            pass

    def test_capture_error_phase_null(self, mock_context):
        """Test capture_error with null phase."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "error": mock_context.get("error"),
            "phase": None,
            "output_dir": mock_context.get("output_dir"),
        }

        try:
            result = capture_error(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - phase is required
            pass

    def test_capture_error_output_dir_null(self, mock_context):
        """Test capture_error with null output_dir."""
        if not COMPUTE_AVAILABLE:
            pytest.skip(f"Compute module not available: {IMPORT_ERROR}")

        inputs = {
            "error": mock_context.get("error"),
            "phase": mock_context.get("phase"),
            "output_dir": None,
        }

        try:
            result = capture_error(inputs)
            # Function should handle null gracefully
            assert result is not None
        except (KeyError, TypeError, ValueError, AttributeError):
            # Expected - output_dir is required
            pass

